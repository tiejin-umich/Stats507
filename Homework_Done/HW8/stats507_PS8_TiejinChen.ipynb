{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3904a58",
   "metadata": {},
   "source": [
    "# Problem set 8\n",
    "### Question 0\n",
    "Here is the script we use to run in the Great Lakes.\n",
    "We only change a little bit to the import part so that\n",
    "it imports all the module we will use in the whole Problem Set\n",
    "while the the script we actually run does not have module it does not need.\n",
    "Here we use two cells to import the module we need is because\n",
    "if we import tensorflow or sklearn, then we can not run pyspark in jupyter.\n",
    "Hence, we adjust the import before we run qs2.\n",
    "(So the second cell does not have run number here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9df460f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import mean\n",
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c3ac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers,models,losses,optimizers,regularizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import multiprocess as mp\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f367518",
   "metadata": {},
   "source": [
    "Here we revise ```cv_fold```and ```mse_score```(```gb_score```)\n",
    "function in ```cv_funcs``` a little bit to fit our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f5ddba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_fold(fit, data, idx_train, idx_val, score, label=None):\n",
    "    \"\"\"\n",
    "    Compute score for a cross-validation fold.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fit - callable.\n",
    "    A callable to fit an estimator to the training data.\n",
    "    data - dataframe\n",
    "    Features and labels for training and validation folds.\n",
    "    idx_train, idx_val - ndarray or slice.\n",
    "    Indices for subsetting x and y into training and validation folds.\n",
    "    More accurately, it should be the index of dataframe instead of raw number.\n",
    "    score - callable\n",
    "    Function with signature (res, x, y) for scoring validation sample\n",
    "    predictions from the estimator fit to training data.\n",
    "    label - string or None, optional.\n",
    "    An optional label for tracking results during parallel execution.\n",
    "    The default is None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A tuple (label, metrics) where metrics is the object returned by the\n",
    "    function passed to score.\n",
    "\n",
    "    \"\"\"\n",
    "    # fit model\n",
    "    res = fit(data.loc[idx_train].values[:,:-1], data.loc[idx_train].values[:,-1])\n",
    "\n",
    "    # compute score(s)\n",
    "    metrics = score(res, data.loc[idx_val].values[:,:-1], data.loc[idx_val].values[:,-1])\n",
    "\n",
    "    # return scores and label\n",
    "    return ((label, metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b2e617",
   "metadata": {},
   "source": [
    "For rest functions in ```cv_funcs```, we remain the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8665aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_score(res, x_v, y_v):\n",
    "    \"\"\"\n",
    "    Compute cross entropy and accuracy at each stage of boosting model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    res = an object returned by sklearn.GradientBoosting*\n",
    "    It's fit method should be called. Th object's predict()\n",
    "    method is called.\n",
    "\n",
    "    x_v, y_v - Validation features and labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A dictionary with entries `Mse` for the validation\n",
    "    cross mse after each fold.\n",
    "    \"\"\"\n",
    "\n",
    "    # accuracy\n",
    "    y_hat = res.predict(x_v)\n",
    "    mse = np.mean((y_hat-y_v)**2)\n",
    "\n",
    "    return ({ \"Mse\": mse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "458fffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiprocess helper functions: ----------------------------------------------\n",
    "def calculate(func, args):\n",
    "    \"\"\"\n",
    "    Call func(*args) as part of a worker process.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    func - callable function\n",
    "    args - a tuple of positional args for func\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The result of `func(*args)`\n",
    "\n",
    "    \"\"\"\n",
    "    result = func(*args)\n",
    "    return (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4af17e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(input, output):\n",
    "    \"\"\"\n",
    "    Function run by worker processes.\n",
    "\n",
    "    Taken from\n",
    "    <https://docs.python.org/3/library/multiprocessing.html\n",
    "    #multiprocessing-programming>\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input, output - Queues.\n",
    "    Input and output queues.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None, called for it's side effects.\n",
    "    \"\"\"\n",
    "    for func, args in iter(input.get, 'STOP'):\n",
    "        result = calculate(func, args)\n",
    "        output.put(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b0ff51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp_apply(tasks, n_processes=2):\n",
    "    \"\"\"\n",
    "    Compute tasks in parallel.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tasks - list of tuples.\n",
    "    A list of tasks, each formulated as a tuple with first element a callable\n",
    "    and second a tuple of positional arguments.\n",
    "    n_processes - int, optional.\n",
    "    The number of child processes used to compute the tasks. The default is 2.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The unordered results of the computed tasks.\n",
    "\n",
    "    \"\"\"\n",
    "    # create queues\n",
    "    task_queue = mp.Queue()\n",
    "    done_queue = mp.Queue()\n",
    "\n",
    "    # submit tasks\n",
    "    for task in tasks:\n",
    "        task_queue.put(task)\n",
    "\n",
    "    # start processes\n",
    "    for i in range(n_processes):\n",
    "        mp.Process(target=worker, args=(task_queue, done_queue)).start()\n",
    "\n",
    "    # get unordered results\n",
    "    results = []\n",
    "    for i, task in enumerate(tasks):\n",
    "        results.append(done_queue.get())\n",
    "\n",
    "    # stop child processes\n",
    "    for i in range(n_processes):\n",
    "        task_queue.put('STOP')\n",
    "\n",
    "    return (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d22d14",
   "metadata": {},
   "source": [
    "First, we prepare all the data, And get the whole data set of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "595ce52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "mater = pd.read_csv(\"unique_m.csv\")\n",
    "unique_mat = mater['material'].unique()\n",
    "np.random.shuffle(unique_mat)\n",
    "train_mat = unique_mat[:int(len(unique_mat)*0.8)]\n",
    "val_mat = unique_mat[int(len(unique_mat)*0.8):int(len(unique_mat)*0.9)]\n",
    "test_mat = unique_mat[int(len(unique_mat)*0.9):]\n",
    "train_index = mater[mater['material'].isin(train_mat)].index.values\n",
    "val_index = mater[mater['material'].isin(val_mat)].index.values\n",
    "test_index = mater[mater['material'].isin(test_mat)].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e6264f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.loc[train_index]\n",
    "val_data = data.loc[val_index]\n",
    "test_data = data.loc[test_index]\n",
    "x_val = val_data.values[:,:-1]\n",
    "y_val = val_data.values[:,-1]\n",
    "x_test = test_data.values[:,:-1]\n",
    "y_test = test_data.values[:,-1]\n",
    "x_train = train_data.values[:,:-1]\n",
    "y_train = train_data.values[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549fd319",
   "metadata": {},
   "source": [
    "Next, we prepare the index of 10-fold training set and testing set in the whole traning data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e069516",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_mat = []\n",
    "for i in range(9):\n",
    "    fold_test_mat = train_mat[i*1243:(i+1)*1243]\n",
    "    fold_train_mat = list(set(train_mat)-set(fold_test_mat))\n",
    "    fold_mat.append((fold_train_mat,fold_test_mat))\n",
    "fold_mat.append((train_mat[:9*1243],train_mat[9*1243:]))\n",
    "fold_index = []\n",
    "for fold in fold_mat:\n",
    "    fold_train_index = mater[mater['material'].isin(fold[0])].index.values\n",
    "    fold_test_index = mater[mater['material'].isin(fold[1])].index.values\n",
    "    fold_index.append((fold_train_index,fold_test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58ab2a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdbt = GradientBoostingRegressor(learning_rate=0.25,random_state=2021,n_estimators=390)\n",
    "n_processes = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51079d6a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Prepare the all the tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9164a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_tasks = []\n",
    "for fold, (idx_train, idx_val) in enumerate(fold_index):\n",
    "    task = (cv_fold,\n",
    "            (gdbt.fit,\n",
    "             train_data,\n",
    "             idx_train,\n",
    "             idx_val,\n",
    "             mse_score,\n",
    "             'gbdt_fold' + str(fold)\n",
    "            )\n",
    "           )\n",
    "    cv_tasks.append(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a723ee7",
   "metadata": {},
   "source": [
    "We find that jupyter notebook cannot run mulitprocessing\n",
    "unless we put our function into other files.\n",
    "Hence we will not run the following code\n",
    "here to make what we upload concisely.\n",
    "And it can run in Pycharm or in Great Lakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e90c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: Fri Dec  3 19:00:29 2021\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print('Start: ' + time.ctime())\n",
    "    result0 = mp_apply(cv_tasks,n_processes)\n",
    "    print('End: ' + time.ctime())\n",
    "    avg_mse = 0\n",
    "    for result in result0:\n",
    "        avg_mse += result[1]['Mse']/10\n",
    "    print(\"10 folds mse:\",avg_mse)\n",
    "    model_res = gdbt.fit(x_train,y_train)\n",
    "    y_hat_val = model_res.predict(x_val)\n",
    "    y_hat_test = model_res.predict(x_test)\n",
    "    mse_val = mean_squared_error(y_hat_val,y_val)\n",
    "    mse_test = mean_squared_error(y_hat_test,y_test)\n",
    "    print(\"validation mse:{:.3f},test mse:{:.3f}\".format(mse_val,mse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6888949d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "The following code is sh script we use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4694b463",
   "metadata": {},
   "source": [
    "\\#!/usr/bin/bash\n",
    "\n",
    "\\#\n",
    "\n",
    "\\# Author: Tiejin Chen\n",
    "\n",
    "\\# Updated: Dec 03, 2021\n",
    "\n",
    "\\# slurm options: --------------------------------------------------------------\n",
    "\n",
    "#SBATCH --job-name=tiejin_ps8qs0\n",
    "\n",
    "#SBATCH --mail-user=tiejin@umich.edu\n",
    "\n",
    "#SBATCH --mail-type=BEGIN,END\n",
    "\n",
    "#SBATCH --cpus-per-task=5\n",
    "\n",
    "#SBATCH --nodes=1\n",
    "\n",
    "#SBATCH --ntasks-per-node=1\n",
    "\n",
    "#SBATCH --mem-per-cpu=5GB\n",
    "\n",
    "#SBATCH --time=10:00\n",
    "\n",
    "#SBATCH --account=stats507f21_class\n",
    "\n",
    "#SBATCH --partition=standard\n",
    "\n",
    "#SBATCH --output=/home/%u/logs/%x-%j-5.log\n",
    "\n",
    "\\# application: ----------------------------------------------------------------\n",
    "\n",
    "\\# modules \n",
    "\n",
    "#SBATCH --get-user-env\n",
    "\n",
    "\\# the contents of this script\n",
    "\n",
    "cat run-tiejin_qs0.sh\n",
    "\n",
    "\\# run the script\n",
    "\n",
    "date\n",
    "\n",
    "cd /home/tiejin/\n",
    "\n",
    "python PS8_chentiejin_qs0.py\n",
    "\n",
    "date\n",
    "\n",
    "echo \"Done.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2335cf5e",
   "metadata": {},
   "source": [
    "And the usage information we get from the command line is:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883c6c20",
   "metadata": {},
   "source": [
    "| JobID | NCPUS  |  Elapsed | CPUTime | TotalCPU |\n",
    "|  ----  | ---- | ---- | ---- | ---- |\n",
    "| 29528720 | 5 |   00:04:19 |  00:21:35 |  15:12.804 |\n",
    "| 29528720.ba+ | 5 |   00:04:19 |  00:21:35 |  15:12.803 |\n",
    "| 29528720.ex+ | 5 |   00:04:19 |  00:21:35 | 00:00:00 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3c7ae0",
   "metadata": {},
   "source": [
    "We can also get the log:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e3254f",
   "metadata": {},
   "source": [
    "```#!/usr/bin/bash\n",
    "#\n",
    "# Author: Tiejin Chen\n",
    "# Updated: Dec 03, 2021\n",
    "# 1: -------------------------------------------------------------------------\n",
    "\n",
    "# slurm options: --------------------------------------------------------------\n",
    "#SBATCH --job-name=tiejin_ps8qs0\n",
    "#SBATCH --mail-user=tiejin@umich.edu\n",
    "#SBATCH --mail-type=BEGIN,END\n",
    "#SBATCH --cpus-per-task=5\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --mem-per-cpu=5GB\n",
    "#SBATCH --time=10:00\n",
    "#SBATCH --account=stats507f21_class\n",
    "#SBATCH --partition=standard\n",
    "#SBATCH --output=/home/%u/logs/%x-%j-5.log\n",
    "\n",
    "# application: ----------------------------------------------------------------\n",
    "\n",
    "# modules \n",
    "#SBATCH --get-user-env\n",
    "\n",
    "# the contents of this script\n",
    "cat run-tiejin_qs0.sh\n",
    "\n",
    "# run the script\n",
    "date\n",
    "\n",
    "cd /home/tiejin/\n",
    "python PS8_chentiejin_qs0.py\n",
    "\n",
    "date\n",
    "echo \"Done.\"\n",
    "\n",
    "Fri Dec  3 17:15:13 EST 2021\n",
    "Start: Fri Dec  3 17:15:15 2021\n",
    "End: Fri Dec  3 17:17:59 2021\n",
    "10 folds mse: 117.09980684701303\n",
    "validation mse:109.446,test mse:112.227\n",
    "Fri Dec  3 17:19:30 EST 2021\n",
    "Done.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092496eb",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "#### Part a\n",
    "in this part, we will consider 6 models:\n",
    "1. model with 3 hidden layers\n",
    "2. model with 1 hidden layer\n",
    "3. model with 2 hidden layers\n",
    "4. model with 3 hidden layers and l2 norm\n",
    "5. model with 3 hidden layers and l1 norm\n",
    "6. model with 3 hidden layers and dropout\n",
    "\n",
    "All the models are trained with ```mse``` loss and we will use ```relu```\n",
    "as the activation function. All the model will be optimized by Adam with learning rate is 1e-4.\n",
    "We set batch_size to 32 and epochs to 500 for every model.\n",
    "For the parameter of normliztion, we will set it to 0.005 for all models.\n",
    "And we will set dropout fraction to 0.3.\n",
    "Also we only save the best model during 500 epochs\n",
    "with least validation mse, and using the least validation mse to get the best model.\n",
    "\n",
    "According to the requirement,\n",
    "we are not required to search best hyper-parameter here\n",
    "and the way we choose the best model is to see their performence in validation set.\n",
    "There is no reason to do the cross-validation here because\n",
    "in the last we will use the whole data to re-train the model\n",
    "and get their last model performance in validation set. Cross-validation\n",
    "does not do anything helpful in this process. In contrast,\n",
    "If we use cross-validation, we will get 10 models in one kind of model.\n",
    "And comparing model_list's performance is quite a large and open question.\n",
    "Overall, we will directly use whole train data to fit 6 models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2bc5bc9",
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 3251.3567 - mean_squared_error: 3251.3567\n",
      "Epoch 00001: val_loss improved from inf to 618.03674, saving model to model1.hdf5\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 3172.5859 - mean_squared_error: 3172.5859 - val_loss: 618.0367 - val_mean_squared_error: 618.0367\n",
      "Epoch 2/500\n",
      "438/526 [=======================>......] - ETA: 0s - loss: 522.0392 - mean_squared_error: 522.0392\n",
      "Epoch 00002: val_loss improved from 618.03674 to 477.32318, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 786us/step - loss: 512.6707 - mean_squared_error: 512.6707 - val_loss: 477.3232 - val_mean_squared_error: 477.3232\n",
      "Epoch 3/500\n",
      "436/526 [=======================>......] - ETA: 0s - loss: 456.0528 - mean_squared_error: 456.0528\n",
      "Epoch 00003: val_loss did not improve from 477.32318\n",
      "526/526 [==============================] - 0s 510us/step - loss: 452.2300 - mean_squared_error: 452.2300 - val_loss: 548.3217 - val_mean_squared_error: 548.3217\n",
      "Epoch 4/500\n",
      "434/526 [=======================>......] - ETA: 0s - loss: 441.0237 - mean_squared_error: 441.0237\n",
      "Epoch 00004: val_loss did not improve from 477.32318\n",
      "526/526 [==============================] - 0s 508us/step - loss: 453.9732 - mean_squared_error: 453.9732 - val_loss: 510.6034 - val_mean_squared_error: 510.6034\n",
      "Epoch 5/500\n",
      "436/526 [=======================>......] - ETA: 0s - loss: 437.6034 - mean_squared_error: 437.6034\n",
      "Epoch 00005: val_loss improved from 477.32318 to 374.62238, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 771us/step - loss: 433.9286 - mean_squared_error: 433.9286 - val_loss: 374.6224 - val_mean_squared_error: 374.6224\n",
      "Epoch 6/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 441.2198 - mean_squared_error: 441.2198\n",
      "Epoch 00006: val_loss did not improve from 374.62238\n",
      "526/526 [==============================] - 0s 512us/step - loss: 437.1663 - mean_squared_error: 437.1663 - val_loss: 519.8090 - val_mean_squared_error: 519.8090\n",
      "Epoch 7/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 384.4207 - mean_squared_error: 384.4207\n",
      "Epoch 00007: val_loss did not improve from 374.62238\n",
      "526/526 [==============================] - 0s 518us/step - loss: 380.3888 - mean_squared_error: 380.3888 - val_loss: 409.7428 - val_mean_squared_error: 409.7428\n",
      "Epoch 8/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 399.8988 - mean_squared_error: 399.8988\n",
      "Epoch 00008: val_loss improved from 374.62238 to 344.61304, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 782us/step - loss: 392.8037 - mean_squared_error: 392.8037 - val_loss: 344.6130 - val_mean_squared_error: 344.6130\n",
      "Epoch 9/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 387.6212 - mean_squared_error: 387.6212\n",
      "Epoch 00009: val_loss improved from 344.61304 to 318.15445, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 766us/step - loss: 389.3723 - mean_squared_error: 389.3723 - val_loss: 318.1544 - val_mean_squared_error: 318.1544\n",
      "Epoch 10/500\n",
      "425/526 [=======================>......] - ETA: 0s - loss: 355.4263 - mean_squared_error: 355.4263\n",
      "Epoch 00010: val_loss did not improve from 318.15445\n",
      "526/526 [==============================] - 0s 519us/step - loss: 352.8087 - mean_squared_error: 352.8087 - val_loss: 422.7951 - val_mean_squared_error: 422.7951\n",
      "Epoch 11/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 369.0330 - mean_squared_error: 369.0330\n",
      "Epoch 00011: val_loss did not improve from 318.15445\n",
      "526/526 [==============================] - 0s 510us/step - loss: 383.3105 - mean_squared_error: 383.3105 - val_loss: 374.0272 - val_mean_squared_error: 374.0272\n",
      "Epoch 12/500\n",
      "436/526 [=======================>......] - ETA: 0s - loss: 368.8121 - mean_squared_error: 368.8121\n",
      "Epoch 00012: val_loss improved from 318.15445 to 310.48672, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 766us/step - loss: 361.5105 - mean_squared_error: 361.5105 - val_loss: 310.4867 - val_mean_squared_error: 310.4867\n",
      "Epoch 13/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 358.9159 - mean_squared_error: 358.9159\n",
      "Epoch 00013: val_loss improved from 310.48672 to 301.40106, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 766us/step - loss: 376.8600 - mean_squared_error: 376.8600 - val_loss: 301.4011 - val_mean_squared_error: 301.4011\n",
      "Epoch 14/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 327.2889 - mean_squared_error: 327.2889\n",
      "Epoch 00014: val_loss did not improve from 301.40106\n",
      "526/526 [==============================] - 0s 512us/step - loss: 327.3832 - mean_squared_error: 327.3832 - val_loss: 308.9609 - val_mean_squared_error: 308.9609\n",
      "Epoch 15/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 371.9820 - mean_squared_error: 371.9820\n",
      "Epoch 00015: val_loss improved from 301.40106 to 291.59433, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 808us/step - loss: 364.4701 - mean_squared_error: 364.4701 - val_loss: 291.5943 - val_mean_squared_error: 291.5943\n",
      "Epoch 16/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 331.8706 - mean_squared_error: 331.8706\n",
      "Epoch 00016: val_loss improved from 291.59433 to 279.65335, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 791us/step - loss: 339.2047 - mean_squared_error: 339.2047 - val_loss: 279.6534 - val_mean_squared_error: 279.6534\n",
      "Epoch 17/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 334.1380 - mean_squared_error: 334.1380\n",
      "Epoch 00017: val_loss did not improve from 279.65335\n",
      "526/526 [==============================] - 0s 533us/step - loss: 333.6800 - mean_squared_error: 333.6800 - val_loss: 316.1898 - val_mean_squared_error: 316.1898\n",
      "Epoch 18/500\n",
      "421/526 [=======================>......] - ETA: 0s - loss: 323.3941 - mean_squared_error: 323.3941\n",
      "Epoch 00018: val_loss did not improve from 279.65335\n",
      "526/526 [==============================] - 0s 521us/step - loss: 323.5663 - mean_squared_error: 323.5663 - val_loss: 529.3254 - val_mean_squared_error: 529.3254\n",
      "Epoch 19/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 312.8681 - mean_squared_error: 312.8681\n",
      "Epoch 00019: val_loss did not improve from 279.65335\n",
      "526/526 [==============================] - 0s 529us/step - loss: 312.9240 - mean_squared_error: 312.9240 - val_loss: 416.7002 - val_mean_squared_error: 416.7002\n",
      "Epoch 20/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 314.8128 - mean_squared_error: 314.8128\n",
      "Epoch 00020: val_loss did not improve from 279.65335\n",
      "526/526 [==============================] - 0s 527us/step - loss: 314.8128 - mean_squared_error: 314.8128 - val_loss: 310.6079 - val_mean_squared_error: 310.6079\n",
      "Epoch 21/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 312.7989 - mean_squared_error: 312.7989\n",
      "Epoch 00021: val_loss did not improve from 279.65335\n",
      "526/526 [==============================] - 0s 512us/step - loss: 326.2591 - mean_squared_error: 326.2591 - val_loss: 353.8694 - val_mean_squared_error: 353.8694\n",
      "Epoch 22/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 303.4900 - mean_squared_error: 303.4900\n",
      "Epoch 00022: val_loss did not improve from 279.65335\n",
      "526/526 [==============================] - 0s 535us/step - loss: 303.4607 - mean_squared_error: 303.4607 - val_loss: 305.7693 - val_mean_squared_error: 305.7693\n",
      "Epoch 23/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 308.4177 - mean_squared_error: 308.4177\n",
      "Epoch 00023: val_loss did not improve from 279.65335\n",
      "526/526 [==============================] - 0s 531us/step - loss: 309.0123 - mean_squared_error: 309.0123 - val_loss: 336.4687 - val_mean_squared_error: 336.4687\n",
      "Epoch 24/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 312.8227 - mean_squared_error: 312.8227\n",
      "Epoch 00024: val_loss did not improve from 279.65335\n",
      "526/526 [==============================] - 0s 523us/step - loss: 309.4556 - mean_squared_error: 309.4556 - val_loss: 364.8638 - val_mean_squared_error: 364.8638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 312.3293 - mean_squared_error: 312.3293\n",
      "Epoch 00025: val_loss improved from 279.65335 to 273.08157, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 788us/step - loss: 311.3496 - mean_squared_error: 311.3496 - val_loss: 273.0816 - val_mean_squared_error: 273.0816\n",
      "Epoch 26/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 284.8234 - mean_squared_error: 284.8234\n",
      "Epoch 00026: val_loss did not improve from 273.08157\n",
      "526/526 [==============================] - 0s 531us/step - loss: 285.0126 - mean_squared_error: 285.0126 - val_loss: 312.0334 - val_mean_squared_error: 312.0334\n",
      "Epoch 27/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 290.3086 - mean_squared_error: 290.3086\n",
      "Epoch 00027: val_loss did not improve from 273.08157\n",
      "526/526 [==============================] - 0s 529us/step - loss: 290.4068 - mean_squared_error: 290.4068 - val_loss: 312.2248 - val_mean_squared_error: 312.2248\n",
      "Epoch 28/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 299.6128 - mean_squared_error: 299.6128\n",
      "Epoch 00028: val_loss improved from 273.08157 to 265.96719, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 793us/step - loss: 299.8564 - mean_squared_error: 299.8564 - val_loss: 265.9672 - val_mean_squared_error: 265.9672\n",
      "Epoch 29/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 294.2393 - mean_squared_error: 294.2393\n",
      "Epoch 00029: val_loss did not improve from 265.96719\n",
      "526/526 [==============================] - 0s 527us/step - loss: 294.5706 - mean_squared_error: 294.5706 - val_loss: 347.0077 - val_mean_squared_error: 347.0077\n",
      "Epoch 30/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 292.2645 - mean_squared_error: 292.2645\n",
      "Epoch 00030: val_loss did not improve from 265.96719\n",
      "526/526 [==============================] - 0s 519us/step - loss: 286.9465 - mean_squared_error: 286.9465 - val_loss: 270.3706 - val_mean_squared_error: 270.3706\n",
      "Epoch 31/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 282.3182 - mean_squared_error: 282.3182\n",
      "Epoch 00031: val_loss improved from 265.96719 to 256.48520, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 772us/step - loss: 281.8387 - mean_squared_error: 281.8387 - val_loss: 256.4852 - val_mean_squared_error: 256.4852\n",
      "Epoch 32/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 278.6295 - mean_squared_error: 278.6295\n",
      "Epoch 00032: val_loss did not improve from 256.48520\n",
      "526/526 [==============================] - 0s 531us/step - loss: 279.0230 - mean_squared_error: 279.0230 - val_loss: 295.2054 - val_mean_squared_error: 295.2054\n",
      "Epoch 33/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 281.2594 - mean_squared_error: 281.2594\n",
      "Epoch 00033: val_loss did not improve from 256.48520\n",
      "526/526 [==============================] - 0s 527us/step - loss: 281.2594 - mean_squared_error: 281.2594 - val_loss: 260.5515 - val_mean_squared_error: 260.5515\n",
      "Epoch 34/500\n",
      "423/526 [=======================>......] - ETA: 0s - loss: 288.3086 - mean_squared_error: 288.3086\n",
      "Epoch 00034: val_loss did not improve from 256.48520\n",
      "526/526 [==============================] - 0s 521us/step - loss: 278.4648 - mean_squared_error: 278.4648 - val_loss: 278.1862 - val_mean_squared_error: 278.1862\n",
      "Epoch 35/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 285.5644 - mean_squared_error: 285.5644\n",
      "Epoch 00035: val_loss improved from 256.48520 to 248.19893, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 759us/step - loss: 284.8911 - mean_squared_error: 284.8911 - val_loss: 248.1989 - val_mean_squared_error: 248.1989\n",
      "Epoch 36/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 292.2887 - mean_squared_error: 292.2887\n",
      "Epoch 00036: val_loss did not improve from 248.19893\n",
      "526/526 [==============================] - 0s 533us/step - loss: 292.0137 - mean_squared_error: 292.0137 - val_loss: 270.5663 - val_mean_squared_error: 270.5663\n",
      "Epoch 37/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 280.5145 - mean_squared_error: 280.5145\n",
      "Epoch 00037: val_loss did not improve from 248.19893\n",
      "526/526 [==============================] - 0s 525us/step - loss: 280.5145 - mean_squared_error: 280.5145 - val_loss: 435.0000 - val_mean_squared_error: 435.0000\n",
      "Epoch 38/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 267.4958 - mean_squared_error: 267.4958\n",
      "Epoch 00038: val_loss did not improve from 248.19893\n",
      "526/526 [==============================] - 0s 519us/step - loss: 266.5640 - mean_squared_error: 266.5640 - val_loss: 299.7669 - val_mean_squared_error: 299.7669\n",
      "Epoch 39/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 267.2565 - mean_squared_error: 267.2565\n",
      "Epoch 00039: val_loss did not improve from 248.19893\n",
      "526/526 [==============================] - 0s 533us/step - loss: 268.4384 - mean_squared_error: 268.4384 - val_loss: 272.4165 - val_mean_squared_error: 272.4165\n",
      "Epoch 40/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 272.6385 - mean_squared_error: 272.6385\n",
      "Epoch 00040: val_loss did not improve from 248.19893\n",
      "526/526 [==============================] - 0s 518us/step - loss: 274.5933 - mean_squared_error: 274.5933 - val_loss: 304.5786 - val_mean_squared_error: 304.5786\n",
      "Epoch 41/500\n",
      "425/526 [=======================>......] - ETA: 0s - loss: 263.0096 - mean_squared_error: 263.0096\n",
      "Epoch 00041: val_loss did not improve from 248.19893\n",
      "526/526 [==============================] - 0s 523us/step - loss: 261.2591 - mean_squared_error: 261.2591 - val_loss: 310.3030 - val_mean_squared_error: 310.3030\n",
      "Epoch 42/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 270.1533 - mean_squared_error: 270.1533\n",
      "Epoch 00042: val_loss did not improve from 248.19893\n",
      "526/526 [==============================] - 0s 533us/step - loss: 270.7911 - mean_squared_error: 270.7911 - val_loss: 387.6340 - val_mean_squared_error: 387.6340\n",
      "Epoch 43/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 254.6759 - mean_squared_error: 254.6759\n",
      "Epoch 00043: val_loss did not improve from 248.19893\n",
      "526/526 [==============================] - 0s 527us/step - loss: 254.7709 - mean_squared_error: 254.7709 - val_loss: 339.3729 - val_mean_squared_error: 339.3729\n",
      "Epoch 44/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 261.4773 - mean_squared_error: 261.4773\n",
      "Epoch 00044: val_loss did not improve from 248.19893\n",
      "526/526 [==============================] - 0s 519us/step - loss: 262.0620 - mean_squared_error: 262.0620 - val_loss: 276.1092 - val_mean_squared_error: 276.1092\n",
      "Epoch 45/500\n",
      "425/526 [=======================>......] - ETA: 0s - loss: 258.1326 - mean_squared_error: 258.1326\n",
      "Epoch 00045: val_loss did not improve from 248.19893\n",
      "526/526 [==============================] - 0s 518us/step - loss: 261.6715 - mean_squared_error: 261.6715 - val_loss: 312.5959 - val_mean_squared_error: 312.5959\n",
      "Epoch 46/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 247.3133 - mean_squared_error: 247.3133\n",
      "Epoch 00046: val_loss did not improve from 248.19893\n",
      "526/526 [==============================] - 0s 519us/step - loss: 255.5138 - mean_squared_error: 255.5138 - val_loss: 304.9027 - val_mean_squared_error: 304.9027\n",
      "Epoch 47/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 269.6092 - mean_squared_error: 269.6092\n",
      "Epoch 00047: val_loss did not improve from 248.19893\n",
      "526/526 [==============================] - 0s 519us/step - loss: 268.8409 - mean_squared_error: 268.8409 - val_loss: 314.3116 - val_mean_squared_error: 314.3116\n",
      "Epoch 48/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 248.3535 - mean_squared_error: 248.3535\n",
      "Epoch 00048: val_loss did not improve from 248.19893\n",
      "526/526 [==============================] - 0s 516us/step - loss: 251.9904 - mean_squared_error: 251.9904 - val_loss: 273.5423 - val_mean_squared_error: 273.5423\n",
      "Epoch 49/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 253.7824 - mean_squared_error: 253.7824\n",
      "Epoch 00049: val_loss improved from 248.19893 to 241.11096, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 537us/step - loss: 250.1431 - mean_squared_error: 250.1431 - val_loss: 241.1110 - val_mean_squared_error: 241.1110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 260.9003 - mean_squared_error: 260.9003\n",
      "Epoch 00050: val_loss did not improve from 241.11096\n",
      "526/526 [==============================] - 0s 516us/step - loss: 260.0759 - mean_squared_error: 260.0759 - val_loss: 444.4107 - val_mean_squared_error: 444.4107\n",
      "Epoch 51/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 261.8663 - mean_squared_error: 261.8663\n",
      "Epoch 00051: val_loss did not improve from 241.11096\n",
      "526/526 [==============================] - 0s 512us/step - loss: 258.5799 - mean_squared_error: 258.5799 - val_loss: 323.3438 - val_mean_squared_error: 323.3438\n",
      "Epoch 52/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 238.5322 - mean_squared_error: 238.5322\n",
      "Epoch 00052: val_loss improved from 241.11096 to 237.50722, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 712us/step - loss: 242.8317 - mean_squared_error: 242.8317 - val_loss: 237.5072 - val_mean_squared_error: 237.5072\n",
      "Epoch 53/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 252.0325 - mean_squared_error: 252.0325\n",
      "Epoch 00053: val_loss improved from 237.50722 to 233.95479, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 811us/step - loss: 251.6052 - mean_squared_error: 251.6052 - val_loss: 233.9548 - val_mean_squared_error: 233.9548\n",
      "Epoch 54/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 247.0573 - mean_squared_error: 247.0573\n",
      "Epoch 00054: val_loss did not improve from 233.95479\n",
      "526/526 [==============================] - 0s 531us/step - loss: 247.1736 - mean_squared_error: 247.1736 - val_loss: 266.2709 - val_mean_squared_error: 266.2709\n",
      "Epoch 55/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 240.2392 - mean_squared_error: 240.2392\n",
      "Epoch 00055: val_loss did not improve from 233.95479\n",
      "526/526 [==============================] - 0s 519us/step - loss: 242.1854 - mean_squared_error: 242.1854 - val_loss: 263.4658 - val_mean_squared_error: 263.4658\n",
      "Epoch 56/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 250.1851 - mean_squared_error: 250.1851\n",
      "Epoch 00056: val_loss did not improve from 233.95479\n",
      "526/526 [==============================] - 0s 516us/step - loss: 246.3613 - mean_squared_error: 246.3613 - val_loss: 264.6684 - val_mean_squared_error: 264.6684\n",
      "Epoch 57/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 238.6268 - mean_squared_error: 238.6268\n",
      "Epoch 00057: val_loss did not improve from 233.95479\n",
      "526/526 [==============================] - 0s 519us/step - loss: 239.0816 - mean_squared_error: 239.0816 - val_loss: 279.2367 - val_mean_squared_error: 279.2367\n",
      "Epoch 58/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 245.8673 - mean_squared_error: 245.8673\n",
      "Epoch 00058: val_loss did not improve from 233.95479\n",
      "526/526 [==============================] - 0s 533us/step - loss: 245.8174 - mean_squared_error: 245.8174 - val_loss: 241.5907 - val_mean_squared_error: 241.5907\n",
      "Epoch 59/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 235.3495 - mean_squared_error: 235.3495\n",
      "Epoch 00059: val_loss did not improve from 233.95479\n",
      "526/526 [==============================] - 0s 531us/step - loss: 235.1270 - mean_squared_error: 235.1270 - val_loss: 240.8966 - val_mean_squared_error: 240.8966\n",
      "Epoch 60/500\n",
      "421/526 [=======================>......] - ETA: 0s - loss: 249.5030 - mean_squared_error: 249.5030\n",
      "Epoch 00060: val_loss did not improve from 233.95479\n",
      "526/526 [==============================] - 0s 521us/step - loss: 252.5928 - mean_squared_error: 252.5928 - val_loss: 267.7496 - val_mean_squared_error: 267.7496\n",
      "Epoch 61/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 235.7916 - mean_squared_error: 235.7916\n",
      "Epoch 00061: val_loss did not improve from 233.95479\n",
      "526/526 [==============================] - 0s 512us/step - loss: 239.0214 - mean_squared_error: 239.0214 - val_loss: 262.8942 - val_mean_squared_error: 262.8942\n",
      "Epoch 62/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 235.4899 - mean_squared_error: 235.4899\n",
      "Epoch 00062: val_loss improved from 233.95479 to 227.10207, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 754us/step - loss: 235.1196 - mean_squared_error: 235.1196 - val_loss: 227.1021 - val_mean_squared_error: 227.1021\n",
      "Epoch 63/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 234.6344 - mean_squared_error: 234.6344\n",
      "Epoch 00063: val_loss did not improve from 227.10207\n",
      "526/526 [==============================] - 0s 527us/step - loss: 234.4900 - mean_squared_error: 234.4900 - val_loss: 256.5873 - val_mean_squared_error: 256.5873\n",
      "Epoch 64/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 231.3770 - mean_squared_error: 231.3770\n",
      "Epoch 00064: val_loss did not improve from 227.10207\n",
      "526/526 [==============================] - 0s 533us/step - loss: 231.0942 - mean_squared_error: 231.0942 - val_loss: 235.0908 - val_mean_squared_error: 235.0908\n",
      "Epoch 65/500\n",
      "422/526 [=======================>......] - ETA: 0s - loss: 233.7397 - mean_squared_error: 233.7397\n",
      "Epoch 00065: val_loss improved from 227.10207 to 226.22670, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 681us/step - loss: 231.2855 - mean_squared_error: 231.2855 - val_loss: 226.2267 - val_mean_squared_error: 226.2267\n",
      "Epoch 66/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 241.2859 - mean_squared_error: 241.2859\n",
      "Epoch 00066: val_loss did not improve from 226.22670\n",
      "526/526 [==============================] - 0s 514us/step - loss: 244.6987 - mean_squared_error: 244.6987 - val_loss: 246.6478 - val_mean_squared_error: 246.6478\n",
      "Epoch 67/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 227.3373 - mean_squared_error: 227.3373\n",
      "Epoch 00067: val_loss improved from 226.22670 to 219.28242, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 720us/step - loss: 227.9846 - mean_squared_error: 227.9846 - val_loss: 219.2824 - val_mean_squared_error: 219.2824\n",
      "Epoch 68/500\n",
      "423/526 [=======================>......] - ETA: 0s - loss: 231.7720 - mean_squared_error: 231.7720\n",
      "Epoch 00068: val_loss did not improve from 219.28242\n",
      "526/526 [==============================] - 0s 521us/step - loss: 232.1725 - mean_squared_error: 232.1725 - val_loss: 262.4003 - val_mean_squared_error: 262.4003\n",
      "Epoch 69/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 224.3982 - mean_squared_error: 224.3982\n",
      "Epoch 00069: val_loss did not improve from 219.28242\n",
      "526/526 [==============================] - 0s 516us/step - loss: 224.5756 - mean_squared_error: 224.5756 - val_loss: 250.2150 - val_mean_squared_error: 250.2150\n",
      "Epoch 70/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 224.5364 - mean_squared_error: 224.5364\n",
      "Epoch 00070: val_loss did not improve from 219.28242\n",
      "526/526 [==============================] - 0s 512us/step - loss: 228.6332 - mean_squared_error: 228.6332 - val_loss: 227.2754 - val_mean_squared_error: 227.2754\n",
      "Epoch 71/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 222.2533 - mean_squared_error: 222.2533\n",
      "Epoch 00071: val_loss did not improve from 219.28242\n",
      "526/526 [==============================] - 0s 519us/step - loss: 223.1538 - mean_squared_error: 223.1538 - val_loss: 227.9037 - val_mean_squared_error: 227.9037\n",
      "Epoch 72/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 235.6862 - mean_squared_error: 235.6862\n",
      "Epoch 00072: val_loss did not improve from 219.28242\n",
      "526/526 [==============================] - 0s 533us/step - loss: 235.9525 - mean_squared_error: 235.9525 - val_loss: 227.9087 - val_mean_squared_error: 227.9087\n",
      "Epoch 73/500\n",
      "421/526 [=======================>......] - ETA: 0s - loss: 224.7288 - mean_squared_error: 224.7288\n",
      "Epoch 00073: val_loss did not improve from 219.28242\n",
      "526/526 [==============================] - 0s 521us/step - loss: 221.9406 - mean_squared_error: 221.9406 - val_loss: 222.4133 - val_mean_squared_error: 222.4133\n",
      "Epoch 74/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 232.7572 - mean_squared_error: 232.7572\n",
      "Epoch 00074: val_loss did not improve from 219.28242\n",
      "526/526 [==============================] - 0s 514us/step - loss: 228.9126 - mean_squared_error: 228.9126 - val_loss: 275.1075 - val_mean_squared_error: 275.1075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 218.1154 - mean_squared_error: 218.1154\n",
      "Epoch 00075: val_loss did not improve from 219.28242\n",
      "526/526 [==============================] - 0s 519us/step - loss: 219.1428 - mean_squared_error: 219.1428 - val_loss: 241.1568 - val_mean_squared_error: 241.1568\n",
      "Epoch 76/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 221.2676 - mean_squared_error: 221.2676\n",
      "Epoch 00076: val_loss improved from 219.28242 to 215.64386, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 769us/step - loss: 224.0114 - mean_squared_error: 224.0114 - val_loss: 215.6439 - val_mean_squared_error: 215.6439\n",
      "Epoch 77/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 213.3620 - mean_squared_error: 213.3620\n",
      "Epoch 00077: val_loss did not improve from 215.64386\n",
      "526/526 [==============================] - 0s 510us/step - loss: 217.7363 - mean_squared_error: 217.7363 - val_loss: 215.7356 - val_mean_squared_error: 215.7356\n",
      "Epoch 78/500\n",
      "437/526 [=======================>......] - ETA: 0s - loss: 215.8100 - mean_squared_error: 215.8100\n",
      "Epoch 00078: val_loss did not improve from 215.64386\n",
      "526/526 [==============================] - 0s 508us/step - loss: 215.4992 - mean_squared_error: 215.4992 - val_loss: 216.0214 - val_mean_squared_error: 216.0214\n",
      "Epoch 79/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 217.9874 - mean_squared_error: 217.9874\n",
      "Epoch 00079: val_loss did not improve from 215.64386\n",
      "526/526 [==============================] - 0s 525us/step - loss: 217.7539 - mean_squared_error: 217.7539 - val_loss: 237.9133 - val_mean_squared_error: 237.9133\n",
      "Epoch 80/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 220.0459 - mean_squared_error: 220.0459\n",
      "Epoch 00080: val_loss did not improve from 215.64386\n",
      "526/526 [==============================] - 0s 535us/step - loss: 219.5083 - mean_squared_error: 219.5083 - val_loss: 217.0208 - val_mean_squared_error: 217.0208\n",
      "Epoch 81/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 220.5622 - mean_squared_error: 220.5622\n",
      "Epoch 00081: val_loss did not improve from 215.64386\n",
      "526/526 [==============================] - 0s 533us/step - loss: 221.2180 - mean_squared_error: 221.2180 - val_loss: 228.6660 - val_mean_squared_error: 228.6660\n",
      "Epoch 82/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 215.1022 - mean_squared_error: 215.1022\n",
      "Epoch 00082: val_loss did not improve from 215.64386\n",
      "526/526 [==============================] - 0s 544us/step - loss: 216.4290 - mean_squared_error: 216.4290 - val_loss: 259.9893 - val_mean_squared_error: 259.9893\n",
      "Epoch 83/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 214.4182 - mean_squared_error: 214.4182\n",
      "Epoch 00083: val_loss did not improve from 215.64386\n",
      "526/526 [==============================] - 0s 531us/step - loss: 214.4237 - mean_squared_error: 214.4237 - val_loss: 217.0967 - val_mean_squared_error: 217.0967\n",
      "Epoch 84/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 217.0781 - mean_squared_error: 217.0781\n",
      "Epoch 00084: val_loss improved from 215.64386 to 207.65251, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 735us/step - loss: 217.3283 - mean_squared_error: 217.3283 - val_loss: 207.6525 - val_mean_squared_error: 207.6525\n",
      "Epoch 85/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 212.0925 - mean_squared_error: 212.0925\n",
      "Epoch 00085: val_loss did not improve from 207.65251\n",
      "526/526 [==============================] - 0s 537us/step - loss: 212.2740 - mean_squared_error: 212.2740 - val_loss: 217.3749 - val_mean_squared_error: 217.3749\n",
      "Epoch 86/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 212.6926 - mean_squared_error: 212.6926\n",
      "Epoch 00086: val_loss did not improve from 207.65251\n",
      "526/526 [==============================] - 0s 540us/step - loss: 211.7863 - mean_squared_error: 211.7863 - val_loss: 210.6524 - val_mean_squared_error: 210.6524\n",
      "Epoch 87/500\n",
      "420/526 [======================>.......] - ETA: 0s - loss: 208.4909 - mean_squared_error: 208.4909\n",
      "Epoch 00087: val_loss did not improve from 207.65251\n",
      "526/526 [==============================] - 0s 525us/step - loss: 206.8043 - mean_squared_error: 206.8043 - val_loss: 217.1720 - val_mean_squared_error: 217.1720\n",
      "Epoch 88/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 211.9062 - mean_squared_error: 211.9062\n",
      "Epoch 00088: val_loss did not improve from 207.65251\n",
      "526/526 [==============================] - 0s 535us/step - loss: 212.4117 - mean_squared_error: 212.4117 - val_loss: 241.7039 - val_mean_squared_error: 241.7039\n",
      "Epoch 89/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 210.5036 - mean_squared_error: 210.5036\n",
      "Epoch 00089: val_loss did not improve from 207.65251\n",
      "526/526 [==============================] - 0s 518us/step - loss: 213.2338 - mean_squared_error: 213.2338 - val_loss: 211.0659 - val_mean_squared_error: 211.0659\n",
      "Epoch 90/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 207.9924 - mean_squared_error: 207.9924\n",
      "Epoch 00090: val_loss did not improve from 207.65251\n",
      "526/526 [==============================] - 0s 531us/step - loss: 208.1671 - mean_squared_error: 208.1671 - val_loss: 210.9743 - val_mean_squared_error: 210.9743\n",
      "Epoch 91/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 209.0093 - mean_squared_error: 209.0093\n",
      "Epoch 00091: val_loss did not improve from 207.65251\n",
      "526/526 [==============================] - 0s 519us/step - loss: 205.9265 - mean_squared_error: 205.9265 - val_loss: 237.2722 - val_mean_squared_error: 237.2722\n",
      "Epoch 92/500\n",
      "425/526 [=======================>......] - ETA: 0s - loss: 211.9735 - mean_squared_error: 211.9735\n",
      "Epoch 00092: val_loss did not improve from 207.65251\n",
      "526/526 [==============================] - 0s 519us/step - loss: 207.5958 - mean_squared_error: 207.5958 - val_loss: 241.6679 - val_mean_squared_error: 241.6679\n",
      "Epoch 93/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 207.9516 - mean_squared_error: 207.9516\n",
      "Epoch 00093: val_loss improved from 207.65251 to 194.10236, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 793us/step - loss: 207.9756 - mean_squared_error: 207.9756 - val_loss: 194.1024 - val_mean_squared_error: 194.1024\n",
      "Epoch 94/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 207.8318 - mean_squared_error: 207.8318\n",
      "Epoch 00094: val_loss did not improve from 194.10236\n",
      "526/526 [==============================] - 0s 563us/step - loss: 206.0558 - mean_squared_error: 206.0558 - val_loss: 196.6019 - val_mean_squared_error: 196.6019\n",
      "Epoch 95/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 200.2261 - mean_squared_error: 200.2261\n",
      "Epoch 00095: val_loss did not improve from 194.10236\n",
      "526/526 [==============================] - 0s 540us/step - loss: 201.1283 - mean_squared_error: 201.1283 - val_loss: 228.0721 - val_mean_squared_error: 228.0721\n",
      "Epoch 96/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 206.5687 - mean_squared_error: 206.5687\n",
      "Epoch 00096: val_loss did not improve from 194.10236\n",
      "526/526 [==============================] - 0s 525us/step - loss: 206.5687 - mean_squared_error: 206.5687 - val_loss: 249.6375 - val_mean_squared_error: 249.6375\n",
      "Epoch 97/500\n",
      "505/526 [===========================>..] - ETA: 0s - loss: 204.7435 - mean_squared_error: 204.7435\n",
      "Epoch 00097: val_loss did not improve from 194.10236\n",
      "526/526 [==============================] - 0s 548us/step - loss: 204.9270 - mean_squared_error: 204.9270 - val_loss: 219.2294 - val_mean_squared_error: 219.2294\n",
      "Epoch 98/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 199.9432 - mean_squared_error: 199.9432\n",
      "Epoch 00098: val_loss did not improve from 194.10236\n",
      "526/526 [==============================] - 0s 531us/step - loss: 200.3016 - mean_squared_error: 200.3016 - val_loss: 229.3160 - val_mean_squared_error: 229.3160\n",
      "Epoch 99/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 199.7360 - mean_squared_error: 199.7360\n",
      "Epoch 00099: val_loss did not improve from 194.10236\n",
      "526/526 [==============================] - 0s 535us/step - loss: 199.4845 - mean_squared_error: 199.4845 - val_loss: 196.7628 - val_mean_squared_error: 196.7628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 201.5186 - mean_squared_error: 201.5186\n",
      "Epoch 00100: val_loss did not improve from 194.10236\n",
      "526/526 [==============================] - 0s 527us/step - loss: 201.2771 - mean_squared_error: 201.2771 - val_loss: 221.7829 - val_mean_squared_error: 221.7829\n",
      "Epoch 101/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 202.1317 - mean_squared_error: 202.1317\n",
      "Epoch 00101: val_loss did not improve from 194.10236\n",
      "526/526 [==============================] - 0s 516us/step - loss: 204.3895 - mean_squared_error: 204.3895 - val_loss: 195.9960 - val_mean_squared_error: 195.9960\n",
      "Epoch 102/500\n",
      "500/526 [===========================>..] - ETA: 0s - loss: 204.4950 - mean_squared_error: 204.4950\n",
      "Epoch 00102: val_loss did not improve from 194.10236\n",
      "526/526 [==============================] - 0s 556us/step - loss: 204.2354 - mean_squared_error: 204.2354 - val_loss: 209.8718 - val_mean_squared_error: 209.8718\n",
      "Epoch 103/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 201.0965 - mean_squared_error: 201.0965\n",
      "Epoch 00103: val_loss did not improve from 194.10236\n",
      "526/526 [==============================] - 0s 561us/step - loss: 200.0786 - mean_squared_error: 200.0786 - val_loss: 202.7971 - val_mean_squared_error: 202.7971\n",
      "Epoch 104/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 197.3945 - mean_squared_error: 197.3945\n",
      "Epoch 00104: val_loss did not improve from 194.10236\n",
      "526/526 [==============================] - 0s 539us/step - loss: 197.7012 - mean_squared_error: 197.7012 - val_loss: 197.4087 - val_mean_squared_error: 197.4087\n",
      "Epoch 105/500\n",
      "422/526 [=======================>......] - ETA: 0s - loss: 197.5125 - mean_squared_error: 197.5125\n",
      "Epoch 00105: val_loss did not improve from 194.10236\n",
      "526/526 [==============================] - 0s 521us/step - loss: 205.7015 - mean_squared_error: 205.7015 - val_loss: 211.0986 - val_mean_squared_error: 211.0986\n",
      "Epoch 106/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 195.6923 - mean_squared_error: 195.6923\n",
      "Epoch 00106: val_loss did not improve from 194.10236\n",
      "526/526 [==============================] - 0s 518us/step - loss: 195.7996 - mean_squared_error: 195.7996 - val_loss: 224.3592 - val_mean_squared_error: 224.3592\n",
      "Epoch 107/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 195.9784 - mean_squared_error: 195.9784\n",
      "Epoch 00107: val_loss improved from 194.10236 to 192.43369, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 706us/step - loss: 196.0693 - mean_squared_error: 196.0693 - val_loss: 192.4337 - val_mean_squared_error: 192.4337\n",
      "Epoch 108/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 193.4517 - mean_squared_error: 193.4517\n",
      "Epoch 00108: val_loss did not improve from 192.43369\n",
      "526/526 [==============================] - 0s 533us/step - loss: 193.2848 - mean_squared_error: 193.2848 - val_loss: 230.8882 - val_mean_squared_error: 230.8882\n",
      "Epoch 109/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 195.5033 - mean_squared_error: 195.5033\n",
      "Epoch 00109: val_loss improved from 192.43369 to 185.65649, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 809us/step - loss: 195.0666 - mean_squared_error: 195.0666 - val_loss: 185.6565 - val_mean_squared_error: 185.6565\n",
      "Epoch 110/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 196.8314 - mean_squared_error: 196.8314\n",
      "Epoch 00110: val_loss did not improve from 185.65649\n",
      "526/526 [==============================] - 0s 542us/step - loss: 196.2677 - mean_squared_error: 196.2677 - val_loss: 186.1011 - val_mean_squared_error: 186.1011\n",
      "Epoch 111/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 200.8897 - mean_squared_error: 200.8897\n",
      "Epoch 00111: val_loss did not improve from 185.65649\n",
      "526/526 [==============================] - 0s 544us/step - loss: 200.3463 - mean_squared_error: 200.3463 - val_loss: 217.6039 - val_mean_squared_error: 217.6039\n",
      "Epoch 112/500\n",
      "505/526 [===========================>..] - ETA: 0s - loss: 190.9158 - mean_squared_error: 190.9158\n",
      "Epoch 00112: val_loss did not improve from 185.65649\n",
      "526/526 [==============================] - 0s 548us/step - loss: 191.3199 - mean_squared_error: 191.3199 - val_loss: 194.6098 - val_mean_squared_error: 194.6098\n",
      "Epoch 113/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 192.9539 - mean_squared_error: 192.9539\n",
      "Epoch 00113: val_loss did not improve from 185.65649\n",
      "526/526 [==============================] - 0s 584us/step - loss: 191.0885 - mean_squared_error: 191.0885 - val_loss: 189.6609 - val_mean_squared_error: 189.6609\n",
      "Epoch 114/500\n",
      "493/526 [===========================>..] - ETA: 0s - loss: 188.4744 - mean_squared_error: 188.4744\n",
      "Epoch 00114: val_loss did not improve from 185.65649\n",
      "526/526 [==============================] - 0s 565us/step - loss: 190.1812 - mean_squared_error: 190.1812 - val_loss: 240.9657 - val_mean_squared_error: 240.9657\n",
      "Epoch 115/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 192.8518 - mean_squared_error: 192.8518\n",
      "Epoch 00115: val_loss did not improve from 185.65649\n",
      "526/526 [==============================] - 0s 561us/step - loss: 190.3974 - mean_squared_error: 190.3974 - val_loss: 189.3254 - val_mean_squared_error: 189.3254\n",
      "Epoch 116/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 189.6796 - mean_squared_error: 189.6796\n",
      "Epoch 00116: val_loss improved from 185.65649 to 184.85176, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 783us/step - loss: 189.5978 - mean_squared_error: 189.5978 - val_loss: 184.8518 - val_mean_squared_error: 184.8518\n",
      "Epoch 117/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 193.0437 - mean_squared_error: 193.0437\n",
      "Epoch 00117: val_loss improved from 184.85176 to 176.97717, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 738us/step - loss: 193.1391 - mean_squared_error: 193.1391 - val_loss: 176.9772 - val_mean_squared_error: 176.9772\n",
      "Epoch 118/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 187.1512 - mean_squared_error: 187.1512\n",
      "Epoch 00118: val_loss did not improve from 176.97717\n",
      "526/526 [==============================] - 0s 521us/step - loss: 188.8519 - mean_squared_error: 188.8519 - val_loss: 248.3219 - val_mean_squared_error: 248.3219\n",
      "Epoch 119/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 188.7303 - mean_squared_error: 188.7303\n",
      "Epoch 00119: val_loss did not improve from 176.97717\n",
      "526/526 [==============================] - 0s 535us/step - loss: 189.1738 - mean_squared_error: 189.1738 - val_loss: 200.3355 - val_mean_squared_error: 200.3355\n",
      "Epoch 120/500\n",
      "497/526 [===========================>..] - ETA: 0s - loss: 188.9513 - mean_squared_error: 188.9513\n",
      "Epoch 00120: val_loss did not improve from 176.97717\n",
      "526/526 [==============================] - 0s 554us/step - loss: 188.0438 - mean_squared_error: 188.0438 - val_loss: 190.7210 - val_mean_squared_error: 190.7210\n",
      "Epoch 121/500\n",
      "421/526 [=======================>......] - ETA: 0s - loss: 190.0516 - mean_squared_error: 190.0516\n",
      "Epoch 00121: val_loss did not improve from 176.97717\n",
      "526/526 [==============================] - 0s 521us/step - loss: 190.6919 - mean_squared_error: 190.6919 - val_loss: 189.5317 - val_mean_squared_error: 189.5317\n",
      "Epoch 122/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 188.9559 - mean_squared_error: 188.9559\n",
      "Epoch 00122: val_loss did not improve from 176.97717\n",
      "526/526 [==============================] - 0s 510us/step - loss: 187.2590 - mean_squared_error: 187.2590 - val_loss: 181.9268 - val_mean_squared_error: 181.9268\n",
      "Epoch 123/500\n",
      "434/526 [=======================>......] - ETA: 0s - loss: 187.0600 - mean_squared_error: 187.0600\n",
      "Epoch 00123: val_loss did not improve from 176.97717\n",
      "526/526 [==============================] - 0s 512us/step - loss: 185.4951 - mean_squared_error: 185.4951 - val_loss: 181.5281 - val_mean_squared_error: 181.5281\n",
      "Epoch 124/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 178.8020 - mean_squared_error: 178.8020\n",
      "Epoch 00124: val_loss did not improve from 176.97717\n",
      "526/526 [==============================] - 0s 512us/step - loss: 180.2578 - mean_squared_error: 180.2578 - val_loss: 212.9770 - val_mean_squared_error: 212.9770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 181.9786 - mean_squared_error: 181.9786\n",
      "Epoch 00125: val_loss did not improve from 176.97717\n",
      "526/526 [==============================] - 0s 512us/step - loss: 184.3697 - mean_squared_error: 184.3697 - val_loss: 178.9017 - val_mean_squared_error: 178.9017\n",
      "Epoch 126/500\n",
      "495/526 [===========================>..] - ETA: 0s - loss: 181.5392 - mean_squared_error: 181.5392\n",
      "Epoch 00126: val_loss did not improve from 176.97717\n",
      "526/526 [==============================] - 0s 558us/step - loss: 180.3496 - mean_squared_error: 180.3496 - val_loss: 187.0286 - val_mean_squared_error: 187.0286\n",
      "Epoch 127/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 183.2921 - mean_squared_error: 183.2921\n",
      "Epoch 00127: val_loss did not improve from 176.97717\n",
      "526/526 [==============================] - 0s 542us/step - loss: 183.7071 - mean_squared_error: 183.7071 - val_loss: 183.6067 - val_mean_squared_error: 183.6067\n",
      "Epoch 128/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 186.6729 - mean_squared_error: 186.6729\n",
      "Epoch 00128: val_loss did not improve from 176.97717\n",
      "526/526 [==============================] - 0s 529us/step - loss: 186.4622 - mean_squared_error: 186.4622 - val_loss: 187.8255 - val_mean_squared_error: 187.8255\n",
      "Epoch 129/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 180.3027 - mean_squared_error: 180.3027\n",
      "Epoch 00129: val_loss did not improve from 176.97717\n",
      "526/526 [==============================] - 0s 539us/step - loss: 180.1164 - mean_squared_error: 180.1164 - val_loss: 190.0646 - val_mean_squared_error: 190.0646\n",
      "Epoch 130/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 182.4973 - mean_squared_error: 182.4973\n",
      "Epoch 00130: val_loss did not improve from 176.97717\n",
      "526/526 [==============================] - 0s 537us/step - loss: 182.8095 - mean_squared_error: 182.8095 - val_loss: 180.7506 - val_mean_squared_error: 180.7506\n",
      "Epoch 131/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 178.0025 - mean_squared_error: 178.0025\n",
      "Epoch 00131: val_loss did not improve from 176.97717\n",
      "526/526 [==============================] - 0s 512us/step - loss: 178.2877 - mean_squared_error: 178.2877 - val_loss: 203.6996 - val_mean_squared_error: 203.6996\n",
      "Epoch 132/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 177.1926 - mean_squared_error: 177.1926\n",
      "Epoch 00132: val_loss did not improve from 176.97717\n",
      "526/526 [==============================] - 0s 510us/step - loss: 179.5341 - mean_squared_error: 179.5341 - val_loss: 193.9982 - val_mean_squared_error: 193.9982\n",
      "Epoch 133/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 182.1362 - mean_squared_error: 182.1362\n",
      "Epoch 00133: val_loss did not improve from 176.97717\n",
      "526/526 [==============================] - 0s 512us/step - loss: 179.3031 - mean_squared_error: 179.3031 - val_loss: 177.7151 - val_mean_squared_error: 177.7151\n",
      "Epoch 134/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 179.7963 - mean_squared_error: 179.7963\n",
      "Epoch 00134: val_loss did not improve from 176.97717\n",
      "526/526 [==============================] - 0s 514us/step - loss: 180.2797 - mean_squared_error: 180.2797 - val_loss: 189.8731 - val_mean_squared_error: 189.8731\n",
      "Epoch 135/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 177.8167 - mean_squared_error: 177.8167\n",
      "Epoch 00135: val_loss improved from 176.97717 to 172.84863, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 729us/step - loss: 176.7791 - mean_squared_error: 176.7791 - val_loss: 172.8486 - val_mean_squared_error: 172.8486\n",
      "Epoch 136/500\n",
      "434/526 [=======================>......] - ETA: 0s - loss: 176.0354 - mean_squared_error: 176.0354\n",
      "Epoch 00136: val_loss improved from 172.84863 to 172.25078, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 742us/step - loss: 177.0190 - mean_squared_error: 177.0190 - val_loss: 172.2508 - val_mean_squared_error: 172.2508\n",
      "Epoch 137/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 172.5115 - mean_squared_error: 172.5115\n",
      "Epoch 00137: val_loss did not improve from 172.25078\n",
      "526/526 [==============================] - 0s 508us/step - loss: 174.0520 - mean_squared_error: 174.0520 - val_loss: 209.1943 - val_mean_squared_error: 209.1943\n",
      "Epoch 138/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 176.2652 - mean_squared_error: 176.2652\n",
      "Epoch 00138: val_loss improved from 172.25078 to 168.31334, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 734us/step - loss: 176.2211 - mean_squared_error: 176.2211 - val_loss: 168.3133 - val_mean_squared_error: 168.3133\n",
      "Epoch 139/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 173.6450 - mean_squared_error: 173.6450\n",
      "Epoch 00139: val_loss did not improve from 168.31334\n",
      "526/526 [==============================] - 0s 514us/step - loss: 173.3367 - mean_squared_error: 173.3367 - val_loss: 170.6149 - val_mean_squared_error: 170.6149\n",
      "Epoch 140/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 175.3709 - mean_squared_error: 175.3709\n",
      "Epoch 00140: val_loss did not improve from 168.31334\n",
      "526/526 [==============================] - 0s 533us/step - loss: 175.3709 - mean_squared_error: 175.3709 - val_loss: 175.4863 - val_mean_squared_error: 175.4863\n",
      "Epoch 141/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 174.9764 - mean_squared_error: 174.9764\n",
      "Epoch 00141: val_loss did not improve from 168.31334\n",
      "526/526 [==============================] - 0s 514us/step - loss: 170.7507 - mean_squared_error: 170.7507 - val_loss: 177.7316 - val_mean_squared_error: 177.7316\n",
      "Epoch 142/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 170.8533 - mean_squared_error: 170.8533\n",
      "Epoch 00142: val_loss did not improve from 168.31334\n",
      "526/526 [==============================] - 0s 516us/step - loss: 171.3176 - mean_squared_error: 171.3176 - val_loss: 192.3835 - val_mean_squared_error: 192.3835\n",
      "Epoch 143/500\n",
      "423/526 [=======================>......] - ETA: 0s - loss: 171.7557 - mean_squared_error: 171.7557\n",
      "Epoch 00143: val_loss did not improve from 168.31334\n",
      "526/526 [==============================] - 0s 523us/step - loss: 173.6478 - mean_squared_error: 173.6478 - val_loss: 178.0575 - val_mean_squared_error: 178.0575\n",
      "Epoch 144/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 170.2524 - mean_squared_error: 170.2524\n",
      "Epoch 00144: val_loss did not improve from 168.31334\n",
      "526/526 [==============================] - 0s 516us/step - loss: 170.3587 - mean_squared_error: 170.3587 - val_loss: 172.3963 - val_mean_squared_error: 172.3963\n",
      "Epoch 145/500\n",
      "423/526 [=======================>......] - ETA: 0s - loss: 172.3806 - mean_squared_error: 172.3806\n",
      "Epoch 00145: val_loss did not improve from 168.31334\n",
      "526/526 [==============================] - 0s 519us/step - loss: 170.8953 - mean_squared_error: 170.8953 - val_loss: 197.8035 - val_mean_squared_error: 197.8035\n",
      "Epoch 146/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 172.9801 - mean_squared_error: 172.9801\n",
      "Epoch 00146: val_loss did not improve from 168.31334\n",
      "526/526 [==============================] - 0s 510us/step - loss: 170.6346 - mean_squared_error: 170.6346 - val_loss: 171.3989 - val_mean_squared_error: 171.3989\n",
      "Epoch 147/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 172.9577 - mean_squared_error: 172.9577\n",
      "Epoch 00147: val_loss did not improve from 168.31334\n",
      "526/526 [==============================] - 0s 542us/step - loss: 173.1774 - mean_squared_error: 173.1774 - val_loss: 177.9717 - val_mean_squared_error: 177.9717\n",
      "Epoch 148/500\n",
      "423/526 [=======================>......] - ETA: 0s - loss: 169.2482 - mean_squared_error: 169.2482\n",
      "Epoch 00148: val_loss did not improve from 168.31334\n",
      "526/526 [==============================] - 0s 523us/step - loss: 171.3637 - mean_squared_error: 171.3637 - val_loss: 171.7699 - val_mean_squared_error: 171.7699\n",
      "Epoch 149/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 164.3937 - mean_squared_error: 164.3937\n",
      "Epoch 00149: val_loss did not improve from 168.31334\n",
      "526/526 [==============================] - 0s 512us/step - loss: 167.1499 - mean_squared_error: 167.1499 - val_loss: 184.8471 - val_mean_squared_error: 184.8471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/500\n",
      "436/526 [=======================>......] - ETA: 0s - loss: 167.4339 - mean_squared_error: 167.4339\n",
      "Epoch 00150: val_loss improved from 168.31334 to 164.18304, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 759us/step - loss: 165.4576 - mean_squared_error: 165.4576 - val_loss: 164.1830 - val_mean_squared_error: 164.1830\n",
      "Epoch 151/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 173.6786 - mean_squared_error: 173.6786\n",
      "Epoch 00151: val_loss did not improve from 164.18304\n",
      "526/526 [==============================] - 0s 512us/step - loss: 171.3117 - mean_squared_error: 171.3117 - val_loss: 174.4400 - val_mean_squared_error: 174.4400\n",
      "Epoch 152/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 172.5124 - mean_squared_error: 172.5124\n",
      "Epoch 00152: val_loss did not improve from 164.18304\n",
      "526/526 [==============================] - 0s 510us/step - loss: 170.2442 - mean_squared_error: 170.2442 - val_loss: 180.5717 - val_mean_squared_error: 180.5717\n",
      "Epoch 153/500\n",
      "434/526 [=======================>......] - ETA: 0s - loss: 164.9531 - mean_squared_error: 164.9531\n",
      "Epoch 00153: val_loss did not improve from 164.18304\n",
      "526/526 [==============================] - 0s 508us/step - loss: 166.3152 - mean_squared_error: 166.3152 - val_loss: 184.7893 - val_mean_squared_error: 184.7893\n",
      "Epoch 154/500\n",
      "435/526 [=======================>......] - ETA: 0s - loss: 163.4436 - mean_squared_error: 163.4436\n",
      "Epoch 00154: val_loss did not improve from 164.18304\n",
      "526/526 [==============================] - 0s 508us/step - loss: 164.2510 - mean_squared_error: 164.2510 - val_loss: 171.5884 - val_mean_squared_error: 171.5884\n",
      "Epoch 155/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 167.5405 - mean_squared_error: 167.5405\n",
      "Epoch 00155: val_loss did not improve from 164.18304\n",
      "526/526 [==============================] - 0s 510us/step - loss: 167.5960 - mean_squared_error: 167.5960 - val_loss: 170.9691 - val_mean_squared_error: 170.9691\n",
      "Epoch 156/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 166.3853 - mean_squared_error: 166.3853\n",
      "Epoch 00156: val_loss did not improve from 164.18304\n",
      "526/526 [==============================] - 0s 516us/step - loss: 164.2294 - mean_squared_error: 164.2294 - val_loss: 174.8825 - val_mean_squared_error: 174.8825\n",
      "Epoch 157/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 165.7610 - mean_squared_error: 165.7610\n",
      "Epoch 00157: val_loss did not improve from 164.18304\n",
      "526/526 [==============================] - 0s 514us/step - loss: 165.2856 - mean_squared_error: 165.2856 - val_loss: 167.0463 - val_mean_squared_error: 167.0463\n",
      "Epoch 158/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 160.9552 - mean_squared_error: 160.9552\n",
      "Epoch 00158: val_loss did not improve from 164.18304\n",
      "526/526 [==============================] - 0s 514us/step - loss: 166.3729 - mean_squared_error: 166.3729 - val_loss: 197.7731 - val_mean_squared_error: 197.7731\n",
      "Epoch 159/500\n",
      "435/526 [=======================>......] - ETA: 0s - loss: 165.7783 - mean_squared_error: 165.7783\n",
      "Epoch 00159: val_loss did not improve from 164.18304\n",
      "526/526 [==============================] - 0s 510us/step - loss: 165.5573 - mean_squared_error: 165.5573 - val_loss: 175.2471 - val_mean_squared_error: 175.2471\n",
      "Epoch 160/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 161.7973 - mean_squared_error: 161.7973\n",
      "Epoch 00160: val_loss did not improve from 164.18304\n",
      "526/526 [==============================] - 0s 516us/step - loss: 162.2069 - mean_squared_error: 162.2069 - val_loss: 173.2065 - val_mean_squared_error: 173.2065\n",
      "Epoch 161/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 159.2596 - mean_squared_error: 159.2596\n",
      "Epoch 00161: val_loss improved from 164.18304 to 157.97356, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 699us/step - loss: 160.2969 - mean_squared_error: 160.2969 - val_loss: 157.9736 - val_mean_squared_error: 157.9736\n",
      "Epoch 162/500\n",
      "435/526 [=======================>......] - ETA: 0s - loss: 164.0351 - mean_squared_error: 164.0351\n",
      "Epoch 00162: val_loss did not improve from 157.97356\n",
      "526/526 [==============================] - 0s 508us/step - loss: 164.0869 - mean_squared_error: 164.0869 - val_loss: 190.0143 - val_mean_squared_error: 190.0143\n",
      "Epoch 163/500\n",
      "422/526 [=======================>......] - ETA: 0s - loss: 162.1544 - mean_squared_error: 162.1544\n",
      "Epoch 00163: val_loss did not improve from 157.97356\n",
      "526/526 [==============================] - 0s 523us/step - loss: 162.1841 - mean_squared_error: 162.1841 - val_loss: 173.4573 - val_mean_squared_error: 173.4573\n",
      "Epoch 164/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 161.2897 - mean_squared_error: 161.2897\n",
      "Epoch 00164: val_loss did not improve from 157.97356\n",
      "526/526 [==============================] - 0s 518us/step - loss: 164.9681 - mean_squared_error: 164.9681 - val_loss: 176.6169 - val_mean_squared_error: 176.6169\n",
      "Epoch 165/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 164.1124 - mean_squared_error: 164.1124\n",
      "Epoch 00165: val_loss did not improve from 157.97356\n",
      "526/526 [==============================] - 0s 514us/step - loss: 162.0615 - mean_squared_error: 162.0615 - val_loss: 179.4897 - val_mean_squared_error: 179.4897\n",
      "Epoch 166/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 162.3152 - mean_squared_error: 162.3152\n",
      "Epoch 00166: val_loss improved from 157.97356 to 151.37177, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 691us/step - loss: 160.3631 - mean_squared_error: 160.3631 - val_loss: 151.3718 - val_mean_squared_error: 151.3718\n",
      "Epoch 167/500\n",
      "421/526 [=======================>......] - ETA: 0s - loss: 160.1426 - mean_squared_error: 160.1426\n",
      "Epoch 00167: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 523us/step - loss: 159.7431 - mean_squared_error: 159.7431 - val_loss: 167.7079 - val_mean_squared_error: 167.7079\n",
      "Epoch 168/500\n",
      "422/526 [=======================>......] - ETA: 0s - loss: 158.4936 - mean_squared_error: 158.4936\n",
      "Epoch 00168: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 521us/step - loss: 159.8513 - mean_squared_error: 159.8513 - val_loss: 182.2305 - val_mean_squared_error: 182.2305\n",
      "Epoch 169/500\n",
      "421/526 [=======================>......] - ETA: 0s - loss: 163.7044 - mean_squared_error: 163.7044\n",
      "Epoch 00169: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 521us/step - loss: 161.1602 - mean_squared_error: 161.1602 - val_loss: 160.6359 - val_mean_squared_error: 160.6359\n",
      "Epoch 170/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 160.7269 - mean_squared_error: 160.7269\n",
      "Epoch 00170: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 514us/step - loss: 160.9832 - mean_squared_error: 160.9832 - val_loss: 189.9974 - val_mean_squared_error: 189.9974\n",
      "Epoch 171/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 159.2012 - mean_squared_error: 159.2012\n",
      "Epoch 00171: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 514us/step - loss: 158.2894 - mean_squared_error: 158.2894 - val_loss: 161.3923 - val_mean_squared_error: 161.3923\n",
      "Epoch 172/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 158.5164 - mean_squared_error: 158.5164\n",
      "Epoch 00172: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 514us/step - loss: 157.9456 - mean_squared_error: 157.9456 - val_loss: 174.1260 - val_mean_squared_error: 174.1260\n",
      "Epoch 173/500\n",
      "436/526 [=======================>......] - ETA: 0s - loss: 159.6483 - mean_squared_error: 159.6483\n",
      "Epoch 00173: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 508us/step - loss: 160.3242 - mean_squared_error: 160.3242 - val_loss: 164.9175 - val_mean_squared_error: 164.9175\n",
      "Epoch 174/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 158.6957 - mean_squared_error: 158.6957\n",
      "Epoch 00174: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 519us/step - loss: 159.6003 - mean_squared_error: 159.6003 - val_loss: 164.1777 - val_mean_squared_error: 164.1777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 153.7651 - mean_squared_error: 153.7651\n",
      "Epoch 00175: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 512us/step - loss: 158.5913 - mean_squared_error: 158.5913 - val_loss: 205.9102 - val_mean_squared_error: 205.9102\n",
      "Epoch 176/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 151.3078 - mean_squared_error: 151.3078\n",
      "Epoch 00176: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 518us/step - loss: 154.1386 - mean_squared_error: 154.1386 - val_loss: 160.8720 - val_mean_squared_error: 160.8720\n",
      "Epoch 177/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 157.6700 - mean_squared_error: 157.6700\n",
      "Epoch 00177: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 519us/step - loss: 158.3980 - mean_squared_error: 158.3980 - val_loss: 153.4537 - val_mean_squared_error: 153.4537\n",
      "Epoch 178/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 153.4415 - mean_squared_error: 153.4415\n",
      "Epoch 00178: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 531us/step - loss: 153.6903 - mean_squared_error: 153.6903 - val_loss: 157.2414 - val_mean_squared_error: 157.2414\n",
      "Epoch 179/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 155.3955 - mean_squared_error: 155.3955\n",
      "Epoch 00179: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 529us/step - loss: 155.3147 - mean_squared_error: 155.3147 - val_loss: 159.0366 - val_mean_squared_error: 159.0366\n",
      "Epoch 180/500\n",
      "423/526 [=======================>......] - ETA: 0s - loss: 156.0093 - mean_squared_error: 156.0093\n",
      "Epoch 00180: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 519us/step - loss: 154.3384 - mean_squared_error: 154.3384 - val_loss: 188.2393 - val_mean_squared_error: 188.2393\n",
      "Epoch 181/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 151.0558 - mean_squared_error: 151.0558\n",
      "Epoch 00181: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 516us/step - loss: 155.4234 - mean_squared_error: 155.4234 - val_loss: 162.7417 - val_mean_squared_error: 162.7417\n",
      "Epoch 182/500\n",
      "420/526 [======================>.......] - ETA: 0s - loss: 150.3744 - mean_squared_error: 150.3744\n",
      "Epoch 00182: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 523us/step - loss: 151.4193 - mean_squared_error: 151.4193 - val_loss: 161.8886 - val_mean_squared_error: 161.8886\n",
      "Epoch 183/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 150.7948 - mean_squared_error: 150.7948\n",
      "Epoch 00183: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 514us/step - loss: 152.6640 - mean_squared_error: 152.6640 - val_loss: 165.9412 - val_mean_squared_error: 165.9412\n",
      "Epoch 184/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 151.8803 - mean_squared_error: 151.8803\n",
      "Epoch 00184: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 518us/step - loss: 151.6098 - mean_squared_error: 151.6098 - val_loss: 157.2433 - val_mean_squared_error: 157.2433\n",
      "Epoch 185/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 151.2826 - mean_squared_error: 151.2826\n",
      "Epoch 00185: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 544us/step - loss: 152.0319 - mean_squared_error: 152.0319 - val_loss: 159.2392 - val_mean_squared_error: 159.2392\n",
      "Epoch 186/500\n",
      "421/526 [=======================>......] - ETA: 0s - loss: 154.8295 - mean_squared_error: 154.8295\n",
      "Epoch 00186: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 523us/step - loss: 156.7175 - mean_squared_error: 156.7175 - val_loss: 156.1529 - val_mean_squared_error: 156.1529\n",
      "Epoch 187/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 149.9821 - mean_squared_error: 149.9821\n",
      "Epoch 00187: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 514us/step - loss: 148.6996 - mean_squared_error: 148.6996 - val_loss: 157.0322 - val_mean_squared_error: 157.0322\n",
      "Epoch 188/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 149.4463 - mean_squared_error: 149.4463\n",
      "Epoch 00188: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 519us/step - loss: 150.4950 - mean_squared_error: 150.4950 - val_loss: 153.1173 - val_mean_squared_error: 153.1173\n",
      "Epoch 189/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 149.4987 - mean_squared_error: 149.4987\n",
      "Epoch 00189: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 518us/step - loss: 149.6394 - mean_squared_error: 149.6394 - val_loss: 169.2259 - val_mean_squared_error: 169.2259\n",
      "Epoch 190/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 155.7930 - mean_squared_error: 155.7930\n",
      "Epoch 00190: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 516us/step - loss: 152.1822 - mean_squared_error: 152.1822 - val_loss: 183.4581 - val_mean_squared_error: 183.4581\n",
      "Epoch 191/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 147.4633 - mean_squared_error: 147.4633\n",
      "Epoch 00191: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 512us/step - loss: 150.6416 - mean_squared_error: 150.6416 - val_loss: 239.6709 - val_mean_squared_error: 239.6709\n",
      "Epoch 192/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 151.9404 - mean_squared_error: 151.9404\n",
      "Epoch 00192: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 514us/step - loss: 151.6245 - mean_squared_error: 151.6245 - val_loss: 161.1462 - val_mean_squared_error: 161.1462\n",
      "Epoch 193/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 150.4232 - mean_squared_error: 150.4232\n",
      "Epoch 00193: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 516us/step - loss: 149.4907 - mean_squared_error: 149.4907 - val_loss: 157.8339 - val_mean_squared_error: 157.8339\n",
      "Epoch 194/500\n",
      "425/526 [=======================>......] - ETA: 0s - loss: 148.1943 - mean_squared_error: 148.1943\n",
      "Epoch 00194: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 516us/step - loss: 147.4848 - mean_squared_error: 147.4848 - val_loss: 156.4669 - val_mean_squared_error: 156.4669\n",
      "Epoch 195/500\n",
      "435/526 [=======================>......] - ETA: 0s - loss: 151.5141 - mean_squared_error: 151.5141\n",
      "Epoch 00195: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 508us/step - loss: 149.5671 - mean_squared_error: 149.5671 - val_loss: 155.6850 - val_mean_squared_error: 155.6850\n",
      "Epoch 196/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 146.8008 - mean_squared_error: 146.8008\n",
      "Epoch 00196: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 514us/step - loss: 147.7153 - mean_squared_error: 147.7153 - val_loss: 161.6852 - val_mean_squared_error: 161.6852\n",
      "Epoch 197/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 150.0844 - mean_squared_error: 150.0844\n",
      "Epoch 00197: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 516us/step - loss: 150.1337 - mean_squared_error: 150.1337 - val_loss: 192.0904 - val_mean_squared_error: 192.0904\n",
      "Epoch 198/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 143.7845 - mean_squared_error: 143.7845\n",
      "Epoch 00198: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 512us/step - loss: 145.9790 - mean_squared_error: 145.9790 - val_loss: 158.4402 - val_mean_squared_error: 158.4402\n",
      "Epoch 199/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 147.8492 - mean_squared_error: 147.8492\n",
      "Epoch 00199: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 512us/step - loss: 146.5024 - mean_squared_error: 146.5024 - val_loss: 161.5285 - val_mean_squared_error: 161.5285\n",
      "Epoch 200/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 143.9920 - mean_squared_error: 143.9920\n",
      "Epoch 00200: val_loss did not improve from 151.37177\n",
      "526/526 [==============================] - 0s 516us/step - loss: 148.0260 - mean_squared_error: 148.0260 - val_loss: 154.6014 - val_mean_squared_error: 154.6014\n",
      "Epoch 201/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 145.6219 - mean_squared_error: 145.6219\n",
      "Epoch 00201: val_loss improved from 151.37177 to 150.53259, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 837us/step - loss: 147.7136 - mean_squared_error: 147.7136 - val_loss: 150.5326 - val_mean_squared_error: 150.5326\n",
      "Epoch 202/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 145.9869 - mean_squared_error: 145.9869\n",
      "Epoch 00202: val_loss did not improve from 150.53259\n",
      "526/526 [==============================] - 0s 510us/step - loss: 144.7623 - mean_squared_error: 144.7623 - val_loss: 152.6262 - val_mean_squared_error: 152.6262\n",
      "Epoch 203/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 150.4991 - mean_squared_error: 150.4991\n",
      "Epoch 00203: val_loss did not improve from 150.53259\n",
      "526/526 [==============================] - 0s 514us/step - loss: 148.3568 - mean_squared_error: 148.3568 - val_loss: 152.1148 - val_mean_squared_error: 152.1148\n",
      "Epoch 204/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 143.4114 - mean_squared_error: 143.4114\n",
      "Epoch 00204: val_loss did not improve from 150.53259\n",
      "526/526 [==============================] - 0s 514us/step - loss: 144.1714 - mean_squared_error: 144.1714 - val_loss: 220.0457 - val_mean_squared_error: 220.0457\n",
      "Epoch 205/500\n",
      "435/526 [=======================>......] - ETA: 0s - loss: 150.2199 - mean_squared_error: 150.2199\n",
      "Epoch 00205: val_loss improved from 150.53259 to 145.71860, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 742us/step - loss: 148.9849 - mean_squared_error: 148.9849 - val_loss: 145.7186 - val_mean_squared_error: 145.7186\n",
      "Epoch 206/500\n",
      "435/526 [=======================>......] - ETA: 0s - loss: 143.7296 - mean_squared_error: 143.7296\n",
      "Epoch 00206: val_loss did not improve from 145.71860\n",
      "526/526 [==============================] - 0s 510us/step - loss: 145.0581 - mean_squared_error: 145.0581 - val_loss: 155.6792 - val_mean_squared_error: 155.6792\n",
      "Epoch 207/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 143.8497 - mean_squared_error: 143.8497\n",
      "Epoch 00207: val_loss did not improve from 145.71860\n",
      "526/526 [==============================] - 0s 514us/step - loss: 144.0521 - mean_squared_error: 144.0521 - val_loss: 161.3646 - val_mean_squared_error: 161.3646\n",
      "Epoch 208/500\n",
      "435/526 [=======================>......] - ETA: 0s - loss: 145.0846 - mean_squared_error: 145.0846\n",
      "Epoch 00208: val_loss did not improve from 145.71860\n",
      "526/526 [==============================] - 0s 508us/step - loss: 146.9144 - mean_squared_error: 146.9144 - val_loss: 168.7088 - val_mean_squared_error: 168.7088\n",
      "Epoch 209/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 143.6515 - mean_squared_error: 143.6515\n",
      "Epoch 00209: val_loss did not improve from 145.71860\n",
      "526/526 [==============================] - 0s 514us/step - loss: 145.3616 - mean_squared_error: 145.3616 - val_loss: 155.1518 - val_mean_squared_error: 155.1518\n",
      "Epoch 210/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 144.3315 - mean_squared_error: 144.3315\n",
      "Epoch 00210: val_loss did not improve from 145.71860\n",
      "526/526 [==============================] - 0s 514us/step - loss: 144.1987 - mean_squared_error: 144.1987 - val_loss: 167.4111 - val_mean_squared_error: 167.4111\n",
      "Epoch 211/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 139.0603 - mean_squared_error: 139.0603\n",
      "Epoch 00211: val_loss did not improve from 145.71860\n",
      "526/526 [==============================] - 0s 518us/step - loss: 142.1464 - mean_squared_error: 142.1464 - val_loss: 164.1172 - val_mean_squared_error: 164.1172\n",
      "Epoch 212/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 141.4870 - mean_squared_error: 141.4870\n",
      "Epoch 00212: val_loss did not improve from 145.71860\n",
      "526/526 [==============================] - 0s 512us/step - loss: 141.4618 - mean_squared_error: 141.4618 - val_loss: 152.9762 - val_mean_squared_error: 152.9762\n",
      "Epoch 213/500\n",
      "434/526 [=======================>......] - ETA: 0s - loss: 146.0534 - mean_squared_error: 146.0534\n",
      "Epoch 00213: val_loss did not improve from 145.71860\n",
      "526/526 [==============================] - 0s 516us/step - loss: 142.8200 - mean_squared_error: 142.8200 - val_loss: 154.3477 - val_mean_squared_error: 154.3477\n",
      "Epoch 214/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 145.5822 - mean_squared_error: 145.5822\n",
      "Epoch 00214: val_loss did not improve from 145.71860\n",
      "526/526 [==============================] - 0s 527us/step - loss: 145.4691 - mean_squared_error: 145.4691 - val_loss: 152.7512 - val_mean_squared_error: 152.7512\n",
      "Epoch 215/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 144.0601 - mean_squared_error: 144.0601\n",
      "Epoch 00215: val_loss improved from 145.71860 to 144.89914, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 688us/step - loss: 143.4146 - mean_squared_error: 143.4146 - val_loss: 144.8991 - val_mean_squared_error: 144.8991\n",
      "Epoch 216/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 143.4054 - mean_squared_error: 143.4054\n",
      "Epoch 00216: val_loss did not improve from 144.89914\n",
      "526/526 [==============================] - 0s 512us/step - loss: 143.8943 - mean_squared_error: 143.8943 - val_loss: 151.9747 - val_mean_squared_error: 151.9747\n",
      "Epoch 217/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 141.5814 - mean_squared_error: 141.5814\n",
      "Epoch 00217: val_loss did not improve from 144.89914\n",
      "526/526 [==============================] - 0s 527us/step - loss: 141.6234 - mean_squared_error: 141.6234 - val_loss: 152.1409 - val_mean_squared_error: 152.1409\n",
      "Epoch 218/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 140.9075 - mean_squared_error: 140.9075\n",
      "Epoch 00218: val_loss did not improve from 144.89914\n",
      "526/526 [==============================] - 0s 519us/step - loss: 139.7970 - mean_squared_error: 139.7970 - val_loss: 145.8242 - val_mean_squared_error: 145.8242\n",
      "Epoch 219/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 140.9327 - mean_squared_error: 140.9327\n",
      "Epoch 00219: val_loss did not improve from 144.89914\n",
      "526/526 [==============================] - 0s 516us/step - loss: 139.4574 - mean_squared_error: 139.4574 - val_loss: 156.4886 - val_mean_squared_error: 156.4886\n",
      "Epoch 220/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 142.2048 - mean_squared_error: 142.2048\n",
      "Epoch 00220: val_loss did not improve from 144.89914\n",
      "526/526 [==============================] - 0s 533us/step - loss: 142.3409 - mean_squared_error: 142.3409 - val_loss: 150.3031 - val_mean_squared_error: 150.3031\n",
      "Epoch 221/500\n",
      "420/526 [======================>.......] - ETA: 0s - loss: 144.8792 - mean_squared_error: 144.8792\n",
      "Epoch 00221: val_loss did not improve from 144.89914\n",
      "526/526 [==============================] - 0s 523us/step - loss: 145.1894 - mean_squared_error: 145.1894 - val_loss: 150.3526 - val_mean_squared_error: 150.3526\n",
      "Epoch 222/500\n",
      "425/526 [=======================>......] - ETA: 0s - loss: 136.2803 - mean_squared_error: 136.2803\n",
      "Epoch 00222: val_loss did not improve from 144.89914\n",
      "526/526 [==============================] - 0s 519us/step - loss: 138.4560 - mean_squared_error: 138.4560 - val_loss: 227.4727 - val_mean_squared_error: 227.4727\n",
      "Epoch 223/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 139.8401 - mean_squared_error: 139.8401\n",
      "Epoch 00223: val_loss did not improve from 144.89914\n",
      "526/526 [==============================] - 0s 518us/step - loss: 139.4940 - mean_squared_error: 139.4940 - val_loss: 150.4068 - val_mean_squared_error: 150.4068\n",
      "Epoch 224/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 141.4275 - mean_squared_error: 141.4275\n",
      "Epoch 00224: val_loss did not improve from 144.89914\n",
      "526/526 [==============================] - 0s 516us/step - loss: 140.6376 - mean_squared_error: 140.6376 - val_loss: 147.8038 - val_mean_squared_error: 147.8038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/500\n",
      "434/526 [=======================>......] - ETA: 0s - loss: 139.7497 - mean_squared_error: 139.7497\n",
      "Epoch 00225: val_loss did not improve from 144.89914\n",
      "526/526 [==============================] - 0s 510us/step - loss: 140.2670 - mean_squared_error: 140.2670 - val_loss: 153.1906 - val_mean_squared_error: 153.1906\n",
      "Epoch 226/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 137.0487 - mean_squared_error: 137.0487\n",
      "Epoch 00226: val_loss did not improve from 144.89914\n",
      "526/526 [==============================] - 0s 523us/step - loss: 139.0500 - mean_squared_error: 139.0500 - val_loss: 158.6037 - val_mean_squared_error: 158.6037\n",
      "Epoch 227/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 141.5044 - mean_squared_error: 141.5044\n",
      "Epoch 00227: val_loss did not improve from 144.89914\n",
      "526/526 [==============================] - 0s 535us/step - loss: 141.5483 - mean_squared_error: 141.5483 - val_loss: 154.8250 - val_mean_squared_error: 154.8250\n",
      "Epoch 228/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 135.9887 - mean_squared_error: 135.9887\n",
      "Epoch 00228: val_loss did not improve from 144.89914\n",
      "526/526 [==============================] - 0s 529us/step - loss: 136.2988 - mean_squared_error: 136.2988 - val_loss: 170.5789 - val_mean_squared_error: 170.5789\n",
      "Epoch 229/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 137.4720 - mean_squared_error: 137.4720\n",
      "Epoch 00229: val_loss improved from 144.89914 to 143.23245, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 822us/step - loss: 136.9352 - mean_squared_error: 136.9352 - val_loss: 143.2325 - val_mean_squared_error: 143.2325\n",
      "Epoch 230/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 137.3332 - mean_squared_error: 137.3332\n",
      "Epoch 00230: val_loss did not improve from 143.23245\n",
      "526/526 [==============================] - 0s 531us/step - loss: 136.9304 - mean_squared_error: 136.9304 - val_loss: 145.2120 - val_mean_squared_error: 145.2120\n",
      "Epoch 231/500\n",
      "422/526 [=======================>......] - ETA: 0s - loss: 138.9464 - mean_squared_error: 138.9464\n",
      "Epoch 00231: val_loss did not improve from 143.23245\n",
      "526/526 [==============================] - 0s 523us/step - loss: 136.4054 - mean_squared_error: 136.4054 - val_loss: 172.6489 - val_mean_squared_error: 172.6489\n",
      "Epoch 232/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 137.0314 - mean_squared_error: 137.0314\n",
      "Epoch 00232: val_loss did not improve from 143.23245\n",
      "526/526 [==============================] - 0s 518us/step - loss: 136.6205 - mean_squared_error: 136.6205 - val_loss: 144.7382 - val_mean_squared_error: 144.7382\n",
      "Epoch 233/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 139.0702 - mean_squared_error: 139.0702\n",
      "Epoch 00233: val_loss did not improve from 143.23245\n",
      "526/526 [==============================] - 0s 529us/step - loss: 138.9938 - mean_squared_error: 138.9938 - val_loss: 144.2709 - val_mean_squared_error: 144.2709\n",
      "Epoch 234/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 133.4200 - mean_squared_error: 133.4200\n",
      "Epoch 00234: val_loss did not improve from 143.23245\n",
      "526/526 [==============================] - 0s 516us/step - loss: 136.2201 - mean_squared_error: 136.2201 - val_loss: 163.8665 - val_mean_squared_error: 163.8665\n",
      "Epoch 235/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 136.7019 - mean_squared_error: 136.7019\n",
      "Epoch 00235: val_loss did not improve from 143.23245\n",
      "526/526 [==============================] - 0s 512us/step - loss: 137.2292 - mean_squared_error: 137.2292 - val_loss: 150.4907 - val_mean_squared_error: 150.4907\n",
      "Epoch 236/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 138.9505 - mean_squared_error: 138.9505\n",
      "Epoch 00236: val_loss did not improve from 143.23245\n",
      "526/526 [==============================] - 0s 518us/step - loss: 135.9602 - mean_squared_error: 135.9602 - val_loss: 146.5400 - val_mean_squared_error: 146.5400\n",
      "Epoch 237/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 137.9738 - mean_squared_error: 137.9738\n",
      "Epoch 00237: val_loss did not improve from 143.23245\n",
      "526/526 [==============================] - 0s 521us/step - loss: 137.6259 - mean_squared_error: 137.6259 - val_loss: 148.1790 - val_mean_squared_error: 148.1790\n",
      "Epoch 238/500\n",
      "423/526 [=======================>......] - ETA: 0s - loss: 136.9308 - mean_squared_error: 136.9308\n",
      "Epoch 00238: val_loss did not improve from 143.23245\n",
      "526/526 [==============================] - 0s 519us/step - loss: 135.4595 - mean_squared_error: 135.4595 - val_loss: 151.2501 - val_mean_squared_error: 151.2501\n",
      "Epoch 239/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 133.1359 - mean_squared_error: 133.1359\n",
      "Epoch 00239: val_loss did not improve from 143.23245\n",
      "526/526 [==============================] - 0s 519us/step - loss: 134.5404 - mean_squared_error: 134.5404 - val_loss: 148.1549 - val_mean_squared_error: 148.1549\n",
      "Epoch 240/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 141.3595 - mean_squared_error: 141.3595\n",
      "Epoch 00240: val_loss did not improve from 143.23245\n",
      "526/526 [==============================] - 0s 519us/step - loss: 137.8003 - mean_squared_error: 137.8003 - val_loss: 148.7131 - val_mean_squared_error: 148.7131\n",
      "Epoch 241/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 135.6005 - mean_squared_error: 135.6005\n",
      "Epoch 00241: val_loss did not improve from 143.23245\n",
      "526/526 [==============================] - 0s 533us/step - loss: 135.6776 - mean_squared_error: 135.6776 - val_loss: 144.1814 - val_mean_squared_error: 144.1814\n",
      "Epoch 242/500\n",
      "421/526 [=======================>......] - ETA: 0s - loss: 139.8930 - mean_squared_error: 139.8930\n",
      "Epoch 00242: val_loss did not improve from 143.23245\n",
      "526/526 [==============================] - 0s 525us/step - loss: 138.8144 - mean_squared_error: 138.8144 - val_loss: 162.7433 - val_mean_squared_error: 162.7433\n",
      "Epoch 243/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 131.0593 - mean_squared_error: 131.0593\n",
      "Epoch 00243: val_loss improved from 143.23245 to 139.22331, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 714us/step - loss: 131.5094 - mean_squared_error: 131.5094 - val_loss: 139.2233 - val_mean_squared_error: 139.2233\n",
      "Epoch 244/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 135.2481 - mean_squared_error: 135.2481\n",
      "Epoch 00244: val_loss improved from 139.22331 to 137.66109, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 725us/step - loss: 135.2222 - mean_squared_error: 135.2222 - val_loss: 137.6611 - val_mean_squared_error: 137.6611\n",
      "Epoch 245/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 135.5328 - mean_squared_error: 135.5328\n",
      "Epoch 00245: val_loss did not improve from 137.66109\n",
      "526/526 [==============================] - 0s 540us/step - loss: 135.9441 - mean_squared_error: 135.9441 - val_loss: 180.3029 - val_mean_squared_error: 180.3029\n",
      "Epoch 246/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 133.4283 - mean_squared_error: 133.4283\n",
      "Epoch 00246: val_loss did not improve from 137.66109\n",
      "526/526 [==============================] - 0s 516us/step - loss: 135.5511 - mean_squared_error: 135.5511 - val_loss: 159.2418 - val_mean_squared_error: 159.2418\n",
      "Epoch 247/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 132.6309 - mean_squared_error: 132.6309\n",
      "Epoch 00247: val_loss did not improve from 137.66109\n",
      "526/526 [==============================] - 0s 525us/step - loss: 132.6309 - mean_squared_error: 132.6309 - val_loss: 146.5640 - val_mean_squared_error: 146.5640\n",
      "Epoch 248/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 134.6072 - mean_squared_error: 134.6072\n",
      "Epoch 00248: val_loss did not improve from 137.66109\n",
      "526/526 [==============================] - 0s 512us/step - loss: 134.3628 - mean_squared_error: 134.3628 - val_loss: 148.3184 - val_mean_squared_error: 148.3184\n",
      "Epoch 249/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 137.8064 - mean_squared_error: 137.8064\n",
      "Epoch 00249: val_loss did not improve from 137.66109\n",
      "526/526 [==============================] - 0s 512us/step - loss: 135.7853 - mean_squared_error: 135.7853 - val_loss: 151.0067 - val_mean_squared_error: 151.0067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 134.8964 - mean_squared_error: 134.8964\n",
      "Epoch 00250: val_loss did not improve from 137.66109\n",
      "526/526 [==============================] - 0s 512us/step - loss: 134.4729 - mean_squared_error: 134.4729 - val_loss: 144.8764 - val_mean_squared_error: 144.8764\n",
      "Epoch 251/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 136.1721 - mean_squared_error: 136.1721\n",
      "Epoch 00251: val_loss did not improve from 137.66109\n",
      "526/526 [==============================] - 0s 519us/step - loss: 133.2579 - mean_squared_error: 133.2579 - val_loss: 144.4657 - val_mean_squared_error: 144.4657\n",
      "Epoch 252/500\n",
      "422/526 [=======================>......] - ETA: 0s - loss: 131.3505 - mean_squared_error: 131.3505\n",
      "Epoch 00252: val_loss did not improve from 137.66109\n",
      "526/526 [==============================] - 0s 521us/step - loss: 131.7732 - mean_squared_error: 131.7732 - val_loss: 145.7148 - val_mean_squared_error: 145.7148\n",
      "Epoch 253/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 130.6247 - mean_squared_error: 130.6247\n",
      "Epoch 00253: val_loss did not improve from 137.66109\n",
      "526/526 [==============================] - 0s 519us/step - loss: 131.6052 - mean_squared_error: 131.6052 - val_loss: 162.3128 - val_mean_squared_error: 162.3128\n",
      "Epoch 254/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 130.2229 - mean_squared_error: 130.2229\n",
      "Epoch 00254: val_loss improved from 137.66109 to 137.19388, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 803us/step - loss: 130.7850 - mean_squared_error: 130.7850 - val_loss: 137.1939 - val_mean_squared_error: 137.1939\n",
      "Epoch 255/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 129.1722 - mean_squared_error: 129.1722\n",
      "Epoch 00255: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 514us/step - loss: 131.4846 - mean_squared_error: 131.4846 - val_loss: 145.4454 - val_mean_squared_error: 145.4454\n",
      "Epoch 256/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 130.7103 - mean_squared_error: 130.7103\n",
      "Epoch 00256: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 512us/step - loss: 131.5627 - mean_squared_error: 131.5627 - val_loss: 155.5094 - val_mean_squared_error: 155.5094\n",
      "Epoch 257/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 131.1373 - mean_squared_error: 131.1373\n",
      "Epoch 00257: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 510us/step - loss: 131.2988 - mean_squared_error: 131.2988 - val_loss: 162.0527 - val_mean_squared_error: 162.0527\n",
      "Epoch 258/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 130.7946 - mean_squared_error: 130.7946\n",
      "Epoch 00258: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 514us/step - loss: 131.5574 - mean_squared_error: 131.5574 - val_loss: 153.1980 - val_mean_squared_error: 153.1980\n",
      "Epoch 259/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 132.9245 - mean_squared_error: 132.9245\n",
      "Epoch 00259: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 508us/step - loss: 131.0805 - mean_squared_error: 131.0805 - val_loss: 140.0903 - val_mean_squared_error: 140.0903\n",
      "Epoch 260/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 125.7275 - mean_squared_error: 125.7275\n",
      "Epoch 00260: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 514us/step - loss: 128.8790 - mean_squared_error: 128.8790 - val_loss: 152.4529 - val_mean_squared_error: 152.4529\n",
      "Epoch 261/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 130.1799 - mean_squared_error: 130.1799\n",
      "Epoch 00261: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 512us/step - loss: 129.2075 - mean_squared_error: 129.2075 - val_loss: 143.1652 - val_mean_squared_error: 143.1652\n",
      "Epoch 262/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 135.5152 - mean_squared_error: 135.5152\n",
      "Epoch 00262: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 516us/step - loss: 131.6565 - mean_squared_error: 131.6565 - val_loss: 146.5655 - val_mean_squared_error: 146.5655\n",
      "Epoch 263/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 126.4508 - mean_squared_error: 126.4508\n",
      "Epoch 00263: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 510us/step - loss: 125.8764 - mean_squared_error: 125.8764 - val_loss: 139.9358 - val_mean_squared_error: 139.9358\n",
      "Epoch 264/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 127.3180 - mean_squared_error: 127.3180\n",
      "Epoch 00264: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 518us/step - loss: 127.2516 - mean_squared_error: 127.2516 - val_loss: 154.6528 - val_mean_squared_error: 154.6528\n",
      "Epoch 265/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 132.4601 - mean_squared_error: 132.4601\n",
      "Epoch 00265: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 516us/step - loss: 132.7410 - mean_squared_error: 132.7410 - val_loss: 146.3616 - val_mean_squared_error: 146.3616\n",
      "Epoch 266/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 130.6138 - mean_squared_error: 130.6138\n",
      "Epoch 00266: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 527us/step - loss: 130.8489 - mean_squared_error: 130.8489 - val_loss: 156.7544 - val_mean_squared_error: 156.7544\n",
      "Epoch 267/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 128.2710 - mean_squared_error: 128.2710\n",
      "Epoch 00267: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 533us/step - loss: 128.9250 - mean_squared_error: 128.9250 - val_loss: 143.6284 - val_mean_squared_error: 143.6284\n",
      "Epoch 268/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 126.8929 - mean_squared_error: 126.8929\n",
      "Epoch 00268: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 540us/step - loss: 126.9579 - mean_squared_error: 126.9579 - val_loss: 144.6609 - val_mean_squared_error: 144.6609\n",
      "Epoch 269/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 126.7134 - mean_squared_error: 126.7134\n",
      "Epoch 00269: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 542us/step - loss: 127.2365 - mean_squared_error: 127.2365 - val_loss: 151.0545 - val_mean_squared_error: 151.0545\n",
      "Epoch 270/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 130.8566 - mean_squared_error: 130.8566\n",
      "Epoch 00270: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 529us/step - loss: 130.9507 - mean_squared_error: 130.9507 - val_loss: 161.0173 - val_mean_squared_error: 161.0173\n",
      "Epoch 271/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 128.6610 - mean_squared_error: 128.6610\n",
      "Epoch 00271: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 516us/step - loss: 128.9092 - mean_squared_error: 128.9092 - val_loss: 145.5595 - val_mean_squared_error: 145.5595\n",
      "Epoch 272/500\n",
      "423/526 [=======================>......] - ETA: 0s - loss: 127.8315 - mean_squared_error: 127.8315\n",
      "Epoch 00272: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 519us/step - loss: 127.9487 - mean_squared_error: 127.9487 - val_loss: 169.2777 - val_mean_squared_error: 169.2777\n",
      "Epoch 273/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 124.6752 - mean_squared_error: 124.6752\n",
      "Epoch 00273: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 521us/step - loss: 127.5402 - mean_squared_error: 127.5402 - val_loss: 150.5235 - val_mean_squared_error: 150.5235\n",
      "Epoch 274/500\n",
      "480/526 [==========================>...] - ETA: 0s - loss: 127.2519 - mean_squared_error: 127.2519\n",
      "Epoch 00274: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 575us/step - loss: 126.6099 - mean_squared_error: 126.6099 - val_loss: 145.9760 - val_mean_squared_error: 145.9760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 132.5210 - mean_squared_error: 132.5210\n",
      "Epoch 00275: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 540us/step - loss: 132.8168 - mean_squared_error: 132.8168 - val_loss: 177.0794 - val_mean_squared_error: 177.0794\n",
      "Epoch 276/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 127.4576 - mean_squared_error: 127.4576\n",
      "Epoch 00276: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 527us/step - loss: 127.2437 - mean_squared_error: 127.2437 - val_loss: 164.1845 - val_mean_squared_error: 164.1845\n",
      "Epoch 277/500\n",
      "425/526 [=======================>......] - ETA: 0s - loss: 125.9050 - mean_squared_error: 125.9050\n",
      "Epoch 00277: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 519us/step - loss: 125.6466 - mean_squared_error: 125.6466 - val_loss: 168.4406 - val_mean_squared_error: 168.4406\n",
      "Epoch 278/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 125.6459 - mean_squared_error: 125.6459\n",
      "Epoch 00278: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 519us/step - loss: 127.2702 - mean_squared_error: 127.2702 - val_loss: 148.3682 - val_mean_squared_error: 148.3682\n",
      "Epoch 279/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 125.5872 - mean_squared_error: 125.5872\n",
      "Epoch 00279: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 535us/step - loss: 125.9579 - mean_squared_error: 125.9579 - val_loss: 153.4708 - val_mean_squared_error: 153.4708\n",
      "Epoch 280/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 127.0166 - mean_squared_error: 127.0166\n",
      "Epoch 00280: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 535us/step - loss: 126.8001 - mean_squared_error: 126.8001 - val_loss: 141.4683 - val_mean_squared_error: 141.4683\n",
      "Epoch 281/500\n",
      "425/526 [=======================>......] - ETA: 0s - loss: 124.7020 - mean_squared_error: 124.7020\n",
      "Epoch 00281: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 521us/step - loss: 126.0585 - mean_squared_error: 126.0585 - val_loss: 145.9932 - val_mean_squared_error: 145.9932\n",
      "Epoch 282/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 126.0827 - mean_squared_error: 126.0827\n",
      "Epoch 00282: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 533us/step - loss: 126.5348 - mean_squared_error: 126.5348 - val_loss: 152.5504 - val_mean_squared_error: 152.5504\n",
      "Epoch 283/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 125.4848 - mean_squared_error: 125.4848\n",
      "Epoch 00283: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 527us/step - loss: 125.4848 - mean_squared_error: 125.4848 - val_loss: 153.2799 - val_mean_squared_error: 153.2799\n",
      "Epoch 284/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 124.7467 - mean_squared_error: 124.7467\n",
      "Epoch 00284: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 525us/step - loss: 124.6782 - mean_squared_error: 124.6782 - val_loss: 140.7496 - val_mean_squared_error: 140.7496\n",
      "Epoch 285/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 122.8766 - mean_squared_error: 122.8766\n",
      "Epoch 00285: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 512us/step - loss: 121.7563 - mean_squared_error: 121.7563 - val_loss: 148.2522 - val_mean_squared_error: 148.2522\n",
      "Epoch 286/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 121.0143 - mean_squared_error: 121.0143\n",
      "Epoch 00286: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 516us/step - loss: 123.8708 - mean_squared_error: 123.8708 - val_loss: 156.6976 - val_mean_squared_error: 156.6976\n",
      "Epoch 287/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 123.6016 - mean_squared_error: 123.6016\n",
      "Epoch 00287: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 519us/step - loss: 124.0926 - mean_squared_error: 124.0926 - val_loss: 160.6711 - val_mean_squared_error: 160.6711\n",
      "Epoch 288/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 123.6365 - mean_squared_error: 123.6365\n",
      "Epoch 00288: val_loss did not improve from 137.19388\n",
      "526/526 [==============================] - 0s 539us/step - loss: 123.3517 - mean_squared_error: 123.3517 - val_loss: 139.0836 - val_mean_squared_error: 139.0836\n",
      "Epoch 289/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 125.3789 - mean_squared_error: 125.3789\n",
      "Epoch 00289: val_loss improved from 137.19388 to 133.72739, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 561us/step - loss: 125.2050 - mean_squared_error: 125.2050 - val_loss: 133.7274 - val_mean_squared_error: 133.7274\n",
      "Epoch 290/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 124.2797 - mean_squared_error: 124.2797\n",
      "Epoch 00290: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 533us/step - loss: 124.9126 - mean_squared_error: 124.9126 - val_loss: 136.0007 - val_mean_squared_error: 136.0007\n",
      "Epoch 291/500\n",
      "421/526 [=======================>......] - ETA: 0s - loss: 121.3222 - mean_squared_error: 121.3222\n",
      "Epoch 00291: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 527us/step - loss: 121.6126 - mean_squared_error: 121.6126 - val_loss: 143.2410 - val_mean_squared_error: 143.2410\n",
      "Epoch 292/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 121.8541 - mean_squared_error: 121.8541\n",
      "Epoch 00292: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 537us/step - loss: 121.6813 - mean_squared_error: 121.6813 - val_loss: 142.8711 - val_mean_squared_error: 142.8711\n",
      "Epoch 293/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 120.8818 - mean_squared_error: 120.8818\n",
      "Epoch 00293: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 521us/step - loss: 121.6317 - mean_squared_error: 121.6317 - val_loss: 137.8777 - val_mean_squared_error: 137.8777\n",
      "Epoch 294/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 127.6895 - mean_squared_error: 127.6895\n",
      "Epoch 00294: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 533us/step - loss: 127.6578 - mean_squared_error: 127.6578 - val_loss: 151.8533 - val_mean_squared_error: 151.8533\n",
      "Epoch 295/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 124.9211 - mean_squared_error: 124.9211\n",
      "Epoch 00295: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 531us/step - loss: 124.5338 - mean_squared_error: 124.5338 - val_loss: 139.8568 - val_mean_squared_error: 139.8568\n",
      "Epoch 296/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 120.8430 - mean_squared_error: 120.8430\n",
      "Epoch 00296: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 525us/step - loss: 120.9411 - mean_squared_error: 120.9411 - val_loss: 142.4987 - val_mean_squared_error: 142.4987\n",
      "Epoch 297/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 122.9961 - mean_squared_error: 122.9961\n",
      "Epoch 00297: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 518us/step - loss: 124.6654 - mean_squared_error: 124.6654 - val_loss: 141.3882 - val_mean_squared_error: 141.3882\n",
      "Epoch 298/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 125.3902 - mean_squared_error: 125.3902\n",
      "Epoch 00298: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 523us/step - loss: 124.3577 - mean_squared_error: 124.3577 - val_loss: 141.5482 - val_mean_squared_error: 141.5482\n",
      "Epoch 299/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 125.9841 - mean_squared_error: 125.9841\n",
      "Epoch 00299: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 533us/step - loss: 126.0460 - mean_squared_error: 126.0460 - val_loss: 153.1749 - val_mean_squared_error: 153.1749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 121.8617 - mean_squared_error: 121.8617\n",
      "Epoch 00300: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 535us/step - loss: 121.7138 - mean_squared_error: 121.7138 - val_loss: 146.5507 - val_mean_squared_error: 146.5507\n",
      "Epoch 301/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 127.7610 - mean_squared_error: 127.7610\n",
      "Epoch 00301: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 519us/step - loss: 126.0233 - mean_squared_error: 126.0233 - val_loss: 146.5500 - val_mean_squared_error: 146.5500\n",
      "Epoch 302/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 121.3145 - mean_squared_error: 121.3145\n",
      "Epoch 00302: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 527us/step - loss: 121.3274 - mean_squared_error: 121.3274 - val_loss: 139.3344 - val_mean_squared_error: 139.3344\n",
      "Epoch 303/500\n",
      "423/526 [=======================>......] - ETA: 0s - loss: 121.7992 - mean_squared_error: 121.7992\n",
      "Epoch 00303: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 523us/step - loss: 120.8587 - mean_squared_error: 120.8587 - val_loss: 149.0838 - val_mean_squared_error: 149.0838\n",
      "Epoch 304/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 125.5956 - mean_squared_error: 125.5956\n",
      "Epoch 00304: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 518us/step - loss: 121.9484 - mean_squared_error: 121.9484 - val_loss: 138.8346 - val_mean_squared_error: 138.8346\n",
      "Epoch 305/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 120.4022 - mean_squared_error: 120.4022\n",
      "Epoch 00305: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 519us/step - loss: 122.7355 - mean_squared_error: 122.7355 - val_loss: 144.0105 - val_mean_squared_error: 144.0105\n",
      "Epoch 306/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 120.1386 - mean_squared_error: 120.1386\n",
      "Epoch 00306: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 514us/step - loss: 120.7444 - mean_squared_error: 120.7444 - val_loss: 141.0649 - val_mean_squared_error: 141.0649\n",
      "Epoch 307/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 120.6162 - mean_squared_error: 120.6162\n",
      "Epoch 00307: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 535us/step - loss: 121.2080 - mean_squared_error: 121.2080 - val_loss: 137.6460 - val_mean_squared_error: 137.6460\n",
      "Epoch 308/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 123.8087 - mean_squared_error: 123.8087\n",
      "Epoch 00308: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 529us/step - loss: 123.9177 - mean_squared_error: 123.9177 - val_loss: 138.0759 - val_mean_squared_error: 138.0759\n",
      "Epoch 309/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 118.7238 - mean_squared_error: 118.7238\n",
      "Epoch 00309: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 531us/step - loss: 118.3892 - mean_squared_error: 118.3892 - val_loss: 152.6604 - val_mean_squared_error: 152.6604\n",
      "Epoch 310/500\n",
      "506/526 [===========================>..] - ETA: 0s - loss: 119.9245 - mean_squared_error: 119.9245\n",
      "Epoch 00310: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 542us/step - loss: 119.1361 - mean_squared_error: 119.1361 - val_loss: 135.9704 - val_mean_squared_error: 135.9704\n",
      "Epoch 311/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 121.3945 - mean_squared_error: 121.3945\n",
      "Epoch 00311: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 525us/step - loss: 121.5588 - mean_squared_error: 121.5588 - val_loss: 139.8141 - val_mean_squared_error: 139.8141\n",
      "Epoch 312/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 119.1627 - mean_squared_error: 119.1627\n",
      "Epoch 00312: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 527us/step - loss: 119.2396 - mean_squared_error: 119.2396 - val_loss: 140.4619 - val_mean_squared_error: 140.4619\n",
      "Epoch 313/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 118.3883 - mean_squared_error: 118.3883\n",
      "Epoch 00313: val_loss did not improve from 133.72739\n",
      "526/526 [==============================] - 0s 518us/step - loss: 120.4597 - mean_squared_error: 120.4597 - val_loss: 136.2126 - val_mean_squared_error: 136.2126\n",
      "Epoch 314/500\n",
      "419/526 [======================>.......] - ETA: 0s - loss: 118.5546 - mean_squared_error: 118.5546\n",
      "Epoch 00314: val_loss improved from 133.72739 to 129.34189, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 714us/step - loss: 119.0471 - mean_squared_error: 119.0471 - val_loss: 129.3419 - val_mean_squared_error: 129.3419\n",
      "Epoch 315/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 117.7419 - mean_squared_error: 117.7419\n",
      "Epoch 00315: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 525us/step - loss: 117.7419 - mean_squared_error: 117.7419 - val_loss: 142.5801 - val_mean_squared_error: 142.5801\n",
      "Epoch 316/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 121.4223 - mean_squared_error: 121.4223\n",
      "Epoch 00316: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 523us/step - loss: 120.5485 - mean_squared_error: 120.5485 - val_loss: 141.3273 - val_mean_squared_error: 141.3273\n",
      "Epoch 317/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 120.7416 - mean_squared_error: 120.7416\n",
      "Epoch 00317: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 533us/step - loss: 120.9988 - mean_squared_error: 120.9988 - val_loss: 146.5065 - val_mean_squared_error: 146.5065\n",
      "Epoch 318/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 120.3338 - mean_squared_error: 120.3338\n",
      "Epoch 00318: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 525us/step - loss: 120.3338 - mean_squared_error: 120.3338 - val_loss: 140.4821 - val_mean_squared_error: 140.4821\n",
      "Epoch 319/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 120.4008 - mean_squared_error: 120.4008\n",
      "Epoch 00319: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 533us/step - loss: 120.3627 - mean_squared_error: 120.3627 - val_loss: 144.4100 - val_mean_squared_error: 144.4100\n",
      "Epoch 320/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 121.4076 - mean_squared_error: 121.4076\n",
      "Epoch 00320: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 523us/step - loss: 119.3783 - mean_squared_error: 119.3783 - val_loss: 134.4214 - val_mean_squared_error: 134.4214\n",
      "Epoch 321/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 120.3285 - mean_squared_error: 120.3285\n",
      "Epoch 00321: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 533us/step - loss: 120.4184 - mean_squared_error: 120.4184 - val_loss: 135.3724 - val_mean_squared_error: 135.3724\n",
      "Epoch 322/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 119.4006 - mean_squared_error: 119.4006\n",
      "Epoch 00322: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 525us/step - loss: 119.4632 - mean_squared_error: 119.4632 - val_loss: 136.8648 - val_mean_squared_error: 136.8648\n",
      "Epoch 323/500\n",
      "422/526 [=======================>......] - ETA: 0s - loss: 118.8253 - mean_squared_error: 118.8253\n",
      "Epoch 00323: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 523us/step - loss: 117.4921 - mean_squared_error: 117.4921 - val_loss: 136.9076 - val_mean_squared_error: 136.9076\n",
      "Epoch 324/500\n",
      "505/526 [===========================>..] - ETA: 0s - loss: 116.7630 - mean_squared_error: 116.7630\n",
      "Epoch 00324: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 544us/step - loss: 117.6344 - mean_squared_error: 117.6344 - val_loss: 132.7329 - val_mean_squared_error: 132.7329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 117.1450 - mean_squared_error: 117.1450\n",
      "Epoch 00325: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 531us/step - loss: 117.1043 - mean_squared_error: 117.1043 - val_loss: 139.1177 - val_mean_squared_error: 139.1177\n",
      "Epoch 326/500\n",
      "422/526 [=======================>......] - ETA: 0s - loss: 121.1976 - mean_squared_error: 121.1976\n",
      "Epoch 00326: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 521us/step - loss: 121.7436 - mean_squared_error: 121.7436 - val_loss: 151.8322 - val_mean_squared_error: 151.8322\n",
      "Epoch 327/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 120.6979 - mean_squared_error: 120.6979\n",
      "Epoch 00327: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 518us/step - loss: 118.4013 - mean_squared_error: 118.4013 - val_loss: 136.5953 - val_mean_squared_error: 136.5953\n",
      "Epoch 328/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 115.8909 - mean_squared_error: 115.8909\n",
      "Epoch 00328: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 531us/step - loss: 115.8851 - mean_squared_error: 115.8851 - val_loss: 169.1942 - val_mean_squared_error: 169.1942\n",
      "Epoch 329/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 116.1956 - mean_squared_error: 116.1956\n",
      "Epoch 00329: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 529us/step - loss: 116.3591 - mean_squared_error: 116.3591 - val_loss: 143.1561 - val_mean_squared_error: 143.1561\n",
      "Epoch 330/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 116.6668 - mean_squared_error: 116.6668\n",
      "Epoch 00330: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 537us/step - loss: 116.3555 - mean_squared_error: 116.3555 - val_loss: 139.8691 - val_mean_squared_error: 139.8691\n",
      "Epoch 331/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 117.8289 - mean_squared_error: 117.8289\n",
      "Epoch 00331: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 539us/step - loss: 117.9924 - mean_squared_error: 117.9924 - val_loss: 146.0795 - val_mean_squared_error: 146.0795\n",
      "Epoch 332/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 116.5179 - mean_squared_error: 116.5179\n",
      "Epoch 00332: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 537us/step - loss: 116.2596 - mean_squared_error: 116.2596 - val_loss: 143.5188 - val_mean_squared_error: 143.5188\n",
      "Epoch 333/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 117.3503 - mean_squared_error: 117.3503\n",
      "Epoch 00333: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 527us/step - loss: 117.3503 - mean_squared_error: 117.3503 - val_loss: 139.6150 - val_mean_squared_error: 139.6150\n",
      "Epoch 334/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 119.3838 - mean_squared_error: 119.3838\n",
      "Epoch 00334: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 535us/step - loss: 119.2930 - mean_squared_error: 119.2930 - val_loss: 138.2816 - val_mean_squared_error: 138.2816\n",
      "Epoch 335/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 115.1688 - mean_squared_error: 115.1688\n",
      "Epoch 00335: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 535us/step - loss: 115.2403 - mean_squared_error: 115.2403 - val_loss: 142.0770 - val_mean_squared_error: 142.0770\n",
      "Epoch 336/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 115.5829 - mean_squared_error: 115.5829\n",
      "Epoch 00336: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 527us/step - loss: 115.5829 - mean_squared_error: 115.5829 - val_loss: 140.7715 - val_mean_squared_error: 140.7715\n",
      "Epoch 337/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 114.2518 - mean_squared_error: 114.2518\n",
      "Epoch 00337: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 519us/step - loss: 115.4271 - mean_squared_error: 115.4271 - val_loss: 141.3125 - val_mean_squared_error: 141.3125\n",
      "Epoch 338/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 117.4152 - mean_squared_error: 117.4152\n",
      "Epoch 00338: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 519us/step - loss: 118.3757 - mean_squared_error: 118.3757 - val_loss: 141.1544 - val_mean_squared_error: 141.1544\n",
      "Epoch 339/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 115.9449 - mean_squared_error: 115.9449\n",
      "Epoch 00339: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 535us/step - loss: 115.8587 - mean_squared_error: 115.8587 - val_loss: 131.2990 - val_mean_squared_error: 131.2990\n",
      "Epoch 340/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 116.6185 - mean_squared_error: 116.6185\n",
      "Epoch 00340: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 537us/step - loss: 116.4174 - mean_squared_error: 116.4174 - val_loss: 140.1105 - val_mean_squared_error: 140.1105\n",
      "Epoch 341/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 115.4229 - mean_squared_error: 115.4229\n",
      "Epoch 00341: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 527us/step - loss: 115.4229 - mean_squared_error: 115.4229 - val_loss: 139.5142 - val_mean_squared_error: 139.5142\n",
      "Epoch 342/500\n",
      "422/526 [=======================>......] - ETA: 0s - loss: 112.9633 - mean_squared_error: 112.9633\n",
      "Epoch 00342: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 521us/step - loss: 116.2335 - mean_squared_error: 116.2335 - val_loss: 133.4414 - val_mean_squared_error: 133.4414\n",
      "Epoch 343/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 116.4573 - mean_squared_error: 116.4573\n",
      "Epoch 00343: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 518us/step - loss: 115.4234 - mean_squared_error: 115.4234 - val_loss: 137.5457 - val_mean_squared_error: 137.5457\n",
      "Epoch 344/500\n",
      "419/526 [======================>.......] - ETA: 0s - loss: 111.3461 - mean_squared_error: 111.3461\n",
      "Epoch 00344: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 523us/step - loss: 112.8344 - mean_squared_error: 112.8344 - val_loss: 139.7450 - val_mean_squared_error: 139.7450\n",
      "Epoch 345/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 113.5622 - mean_squared_error: 113.5622\n",
      "Epoch 00345: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 527us/step - loss: 113.5622 - mean_squared_error: 113.5622 - val_loss: 149.2906 - val_mean_squared_error: 149.2906\n",
      "Epoch 346/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 114.5202 - mean_squared_error: 114.5202\n",
      "Epoch 00346: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 521us/step - loss: 114.5454 - mean_squared_error: 114.5454 - val_loss: 129.6569 - val_mean_squared_error: 129.6569\n",
      "Epoch 347/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 114.3477 - mean_squared_error: 114.3477\n",
      "Epoch 00347: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 540us/step - loss: 114.5270 - mean_squared_error: 114.5270 - val_loss: 130.8232 - val_mean_squared_error: 130.8232\n",
      "Epoch 348/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 116.9950 - mean_squared_error: 116.9950\n",
      "Epoch 00348: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 527us/step - loss: 117.0427 - mean_squared_error: 117.0427 - val_loss: 145.8068 - val_mean_squared_error: 145.8068\n",
      "Epoch 349/500\n",
      "423/526 [=======================>......] - ETA: 0s - loss: 118.1187 - mean_squared_error: 118.1187\n",
      "Epoch 00349: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 523us/step - loss: 117.0464 - mean_squared_error: 117.0464 - val_loss: 137.4154 - val_mean_squared_error: 137.4154\n",
      "Epoch 350/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 114.1506 - mean_squared_error: 114.1506\n",
      "Epoch 00350: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 531us/step - loss: 114.2511 - mean_squared_error: 114.2511 - val_loss: 141.7484 - val_mean_squared_error: 141.7484\n",
      "Epoch 351/500\n",
      "422/526 [=======================>......] - ETA: 0s - loss: 111.6166 - mean_squared_error: 111.6166\n",
      "Epoch 00351: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 523us/step - loss: 114.2780 - mean_squared_error: 114.2780 - val_loss: 135.6323 - val_mean_squared_error: 135.6323\n",
      "Epoch 352/500\n",
      "503/526 [===========================>..] - ETA: 0s - loss: 114.9145 - mean_squared_error: 114.9145\n",
      "Epoch 00352: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 548us/step - loss: 115.7942 - mean_squared_error: 115.7942 - val_loss: 132.3822 - val_mean_squared_error: 132.3822\n",
      "Epoch 353/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 113.9546 - mean_squared_error: 113.9546\n",
      "Epoch 00353: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 540us/step - loss: 113.6774 - mean_squared_error: 113.6774 - val_loss: 141.2571 - val_mean_squared_error: 141.2571\n",
      "Epoch 354/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 115.5609 - mean_squared_error: 115.5609\n",
      "Epoch 00354: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 527us/step - loss: 115.4653 - mean_squared_error: 115.4653 - val_loss: 139.1855 - val_mean_squared_error: 139.1855\n",
      "Epoch 355/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 110.9639 - mean_squared_error: 110.9639\n",
      "Epoch 00355: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 533us/step - loss: 110.9547 - mean_squared_error: 110.9547 - val_loss: 132.8353 - val_mean_squared_error: 132.8353\n",
      "Epoch 356/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 116.5924 - mean_squared_error: 116.5924\n",
      "Epoch 00356: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 527us/step - loss: 116.6665 - mean_squared_error: 116.6665 - val_loss: 135.0287 - val_mean_squared_error: 135.0287\n",
      "Epoch 357/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 113.5939 - mean_squared_error: 113.5939\n",
      "Epoch 00357: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 516us/step - loss: 113.8494 - mean_squared_error: 113.8494 - val_loss: 140.6176 - val_mean_squared_error: 140.6176\n",
      "Epoch 358/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 113.5398 - mean_squared_error: 113.5398\n",
      "Epoch 00358: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 539us/step - loss: 114.0604 - mean_squared_error: 114.0604 - val_loss: 141.8425 - val_mean_squared_error: 141.8425\n",
      "Epoch 359/500\n",
      "495/526 [===========================>..] - ETA: 0s - loss: 113.6750 - mean_squared_error: 113.6750\n",
      "Epoch 00359: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 556us/step - loss: 113.6239 - mean_squared_error: 113.6239 - val_loss: 146.1013 - val_mean_squared_error: 146.1013\n",
      "Epoch 360/500\n",
      "505/526 [===========================>..] - ETA: 0s - loss: 112.7244 - mean_squared_error: 112.7244\n",
      "Epoch 00360: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 548us/step - loss: 112.0180 - mean_squared_error: 112.0180 - val_loss: 133.8984 - val_mean_squared_error: 133.8984\n",
      "Epoch 361/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 113.6292 - mean_squared_error: 113.6292\n",
      "Epoch 00361: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 533us/step - loss: 114.2797 - mean_squared_error: 114.2797 - val_loss: 155.2291 - val_mean_squared_error: 155.2291\n",
      "Epoch 362/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 111.5735 - mean_squared_error: 111.5735\n",
      "Epoch 00362: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 546us/step - loss: 112.1641 - mean_squared_error: 112.1641 - val_loss: 149.4081 - val_mean_squared_error: 149.4081\n",
      "Epoch 363/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 112.4975 - mean_squared_error: 112.4975\n",
      "Epoch 00363: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 539us/step - loss: 112.9433 - mean_squared_error: 112.9433 - val_loss: 161.2694 - val_mean_squared_error: 161.2694\n",
      "Epoch 364/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 111.6546 - mean_squared_error: 111.6546\n",
      "Epoch 00364: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 537us/step - loss: 111.6359 - mean_squared_error: 111.6359 - val_loss: 139.6315 - val_mean_squared_error: 139.6315\n",
      "Epoch 365/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 114.5660 - mean_squared_error: 114.5660\n",
      "Epoch 00365: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 533us/step - loss: 114.3244 - mean_squared_error: 114.3244 - val_loss: 129.3692 - val_mean_squared_error: 129.3692\n",
      "Epoch 366/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 110.2061 - mean_squared_error: 110.2061\n",
      "Epoch 00366: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 533us/step - loss: 110.2909 - mean_squared_error: 110.2909 - val_loss: 135.0576 - val_mean_squared_error: 135.0576\n",
      "Epoch 367/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 112.2747 - mean_squared_error: 112.2747\n",
      "Epoch 00367: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 544us/step - loss: 112.3109 - mean_squared_error: 112.3109 - val_loss: 147.1751 - val_mean_squared_error: 147.1751\n",
      "Epoch 368/500\n",
      "422/526 [=======================>......] - ETA: 0s - loss: 113.3513 - mean_squared_error: 113.3513\n",
      "Epoch 00368: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 519us/step - loss: 111.7353 - mean_squared_error: 111.7353 - val_loss: 150.9334 - val_mean_squared_error: 150.9334\n",
      "Epoch 369/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 110.2659 - mean_squared_error: 110.2659\n",
      "Epoch 00369: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 514us/step - loss: 109.9948 - mean_squared_error: 109.9948 - val_loss: 133.4126 - val_mean_squared_error: 133.4126\n",
      "Epoch 370/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 109.0645 - mean_squared_error: 109.0645\n",
      "Epoch 00370: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 512us/step - loss: 111.0492 - mean_squared_error: 111.0492 - val_loss: 135.1477 - val_mean_squared_error: 135.1477\n",
      "Epoch 371/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 112.6990 - mean_squared_error: 112.6990\n",
      "Epoch 00371: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 514us/step - loss: 110.5180 - mean_squared_error: 110.5180 - val_loss: 143.4832 - val_mean_squared_error: 143.4832\n",
      "Epoch 372/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 110.5299 - mean_squared_error: 110.5299\n",
      "Epoch 00372: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 512us/step - loss: 111.9977 - mean_squared_error: 111.9977 - val_loss: 141.9181 - val_mean_squared_error: 141.9181\n",
      "Epoch 373/500\n",
      "422/526 [=======================>......] - ETA: 0s - loss: 111.6853 - mean_squared_error: 111.6853\n",
      "Epoch 00373: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 523us/step - loss: 111.9788 - mean_squared_error: 111.9788 - val_loss: 136.8219 - val_mean_squared_error: 136.8219\n",
      "Epoch 374/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 111.1146 - mean_squared_error: 111.1146\n",
      "Epoch 00374: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 514us/step - loss: 110.0852 - mean_squared_error: 110.0852 - val_loss: 136.4019 - val_mean_squared_error: 136.4019\n",
      "Epoch 375/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428/526 [=======================>......] - ETA: 0s - loss: 111.0095 - mean_squared_error: 111.0095\n",
      "Epoch 00375: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 516us/step - loss: 110.7927 - mean_squared_error: 110.7927 - val_loss: 143.8042 - val_mean_squared_error: 143.8042\n",
      "Epoch 376/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 111.0882 - mean_squared_error: 111.0882\n",
      "Epoch 00376: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 525us/step - loss: 112.1952 - mean_squared_error: 112.1952 - val_loss: 131.9046 - val_mean_squared_error: 131.9046\n",
      "Epoch 377/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 111.7324 - mean_squared_error: 111.7324\n",
      "Epoch 00377: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 516us/step - loss: 111.7837 - mean_squared_error: 111.7837 - val_loss: 135.8340 - val_mean_squared_error: 135.8340\n",
      "Epoch 378/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 110.6756 - mean_squared_error: 110.6756\n",
      "Epoch 00378: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 518us/step - loss: 111.2565 - mean_squared_error: 111.2565 - val_loss: 151.4617 - val_mean_squared_error: 151.4617\n",
      "Epoch 379/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 110.3822 - mean_squared_error: 110.3822\n",
      "Epoch 00379: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 527us/step - loss: 110.3996 - mean_squared_error: 110.3996 - val_loss: 133.0958 - val_mean_squared_error: 133.0958\n",
      "Epoch 380/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 110.1477 - mean_squared_error: 110.1477\n",
      "Epoch 00380: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 516us/step - loss: 109.7672 - mean_squared_error: 109.7672 - val_loss: 130.3118 - val_mean_squared_error: 130.3118\n",
      "Epoch 381/500\n",
      "434/526 [=======================>......] - ETA: 0s - loss: 109.4325 - mean_squared_error: 109.4325\n",
      "Epoch 00381: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 512us/step - loss: 110.0797 - mean_squared_error: 110.0797 - val_loss: 141.9095 - val_mean_squared_error: 141.9095\n",
      "Epoch 382/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 108.6173 - mean_squared_error: 108.6173\n",
      "Epoch 00382: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 519us/step - loss: 109.6344 - mean_squared_error: 109.6344 - val_loss: 130.5403 - val_mean_squared_error: 130.5403\n",
      "Epoch 383/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 111.7023 - mean_squared_error: 111.7023\n",
      "Epoch 00383: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 516us/step - loss: 111.3455 - mean_squared_error: 111.3455 - val_loss: 130.1297 - val_mean_squared_error: 130.1297\n",
      "Epoch 384/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 110.3815 - mean_squared_error: 110.3815\n",
      "Epoch 00384: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 514us/step - loss: 110.4762 - mean_squared_error: 110.4762 - val_loss: 136.4319 - val_mean_squared_error: 136.4319\n",
      "Epoch 385/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 112.1609 - mean_squared_error: 112.1609\n",
      "Epoch 00385: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 512us/step - loss: 111.5488 - mean_squared_error: 111.5488 - val_loss: 131.5952 - val_mean_squared_error: 131.5952\n",
      "Epoch 386/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 107.6049 - mean_squared_error: 107.6049\n",
      "Epoch 00386: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 510us/step - loss: 108.1271 - mean_squared_error: 108.1271 - val_loss: 143.0375 - val_mean_squared_error: 143.0375\n",
      "Epoch 387/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 114.0346 - mean_squared_error: 114.0346\n",
      "Epoch 00387: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 508us/step - loss: 113.6383 - mean_squared_error: 113.6383 - val_loss: 134.1557 - val_mean_squared_error: 134.1557\n",
      "Epoch 388/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 110.8897 - mean_squared_error: 110.8897\n",
      "Epoch 00388: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 512us/step - loss: 111.0418 - mean_squared_error: 111.0418 - val_loss: 132.9523 - val_mean_squared_error: 132.9523\n",
      "Epoch 389/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 108.7980 - mean_squared_error: 108.7980\n",
      "Epoch 00389: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 510us/step - loss: 109.8445 - mean_squared_error: 109.8445 - val_loss: 138.6446 - val_mean_squared_error: 138.6446\n",
      "Epoch 390/500\n",
      "436/526 [=======================>......] - ETA: 0s - loss: 105.9319 - mean_squared_error: 105.9319\n",
      "Epoch 00390: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 508us/step - loss: 107.1792 - mean_squared_error: 107.1792 - val_loss: 137.1962 - val_mean_squared_error: 137.1962\n",
      "Epoch 391/500\n",
      "425/526 [=======================>......] - ETA: 0s - loss: 111.3059 - mean_squared_error: 111.3059\n",
      "Epoch 00391: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 519us/step - loss: 108.7914 - mean_squared_error: 108.7914 - val_loss: 131.5459 - val_mean_squared_error: 131.5459\n",
      "Epoch 392/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 110.7395 - mean_squared_error: 110.7395\n",
      "Epoch 00392: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 516us/step - loss: 109.3192 - mean_squared_error: 109.3192 - val_loss: 133.5173 - val_mean_squared_error: 133.5173\n",
      "Epoch 393/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 113.2021 - mean_squared_error: 113.2021\n",
      "Epoch 00393: val_loss did not improve from 129.34189\n",
      "526/526 [==============================] - 0s 521us/step - loss: 111.1406 - mean_squared_error: 111.1406 - val_loss: 140.7104 - val_mean_squared_error: 140.7104\n",
      "Epoch 394/500\n",
      "435/526 [=======================>......] - ETA: 0s - loss: 107.4820 - mean_squared_error: 107.4820\n",
      "Epoch 00394: val_loss improved from 129.34189 to 128.77081, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 668us/step - loss: 108.8749 - mean_squared_error: 108.8749 - val_loss: 128.7708 - val_mean_squared_error: 128.7708\n",
      "Epoch 395/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 108.9598 - mean_squared_error: 108.9598\n",
      "Epoch 00395: val_loss did not improve from 128.77081\n",
      "526/526 [==============================] - 0s 518us/step - loss: 109.9778 - mean_squared_error: 109.9778 - val_loss: 134.6906 - val_mean_squared_error: 134.6906\n",
      "Epoch 396/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 110.7322 - mean_squared_error: 110.7322\n",
      "Epoch 00396: val_loss did not improve from 128.77081\n",
      "526/526 [==============================] - 0s 512us/step - loss: 109.5984 - mean_squared_error: 109.5984 - val_loss: 149.7784 - val_mean_squared_error: 149.7784\n",
      "Epoch 397/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 107.5778 - mean_squared_error: 107.5778\n",
      "Epoch 00397: val_loss did not improve from 128.77081\n",
      "526/526 [==============================] - 0s 512us/step - loss: 108.6074 - mean_squared_error: 108.6074 - val_loss: 133.4784 - val_mean_squared_error: 133.4784\n",
      "Epoch 398/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 108.6093 - mean_squared_error: 108.6093\n",
      "Epoch 00398: val_loss did not improve from 128.77081\n",
      "526/526 [==============================] - 0s 518us/step - loss: 108.9696 - mean_squared_error: 108.9696 - val_loss: 132.3078 - val_mean_squared_error: 132.3078\n",
      "Epoch 399/500\n",
      "423/526 [=======================>......] - ETA: 0s - loss: 109.0685 - mean_squared_error: 109.0685\n",
      "Epoch 00399: val_loss did not improve from 128.77081\n",
      "526/526 [==============================] - 0s 521us/step - loss: 107.3207 - mean_squared_error: 107.3207 - val_loss: 147.4583 - val_mean_squared_error: 147.4583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 108.0156 - mean_squared_error: 108.0156\n",
      "Epoch 00400: val_loss did not improve from 128.77081\n",
      "526/526 [==============================] - 0s 516us/step - loss: 110.6158 - mean_squared_error: 110.6158 - val_loss: 147.3625 - val_mean_squared_error: 147.3625\n",
      "Epoch 401/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 112.2290 - mean_squared_error: 112.2290\n",
      "Epoch 00401: val_loss did not improve from 128.77081\n",
      "526/526 [==============================] - 0s 519us/step - loss: 110.5598 - mean_squared_error: 110.5598 - val_loss: 147.9990 - val_mean_squared_error: 147.9990\n",
      "Epoch 402/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 110.3440 - mean_squared_error: 110.3440\n",
      "Epoch 00402: val_loss did not improve from 128.77081\n",
      "526/526 [==============================] - 0s 512us/step - loss: 111.5364 - mean_squared_error: 111.5364 - val_loss: 144.6127 - val_mean_squared_error: 144.6127\n",
      "Epoch 403/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 104.6747 - mean_squared_error: 104.6747\n",
      "Epoch 00403: val_loss did not improve from 128.77081\n",
      "526/526 [==============================] - 0s 516us/step - loss: 106.5316 - mean_squared_error: 106.5316 - val_loss: 144.2494 - val_mean_squared_error: 144.2494\n",
      "Epoch 404/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 109.3501 - mean_squared_error: 109.3501\n",
      "Epoch 00404: val_loss did not improve from 128.77081\n",
      "526/526 [==============================] - 0s 514us/step - loss: 109.7451 - mean_squared_error: 109.7451 - val_loss: 131.8563 - val_mean_squared_error: 131.8563\n",
      "Epoch 405/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 105.3016 - mean_squared_error: 105.3016\n",
      "Epoch 00405: val_loss did not improve from 128.77081\n",
      "526/526 [==============================] - 0s 512us/step - loss: 107.0009 - mean_squared_error: 107.0009 - val_loss: 140.4592 - val_mean_squared_error: 140.4592\n",
      "Epoch 406/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 109.0097 - mean_squared_error: 109.0097\n",
      "Epoch 00406: val_loss did not improve from 128.77081\n",
      "526/526 [==============================] - 0s 510us/step - loss: 109.8254 - mean_squared_error: 109.8254 - val_loss: 146.6895 - val_mean_squared_error: 146.6895\n",
      "Epoch 407/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 107.2743 - mean_squared_error: 107.2743\n",
      "Epoch 00407: val_loss did not improve from 128.77081\n",
      "526/526 [==============================] - 0s 514us/step - loss: 107.0263 - mean_squared_error: 107.0263 - val_loss: 145.1701 - val_mean_squared_error: 145.1701\n",
      "Epoch 408/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 108.8072 - mean_squared_error: 108.8072\n",
      "Epoch 00408: val_loss did not improve from 128.77081\n",
      "526/526 [==============================] - 0s 512us/step - loss: 108.8829 - mean_squared_error: 108.8829 - val_loss: 135.6743 - val_mean_squared_error: 135.6743\n",
      "Epoch 409/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 105.6397 - mean_squared_error: 105.6397\n",
      "Epoch 00409: val_loss did not improve from 128.77081\n",
      "526/526 [==============================] - 0s 516us/step - loss: 105.7362 - mean_squared_error: 105.7362 - val_loss: 132.5466 - val_mean_squared_error: 132.5466\n",
      "Epoch 410/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 108.2012 - mean_squared_error: 108.2012\n",
      "Epoch 00410: val_loss improved from 128.77081 to 124.61942, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 685us/step - loss: 107.4712 - mean_squared_error: 107.4712 - val_loss: 124.6194 - val_mean_squared_error: 124.6194\n",
      "Epoch 411/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 106.5948 - mean_squared_error: 106.5948\n",
      "Epoch 00411: val_loss did not improve from 124.61942\n",
      "526/526 [==============================] - 0s 516us/step - loss: 107.0870 - mean_squared_error: 107.0870 - val_loss: 139.7227 - val_mean_squared_error: 139.7227\n",
      "Epoch 412/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 106.7722 - mean_squared_error: 106.7722\n",
      "Epoch 00412: val_loss did not improve from 124.61942\n",
      "526/526 [==============================] - 0s 527us/step - loss: 106.9447 - mean_squared_error: 106.9447 - val_loss: 130.1764 - val_mean_squared_error: 130.1764\n",
      "Epoch 413/500\n",
      "421/526 [=======================>......] - ETA: 0s - loss: 109.4887 - mean_squared_error: 109.4887\n",
      "Epoch 00413: val_loss did not improve from 124.61942\n",
      "526/526 [==============================] - 0s 521us/step - loss: 108.3698 - mean_squared_error: 108.3698 - val_loss: 130.7131 - val_mean_squared_error: 130.7131\n",
      "Epoch 414/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 106.6273 - mean_squared_error: 106.6273\n",
      "Epoch 00414: val_loss did not improve from 124.61942\n",
      "526/526 [==============================] - 0s 542us/step - loss: 106.6693 - mean_squared_error: 106.6693 - val_loss: 137.8115 - val_mean_squared_error: 137.8115\n",
      "Epoch 415/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 104.3078 - mean_squared_error: 104.3078\n",
      "Epoch 00415: val_loss did not improve from 124.61942\n",
      "526/526 [==============================] - 0s 542us/step - loss: 104.4387 - mean_squared_error: 104.4387 - val_loss: 148.5772 - val_mean_squared_error: 148.5772\n",
      "Epoch 416/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 107.1236 - mean_squared_error: 107.1236\n",
      "Epoch 00416: val_loss did not improve from 124.61942\n",
      "526/526 [==============================] - 0s 535us/step - loss: 106.8327 - mean_squared_error: 106.8327 - val_loss: 134.5224 - val_mean_squared_error: 134.5224\n",
      "Epoch 417/500\n",
      "505/526 [===========================>..] - ETA: 0s - loss: 105.8944 - mean_squared_error: 105.8944\n",
      "Epoch 00417: val_loss did not improve from 124.61942\n",
      "526/526 [==============================] - 0s 548us/step - loss: 106.1503 - mean_squared_error: 106.1503 - val_loss: 143.3930 - val_mean_squared_error: 143.3930\n",
      "Epoch 418/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 110.4794 - mean_squared_error: 110.4794\n",
      "Epoch 00418: val_loss did not improve from 124.61942\n",
      "526/526 [==============================] - 0s 529us/step - loss: 110.5893 - mean_squared_error: 110.5893 - val_loss: 129.0570 - val_mean_squared_error: 129.0570\n",
      "Epoch 419/500\n",
      "500/526 [===========================>..] - ETA: 0s - loss: 106.9346 - mean_squared_error: 106.9346\n",
      "Epoch 00419: val_loss did not improve from 124.61942\n",
      "526/526 [==============================] - 0s 550us/step - loss: 106.3802 - mean_squared_error: 106.3802 - val_loss: 134.6853 - val_mean_squared_error: 134.6853\n",
      "Epoch 420/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 107.8420 - mean_squared_error: 107.8420\n",
      "Epoch 00420: val_loss did not improve from 124.61942\n",
      "526/526 [==============================] - 0s 531us/step - loss: 107.8565 - mean_squared_error: 107.8565 - val_loss: 136.5917 - val_mean_squared_error: 136.5917\n",
      "Epoch 421/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 110.0335 - mean_squared_error: 110.0335\n",
      "Epoch 00421: val_loss did not improve from 124.61942\n",
      "526/526 [==============================] - 0s 531us/step - loss: 109.7910 - mean_squared_error: 109.7910 - val_loss: 148.2656 - val_mean_squared_error: 148.2656\n",
      "Epoch 422/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 102.3996 - mean_squared_error: 102.3996\n",
      "Epoch 00422: val_loss did not improve from 124.61942\n",
      "526/526 [==============================] - 0s 523us/step - loss: 104.7881 - mean_squared_error: 104.7881 - val_loss: 141.2191 - val_mean_squared_error: 141.2191\n",
      "Epoch 423/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 105.4546 - mean_squared_error: 105.4546\n",
      "Epoch 00423: val_loss did not improve from 124.61942\n",
      "526/526 [==============================] - 0s 529us/step - loss: 105.5302 - mean_squared_error: 105.5302 - val_loss: 138.7477 - val_mean_squared_error: 138.7477\n",
      "Epoch 424/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 105.0010 - mean_squared_error: 105.0010\n",
      "Epoch 00424: val_loss did not improve from 124.61942\n",
      "526/526 [==============================] - 0s 512us/step - loss: 106.5758 - mean_squared_error: 106.5758 - val_loss: 137.9145 - val_mean_squared_error: 137.9145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 104.4922 - mean_squared_error: 104.4922\n",
      "Epoch 00425: val_loss did not improve from 124.61942\n",
      "526/526 [==============================] - 0s 519us/step - loss: 105.3479 - mean_squared_error: 105.3479 - val_loss: 126.0041 - val_mean_squared_error: 126.0041\n",
      "Epoch 426/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 104.4612 - mean_squared_error: 104.4612\n",
      "Epoch 00426: val_loss improved from 124.61942 to 123.40611, saving model to model1.hdf5\n",
      "526/526 [==============================] - 0s 666us/step - loss: 104.4666 - mean_squared_error: 104.4666 - val_loss: 123.4061 - val_mean_squared_error: 123.4061\n",
      "Epoch 427/500\n",
      "425/526 [=======================>......] - ETA: 0s - loss: 106.0058 - mean_squared_error: 106.0058\n",
      "Epoch 00427: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 519us/step - loss: 105.9179 - mean_squared_error: 105.9179 - val_loss: 152.7446 - val_mean_squared_error: 152.7446\n",
      "Epoch 428/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 103.0084 - mean_squared_error: 103.0084\n",
      "Epoch 00428: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 523us/step - loss: 104.4603 - mean_squared_error: 104.4603 - val_loss: 139.1405 - val_mean_squared_error: 139.1405\n",
      "Epoch 429/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 104.1819 - mean_squared_error: 104.1819\n",
      "Epoch 00429: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 516us/step - loss: 105.0261 - mean_squared_error: 105.0261 - val_loss: 132.9640 - val_mean_squared_error: 132.9640\n",
      "Epoch 430/500\n",
      "420/526 [======================>.......] - ETA: 0s - loss: 110.3853 - mean_squared_error: 110.3853\n",
      "Epoch 00430: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 525us/step - loss: 107.8599 - mean_squared_error: 107.8599 - val_loss: 138.5970 - val_mean_squared_error: 138.5970\n",
      "Epoch 431/500\n",
      "421/526 [=======================>......] - ETA: 0s - loss: 103.7035 - mean_squared_error: 103.7035\n",
      "Epoch 00431: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 523us/step - loss: 105.3273 - mean_squared_error: 105.3273 - val_loss: 141.2449 - val_mean_squared_error: 141.2449\n",
      "Epoch 432/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 107.2059 - mean_squared_error: 107.2059\n",
      "Epoch 00432: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 525us/step - loss: 107.2059 - mean_squared_error: 107.2059 - val_loss: 134.0286 - val_mean_squared_error: 134.0286\n",
      "Epoch 433/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 103.4782 - mean_squared_error: 103.4782\n",
      "Epoch 00433: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 514us/step - loss: 103.6862 - mean_squared_error: 103.6862 - val_loss: 135.2539 - val_mean_squared_error: 135.2539\n",
      "Epoch 434/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 105.1422 - mean_squared_error: 105.1422\n",
      "Epoch 00434: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 529us/step - loss: 105.2902 - mean_squared_error: 105.2902 - val_loss: 130.5668 - val_mean_squared_error: 130.5668\n",
      "Epoch 435/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 103.5994 - mean_squared_error: 103.5994\n",
      "Epoch 00435: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 519us/step - loss: 105.3250 - mean_squared_error: 105.3250 - val_loss: 128.7328 - val_mean_squared_error: 128.7328\n",
      "Epoch 436/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 105.3095 - mean_squared_error: 105.3095\n",
      "Epoch 00436: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 518us/step - loss: 106.2510 - mean_squared_error: 106.2510 - val_loss: 132.4694 - val_mean_squared_error: 132.4694\n",
      "Epoch 437/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 101.8637 - mean_squared_error: 101.8637\n",
      "Epoch 00437: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 516us/step - loss: 104.9079 - mean_squared_error: 104.9079 - val_loss: 133.8184 - val_mean_squared_error: 133.8184\n",
      "Epoch 438/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 106.0996 - mean_squared_error: 106.0996\n",
      "Epoch 00438: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 518us/step - loss: 106.3771 - mean_squared_error: 106.3771 - val_loss: 132.4469 - val_mean_squared_error: 132.4469\n",
      "Epoch 439/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 104.0985 - mean_squared_error: 104.0985\n",
      "Epoch 00439: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 518us/step - loss: 104.3457 - mean_squared_error: 104.3457 - val_loss: 125.8379 - val_mean_squared_error: 125.8379\n",
      "Epoch 440/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 107.0426 - mean_squared_error: 107.0426\n",
      "Epoch 00440: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 516us/step - loss: 105.9979 - mean_squared_error: 105.9979 - val_loss: 146.1250 - val_mean_squared_error: 146.1250\n",
      "Epoch 441/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 103.3339 - mean_squared_error: 103.3339\n",
      "Epoch 00441: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 518us/step - loss: 103.0386 - mean_squared_error: 103.0386 - val_loss: 135.0427 - val_mean_squared_error: 135.0427\n",
      "Epoch 442/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 104.9063 - mean_squared_error: 104.9063\n",
      "Epoch 00442: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 510us/step - loss: 104.1990 - mean_squared_error: 104.1990 - val_loss: 142.4344 - val_mean_squared_error: 142.4344\n",
      "Epoch 443/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 103.4276 - mean_squared_error: 103.4276\n",
      "Epoch 00443: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 519us/step - loss: 103.2749 - mean_squared_error: 103.2749 - val_loss: 136.1404 - val_mean_squared_error: 136.1404\n",
      "Epoch 444/500\n",
      "422/526 [=======================>......] - ETA: 0s - loss: 101.6441 - mean_squared_error: 101.6441\n",
      "Epoch 00444: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 523us/step - loss: 102.4934 - mean_squared_error: 102.4934 - val_loss: 125.8969 - val_mean_squared_error: 125.8969\n",
      "Epoch 445/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 102.5968 - mean_squared_error: 102.5968\n",
      "Epoch 00445: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 519us/step - loss: 103.9614 - mean_squared_error: 103.9614 - val_loss: 128.7838 - val_mean_squared_error: 128.7838\n",
      "Epoch 446/500\n",
      "423/526 [=======================>......] - ETA: 0s - loss: 103.0852 - mean_squared_error: 103.0852\n",
      "Epoch 00446: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 519us/step - loss: 102.2565 - mean_squared_error: 102.2565 - val_loss: 136.5827 - val_mean_squared_error: 136.5827\n",
      "Epoch 447/500\n",
      "425/526 [=======================>......] - ETA: 0s - loss: 105.7689 - mean_squared_error: 105.7689\n",
      "Epoch 00447: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 523us/step - loss: 106.1900 - mean_squared_error: 106.1900 - val_loss: 133.1145 - val_mean_squared_error: 133.1145\n",
      "Epoch 448/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 104.3799 - mean_squared_error: 104.3799\n",
      "Epoch 00448: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 518us/step - loss: 104.2448 - mean_squared_error: 104.2448 - val_loss: 126.9421 - val_mean_squared_error: 126.9421\n",
      "Epoch 449/500\n",
      "434/526 [=======================>......] - ETA: 0s - loss: 103.8102 - mean_squared_error: 103.8102\n",
      "Epoch 00449: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 510us/step - loss: 103.5264 - mean_squared_error: 103.5264 - val_loss: 128.4983 - val_mean_squared_error: 128.4983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 102.9436 - mean_squared_error: 102.9436\n",
      "Epoch 00450: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 519us/step - loss: 102.4376 - mean_squared_error: 102.4376 - val_loss: 131.9510 - val_mean_squared_error: 131.9510\n",
      "Epoch 451/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 104.3370 - mean_squared_error: 104.3370\n",
      "Epoch 00451: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 525us/step - loss: 104.3370 - mean_squared_error: 104.3370 - val_loss: 133.8362 - val_mean_squared_error: 133.8362\n",
      "Epoch 452/500\n",
      "421/526 [=======================>......] - ETA: 0s - loss: 103.9166 - mean_squared_error: 103.9166\n",
      "Epoch 00452: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 523us/step - loss: 102.8290 - mean_squared_error: 102.8290 - val_loss: 132.7946 - val_mean_squared_error: 132.7946\n",
      "Epoch 453/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 103.7287 - mean_squared_error: 103.7287\n",
      "Epoch 00453: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 518us/step - loss: 103.7677 - mean_squared_error: 103.7677 - val_loss: 127.5135 - val_mean_squared_error: 127.5135\n",
      "Epoch 454/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 102.2732 - mean_squared_error: 102.2732\n",
      "Epoch 00454: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 512us/step - loss: 103.9204 - mean_squared_error: 103.9204 - val_loss: 142.4678 - val_mean_squared_error: 142.4678\n",
      "Epoch 455/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 103.4926 - mean_squared_error: 103.4926\n",
      "Epoch 00455: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 518us/step - loss: 103.8528 - mean_squared_error: 103.8528 - val_loss: 137.5787 - val_mean_squared_error: 137.5787\n",
      "Epoch 456/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 102.3016 - mean_squared_error: 102.3016\n",
      "Epoch 00456: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 518us/step - loss: 102.5856 - mean_squared_error: 102.5856 - val_loss: 134.3499 - val_mean_squared_error: 134.3499\n",
      "Epoch 457/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 105.9930 - mean_squared_error: 105.9930\n",
      "Epoch 00457: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 512us/step - loss: 105.2293 - mean_squared_error: 105.2293 - val_loss: 132.6572 - val_mean_squared_error: 132.6572\n",
      "Epoch 458/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 103.2546 - mean_squared_error: 103.2546\n",
      "Epoch 00458: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 516us/step - loss: 101.9936 - mean_squared_error: 101.9936 - val_loss: 131.6659 - val_mean_squared_error: 131.6659\n",
      "Epoch 459/500\n",
      "422/526 [=======================>......] - ETA: 0s - loss: 102.6771 - mean_squared_error: 102.6771\n",
      "Epoch 00459: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 523us/step - loss: 101.0520 - mean_squared_error: 101.0520 - val_loss: 127.6277 - val_mean_squared_error: 127.6277\n",
      "Epoch 460/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 103.1171 - mean_squared_error: 103.1171\n",
      "Epoch 00460: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 518us/step - loss: 103.0200 - mean_squared_error: 103.0200 - val_loss: 152.2586 - val_mean_squared_error: 152.2586\n",
      "Epoch 461/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 102.3690 - mean_squared_error: 102.3690\n",
      "Epoch 00461: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 514us/step - loss: 101.9342 - mean_squared_error: 101.9342 - val_loss: 128.8021 - val_mean_squared_error: 128.8021\n",
      "Epoch 462/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 108.0171 - mean_squared_error: 108.0171\n",
      "Epoch 00462: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 510us/step - loss: 105.9604 - mean_squared_error: 105.9604 - val_loss: 129.4952 - val_mean_squared_error: 129.4952\n",
      "Epoch 463/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 102.1472 - mean_squared_error: 102.1472\n",
      "Epoch 00463: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 516us/step - loss: 101.7463 - mean_squared_error: 101.7463 - val_loss: 142.9910 - val_mean_squared_error: 142.9910\n",
      "Epoch 464/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 101.6612 - mean_squared_error: 101.6612\n",
      "Epoch 00464: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 519us/step - loss: 103.0632 - mean_squared_error: 103.0632 - val_loss: 151.7872 - val_mean_squared_error: 151.7872\n",
      "Epoch 465/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 102.0103 - mean_squared_error: 102.0103\n",
      "Epoch 00465: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 531us/step - loss: 101.7588 - mean_squared_error: 101.7588 - val_loss: 126.2056 - val_mean_squared_error: 126.2056\n",
      "Epoch 466/500\n",
      "423/526 [=======================>......] - ETA: 0s - loss: 106.6590 - mean_squared_error: 106.6590\n",
      "Epoch 00466: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 523us/step - loss: 104.1265 - mean_squared_error: 104.1265 - val_loss: 132.1970 - val_mean_squared_error: 132.1970\n",
      "Epoch 467/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 99.0213 - mean_squared_error: 99.0213\n",
      "Epoch 00467: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 510us/step - loss: 100.9716 - mean_squared_error: 100.9716 - val_loss: 134.8064 - val_mean_squared_error: 134.8064\n",
      "Epoch 468/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 101.6957 - mean_squared_error: 101.6957\n",
      "Epoch 00468: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 514us/step - loss: 101.9391 - mean_squared_error: 101.9391 - val_loss: 168.0374 - val_mean_squared_error: 168.0374\n",
      "Epoch 469/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 101.5890 - mean_squared_error: 101.5890\n",
      "Epoch 00469: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 512us/step - loss: 103.9772 - mean_squared_error: 103.9772 - val_loss: 128.8433 - val_mean_squared_error: 128.8433\n",
      "Epoch 470/500\n",
      "423/526 [=======================>......] - ETA: 0s - loss: 103.0674 - mean_squared_error: 103.0674\n",
      "Epoch 00470: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 523us/step - loss: 101.5972 - mean_squared_error: 101.5972 - val_loss: 130.9035 - val_mean_squared_error: 130.9035\n",
      "Epoch 471/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 99.8750 - mean_squared_error: 99.8750\n",
      "Epoch 00471: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 521us/step - loss: 101.6215 - mean_squared_error: 101.6215 - val_loss: 138.4302 - val_mean_squared_error: 138.4302\n",
      "Epoch 472/500\n",
      "425/526 [=======================>......] - ETA: 0s - loss: 100.1345 - mean_squared_error: 100.1345\n",
      "Epoch 00472: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 516us/step - loss: 101.5015 - mean_squared_error: 101.5015 - val_loss: 131.5159 - val_mean_squared_error: 131.5159\n",
      "Epoch 473/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 99.7211 - mean_squared_error: 99.7211  \n",
      "Epoch 00473: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 510us/step - loss: 100.2148 - mean_squared_error: 100.2148 - val_loss: 133.6447 - val_mean_squared_error: 133.6447\n",
      "Epoch 474/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 102.4666 - mean_squared_error: 102.4666\n",
      "Epoch 00474: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 518us/step - loss: 101.7417 - mean_squared_error: 101.7417 - val_loss: 143.6464 - val_mean_squared_error: 143.6464\n",
      "Epoch 475/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 101.6255 - mean_squared_error: 101.6255\n",
      "Epoch 00475: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 527us/step - loss: 101.5765 - mean_squared_error: 101.5765 - val_loss: 134.7261 - val_mean_squared_error: 134.7261\n",
      "Epoch 476/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 103.4057 - mean_squared_error: 103.4057\n",
      "Epoch 00476: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 516us/step - loss: 103.0241 - mean_squared_error: 103.0241 - val_loss: 148.9023 - val_mean_squared_error: 148.9023\n",
      "Epoch 477/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 102.8394 - mean_squared_error: 102.8394\n",
      "Epoch 00477: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 512us/step - loss: 104.7293 - mean_squared_error: 104.7293 - val_loss: 138.5629 - val_mean_squared_error: 138.5629\n",
      "Epoch 478/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 106.0533 - mean_squared_error: 106.0533\n",
      "Epoch 00478: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 512us/step - loss: 102.7559 - mean_squared_error: 102.7559 - val_loss: 134.5679 - val_mean_squared_error: 134.5679\n",
      "Epoch 479/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 102.2386 - mean_squared_error: 102.2386\n",
      "Epoch 00479: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 512us/step - loss: 102.3597 - mean_squared_error: 102.3597 - val_loss: 135.4795 - val_mean_squared_error: 135.4795\n",
      "Epoch 480/500\n",
      "428/526 [=======================>......] - ETA: 0s - loss: 97.2380 - mean_squared_error: 97.2380\n",
      "Epoch 00480: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 514us/step - loss: 99.5193 - mean_squared_error: 99.5193 - val_loss: 130.3932 - val_mean_squared_error: 130.3932\n",
      "Epoch 481/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 99.7216 - mean_squared_error: 99.7216\n",
      "Epoch 00481: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 510us/step - loss: 100.5390 - mean_squared_error: 100.5390 - val_loss: 129.2394 - val_mean_squared_error: 129.2394\n",
      "Epoch 482/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 100.5685 - mean_squared_error: 100.5685\n",
      "Epoch 00482: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 512us/step - loss: 99.6364 - mean_squared_error: 99.6364 - val_loss: 134.0687 - val_mean_squared_error: 134.0687\n",
      "Epoch 483/500\n",
      "423/526 [=======================>......] - ETA: 0s - loss: 100.4736 - mean_squared_error: 100.4736\n",
      "Epoch 00483: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 518us/step - loss: 100.6472 - mean_squared_error: 100.6472 - val_loss: 124.7161 - val_mean_squared_error: 124.7161\n",
      "Epoch 484/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 102.5498 - mean_squared_error: 102.5498\n",
      "Epoch 00484: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 510us/step - loss: 101.5186 - mean_squared_error: 101.5186 - val_loss: 137.2554 - val_mean_squared_error: 137.2554\n",
      "Epoch 485/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 98.2980 - mean_squared_error: 98.2980\n",
      "Epoch 00485: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 516us/step - loss: 99.3627 - mean_squared_error: 99.3627 - val_loss: 139.1461 - val_mean_squared_error: 139.1461\n",
      "Epoch 486/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 100.7163 - mean_squared_error: 100.7163\n",
      "Epoch 00486: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 516us/step - loss: 101.5482 - mean_squared_error: 101.5482 - val_loss: 134.3727 - val_mean_squared_error: 134.3727\n",
      "Epoch 487/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 99.6512 - mean_squared_error: 99.6512\n",
      "Epoch 00487: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 514us/step - loss: 100.9559 - mean_squared_error: 100.9559 - val_loss: 130.7384 - val_mean_squared_error: 130.7384\n",
      "Epoch 488/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 98.2394 - mean_squared_error: 98.2394\n",
      "Epoch 00488: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 518us/step - loss: 98.9304 - mean_squared_error: 98.9304 - val_loss: 135.6117 - val_mean_squared_error: 135.6117\n",
      "Epoch 489/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 98.6115 - mean_squared_error: 98.6115\n",
      "Epoch 00489: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 525us/step - loss: 98.6353 - mean_squared_error: 98.6353 - val_loss: 131.4821 - val_mean_squared_error: 131.4821\n",
      "Epoch 490/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 98.5864 - mean_squared_error: 98.5864\n",
      "Epoch 00490: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 529us/step - loss: 98.7703 - mean_squared_error: 98.7703 - val_loss: 139.2057 - val_mean_squared_error: 139.2057\n",
      "Epoch 491/500\n",
      "425/526 [=======================>......] - ETA: 0s - loss: 102.1407 - mean_squared_error: 102.1407\n",
      "Epoch 00491: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 518us/step - loss: 102.3092 - mean_squared_error: 102.3092 - val_loss: 134.0374 - val_mean_squared_error: 134.0374\n",
      "Epoch 492/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 102.7294 - mean_squared_error: 102.7294\n",
      "Epoch 00492: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 512us/step - loss: 101.4258 - mean_squared_error: 101.4258 - val_loss: 143.2955 - val_mean_squared_error: 143.2955\n",
      "Epoch 493/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 100.4499 - mean_squared_error: 100.4499\n",
      "Epoch 00493: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 519us/step - loss: 100.9366 - mean_squared_error: 100.9366 - val_loss: 127.3500 - val_mean_squared_error: 127.3500\n",
      "Epoch 494/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 102.5521 - mean_squared_error: 102.5521\n",
      "Epoch 00494: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 512us/step - loss: 102.4743 - mean_squared_error: 102.4743 - val_loss: 126.5847 - val_mean_squared_error: 126.5847\n",
      "Epoch 495/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 99.1450 - mean_squared_error: 99.1450\n",
      "Epoch 00495: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 537us/step - loss: 98.9464 - mean_squared_error: 98.9464 - val_loss: 139.6945 - val_mean_squared_error: 139.6945\n",
      "Epoch 496/500\n",
      "423/526 [=======================>......] - ETA: 0s - loss: 100.4557 - mean_squared_error: 100.4557\n",
      "Epoch 00496: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 523us/step - loss: 99.9246 - mean_squared_error: 99.9246 - val_loss: 129.6515 - val_mean_squared_error: 129.6515\n",
      "Epoch 497/500\n",
      "423/526 [=======================>......] - ETA: 0s - loss: 97.8921 - mean_squared_error: 97.8921\n",
      "Epoch 00497: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 519us/step - loss: 98.2414 - mean_squared_error: 98.2414 - val_loss: 144.5213 - val_mean_squared_error: 144.5213\n",
      "Epoch 498/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 99.1907 - mean_squared_error: 99.1907\n",
      "Epoch 00498: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 514us/step - loss: 100.0776 - mean_squared_error: 100.0776 - val_loss: 137.1021 - val_mean_squared_error: 137.1021\n",
      "Epoch 499/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 99.1761 - mean_squared_error: 99.1761\n",
      "Epoch 00499: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 525us/step - loss: 99.1761 - mean_squared_error: 99.1761 - val_loss: 138.1065 - val_mean_squared_error: 138.1065\n",
      "Epoch 500/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421/526 [=======================>......] - ETA: 0s - loss: 98.5449 - mean_squared_error: 98.5449\n",
      "Epoch 00500: val_loss did not improve from 123.40611\n",
      "526/526 [==============================] - 0s 525us/step - loss: 99.2952 - mean_squared_error: 99.2952 - val_loss: 140.1748 - val_mean_squared_error: 140.1748\n"
     ]
    }
   ],
   "source": [
    "model1 = models.Sequential()\n",
    "model1.add(layers.Dense(256,activation=\"relu\",input_dim=81))\n",
    "model1.add(layers.Dense(128,activation=\"relu\"))\n",
    "model1.add(layers.Dense(128,activation=\"relu\"))\n",
    "model1.add(layers.Dense(1))\n",
    "model1.compile(\n",
    "    optimizers.Adam(learning_rate=1e-4),\n",
    "    losses.mean_squared_error,\n",
    "    metrics = [losses.mean_squared_error]\n",
    ")\n",
    "file_path = \"model1.hdf5\"\n",
    "checkpoint = ModelCheckpoint(file_path,monitor='val_loss', verbose=1,\n",
    "                             save_best_only=True,period=1)\n",
    "train_history1 = model1.fit(x_train,y_train,epochs=500,batch_size = 32,\n",
    "                            validation_data = (x_val,y_val),callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dff1d4ea",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/500\n",
      "444/526 [========================>.....] - ETA: 0s - loss: 38190.9688 - mean_squared_error: 38190.9688\n",
      "Epoch 00001: val_loss improved from inf to 3169.97461, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 658us/step - loss: 32837.5000 - mean_squared_error: 32837.5000 - val_loss: 3169.9746 - val_mean_squared_error: 3169.9746\n",
      "Epoch 2/500\n",
      "451/526 [========================>.....] - ETA: 0s - loss: 2291.8909 - mean_squared_error: 2291.8909\n",
      "Epoch 00002: val_loss improved from 3169.97461 to 1573.40198, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 502us/step - loss: 2192.9316 - mean_squared_error: 2192.9316 - val_loss: 1573.4020 - val_mean_squared_error: 1573.4020\n",
      "Epoch 3/500\n",
      "451/526 [========================>.....] - ETA: 0s - loss: 1273.4939 - mean_squared_error: 1273.4939\n",
      "Epoch 00003: val_loss improved from 1573.40198 to 1052.36792, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 489us/step - loss: 1235.8887 - mean_squared_error: 1235.8887 - val_loss: 1052.3679 - val_mean_squared_error: 1052.3679\n",
      "Epoch 4/500\n",
      "448/526 [========================>.....] - ETA: 0s - loss: 887.7346 - mean_squared_error: 887.7346\n",
      "Epoch 00004: val_loss improved from 1052.36792 to 757.00140, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 525us/step - loss: 866.1976 - mean_squared_error: 866.1976 - val_loss: 757.0014 - val_mean_squared_error: 757.0014\n",
      "Epoch 5/500\n",
      "444/526 [========================>.....] - ETA: 0s - loss: 689.8621 - mean_squared_error: 689.8621\n",
      "Epoch 00005: val_loss improved from 757.00140 to 617.97040, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 491us/step - loss: 679.8029 - mean_squared_error: 679.8029 - val_loss: 617.9704 - val_mean_squared_error: 617.9704\n",
      "Epoch 6/500\n",
      "456/526 [=========================>....] - ETA: 0s - loss: 569.9294 - mean_squared_error: 569.9294\n",
      "Epoch 00006: val_loss improved from 617.97040 to 487.27698, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 534us/step - loss: 566.5187 - mean_squared_error: 566.5187 - val_loss: 487.2770 - val_mean_squared_error: 487.2770\n",
      "Epoch 7/500\n",
      "457/526 [=========================>....] - ETA: 0s - loss: 506.6090 - mean_squared_error: 506.6090\n",
      "Epoch 00007: val_loss did not improve from 487.27698\n",
      "526/526 [==============================] - 0s 375us/step - loss: 502.9768 - mean_squared_error: 502.9768 - val_loss: 576.1731 - val_mean_squared_error: 576.1731\n",
      "Epoch 8/500\n",
      "458/526 [=========================>....] - ETA: 0s - loss: 480.0532 - mean_squared_error: 480.0532\n",
      "Epoch 00008: val_loss did not improve from 487.27698\n",
      "526/526 [==============================] - 0s 371us/step - loss: 475.2230 - mean_squared_error: 475.2230 - val_loss: 533.6408 - val_mean_squared_error: 533.6408\n",
      "Epoch 9/500\n",
      "459/526 [=========================>....] - ETA: 0s - loss: 457.0652 - mean_squared_error: 457.0652\n",
      "Epoch 00009: val_loss did not improve from 487.27698\n",
      "526/526 [==============================] - 0s 373us/step - loss: 456.7827 - mean_squared_error: 456.7827 - val_loss: 645.1472 - val_mean_squared_error: 645.1472\n",
      "Epoch 10/500\n",
      "455/526 [========================>.....] - ETA: 0s - loss: 440.9188 - mean_squared_error: 440.9188\n",
      "Epoch 00010: val_loss improved from 487.27698 to 386.99203, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 518us/step - loss: 439.1495 - mean_squared_error: 439.1495 - val_loss: 386.9920 - val_mean_squared_error: 386.9920\n",
      "Epoch 11/500\n",
      "458/526 [=========================>....] - ETA: 0s - loss: 430.5677 - mean_squared_error: 430.5677\n",
      "Epoch 00011: val_loss did not improve from 386.99203\n",
      "526/526 [==============================] - 0s 373us/step - loss: 429.2466 - mean_squared_error: 429.2466 - val_loss: 911.8621 - val_mean_squared_error: 911.8621\n",
      "Epoch 12/500\n",
      "447/526 [========================>.....] - ETA: 0s - loss: 427.5866 - mean_squared_error: 427.5866\n",
      "Epoch 00012: val_loss did not improve from 386.99203\n",
      "526/526 [==============================] - 0s 382us/step - loss: 426.0705 - mean_squared_error: 426.0705 - val_loss: 417.9029 - val_mean_squared_error: 417.9029\n",
      "Epoch 13/500\n",
      "454/526 [========================>.....] - ETA: 0s - loss: 423.7265 - mean_squared_error: 423.7265\n",
      "Epoch 00013: val_loss improved from 386.99203 to 386.23962, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 523us/step - loss: 415.6484 - mean_squared_error: 415.6484 - val_loss: 386.2396 - val_mean_squared_error: 386.2396\n",
      "Epoch 14/500\n",
      "443/526 [========================>.....] - ETA: 0s - loss: 400.5848 - mean_squared_error: 400.5848\n",
      "Epoch 00014: val_loss improved from 386.23962 to 342.67889, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 512us/step - loss: 403.0954 - mean_squared_error: 403.0954 - val_loss: 342.6789 - val_mean_squared_error: 342.6789\n",
      "Epoch 15/500\n",
      "443/526 [========================>.....] - ETA: 0s - loss: 387.4733 - mean_squared_error: 387.4733\n",
      "Epoch 00015: val_loss did not improve from 342.67889\n",
      "526/526 [==============================] - 0s 382us/step - loss: 386.5586 - mean_squared_error: 386.5586 - val_loss: 388.1437 - val_mean_squared_error: 388.1437\n",
      "Epoch 16/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 413.9276 - mean_squared_error: 413.9276\n",
      "Epoch 00016: val_loss did not improve from 342.67889\n",
      "526/526 [==============================] - 0s 398us/step - loss: 407.4113 - mean_squared_error: 407.4113 - val_loss: 355.5323 - val_mean_squared_error: 355.5323\n",
      "Epoch 17/500\n",
      "423/526 [=======================>......] - ETA: 0s - loss: 387.2760 - mean_squared_error: 387.2760\n",
      "Epoch 00017: val_loss did not improve from 342.67889\n",
      "526/526 [==============================] - 0s 400us/step - loss: 380.0480 - mean_squared_error: 380.0480 - val_loss: 362.4212 - val_mean_squared_error: 362.4212\n",
      "Epoch 18/500\n",
      "444/526 [========================>.....] - ETA: 0s - loss: 378.0384 - mean_squared_error: 378.0384\n",
      "Epoch 00018: val_loss did not improve from 342.67889\n",
      "526/526 [==============================] - 0s 386us/step - loss: 373.2432 - mean_squared_error: 373.2432 - val_loss: 364.0106 - val_mean_squared_error: 364.0106\n",
      "Epoch 19/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 355.6668 - mean_squared_error: 355.6668\n",
      "Epoch 00019: val_loss did not improve from 342.67889\n",
      "526/526 [==============================] - 0s 394us/step - loss: 364.0931 - mean_squared_error: 364.0931 - val_loss: 356.3324 - val_mean_squared_error: 356.3324\n",
      "Epoch 20/500\n",
      "440/526 [========================>.....] - ETA: 0s - loss: 340.8554 - mean_squared_error: 340.8554\n",
      "Epoch 00020: val_loss did not improve from 342.67889\n",
      "526/526 [==============================] - 0s 384us/step - loss: 346.2991 - mean_squared_error: 346.2991 - val_loss: 381.3258 - val_mean_squared_error: 381.3258\n",
      "Epoch 21/500\n",
      "449/526 [========================>.....] - ETA: 0s - loss: 366.4545 - mean_squared_error: 366.4545\n",
      "Epoch 00021: val_loss improved from 342.67889 to 304.73474, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 516us/step - loss: 361.3417 - mean_squared_error: 361.3417 - val_loss: 304.7347 - val_mean_squared_error: 304.7347\n",
      "Epoch 22/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 365.9489 - mean_squared_error: 365.9489\n",
      "Epoch 00022: val_loss did not improve from 304.73474\n",
      "526/526 [==============================] - 0s 394us/step - loss: 359.3430 - mean_squared_error: 359.3430 - val_loss: 467.0820 - val_mean_squared_error: 467.0820\n",
      "Epoch 23/500\n",
      "448/526 [========================>.....] - ETA: 0s - loss: 355.5710 - mean_squared_error: 355.5710\n",
      "Epoch 00023: val_loss did not improve from 304.73474\n",
      "526/526 [==============================] - 0s 381us/step - loss: 349.6387 - mean_squared_error: 349.6387 - val_loss: 340.8291 - val_mean_squared_error: 340.8291\n",
      "Epoch 24/500\n",
      "445/526 [========================>.....] - ETA: 0s - loss: 340.7038 - mean_squared_error: 340.7038\n",
      "Epoch 00024: val_loss did not improve from 304.73474\n",
      "526/526 [==============================] - 0s 382us/step - loss: 339.1259 - mean_squared_error: 339.1259 - val_loss: 320.6100 - val_mean_squared_error: 320.6100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "450/526 [========================>.....] - ETA: 0s - loss: 364.2608 - mean_squared_error: 364.2608\n",
      "Epoch 00025: val_loss improved from 304.73474 to 295.90784, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 526us/step - loss: 363.5198 - mean_squared_error: 363.5198 - val_loss: 295.9078 - val_mean_squared_error: 295.9078\n",
      "Epoch 26/500\n",
      "447/526 [========================>.....] - ETA: 0s - loss: 340.2424 - mean_squared_error: 340.2424\n",
      "Epoch 00026: val_loss improved from 295.90784 to 283.16986, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 415us/step - loss: 338.2516 - mean_squared_error: 338.2516 - val_loss: 283.1699 - val_mean_squared_error: 283.1699\n",
      "Epoch 27/500\n",
      "440/526 [========================>.....] - ETA: 0s - loss: 343.7614 - mean_squared_error: 343.7614\n",
      "Epoch 00027: val_loss did not improve from 283.16986\n",
      "526/526 [==============================] - 0s 386us/step - loss: 339.3099 - mean_squared_error: 339.3099 - val_loss: 400.5114 - val_mean_squared_error: 400.5114\n",
      "Epoch 28/500\n",
      "441/526 [========================>.....] - ETA: 0s - loss: 342.1954 - mean_squared_error: 342.1954\n",
      "Epoch 00028: val_loss did not improve from 283.16986\n",
      "526/526 [==============================] - 0s 390us/step - loss: 339.2999 - mean_squared_error: 339.2999 - val_loss: 376.4109 - val_mean_squared_error: 376.4109\n",
      "Epoch 29/500\n",
      "438/526 [=======================>......] - ETA: 0s - loss: 317.3750 - mean_squared_error: 317.3750\n",
      "Epoch 00029: val_loss did not improve from 283.16986\n",
      "526/526 [==============================] - 0s 386us/step - loss: 325.6489 - mean_squared_error: 325.6489 - val_loss: 312.8498 - val_mean_squared_error: 312.8498\n",
      "Epoch 30/500\n",
      "437/526 [=======================>......] - ETA: 0s - loss: 317.7605 - mean_squared_error: 317.7605\n",
      "Epoch 00030: val_loss did not improve from 283.16986\n",
      "526/526 [==============================] - 0s 391us/step - loss: 320.2089 - mean_squared_error: 320.2089 - val_loss: 291.2017 - val_mean_squared_error: 291.2017\n",
      "Epoch 31/500\n",
      "440/526 [========================>.....] - ETA: 0s - loss: 342.2585 - mean_squared_error: 342.2585\n",
      "Epoch 00031: val_loss did not improve from 283.16986\n",
      "526/526 [==============================] - 0s 388us/step - loss: 342.3340 - mean_squared_error: 342.3340 - val_loss: 384.9502 - val_mean_squared_error: 384.9502\n",
      "Epoch 32/500\n",
      "454/526 [========================>.....] - ETA: 0s - loss: 311.4586 - mean_squared_error: 311.4586\n",
      "Epoch 00032: val_loss did not improve from 283.16986\n",
      "526/526 [==============================] - 0s 377us/step - loss: 312.0628 - mean_squared_error: 312.0628 - val_loss: 336.2350 - val_mean_squared_error: 336.2350\n",
      "Epoch 33/500\n",
      "450/526 [========================>.....] - ETA: 0s - loss: 344.9052 - mean_squared_error: 344.9052\n",
      "Epoch 00033: val_loss did not improve from 283.16986\n",
      "526/526 [==============================] - 0s 379us/step - loss: 340.8823 - mean_squared_error: 340.8823 - val_loss: 306.7992 - val_mean_squared_error: 306.7992\n",
      "Epoch 34/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 318.2984 - mean_squared_error: 318.2984\n",
      "Epoch 00034: val_loss did not improve from 283.16986\n",
      "526/526 [==============================] - 0s 388us/step - loss: 321.8417 - mean_squared_error: 321.8417 - val_loss: 311.3398 - val_mean_squared_error: 311.3398\n",
      "Epoch 35/500\n",
      "459/526 [=========================>....] - ETA: 0s - loss: 314.9510 - mean_squared_error: 314.9510\n",
      "Epoch 00035: val_loss did not improve from 283.16986\n",
      "526/526 [==============================] - 0s 371us/step - loss: 310.8814 - mean_squared_error: 310.8814 - val_loss: 317.0242 - val_mean_squared_error: 317.0242\n",
      "Epoch 36/500\n",
      "450/526 [========================>.....] - ETA: 0s - loss: 328.0585 - mean_squared_error: 328.0585\n",
      "Epoch 00036: val_loss did not improve from 283.16986\n",
      "526/526 [==============================] - 0s 379us/step - loss: 323.3908 - mean_squared_error: 323.3908 - val_loss: 329.4226 - val_mean_squared_error: 329.4226\n",
      "Epoch 37/500\n",
      "459/526 [=========================>....] - ETA: 0s - loss: 329.1763 - mean_squared_error: 329.1763\n",
      "Epoch 00037: val_loss did not improve from 283.16986\n",
      "526/526 [==============================] - 0s 373us/step - loss: 333.5099 - mean_squared_error: 333.5099 - val_loss: 397.5331 - val_mean_squared_error: 397.5331\n",
      "Epoch 38/500\n",
      "456/526 [=========================>....] - ETA: 0s - loss: 326.4810 - mean_squared_error: 326.4810\n",
      "Epoch 00038: val_loss did not improve from 283.16986\n",
      "526/526 [==============================] - 0s 373us/step - loss: 323.5618 - mean_squared_error: 323.5618 - val_loss: 328.5197 - val_mean_squared_error: 328.5197\n",
      "Epoch 39/500\n",
      "460/526 [=========================>....] - ETA: 0s - loss: 308.7734 - mean_squared_error: 308.7734\n",
      "Epoch 00039: val_loss did not improve from 283.16986\n",
      "526/526 [==============================] - 0s 371us/step - loss: 310.0673 - mean_squared_error: 310.0673 - val_loss: 333.0578 - val_mean_squared_error: 333.0578\n",
      "Epoch 40/500\n",
      "455/526 [========================>.....] - ETA: 0s - loss: 313.5790 - mean_squared_error: 313.5790\n",
      "Epoch 00040: val_loss did not improve from 283.16986\n",
      "526/526 [==============================] - 0s 373us/step - loss: 315.3761 - mean_squared_error: 315.3761 - val_loss: 388.0548 - val_mean_squared_error: 388.0548\n",
      "Epoch 41/500\n",
      "458/526 [=========================>....] - ETA: 0s - loss: 311.0243 - mean_squared_error: 311.0243\n",
      "Epoch 00041: val_loss did not improve from 283.16986\n",
      "526/526 [==============================] - 0s 373us/step - loss: 315.0627 - mean_squared_error: 315.0627 - val_loss: 326.2495 - val_mean_squared_error: 326.2495\n",
      "Epoch 42/500\n",
      "461/526 [=========================>....] - ETA: 0s - loss: 357.6300 - mean_squared_error: 357.6300\n",
      "Epoch 00042: val_loss did not improve from 283.16986\n",
      "526/526 [==============================] - 0s 377us/step - loss: 350.7299 - mean_squared_error: 350.7299 - val_loss: 299.8288 - val_mean_squared_error: 299.8288\n",
      "Epoch 43/500\n",
      "450/526 [========================>.....] - ETA: 0s - loss: 281.6431 - mean_squared_error: 281.6431\n",
      "Epoch 00043: val_loss did not improve from 283.16986\n",
      "526/526 [==============================] - 0s 379us/step - loss: 286.6934 - mean_squared_error: 286.6934 - val_loss: 391.7226 - val_mean_squared_error: 391.7226\n",
      "Epoch 44/500\n",
      "443/526 [========================>.....] - ETA: 0s - loss: 308.1732 - mean_squared_error: 308.1732\n",
      "Epoch 00044: val_loss did not improve from 283.16986\n",
      "526/526 [==============================] - 0s 382us/step - loss: 309.6789 - mean_squared_error: 309.6789 - val_loss: 300.7776 - val_mean_squared_error: 300.7776\n",
      "Epoch 45/500\n",
      "457/526 [=========================>....] - ETA: 0s - loss: 293.6121 - mean_squared_error: 293.6121\n",
      "Epoch 00045: val_loss did not improve from 283.16986\n",
      "526/526 [==============================] - 0s 371us/step - loss: 295.5601 - mean_squared_error: 295.5601 - val_loss: 335.6891 - val_mean_squared_error: 335.6891\n",
      "Epoch 46/500\n",
      "460/526 [=========================>....] - ETA: 0s - loss: 316.9637 - mean_squared_error: 316.9637\n",
      "Epoch 00046: val_loss improved from 283.16986 to 282.55350, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 497us/step - loss: 314.0574 - mean_squared_error: 314.0574 - val_loss: 282.5535 - val_mean_squared_error: 282.5535\n",
      "Epoch 47/500\n",
      "459/526 [=========================>....] - ETA: 0s - loss: 292.9707 - mean_squared_error: 292.9707\n",
      "Epoch 00047: val_loss did not improve from 282.55350\n",
      "526/526 [==============================] - 0s 371us/step - loss: 312.0678 - mean_squared_error: 312.0678 - val_loss: 288.0159 - val_mean_squared_error: 288.0159\n",
      "Epoch 48/500\n",
      "457/526 [=========================>....] - ETA: 0s - loss: 319.2164 - mean_squared_error: 319.2164\n",
      "Epoch 00048: val_loss did not improve from 282.55350\n",
      "526/526 [==============================] - 0s 373us/step - loss: 315.3359 - mean_squared_error: 315.3359 - val_loss: 390.9850 - val_mean_squared_error: 390.9850\n",
      "Epoch 49/500\n",
      "447/526 [========================>.....] - ETA: 0s - loss: 289.8228 - mean_squared_error: 289.8228\n",
      "Epoch 00049: val_loss improved from 282.55350 to 273.61508, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 519us/step - loss: 290.0490 - mean_squared_error: 290.0490 - val_loss: 273.6151 - val_mean_squared_error: 273.6151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500\n",
      "446/526 [========================>.....] - ETA: 0s - loss: 286.2586 - mean_squared_error: 286.2586\n",
      "Epoch 00050: val_loss did not improve from 273.61508\n",
      "526/526 [==============================] - 0s 381us/step - loss: 292.1905 - mean_squared_error: 292.1905 - val_loss: 280.6726 - val_mean_squared_error: 280.6726\n",
      "Epoch 51/500\n",
      "439/526 [========================>.....] - ETA: 0s - loss: 306.8182 - mean_squared_error: 306.8182\n",
      "Epoch 00051: val_loss did not improve from 273.61508\n",
      "526/526 [==============================] - 0s 384us/step - loss: 304.7008 - mean_squared_error: 304.7008 - val_loss: 302.0627 - val_mean_squared_error: 302.0627\n",
      "Epoch 52/500\n",
      "452/526 [========================>.....] - ETA: 0s - loss: 300.4867 - mean_squared_error: 300.4867\n",
      "Epoch 00052: val_loss improved from 273.61508 to 263.26141, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 481us/step - loss: 297.5890 - mean_squared_error: 297.5890 - val_loss: 263.2614 - val_mean_squared_error: 263.2614\n",
      "Epoch 53/500\n",
      "461/526 [=========================>....] - ETA: 0s - loss: 296.2758 - mean_squared_error: 296.2758\n",
      "Epoch 00053: val_loss did not improve from 263.26141\n",
      "526/526 [==============================] - 0s 369us/step - loss: 296.8982 - mean_squared_error: 296.8982 - val_loss: 294.4887 - val_mean_squared_error: 294.4887\n",
      "Epoch 54/500\n",
      "462/526 [=========================>....] - ETA: 0s - loss: 312.6429 - mean_squared_error: 312.6429\n",
      "Epoch 00054: val_loss did not improve from 263.26141\n",
      "526/526 [==============================] - 0s 369us/step - loss: 310.5131 - mean_squared_error: 310.5131 - val_loss: 343.6576 - val_mean_squared_error: 343.6576\n",
      "Epoch 55/500\n",
      "451/526 [========================>.....] - ETA: 0s - loss: 289.8632 - mean_squared_error: 289.8632\n",
      "Epoch 00055: val_loss improved from 263.26141 to 259.15366, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 517us/step - loss: 290.0464 - mean_squared_error: 290.0464 - val_loss: 259.1537 - val_mean_squared_error: 259.1537\n",
      "Epoch 56/500\n",
      "441/526 [========================>.....] - ETA: 0s - loss: 310.4790 - mean_squared_error: 310.4790\n",
      "Epoch 00056: val_loss improved from 259.15366 to 258.72293, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 504us/step - loss: 307.9968 - mean_squared_error: 307.9968 - val_loss: 258.7229 - val_mean_squared_error: 258.7229\n",
      "Epoch 57/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 304.6867 - mean_squared_error: 304.6867\n",
      "Epoch 00057: val_loss improved from 258.72293 to 257.16266, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 511us/step - loss: 300.0046 - mean_squared_error: 300.0046 - val_loss: 257.1627 - val_mean_squared_error: 257.1627\n",
      "Epoch 58/500\n",
      "450/526 [========================>.....] - ETA: 0s - loss: 281.8186 - mean_squared_error: 281.8186\n",
      "Epoch 00058: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 379us/step - loss: 293.7154 - mean_squared_error: 293.7154 - val_loss: 272.8904 - val_mean_squared_error: 272.8904\n",
      "Epoch 59/500\n",
      "439/526 [========================>.....] - ETA: 0s - loss: 291.7064 - mean_squared_error: 291.7064\n",
      "Epoch 00059: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 388us/step - loss: 295.0118 - mean_squared_error: 295.0118 - val_loss: 432.6105 - val_mean_squared_error: 432.6105\n",
      "Epoch 60/500\n",
      "442/526 [========================>.....] - ETA: 0s - loss: 295.3573 - mean_squared_error: 295.3573\n",
      "Epoch 00060: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 384us/step - loss: 298.2182 - mean_squared_error: 298.2182 - val_loss: 260.1904 - val_mean_squared_error: 260.1904\n",
      "Epoch 61/500\n",
      "434/526 [=======================>......] - ETA: 0s - loss: 287.0162 - mean_squared_error: 287.0162\n",
      "Epoch 00061: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 392us/step - loss: 298.1037 - mean_squared_error: 298.1037 - val_loss: 266.4240 - val_mean_squared_error: 266.4240\n",
      "Epoch 62/500\n",
      "444/526 [========================>.....] - ETA: 0s - loss: 303.5822 - mean_squared_error: 303.5822\n",
      "Epoch 00062: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 382us/step - loss: 305.8335 - mean_squared_error: 305.8335 - val_loss: 335.8449 - val_mean_squared_error: 335.8449\n",
      "Epoch 63/500\n",
      "447/526 [========================>.....] - ETA: 0s - loss: 287.4614 - mean_squared_error: 287.4614\n",
      "Epoch 00063: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 379us/step - loss: 292.4098 - mean_squared_error: 292.4098 - val_loss: 273.3497 - val_mean_squared_error: 273.3497\n",
      "Epoch 64/500\n",
      "444/526 [========================>.....] - ETA: 0s - loss: 278.1667 - mean_squared_error: 278.1667\n",
      "Epoch 00064: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 386us/step - loss: 281.0281 - mean_squared_error: 281.0281 - val_loss: 268.9450 - val_mean_squared_error: 268.9450\n",
      "Epoch 65/500\n",
      "445/526 [========================>.....] - ETA: 0s - loss: 287.1271 - mean_squared_error: 287.1271\n",
      "Epoch 00065: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 386us/step - loss: 291.5511 - mean_squared_error: 291.5511 - val_loss: 330.9836 - val_mean_squared_error: 330.9836\n",
      "Epoch 66/500\n",
      "438/526 [=======================>......] - ETA: 0s - loss: 286.4232 - mean_squared_error: 286.4232\n",
      "Epoch 00066: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 386us/step - loss: 287.2415 - mean_squared_error: 287.2415 - val_loss: 321.5023 - val_mean_squared_error: 321.5023\n",
      "Epoch 67/500\n",
      "445/526 [========================>.....] - ETA: 0s - loss: 288.5878 - mean_squared_error: 288.5878\n",
      "Epoch 00067: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 382us/step - loss: 289.7592 - mean_squared_error: 289.7592 - val_loss: 391.6431 - val_mean_squared_error: 391.6431\n",
      "Epoch 68/500\n",
      "454/526 [========================>.....] - ETA: 0s - loss: 299.9875 - mean_squared_error: 299.9875\n",
      "Epoch 00068: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 375us/step - loss: 301.0902 - mean_squared_error: 301.0902 - val_loss: 301.8265 - val_mean_squared_error: 301.8265\n",
      "Epoch 69/500\n",
      "459/526 [=========================>....] - ETA: 0s - loss: 301.1732 - mean_squared_error: 301.1732\n",
      "Epoch 00069: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 371us/step - loss: 305.2829 - mean_squared_error: 305.2829 - val_loss: 315.1965 - val_mean_squared_error: 315.1965\n",
      "Epoch 70/500\n",
      "457/526 [=========================>....] - ETA: 0s - loss: 290.5839 - mean_squared_error: 290.5839\n",
      "Epoch 00070: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 375us/step - loss: 287.0333 - mean_squared_error: 287.0333 - val_loss: 327.5623 - val_mean_squared_error: 327.5623\n",
      "Epoch 71/500\n",
      "456/526 [=========================>....] - ETA: 0s - loss: 301.2165 - mean_squared_error: 301.2165\n",
      "Epoch 00071: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 373us/step - loss: 301.4833 - mean_squared_error: 301.4833 - val_loss: 269.7729 - val_mean_squared_error: 269.7729\n",
      "Epoch 72/500\n",
      "463/526 [=========================>....] - ETA: 0s - loss: 285.5667 - mean_squared_error: 285.5667\n",
      "Epoch 00072: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 369us/step - loss: 289.1025 - mean_squared_error: 289.1025 - val_loss: 259.9420 - val_mean_squared_error: 259.9420\n",
      "Epoch 73/500\n",
      "456/526 [=========================>....] - ETA: 0s - loss: 281.4092 - mean_squared_error: 281.4092\n",
      "Epoch 00073: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 373us/step - loss: 289.2196 - mean_squared_error: 289.2196 - val_loss: 263.6776 - val_mean_squared_error: 263.6776\n",
      "Epoch 74/500\n",
      "461/526 [=========================>....] - ETA: 0s - loss: 293.0005 - mean_squared_error: 293.0005\n",
      "Epoch 00074: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 371us/step - loss: 289.9862 - mean_squared_error: 289.9862 - val_loss: 280.5875 - val_mean_squared_error: 280.5875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/500\n",
      "411/526 [======================>.......] - ETA: 0s - loss: 293.5168 - mean_squared_error: 293.5168\n",
      "Epoch 00075: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 407us/step - loss: 294.0330 - mean_squared_error: 294.0330 - val_loss: 395.6811 - val_mean_squared_error: 395.6811\n",
      "Epoch 76/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 275.6886 - mean_squared_error: 275.6886\n",
      "Epoch 00076: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 392us/step - loss: 280.8712 - mean_squared_error: 280.8712 - val_loss: 668.3412 - val_mean_squared_error: 668.3412\n",
      "Epoch 77/500\n",
      "441/526 [========================>.....] - ETA: 0s - loss: 296.9796 - mean_squared_error: 296.9796\n",
      "Epoch 00077: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 388us/step - loss: 290.9227 - mean_squared_error: 290.9227 - val_loss: 310.2321 - val_mean_squared_error: 310.2321\n",
      "Epoch 78/500\n",
      "439/526 [========================>.....] - ETA: 0s - loss: 290.5787 - mean_squared_error: 290.5787\n",
      "Epoch 00078: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 384us/step - loss: 285.6029 - mean_squared_error: 285.6029 - val_loss: 260.8863 - val_mean_squared_error: 260.8863\n",
      "Epoch 79/500\n",
      "460/526 [=========================>....] - ETA: 0s - loss: 278.4520 - mean_squared_error: 278.4520\n",
      "Epoch 00079: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 371us/step - loss: 279.7967 - mean_squared_error: 279.7967 - val_loss: 269.4697 - val_mean_squared_error: 269.4697\n",
      "Epoch 80/500\n",
      "441/526 [========================>.....] - ETA: 0s - loss: 270.3420 - mean_squared_error: 270.3420\n",
      "Epoch 00080: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 382us/step - loss: 274.3141 - mean_squared_error: 274.3141 - val_loss: 266.5271 - val_mean_squared_error: 266.5271\n",
      "Epoch 81/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 282.5352 - mean_squared_error: 282.5352\n",
      "Epoch 00081: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 378us/step - loss: 292.2739 - mean_squared_error: 292.2739 - val_loss: 336.0708 - val_mean_squared_error: 336.0708\n",
      "Epoch 82/500\n",
      "442/526 [========================>.....] - ETA: 0s - loss: 287.8425 - mean_squared_error: 287.8425\n",
      "Epoch 00082: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 382us/step - loss: 291.2080 - mean_squared_error: 291.2080 - val_loss: 383.9005 - val_mean_squared_error: 383.9005\n",
      "Epoch 83/500\n",
      "450/526 [========================>.....] - ETA: 0s - loss: 284.8835 - mean_squared_error: 284.8835\n",
      "Epoch 00083: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 377us/step - loss: 283.0169 - mean_squared_error: 283.0169 - val_loss: 276.3639 - val_mean_squared_error: 276.3639\n",
      "Epoch 84/500\n",
      "440/526 [========================>.....] - ETA: 0s - loss: 273.2371 - mean_squared_error: 273.2371\n",
      "Epoch 00084: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 386us/step - loss: 276.1853 - mean_squared_error: 276.1853 - val_loss: 272.9564 - val_mean_squared_error: 272.9564\n",
      "Epoch 85/500\n",
      "447/526 [========================>.....] - ETA: 0s - loss: 293.2285 - mean_squared_error: 293.2285\n",
      "Epoch 00085: val_loss did not improve from 257.16266\n",
      "526/526 [==============================] - 0s 381us/step - loss: 295.1725 - mean_squared_error: 295.1725 - val_loss: 275.7518 - val_mean_squared_error: 275.7518\n",
      "Epoch 86/500\n",
      "445/526 [========================>.....] - ETA: 0s - loss: 286.6614 - mean_squared_error: 286.6614\n",
      "Epoch 00086: val_loss improved from 257.16266 to 253.38568, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 550us/step - loss: 284.5492 - mean_squared_error: 284.5492 - val_loss: 253.3857 - val_mean_squared_error: 253.3857\n",
      "Epoch 87/500\n",
      "455/526 [========================>.....] - ETA: 0s - loss: 289.0498 - mean_squared_error: 289.0498\n",
      "Epoch 00087: val_loss did not improve from 253.38568\n",
      "526/526 [==============================] - 0s 373us/step - loss: 288.7275 - mean_squared_error: 288.7275 - val_loss: 361.3281 - val_mean_squared_error: 361.3281\n",
      "Epoch 88/500\n",
      "448/526 [========================>.....] - ETA: 0s - loss: 291.0848 - mean_squared_error: 291.0848\n",
      "Epoch 00088: val_loss improved from 253.38568 to 250.10808, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 535us/step - loss: 285.9599 - mean_squared_error: 285.9599 - val_loss: 250.1081 - val_mean_squared_error: 250.1081\n",
      "Epoch 89/500\n",
      "455/526 [========================>.....] - ETA: 0s - loss: 266.4687 - mean_squared_error: 266.4687\n",
      "Epoch 00089: val_loss did not improve from 250.10808\n",
      "526/526 [==============================] - 0s 375us/step - loss: 265.1919 - mean_squared_error: 265.1919 - val_loss: 275.0811 - val_mean_squared_error: 275.0811\n",
      "Epoch 90/500\n",
      "444/526 [========================>.....] - ETA: 0s - loss: 284.7700 - mean_squared_error: 284.7700\n",
      "Epoch 00090: val_loss did not improve from 250.10808\n",
      "526/526 [==============================] - 0s 381us/step - loss: 295.3459 - mean_squared_error: 295.3459 - val_loss: 276.2692 - val_mean_squared_error: 276.2692\n",
      "Epoch 91/500\n",
      "449/526 [========================>.....] - ETA: 0s - loss: 281.8408 - mean_squared_error: 281.8408\n",
      "Epoch 00091: val_loss did not improve from 250.10808\n",
      "526/526 [==============================] - 0s 381us/step - loss: 279.9547 - mean_squared_error: 279.9547 - val_loss: 289.7371 - val_mean_squared_error: 289.7371\n",
      "Epoch 92/500\n",
      "451/526 [========================>.....] - ETA: 0s - loss: 280.4058 - mean_squared_error: 280.4058\n",
      "Epoch 00092: val_loss did not improve from 250.10808\n",
      "526/526 [==============================] - 0s 377us/step - loss: 276.9735 - mean_squared_error: 276.9735 - val_loss: 282.3388 - val_mean_squared_error: 282.3388\n",
      "Epoch 93/500\n",
      "450/526 [========================>.....] - ETA: 0s - loss: 283.7320 - mean_squared_error: 283.7320\n",
      "Epoch 00093: val_loss did not improve from 250.10808\n",
      "526/526 [==============================] - 0s 381us/step - loss: 281.9970 - mean_squared_error: 281.9970 - val_loss: 290.5603 - val_mean_squared_error: 290.5603\n",
      "Epoch 94/500\n",
      "440/526 [========================>.....] - ETA: 0s - loss: 285.0540 - mean_squared_error: 285.0540\n",
      "Epoch 00094: val_loss did not improve from 250.10808\n",
      "526/526 [==============================] - 0s 386us/step - loss: 284.1256 - mean_squared_error: 284.1256 - val_loss: 317.7361 - val_mean_squared_error: 317.7361\n",
      "Epoch 95/500\n",
      "440/526 [========================>.....] - ETA: 0s - loss: 269.4674 - mean_squared_error: 269.4674\n",
      "Epoch 00095: val_loss improved from 250.10808 to 242.09196, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 531us/step - loss: 270.0399 - mean_squared_error: 270.0399 - val_loss: 242.0920 - val_mean_squared_error: 242.0920\n",
      "Epoch 96/500\n",
      "449/526 [========================>.....] - ETA: 0s - loss: 269.6709 - mean_squared_error: 269.6709\n",
      "Epoch 00096: val_loss did not improve from 242.09196\n",
      "526/526 [==============================] - 0s 390us/step - loss: 270.6467 - mean_squared_error: 270.6467 - val_loss: 252.0479 - val_mean_squared_error: 252.0479\n",
      "Epoch 97/500\n",
      "445/526 [========================>.....] - ETA: 0s - loss: 283.3863 - mean_squared_error: 283.3863\n",
      "Epoch 00097: val_loss did not improve from 242.09196\n",
      "526/526 [==============================] - 0s 388us/step - loss: 288.2884 - mean_squared_error: 288.2884 - val_loss: 260.4626 - val_mean_squared_error: 260.4626\n",
      "Epoch 98/500\n",
      "436/526 [=======================>......] - ETA: 0s - loss: 272.4859 - mean_squared_error: 272.4859\n",
      "Epoch 00098: val_loss did not improve from 242.09196\n",
      "526/526 [==============================] - 0s 390us/step - loss: 278.4279 - mean_squared_error: 278.4279 - val_loss: 313.5456 - val_mean_squared_error: 313.5456\n",
      "Epoch 99/500\n",
      "449/526 [========================>.....] - ETA: 0s - loss: 281.8040 - mean_squared_error: 281.8040\n",
      "Epoch 00099: val_loss improved from 242.09196 to 241.97948, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 491us/step - loss: 278.0737 - mean_squared_error: 278.0737 - val_loss: 241.9795 - val_mean_squared_error: 241.9795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500\n",
      "445/526 [========================>.....] - ETA: 0s - loss: 272.4223 - mean_squared_error: 272.4223\n",
      "Epoch 00100: val_loss did not improve from 241.97948\n",
      "526/526 [==============================] - 0s 382us/step - loss: 272.2757 - mean_squared_error: 272.2757 - val_loss: 250.2926 - val_mean_squared_error: 250.2926\n",
      "Epoch 101/500\n",
      "454/526 [========================>.....] - ETA: 0s - loss: 287.4725 - mean_squared_error: 287.4725\n",
      "Epoch 00101: val_loss did not improve from 241.97948\n",
      "526/526 [==============================] - 0s 373us/step - loss: 286.6204 - mean_squared_error: 286.6204 - val_loss: 279.8168 - val_mean_squared_error: 279.8168\n",
      "Epoch 102/500\n",
      "462/526 [=========================>....] - ETA: 0s - loss: 264.3965 - mean_squared_error: 264.3965\n",
      "Epoch 00102: val_loss did not improve from 241.97948\n",
      "526/526 [==============================] - 0s 369us/step - loss: 266.3490 - mean_squared_error: 266.3490 - val_loss: 263.7960 - val_mean_squared_error: 263.7960\n",
      "Epoch 103/500\n",
      "448/526 [========================>.....] - ETA: 0s - loss: 271.0811 - mean_squared_error: 271.0811\n",
      "Epoch 00103: val_loss did not improve from 241.97948\n",
      "526/526 [==============================] - 0s 379us/step - loss: 272.9588 - mean_squared_error: 272.9588 - val_loss: 282.2650 - val_mean_squared_error: 282.2650\n",
      "Epoch 104/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 262.4917 - mean_squared_error: 262.4917\n",
      "Epoch 00104: val_loss did not improve from 241.97948\n",
      "526/526 [==============================] - 0s 375us/step - loss: 262.2403 - mean_squared_error: 262.2403 - val_loss: 282.9916 - val_mean_squared_error: 282.9916\n",
      "Epoch 105/500\n",
      "441/526 [========================>.....] - ETA: 0s - loss: 280.2247 - mean_squared_error: 280.2247\n",
      "Epoch 00105: val_loss did not improve from 241.97948\n",
      "526/526 [==============================] - 0s 386us/step - loss: 273.9978 - mean_squared_error: 273.9978 - val_loss: 492.4561 - val_mean_squared_error: 492.4561\n",
      "Epoch 106/500\n",
      "438/526 [=======================>......] - ETA: 0s - loss: 279.9153 - mean_squared_error: 279.9153\n",
      "Epoch 00106: val_loss did not improve from 241.97948\n",
      "526/526 [==============================] - 0s 388us/step - loss: 275.1239 - mean_squared_error: 275.1239 - val_loss: 285.1867 - val_mean_squared_error: 285.1867\n",
      "Epoch 107/500\n",
      "447/526 [========================>.....] - ETA: 0s - loss: 290.7318 - mean_squared_error: 290.7318\n",
      "Epoch 00107: val_loss did not improve from 241.97948\n",
      "526/526 [==============================] - 0s 379us/step - loss: 283.7744 - mean_squared_error: 283.7744 - val_loss: 255.0678 - val_mean_squared_error: 255.0678\n",
      "Epoch 108/500\n",
      "452/526 [========================>.....] - ETA: 0s - loss: 264.4122 - mean_squared_error: 264.4122\n",
      "Epoch 00108: val_loss did not improve from 241.97948\n",
      "526/526 [==============================] - 0s 377us/step - loss: 267.4315 - mean_squared_error: 267.4315 - val_loss: 300.2203 - val_mean_squared_error: 300.2203\n",
      "Epoch 109/500\n",
      "458/526 [=========================>....] - ETA: 0s - loss: 276.3183 - mean_squared_error: 276.3183\n",
      "Epoch 00109: val_loss did not improve from 241.97948\n",
      "526/526 [==============================] - 0s 371us/step - loss: 275.9490 - mean_squared_error: 275.9490 - val_loss: 281.2900 - val_mean_squared_error: 281.2900\n",
      "Epoch 110/500\n",
      "450/526 [========================>.....] - ETA: 0s - loss: 268.1771 - mean_squared_error: 268.1771\n",
      "Epoch 00110: val_loss did not improve from 241.97948\n",
      "526/526 [==============================] - 0s 379us/step - loss: 275.1226 - mean_squared_error: 275.1226 - val_loss: 259.3406 - val_mean_squared_error: 259.3406\n",
      "Epoch 111/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 273.0501 - mean_squared_error: 273.0501\n",
      "Epoch 00111: val_loss did not improve from 241.97948\n",
      "526/526 [==============================] - 0s 373us/step - loss: 285.1125 - mean_squared_error: 285.1125 - val_loss: 266.0474 - val_mean_squared_error: 266.0474\n",
      "Epoch 112/500\n",
      "463/526 [=========================>....] - ETA: 0s - loss: 281.2750 - mean_squared_error: 281.2750\n",
      "Epoch 00112: val_loss did not improve from 241.97948\n",
      "526/526 [==============================] - 0s 367us/step - loss: 277.0882 - mean_squared_error: 277.0882 - val_loss: 249.5679 - val_mean_squared_error: 249.5679\n",
      "Epoch 113/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 268.8503 - mean_squared_error: 268.8503\n",
      "Epoch 00113: val_loss did not improve from 241.97948\n",
      "526/526 [==============================] - 0s 375us/step - loss: 265.7897 - mean_squared_error: 265.7897 - val_loss: 261.1890 - val_mean_squared_error: 261.1890\n",
      "Epoch 114/500\n",
      "460/526 [=========================>....] - ETA: 0s - loss: 266.5452 - mean_squared_error: 266.5452\n",
      "Epoch 00114: val_loss did not improve from 241.97948\n",
      "526/526 [==============================] - 0s 369us/step - loss: 264.7682 - mean_squared_error: 264.7682 - val_loss: 249.0431 - val_mean_squared_error: 249.0431\n",
      "Epoch 115/500\n",
      "460/526 [=========================>....] - ETA: 0s - loss: 249.7033 - mean_squared_error: 249.7033\n",
      "Epoch 00115: val_loss did not improve from 241.97948\n",
      "526/526 [==============================] - 0s 371us/step - loss: 251.4585 - mean_squared_error: 251.4585 - val_loss: 341.2107 - val_mean_squared_error: 341.2107\n",
      "Epoch 116/500\n",
      "458/526 [=========================>....] - ETA: 0s - loss: 284.1288 - mean_squared_error: 284.1288\n",
      "Epoch 00116: val_loss did not improve from 241.97948\n",
      "526/526 [==============================] - 0s 371us/step - loss: 282.5738 - mean_squared_error: 282.5738 - val_loss: 243.7734 - val_mean_squared_error: 243.7734\n",
      "Epoch 117/500\n",
      "462/526 [=========================>....] - ETA: 0s - loss: 273.2853 - mean_squared_error: 273.2853\n",
      "Epoch 00117: val_loss did not improve from 241.97948\n",
      "526/526 [==============================] - 0s 367us/step - loss: 273.0700 - mean_squared_error: 273.0700 - val_loss: 252.0165 - val_mean_squared_error: 252.0165\n",
      "Epoch 118/500\n",
      "465/526 [=========================>....] - ETA: 0s - loss: 275.8895 - mean_squared_error: 275.8895\n",
      "Epoch 00118: val_loss improved from 241.97948 to 240.80853, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 531us/step - loss: 271.1659 - mean_squared_error: 271.1659 - val_loss: 240.8085 - val_mean_squared_error: 240.8085\n",
      "Epoch 119/500\n",
      "455/526 [========================>.....] - ETA: 0s - loss: 263.1456 - mean_squared_error: 263.1456\n",
      "Epoch 00119: val_loss did not improve from 240.80853\n",
      "526/526 [==============================] - 0s 373us/step - loss: 262.8677 - mean_squared_error: 262.8677 - val_loss: 265.8749 - val_mean_squared_error: 265.8749\n",
      "Epoch 120/500\n",
      "459/526 [=========================>....] - ETA: 0s - loss: 277.4116 - mean_squared_error: 277.4116\n",
      "Epoch 00120: val_loss did not improve from 240.80853\n",
      "526/526 [==============================] - 0s 371us/step - loss: 272.5696 - mean_squared_error: 272.5696 - val_loss: 268.8052 - val_mean_squared_error: 268.8052\n",
      "Epoch 121/500\n",
      "461/526 [=========================>....] - ETA: 0s - loss: 298.9365 - mean_squared_error: 298.9365\n",
      "Epoch 00121: val_loss did not improve from 240.80853\n",
      "526/526 [==============================] - 0s 369us/step - loss: 293.0422 - mean_squared_error: 293.0422 - val_loss: 279.2896 - val_mean_squared_error: 279.2896\n",
      "Epoch 122/500\n",
      "458/526 [=========================>....] - ETA: 0s - loss: 256.0903 - mean_squared_error: 256.0903\n",
      "Epoch 00122: val_loss did not improve from 240.80853\n",
      "526/526 [==============================] - 0s 369us/step - loss: 258.8072 - mean_squared_error: 258.8072 - val_loss: 292.9301 - val_mean_squared_error: 292.9301\n",
      "Epoch 123/500\n",
      "460/526 [=========================>....] - ETA: 0s - loss: 269.6837 - mean_squared_error: 269.6837\n",
      "Epoch 00123: val_loss did not improve from 240.80853\n",
      "526/526 [==============================] - 0s 371us/step - loss: 275.4856 - mean_squared_error: 275.4856 - val_loss: 252.7318 - val_mean_squared_error: 252.7318\n",
      "Epoch 124/500\n",
      "456/526 [=========================>....] - ETA: 0s - loss: 257.9871 - mean_squared_error: 257.9871\n",
      "Epoch 00124: val_loss did not improve from 240.80853\n",
      "526/526 [==============================] - 0s 373us/step - loss: 255.5844 - mean_squared_error: 255.5844 - val_loss: 250.2770 - val_mean_squared_error: 250.2770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/500\n",
      "449/526 [========================>.....] - ETA: 0s - loss: 275.4492 - mean_squared_error: 275.4492\n",
      "Epoch 00125: val_loss did not improve from 240.80853\n",
      "526/526 [==============================] - 0s 377us/step - loss: 275.4047 - mean_squared_error: 275.4047 - val_loss: 253.8179 - val_mean_squared_error: 253.8179\n",
      "Epoch 126/500\n",
      "460/526 [=========================>....] - ETA: 0s - loss: 271.2836 - mean_squared_error: 271.2836\n",
      "Epoch 00126: val_loss did not improve from 240.80853\n",
      "526/526 [==============================] - 0s 369us/step - loss: 266.9186 - mean_squared_error: 266.9186 - val_loss: 255.6643 - val_mean_squared_error: 255.6643\n",
      "Epoch 127/500\n",
      "461/526 [=========================>....] - ETA: 0s - loss: 268.1300 - mean_squared_error: 268.1300\n",
      "Epoch 00127: val_loss did not improve from 240.80853\n",
      "526/526 [==============================] - 0s 369us/step - loss: 265.2883 - mean_squared_error: 265.2883 - val_loss: 285.6350 - val_mean_squared_error: 285.6350\n",
      "Epoch 128/500\n",
      "460/526 [=========================>....] - ETA: 0s - loss: 265.3855 - mean_squared_error: 265.3855\n",
      "Epoch 00128: val_loss did not improve from 240.80853\n",
      "526/526 [==============================] - 0s 369us/step - loss: 268.5210 - mean_squared_error: 268.5210 - val_loss: 246.7314 - val_mean_squared_error: 246.7314\n",
      "Epoch 129/500\n",
      "461/526 [=========================>....] - ETA: 0s - loss: 267.2722 - mean_squared_error: 267.2722\n",
      "Epoch 00129: val_loss did not improve from 240.80853\n",
      "526/526 [==============================] - 0s 369us/step - loss: 266.6337 - mean_squared_error: 266.6337 - val_loss: 288.0912 - val_mean_squared_error: 288.0912\n",
      "Epoch 130/500\n",
      "460/526 [=========================>....] - ETA: 0s - loss: 261.7086 - mean_squared_error: 261.7086\n",
      "Epoch 00130: val_loss did not improve from 240.80853\n",
      "526/526 [==============================] - 0s 371us/step - loss: 261.1120 - mean_squared_error: 261.1120 - val_loss: 257.1682 - val_mean_squared_error: 257.1682\n",
      "Epoch 131/500\n",
      "458/526 [=========================>....] - ETA: 0s - loss: 285.7286 - mean_squared_error: 285.7286\n",
      "Epoch 00131: val_loss did not improve from 240.80853\n",
      "526/526 [==============================] - 0s 371us/step - loss: 280.1586 - mean_squared_error: 280.1586 - val_loss: 241.3772 - val_mean_squared_error: 241.3772\n",
      "Epoch 132/500\n",
      "467/526 [=========================>....] - ETA: 0s - loss: 274.8062 - mean_squared_error: 274.8062\n",
      "Epoch 00132: val_loss did not improve from 240.80853\n",
      "526/526 [==============================] - 0s 365us/step - loss: 273.5745 - mean_squared_error: 273.5745 - val_loss: 275.4423 - val_mean_squared_error: 275.4423\n",
      "Epoch 133/500\n",
      "459/526 [=========================>....] - ETA: 0s - loss: 275.4223 - mean_squared_error: 275.4223\n",
      "Epoch 00133: val_loss did not improve from 240.80853\n",
      "526/526 [==============================] - 0s 371us/step - loss: 272.4955 - mean_squared_error: 272.4955 - val_loss: 274.6205 - val_mean_squared_error: 274.6205\n",
      "Epoch 134/500\n",
      "456/526 [=========================>....] - ETA: 0s - loss: 268.7119 - mean_squared_error: 268.7119\n",
      "Epoch 00134: val_loss did not improve from 240.80853\n",
      "526/526 [==============================] - 0s 373us/step - loss: 267.8619 - mean_squared_error: 267.8619 - val_loss: 247.7617 - val_mean_squared_error: 247.7617\n",
      "Epoch 135/500\n",
      "452/526 [========================>.....] - ETA: 0s - loss: 257.6904 - mean_squared_error: 257.6904\n",
      "Epoch 00135: val_loss improved from 240.80853 to 235.86546, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 542us/step - loss: 259.3436 - mean_squared_error: 259.3436 - val_loss: 235.8655 - val_mean_squared_error: 235.8655\n",
      "Epoch 136/500\n",
      "456/526 [=========================>....] - ETA: 0s - loss: 265.0142 - mean_squared_error: 265.0142\n",
      "Epoch 00136: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 373us/step - loss: 265.0118 - mean_squared_error: 265.0118 - val_loss: 276.3745 - val_mean_squared_error: 276.3745\n",
      "Epoch 137/500\n",
      "461/526 [=========================>....] - ETA: 0s - loss: 270.7941 - mean_squared_error: 270.7941\n",
      "Epoch 00137: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 369us/step - loss: 269.6587 - mean_squared_error: 269.6587 - val_loss: 248.5294 - val_mean_squared_error: 248.5294\n",
      "Epoch 138/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 262.5040 - mean_squared_error: 262.5040\n",
      "Epoch 00138: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 375us/step - loss: 260.3614 - mean_squared_error: 260.3614 - val_loss: 262.0264 - val_mean_squared_error: 262.0264\n",
      "Epoch 139/500\n",
      "455/526 [========================>.....] - ETA: 0s - loss: 262.5725 - mean_squared_error: 262.5725\n",
      "Epoch 00139: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 373us/step - loss: 260.0795 - mean_squared_error: 260.0795 - val_loss: 241.0172 - val_mean_squared_error: 241.0172\n",
      "Epoch 140/500\n",
      "454/526 [========================>.....] - ETA: 0s - loss: 257.6305 - mean_squared_error: 257.6305\n",
      "Epoch 00140: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 375us/step - loss: 260.1084 - mean_squared_error: 260.1084 - val_loss: 243.3657 - val_mean_squared_error: 243.3657\n",
      "Epoch 141/500\n",
      "451/526 [========================>.....] - ETA: 0s - loss: 284.4759 - mean_squared_error: 284.4759\n",
      "Epoch 00141: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 375us/step - loss: 279.8347 - mean_squared_error: 279.8347 - val_loss: 268.6006 - val_mean_squared_error: 268.6006\n",
      "Epoch 142/500\n",
      "467/526 [=========================>....] - ETA: 0s - loss: 253.4670 - mean_squared_error: 253.4670\n",
      "Epoch 00142: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 363us/step - loss: 253.6066 - mean_squared_error: 253.6066 - val_loss: 393.0500 - val_mean_squared_error: 393.0500\n",
      "Epoch 143/500\n",
      "462/526 [=========================>....] - ETA: 0s - loss: 289.6299 - mean_squared_error: 289.6299\n",
      "Epoch 00143: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 369us/step - loss: 284.3594 - mean_squared_error: 284.3594 - val_loss: 290.3157 - val_mean_squared_error: 290.3157\n",
      "Epoch 144/500\n",
      "459/526 [=========================>....] - ETA: 0s - loss: 269.5423 - mean_squared_error: 269.5423\n",
      "Epoch 00144: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 369us/step - loss: 266.1065 - mean_squared_error: 266.1065 - val_loss: 237.6835 - val_mean_squared_error: 237.6835\n",
      "Epoch 145/500\n",
      "449/526 [========================>.....] - ETA: 0s - loss: 264.6911 - mean_squared_error: 264.6911\n",
      "Epoch 00145: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 381us/step - loss: 263.9105 - mean_squared_error: 263.9105 - val_loss: 256.3411 - val_mean_squared_error: 256.3411\n",
      "Epoch 146/500\n",
      "434/526 [=======================>......] - ETA: 0s - loss: 263.9219 - mean_squared_error: 263.9219\n",
      "Epoch 00146: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 390us/step - loss: 266.1324 - mean_squared_error: 266.1324 - val_loss: 377.4351 - val_mean_squared_error: 377.4351\n",
      "Epoch 147/500\n",
      "446/526 [========================>.....] - ETA: 0s - loss: 256.2244 - mean_squared_error: 256.2244\n",
      "Epoch 00147: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 381us/step - loss: 258.2901 - mean_squared_error: 258.2901 - val_loss: 333.3965 - val_mean_squared_error: 333.3965\n",
      "Epoch 148/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 260.4887 - mean_squared_error: 260.4887\n",
      "Epoch 00148: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 392us/step - loss: 262.6913 - mean_squared_error: 262.6913 - val_loss: 257.7313 - val_mean_squared_error: 257.7313\n",
      "Epoch 149/500\n",
      "435/526 [=======================>......] - ETA: 0s - loss: 284.4609 - mean_squared_error: 284.4609\n",
      "Epoch 00149: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 392us/step - loss: 278.3033 - mean_squared_error: 278.3033 - val_loss: 355.1342 - val_mean_squared_error: 355.1342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/500\n",
      "430/526 [=======================>......] - ETA: 0s - loss: 258.8556 - mean_squared_error: 258.8556\n",
      "Epoch 00150: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 396us/step - loss: 257.9751 - mean_squared_error: 257.9751 - val_loss: 243.6592 - val_mean_squared_error: 243.6592\n",
      "Epoch 151/500\n",
      "435/526 [=======================>......] - ETA: 0s - loss: 265.2457 - mean_squared_error: 265.2457\n",
      "Epoch 00151: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 390us/step - loss: 269.7183 - mean_squared_error: 269.7183 - val_loss: 251.9326 - val_mean_squared_error: 251.9326\n",
      "Epoch 152/500\n",
      "447/526 [========================>.....] - ETA: 0s - loss: 275.1345 - mean_squared_error: 275.1345\n",
      "Epoch 00152: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 382us/step - loss: 270.1928 - mean_squared_error: 270.1928 - val_loss: 280.9824 - val_mean_squared_error: 280.9824\n",
      "Epoch 153/500\n",
      "442/526 [========================>.....] - ETA: 0s - loss: 253.3859 - mean_squared_error: 253.3859\n",
      "Epoch 00153: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 384us/step - loss: 258.4998 - mean_squared_error: 258.4998 - val_loss: 283.3722 - val_mean_squared_error: 283.3722\n",
      "Epoch 154/500\n",
      "440/526 [========================>.....] - ETA: 0s - loss: 254.0033 - mean_squared_error: 254.0033\n",
      "Epoch 00154: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 386us/step - loss: 254.0788 - mean_squared_error: 254.0788 - val_loss: 253.1799 - val_mean_squared_error: 253.1799\n",
      "Epoch 155/500\n",
      "444/526 [========================>.....] - ETA: 0s - loss: 253.8635 - mean_squared_error: 253.8635\n",
      "Epoch 00155: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 386us/step - loss: 254.7130 - mean_squared_error: 254.7130 - val_loss: 277.7510 - val_mean_squared_error: 277.7510\n",
      "Epoch 156/500\n",
      "442/526 [========================>.....] - ETA: 0s - loss: 269.0519 - mean_squared_error: 269.0519\n",
      "Epoch 00156: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 388us/step - loss: 267.5169 - mean_squared_error: 267.5169 - val_loss: 258.6623 - val_mean_squared_error: 258.6623\n",
      "Epoch 157/500\n",
      "437/526 [=======================>......] - ETA: 0s - loss: 251.2998 - mean_squared_error: 251.2998\n",
      "Epoch 00157: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 388us/step - loss: 249.9100 - mean_squared_error: 249.9100 - val_loss: 264.3928 - val_mean_squared_error: 264.3928\n",
      "Epoch 158/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 273.5477 - mean_squared_error: 273.5477\n",
      "Epoch 00158: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 377us/step - loss: 286.5369 - mean_squared_error: 286.5369 - val_loss: 290.9146 - val_mean_squared_error: 290.9146\n",
      "Epoch 159/500\n",
      "442/526 [========================>.....] - ETA: 0s - loss: 258.9106 - mean_squared_error: 258.9106\n",
      "Epoch 00159: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 384us/step - loss: 255.1199 - mean_squared_error: 255.1199 - val_loss: 330.5368 - val_mean_squared_error: 330.5368\n",
      "Epoch 160/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 268.9736 - mean_squared_error: 268.9736\n",
      "Epoch 00160: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 392us/step - loss: 272.2658 - mean_squared_error: 272.2658 - val_loss: 247.5223 - val_mean_squared_error: 247.5223\n",
      "Epoch 161/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 262.7440 - mean_squared_error: 262.7440\n",
      "Epoch 00161: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 396us/step - loss: 258.8921 - mean_squared_error: 258.8921 - val_loss: 240.1808 - val_mean_squared_error: 240.1808\n",
      "Epoch 162/500\n",
      "438/526 [=======================>......] - ETA: 0s - loss: 269.4182 - mean_squared_error: 269.4182\n",
      "Epoch 00162: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 388us/step - loss: 267.0187 - mean_squared_error: 267.0187 - val_loss: 243.9789 - val_mean_squared_error: 243.9789\n",
      "Epoch 163/500\n",
      "441/526 [========================>.....] - ETA: 0s - loss: 246.2988 - mean_squared_error: 246.2988\n",
      "Epoch 00163: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 384us/step - loss: 246.4948 - mean_squared_error: 246.4948 - val_loss: 254.2372 - val_mean_squared_error: 254.2372\n",
      "Epoch 164/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 257.5875 - mean_squared_error: 257.5875\n",
      "Epoch 00164: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 377us/step - loss: 257.4912 - mean_squared_error: 257.4912 - val_loss: 307.4045 - val_mean_squared_error: 307.4045\n",
      "Epoch 165/500\n",
      "447/526 [========================>.....] - ETA: 0s - loss: 257.7711 - mean_squared_error: 257.7711\n",
      "Epoch 00165: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 381us/step - loss: 262.1028 - mean_squared_error: 262.1028 - val_loss: 276.8764 - val_mean_squared_error: 276.8764\n",
      "Epoch 166/500\n",
      "440/526 [========================>.....] - ETA: 0s - loss: 249.6133 - mean_squared_error: 249.6133\n",
      "Epoch 00166: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 390us/step - loss: 251.1756 - mean_squared_error: 251.1756 - val_loss: 262.4066 - val_mean_squared_error: 262.4066\n",
      "Epoch 167/500\n",
      "440/526 [========================>.....] - ETA: 0s - loss: 261.1076 - mean_squared_error: 261.1076\n",
      "Epoch 00167: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 382us/step - loss: 260.7978 - mean_squared_error: 260.7978 - val_loss: 312.9356 - val_mean_squared_error: 312.9356\n",
      "Epoch 168/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 257.9108 - mean_squared_error: 257.9108\n",
      "Epoch 00168: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 377us/step - loss: 256.0706 - mean_squared_error: 256.0706 - val_loss: 248.3449 - val_mean_squared_error: 248.3449\n",
      "Epoch 169/500\n",
      "446/526 [========================>.....] - ETA: 0s - loss: 266.7023 - mean_squared_error: 266.7023\n",
      "Epoch 00169: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 381us/step - loss: 265.7464 - mean_squared_error: 265.7464 - val_loss: 251.8155 - val_mean_squared_error: 251.8155\n",
      "Epoch 170/500\n",
      "447/526 [========================>.....] - ETA: 0s - loss: 246.4752 - mean_squared_error: 246.4752\n",
      "Epoch 00170: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 381us/step - loss: 248.9875 - mean_squared_error: 248.9875 - val_loss: 272.3765 - val_mean_squared_error: 272.3765\n",
      "Epoch 171/500\n",
      "458/526 [=========================>....] - ETA: 0s - loss: 260.7045 - mean_squared_error: 260.7045\n",
      "Epoch 00171: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 375us/step - loss: 258.7580 - mean_squared_error: 258.7580 - val_loss: 326.8996 - val_mean_squared_error: 326.8996\n",
      "Epoch 172/500\n",
      "444/526 [========================>.....] - ETA: 0s - loss: 252.0101 - mean_squared_error: 252.0101\n",
      "Epoch 00172: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 382us/step - loss: 253.2720 - mean_squared_error: 253.2720 - val_loss: 254.5814 - val_mean_squared_error: 254.5814\n",
      "Epoch 173/500\n",
      "441/526 [========================>.....] - ETA: 0s - loss: 272.9655 - mean_squared_error: 272.9655\n",
      "Epoch 00173: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 386us/step - loss: 269.4484 - mean_squared_error: 269.4484 - val_loss: 240.0153 - val_mean_squared_error: 240.0153\n",
      "Epoch 174/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 262.4857 - mean_squared_error: 262.4857\n",
      "Epoch 00174: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 375us/step - loss: 264.5965 - mean_squared_error: 264.5965 - val_loss: 248.3879 - val_mean_squared_error: 248.3879\n",
      "Epoch 175/500\n",
      "456/526 [=========================>....] - ETA: 0s - loss: 257.7584 - mean_squared_error: 257.7584\n",
      "Epoch 00175: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 375us/step - loss: 253.4644 - mean_squared_error: 253.4644 - val_loss: 238.1497 - val_mean_squared_error: 238.1497\n",
      "Epoch 176/500\n",
      "445/526 [========================>.....] - ETA: 0s - loss: 258.7286 - mean_squared_error: 258.7286\n",
      "Epoch 00176: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 386us/step - loss: 254.2152 - mean_squared_error: 254.2152 - val_loss: 257.4126 - val_mean_squared_error: 257.4126\n",
      "Epoch 177/500\n",
      "446/526 [========================>.....] - ETA: 0s - loss: 257.6431 - mean_squared_error: 257.6431\n",
      "Epoch 00177: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 381us/step - loss: 254.9924 - mean_squared_error: 254.9924 - val_loss: 264.4362 - val_mean_squared_error: 264.4362\n",
      "Epoch 178/500\n",
      "452/526 [========================>.....] - ETA: 0s - loss: 268.7973 - mean_squared_error: 268.7973\n",
      "Epoch 00178: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 377us/step - loss: 267.6856 - mean_squared_error: 267.6856 - val_loss: 302.3108 - val_mean_squared_error: 302.3108\n",
      "Epoch 179/500\n",
      "454/526 [========================>.....] - ETA: 0s - loss: 252.5715 - mean_squared_error: 252.5715\n",
      "Epoch 00179: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 375us/step - loss: 252.7196 - mean_squared_error: 252.7196 - val_loss: 287.9398 - val_mean_squared_error: 287.9398\n",
      "Epoch 180/500\n",
      "455/526 [========================>.....] - ETA: 0s - loss: 257.6793 - mean_squared_error: 257.6793\n",
      "Epoch 00180: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 375us/step - loss: 259.8721 - mean_squared_error: 259.8721 - val_loss: 411.8713 - val_mean_squared_error: 411.8713\n",
      "Epoch 181/500\n",
      "450/526 [========================>.....] - ETA: 0s - loss: 254.5423 - mean_squared_error: 254.5423\n",
      "Epoch 00181: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 377us/step - loss: 256.7838 - mean_squared_error: 256.7838 - val_loss: 246.2958 - val_mean_squared_error: 246.2958\n",
      "Epoch 182/500\n",
      "452/526 [========================>.....] - ETA: 0s - loss: 243.7106 - mean_squared_error: 243.7106\n",
      "Epoch 00182: val_loss did not improve from 235.86546\n",
      "526/526 [==============================] - 0s 379us/step - loss: 244.9331 - mean_squared_error: 244.9331 - val_loss: 381.6965 - val_mean_squared_error: 381.6965\n",
      "Epoch 183/500\n",
      "447/526 [========================>.....] - ETA: 0s - loss: 250.2057 - mean_squared_error: 250.2057\n",
      "Epoch 00183: val_loss improved from 235.86546 to 227.41774, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 504us/step - loss: 247.5911 - mean_squared_error: 247.5911 - val_loss: 227.4177 - val_mean_squared_error: 227.4177\n",
      "Epoch 184/500\n",
      "446/526 [========================>.....] - ETA: 0s - loss: 251.6840 - mean_squared_error: 251.6840\n",
      "Epoch 00184: val_loss did not improve from 227.41774\n",
      "526/526 [==============================] - 0s 381us/step - loss: 251.3339 - mean_squared_error: 251.3339 - val_loss: 265.5132 - val_mean_squared_error: 265.5132\n",
      "Epoch 185/500\n",
      "454/526 [========================>.....] - ETA: 0s - loss: 254.0644 - mean_squared_error: 254.0644\n",
      "Epoch 00185: val_loss did not improve from 227.41774\n",
      "526/526 [==============================] - 0s 375us/step - loss: 253.4464 - mean_squared_error: 253.4464 - val_loss: 257.7080 - val_mean_squared_error: 257.7080\n",
      "Epoch 186/500\n",
      "444/526 [========================>.....] - ETA: 0s - loss: 258.4600 - mean_squared_error: 258.4600\n",
      "Epoch 00186: val_loss did not improve from 227.41774\n",
      "526/526 [==============================] - 0s 381us/step - loss: 259.9465 - mean_squared_error: 259.9465 - val_loss: 230.1517 - val_mean_squared_error: 230.1517\n",
      "Epoch 187/500\n",
      "450/526 [========================>.....] - ETA: 0s - loss: 252.8333 - mean_squared_error: 252.8333\n",
      "Epoch 00187: val_loss improved from 227.41774 to 226.50490, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 561us/step - loss: 251.6510 - mean_squared_error: 251.6510 - val_loss: 226.5049 - val_mean_squared_error: 226.5049\n",
      "Epoch 188/500\n",
      "449/526 [========================>.....] - ETA: 0s - loss: 264.9445 - mean_squared_error: 264.9445\n",
      "Epoch 00188: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 381us/step - loss: 264.5832 - mean_squared_error: 264.5832 - val_loss: 253.3868 - val_mean_squared_error: 253.3868\n",
      "Epoch 189/500\n",
      "446/526 [========================>.....] - ETA: 0s - loss: 257.1176 - mean_squared_error: 257.1176\n",
      "Epoch 00189: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 382us/step - loss: 260.2923 - mean_squared_error: 260.2923 - val_loss: 244.6849 - val_mean_squared_error: 244.6849\n",
      "Epoch 190/500\n",
      "446/526 [========================>.....] - ETA: 0s - loss: 250.5917 - mean_squared_error: 250.5917\n",
      "Epoch 00190: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 381us/step - loss: 250.5018 - mean_squared_error: 250.5018 - val_loss: 266.7402 - val_mean_squared_error: 266.7402\n",
      "Epoch 191/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 246.6420 - mean_squared_error: 246.6420\n",
      "Epoch 00191: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 379us/step - loss: 249.5680 - mean_squared_error: 249.5680 - val_loss: 265.4971 - val_mean_squared_error: 265.4971\n",
      "Epoch 192/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 262.4573 - mean_squared_error: 262.4573\n",
      "Epoch 00192: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 373us/step - loss: 259.3830 - mean_squared_error: 259.3830 - val_loss: 266.1509 - val_mean_squared_error: 266.1509\n",
      "Epoch 193/500\n",
      "451/526 [========================>.....] - ETA: 0s - loss: 260.9524 - mean_squared_error: 260.9524\n",
      "Epoch 00193: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 379us/step - loss: 258.4451 - mean_squared_error: 258.4451 - val_loss: 250.4592 - val_mean_squared_error: 250.4592\n",
      "Epoch 194/500\n",
      "447/526 [========================>.....] - ETA: 0s - loss: 234.7553 - mean_squared_error: 234.7553\n",
      "Epoch 00194: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 381us/step - loss: 238.6161 - mean_squared_error: 238.6161 - val_loss: 275.2149 - val_mean_squared_error: 275.2149\n",
      "Epoch 195/500\n",
      "448/526 [========================>.....] - ETA: 0s - loss: 257.4728 - mean_squared_error: 257.4728\n",
      "Epoch 00195: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 381us/step - loss: 256.9706 - mean_squared_error: 256.9706 - val_loss: 290.4185 - val_mean_squared_error: 290.4185\n",
      "Epoch 196/500\n",
      "452/526 [========================>.....] - ETA: 0s - loss: 249.2262 - mean_squared_error: 249.2262\n",
      "Epoch 00196: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 375us/step - loss: 249.8128 - mean_squared_error: 249.8128 - val_loss: 270.7400 - val_mean_squared_error: 270.7400\n",
      "Epoch 197/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 257.7787 - mean_squared_error: 257.7787\n",
      "Epoch 00197: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 375us/step - loss: 264.3781 - mean_squared_error: 264.3781 - val_loss: 230.8762 - val_mean_squared_error: 230.8762\n",
      "Epoch 198/500\n",
      "452/526 [========================>.....] - ETA: 0s - loss: 252.1449 - mean_squared_error: 252.1449\n",
      "Epoch 00198: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 377us/step - loss: 253.0051 - mean_squared_error: 253.0051 - val_loss: 246.4827 - val_mean_squared_error: 246.4827\n",
      "Epoch 199/500\n",
      "448/526 [========================>.....] - ETA: 0s - loss: 250.1205 - mean_squared_error: 250.1205\n",
      "Epoch 00199: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 381us/step - loss: 252.5421 - mean_squared_error: 252.5421 - val_loss: 288.7657 - val_mean_squared_error: 288.7657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/500\n",
      "456/526 [=========================>....] - ETA: 0s - loss: 251.0487 - mean_squared_error: 251.0487\n",
      "Epoch 00200: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 373us/step - loss: 253.1181 - mean_squared_error: 253.1181 - val_loss: 357.3454 - val_mean_squared_error: 357.3454\n",
      "Epoch 201/500\n",
      "450/526 [========================>.....] - ETA: 0s - loss: 267.4004 - mean_squared_error: 267.4004\n",
      "Epoch 00201: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 377us/step - loss: 263.0451 - mean_squared_error: 263.0451 - val_loss: 231.4991 - val_mean_squared_error: 231.4991\n",
      "Epoch 202/500\n",
      "447/526 [========================>.....] - ETA: 0s - loss: 236.6047 - mean_squared_error: 236.6047\n",
      "Epoch 00202: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 379us/step - loss: 235.9361 - mean_squared_error: 235.9361 - val_loss: 228.3422 - val_mean_squared_error: 228.3422\n",
      "Epoch 203/500\n",
      "451/526 [========================>.....] - ETA: 0s - loss: 255.2496 - mean_squared_error: 255.2496\n",
      "Epoch 00203: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 377us/step - loss: 254.6219 - mean_squared_error: 254.6219 - val_loss: 279.1860 - val_mean_squared_error: 279.1860\n",
      "Epoch 204/500\n",
      "456/526 [=========================>....] - ETA: 0s - loss: 262.5691 - mean_squared_error: 262.5691\n",
      "Epoch 00204: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 375us/step - loss: 266.3478 - mean_squared_error: 266.3478 - val_loss: 242.3054 - val_mean_squared_error: 242.3054\n",
      "Epoch 205/500\n",
      "446/526 [========================>.....] - ETA: 0s - loss: 246.5414 - mean_squared_error: 246.5414\n",
      "Epoch 00205: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 382us/step - loss: 245.4456 - mean_squared_error: 245.4456 - val_loss: 238.9231 - val_mean_squared_error: 238.9231\n",
      "Epoch 206/500\n",
      "455/526 [========================>.....] - ETA: 0s - loss: 257.9263 - mean_squared_error: 257.9263\n",
      "Epoch 00206: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 375us/step - loss: 255.7027 - mean_squared_error: 255.7027 - val_loss: 226.7018 - val_mean_squared_error: 226.7018\n",
      "Epoch 207/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 271.4582 - mean_squared_error: 271.4582\n",
      "Epoch 00207: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 377us/step - loss: 264.7061 - mean_squared_error: 264.7061 - val_loss: 229.8360 - val_mean_squared_error: 229.8360\n",
      "Epoch 208/500\n",
      "454/526 [========================>.....] - ETA: 0s - loss: 251.4860 - mean_squared_error: 251.4860\n",
      "Epoch 00208: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 375us/step - loss: 249.0980 - mean_squared_error: 249.0980 - val_loss: 241.4776 - val_mean_squared_error: 241.4776\n",
      "Epoch 209/500\n",
      "450/526 [========================>.....] - ETA: 0s - loss: 249.3706 - mean_squared_error: 249.3706\n",
      "Epoch 00209: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 379us/step - loss: 246.0965 - mean_squared_error: 246.0965 - val_loss: 263.1732 - val_mean_squared_error: 263.1732\n",
      "Epoch 210/500\n",
      "452/526 [========================>.....] - ETA: 0s - loss: 234.8346 - mean_squared_error: 234.8346\n",
      "Epoch 00210: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 377us/step - loss: 242.2387 - mean_squared_error: 242.2387 - val_loss: 263.9776 - val_mean_squared_error: 263.9776\n",
      "Epoch 211/500\n",
      "456/526 [=========================>....] - ETA: 0s - loss: 240.8824 - mean_squared_error: 240.8824\n",
      "Epoch 00211: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 373us/step - loss: 240.6771 - mean_squared_error: 240.6771 - val_loss: 293.2245 - val_mean_squared_error: 293.2245\n",
      "Epoch 212/500\n",
      "456/526 [=========================>....] - ETA: 0s - loss: 246.9351 - mean_squared_error: 246.9351\n",
      "Epoch 00212: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 377us/step - loss: 249.1792 - mean_squared_error: 249.1792 - val_loss: 295.8544 - val_mean_squared_error: 295.8544\n",
      "Epoch 213/500\n",
      "455/526 [========================>.....] - ETA: 0s - loss: 257.5714 - mean_squared_error: 257.5714\n",
      "Epoch 00213: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 373us/step - loss: 257.0662 - mean_squared_error: 257.0662 - val_loss: 231.0902 - val_mean_squared_error: 231.0902\n",
      "Epoch 214/500\n",
      "462/526 [=========================>....] - ETA: 0s - loss: 243.8335 - mean_squared_error: 243.8335\n",
      "Epoch 00214: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 371us/step - loss: 251.0083 - mean_squared_error: 251.0083 - val_loss: 257.6797 - val_mean_squared_error: 257.6797\n",
      "Epoch 215/500\n",
      "450/526 [========================>.....] - ETA: 0s - loss: 251.8815 - mean_squared_error: 251.8815\n",
      "Epoch 00215: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 377us/step - loss: 253.1540 - mean_squared_error: 253.1540 - val_loss: 241.6113 - val_mean_squared_error: 241.6113\n",
      "Epoch 216/500\n",
      "454/526 [========================>.....] - ETA: 0s - loss: 259.7252 - mean_squared_error: 259.7252\n",
      "Epoch 00216: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 373us/step - loss: 255.9384 - mean_squared_error: 255.9384 - val_loss: 245.3292 - val_mean_squared_error: 245.3292\n",
      "Epoch 217/500\n",
      "450/526 [========================>.....] - ETA: 0s - loss: 246.7857 - mean_squared_error: 246.7857\n",
      "Epoch 00217: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 377us/step - loss: 242.7137 - mean_squared_error: 242.7137 - val_loss: 345.4800 - val_mean_squared_error: 345.4800\n",
      "Epoch 218/500\n",
      "460/526 [=========================>....] - ETA: 0s - loss: 249.2812 - mean_squared_error: 249.2812\n",
      "Epoch 00218: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 371us/step - loss: 248.6003 - mean_squared_error: 248.6003 - val_loss: 339.7720 - val_mean_squared_error: 339.7720\n",
      "Epoch 219/500\n",
      "459/526 [=========================>....] - ETA: 0s - loss: 260.9301 - mean_squared_error: 260.9301\n",
      "Epoch 00219: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 371us/step - loss: 255.0877 - mean_squared_error: 255.0877 - val_loss: 235.5437 - val_mean_squared_error: 235.5437\n",
      "Epoch 220/500\n",
      "460/526 [=========================>....] - ETA: 0s - loss: 242.0836 - mean_squared_error: 242.0836\n",
      "Epoch 00220: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 371us/step - loss: 243.2445 - mean_squared_error: 243.2445 - val_loss: 329.0227 - val_mean_squared_error: 329.0227\n",
      "Epoch 221/500\n",
      "460/526 [=========================>....] - ETA: 0s - loss: 266.8774 - mean_squared_error: 266.8774\n",
      "Epoch 00221: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 373us/step - loss: 265.1160 - mean_squared_error: 265.1160 - val_loss: 330.4375 - val_mean_squared_error: 330.4375\n",
      "Epoch 222/500\n",
      "454/526 [========================>.....] - ETA: 0s - loss: 242.8495 - mean_squared_error: 242.8495\n",
      "Epoch 00222: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 375us/step - loss: 238.8649 - mean_squared_error: 238.8649 - val_loss: 287.3816 - val_mean_squared_error: 287.3816\n",
      "Epoch 223/500\n",
      "457/526 [=========================>....] - ETA: 0s - loss: 258.8707 - mean_squared_error: 258.8707\n",
      "Epoch 00223: val_loss did not improve from 226.50490\n",
      "526/526 [==============================] - 0s 375us/step - loss: 261.0484 - mean_squared_error: 261.0484 - val_loss: 268.8230 - val_mean_squared_error: 268.8230\n",
      "Epoch 224/500\n",
      "452/526 [========================>.....] - ETA: 0s - loss: 247.6326 - mean_squared_error: 247.6326\n",
      "Epoch 00224: val_loss improved from 226.50490 to 225.47670, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 483us/step - loss: 245.5679 - mean_squared_error: 245.5679 - val_loss: 225.4767 - val_mean_squared_error: 225.4767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/500\n",
      "456/526 [=========================>....] - ETA: 0s - loss: 251.8014 - mean_squared_error: 251.8014\n",
      "Epoch 00225: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 375us/step - loss: 246.5497 - mean_squared_error: 246.5497 - val_loss: 244.9622 - val_mean_squared_error: 244.9622\n",
      "Epoch 226/500\n",
      "456/526 [=========================>....] - ETA: 0s - loss: 234.5416 - mean_squared_error: 234.5416\n",
      "Epoch 00226: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 373us/step - loss: 239.7499 - mean_squared_error: 239.7499 - val_loss: 328.7018 - val_mean_squared_error: 328.7018\n",
      "Epoch 227/500\n",
      "455/526 [========================>.....] - ETA: 0s - loss: 238.4090 - mean_squared_error: 238.4090\n",
      "Epoch 00227: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 375us/step - loss: 239.3511 - mean_squared_error: 239.3511 - val_loss: 259.7541 - val_mean_squared_error: 259.7541\n",
      "Epoch 228/500\n",
      "447/526 [========================>.....] - ETA: 0s - loss: 279.2019 - mean_squared_error: 279.2019\n",
      "Epoch 00228: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 381us/step - loss: 274.8676 - mean_squared_error: 274.8676 - val_loss: 237.3579 - val_mean_squared_error: 237.3579\n",
      "Epoch 229/500\n",
      "452/526 [========================>.....] - ETA: 0s - loss: 236.2974 - mean_squared_error: 236.2974\n",
      "Epoch 00229: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 377us/step - loss: 237.5814 - mean_squared_error: 237.5814 - val_loss: 263.9474 - val_mean_squared_error: 263.9474\n",
      "Epoch 230/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 248.8390 - mean_squared_error: 248.8390\n",
      "Epoch 00230: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 379us/step - loss: 246.2525 - mean_squared_error: 246.2525 - val_loss: 238.4008 - val_mean_squared_error: 238.4008\n",
      "Epoch 231/500\n",
      "458/526 [=========================>....] - ETA: 0s - loss: 245.4165 - mean_squared_error: 245.4165\n",
      "Epoch 00231: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 373us/step - loss: 242.1039 - mean_squared_error: 242.1039 - val_loss: 280.8536 - val_mean_squared_error: 280.8536\n",
      "Epoch 232/500\n",
      "447/526 [========================>.....] - ETA: 0s - loss: 248.0075 - mean_squared_error: 248.0075\n",
      "Epoch 00232: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 382us/step - loss: 245.7450 - mean_squared_error: 245.7450 - val_loss: 340.7550 - val_mean_squared_error: 340.7550\n",
      "Epoch 233/500\n",
      "439/526 [========================>.....] - ETA: 0s - loss: 270.7758 - mean_squared_error: 270.7758\n",
      "Epoch 00233: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 386us/step - loss: 267.9886 - mean_squared_error: 267.9886 - val_loss: 232.7355 - val_mean_squared_error: 232.7355\n",
      "Epoch 234/500\n",
      "458/526 [=========================>....] - ETA: 0s - loss: 261.4732 - mean_squared_error: 261.4732\n",
      "Epoch 00234: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 371us/step - loss: 258.7199 - mean_squared_error: 258.7199 - val_loss: 329.5666 - val_mean_squared_error: 329.5666\n",
      "Epoch 235/500\n",
      "462/526 [=========================>....] - ETA: 0s - loss: 264.1975 - mean_squared_error: 264.1975\n",
      "Epoch 00235: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 369us/step - loss: 261.9532 - mean_squared_error: 261.9532 - val_loss: 229.0646 - val_mean_squared_error: 229.0646\n",
      "Epoch 236/500\n",
      "458/526 [=========================>....] - ETA: 0s - loss: 248.0005 - mean_squared_error: 248.0005\n",
      "Epoch 00236: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 373us/step - loss: 251.8069 - mean_squared_error: 251.8069 - val_loss: 227.4293 - val_mean_squared_error: 227.4293\n",
      "Epoch 237/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 235.7433 - mean_squared_error: 235.7433\n",
      "Epoch 00237: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 375us/step - loss: 236.2568 - mean_squared_error: 236.2568 - val_loss: 322.8478 - val_mean_squared_error: 322.8478\n",
      "Epoch 238/500\n",
      "454/526 [========================>.....] - ETA: 0s - loss: 251.7320 - mean_squared_error: 251.7320\n",
      "Epoch 00238: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 373us/step - loss: 249.7598 - mean_squared_error: 249.7598 - val_loss: 268.7415 - val_mean_squared_error: 268.7415\n",
      "Epoch 239/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 250.8480 - mean_squared_error: 250.8480\n",
      "Epoch 00239: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 377us/step - loss: 246.2792 - mean_squared_error: 246.2792 - val_loss: 243.6607 - val_mean_squared_error: 243.6607\n",
      "Epoch 240/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 239.4011 - mean_squared_error: 239.4011\n",
      "Epoch 00240: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 375us/step - loss: 244.1754 - mean_squared_error: 244.1754 - val_loss: 373.4702 - val_mean_squared_error: 373.4702\n",
      "Epoch 241/500\n",
      "452/526 [========================>.....] - ETA: 0s - loss: 252.4406 - mean_squared_error: 252.4406\n",
      "Epoch 00241: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 377us/step - loss: 249.6120 - mean_squared_error: 249.6120 - val_loss: 261.9349 - val_mean_squared_error: 261.9349\n",
      "Epoch 242/500\n",
      "459/526 [=========================>....] - ETA: 0s - loss: 259.9785 - mean_squared_error: 259.9785\n",
      "Epoch 00242: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 373us/step - loss: 258.2874 - mean_squared_error: 258.2874 - val_loss: 229.3596 - val_mean_squared_error: 229.3596\n",
      "Epoch 243/500\n",
      "449/526 [========================>.....] - ETA: 0s - loss: 250.5208 - mean_squared_error: 250.5208\n",
      "Epoch 00243: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 381us/step - loss: 249.5858 - mean_squared_error: 249.5858 - val_loss: 226.4488 - val_mean_squared_error: 226.4488\n",
      "Epoch 244/500\n",
      "438/526 [=======================>......] - ETA: 0s - loss: 234.6328 - mean_squared_error: 234.6328\n",
      "Epoch 00244: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 388us/step - loss: 235.1292 - mean_squared_error: 235.1292 - val_loss: 228.7985 - val_mean_squared_error: 228.7985\n",
      "Epoch 245/500\n",
      "438/526 [=======================>......] - ETA: 0s - loss: 255.1047 - mean_squared_error: 255.1047\n",
      "Epoch 00245: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 388us/step - loss: 256.0711 - mean_squared_error: 256.0711 - val_loss: 251.1270 - val_mean_squared_error: 251.1270\n",
      "Epoch 246/500\n",
      "436/526 [=======================>......] - ETA: 0s - loss: 234.6374 - mean_squared_error: 234.6374\n",
      "Epoch 00246: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 390us/step - loss: 233.1867 - mean_squared_error: 233.1867 - val_loss: 242.8106 - val_mean_squared_error: 242.8106\n",
      "Epoch 247/500\n",
      "438/526 [=======================>......] - ETA: 0s - loss: 259.3106 - mean_squared_error: 259.3106\n",
      "Epoch 00247: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 388us/step - loss: 253.1950 - mean_squared_error: 253.1950 - val_loss: 281.8252 - val_mean_squared_error: 281.8252\n",
      "Epoch 248/500\n",
      "440/526 [========================>.....] - ETA: 0s - loss: 248.2354 - mean_squared_error: 248.2354\n",
      "Epoch 00248: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 388us/step - loss: 244.7814 - mean_squared_error: 244.7814 - val_loss: 274.9672 - val_mean_squared_error: 274.9672\n",
      "Epoch 249/500\n",
      "445/526 [========================>.....] - ETA: 0s - loss: 244.5792 - mean_squared_error: 244.5792\n",
      "Epoch 00249: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 384us/step - loss: 243.6372 - mean_squared_error: 243.6372 - val_loss: 269.3222 - val_mean_squared_error: 269.3222\n",
      "Epoch 250/500\n",
      "448/526 [========================>.....] - ETA: 0s - loss: 252.9025 - mean_squared_error: 252.9025\n",
      "Epoch 00250: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 379us/step - loss: 255.0958 - mean_squared_error: 255.0958 - val_loss: 233.1394 - val_mean_squared_error: 233.1394\n",
      "Epoch 251/500\n",
      "439/526 [========================>.....] - ETA: 0s - loss: 234.8698 - mean_squared_error: 234.8698\n",
      "Epoch 00251: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 388us/step - loss: 240.8780 - mean_squared_error: 240.8780 - val_loss: 237.1857 - val_mean_squared_error: 237.1857\n",
      "Epoch 252/500\n",
      "447/526 [========================>.....] - ETA: 0s - loss: 244.9964 - mean_squared_error: 244.9964\n",
      "Epoch 00252: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 381us/step - loss: 243.5054 - mean_squared_error: 243.5054 - val_loss: 289.8122 - val_mean_squared_error: 289.8122\n",
      "Epoch 253/500\n",
      "444/526 [========================>.....] - ETA: 0s - loss: 253.5450 - mean_squared_error: 253.5450\n",
      "Epoch 00253: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 382us/step - loss: 255.0267 - mean_squared_error: 255.0267 - val_loss: 282.8731 - val_mean_squared_error: 282.8731\n",
      "Epoch 254/500\n",
      "443/526 [========================>.....] - ETA: 0s - loss: 240.9398 - mean_squared_error: 240.9398\n",
      "Epoch 00254: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 386us/step - loss: 242.0129 - mean_squared_error: 242.0129 - val_loss: 240.1754 - val_mean_squared_error: 240.1754\n",
      "Epoch 255/500\n",
      "445/526 [========================>.....] - ETA: 0s - loss: 234.0518 - mean_squared_error: 234.0518\n",
      "Epoch 00255: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 382us/step - loss: 237.2957 - mean_squared_error: 237.2957 - val_loss: 258.3131 - val_mean_squared_error: 258.3131\n",
      "Epoch 256/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 248.6272 - mean_squared_error: 248.6272\n",
      "Epoch 00256: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 398us/step - loss: 246.7547 - mean_squared_error: 246.7547 - val_loss: 267.9807 - val_mean_squared_error: 267.9807\n",
      "Epoch 257/500\n",
      "434/526 [=======================>......] - ETA: 0s - loss: 276.0450 - mean_squared_error: 276.0450\n",
      "Epoch 00257: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 388us/step - loss: 271.1176 - mean_squared_error: 271.1176 - val_loss: 256.0733 - val_mean_squared_error: 256.0733\n",
      "Epoch 258/500\n",
      "443/526 [========================>.....] - ETA: 0s - loss: 231.0374 - mean_squared_error: 231.0374\n",
      "Epoch 00258: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 382us/step - loss: 234.0643 - mean_squared_error: 234.0643 - val_loss: 259.7805 - val_mean_squared_error: 259.7805\n",
      "Epoch 259/500\n",
      "452/526 [========================>.....] - ETA: 0s - loss: 251.3327 - mean_squared_error: 251.3327\n",
      "Epoch 00259: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 379us/step - loss: 250.8595 - mean_squared_error: 250.8595 - val_loss: 235.5857 - val_mean_squared_error: 235.5857\n",
      "Epoch 260/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 230.3780 - mean_squared_error: 230.3780\n",
      "Epoch 00260: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 390us/step - loss: 235.6394 - mean_squared_error: 235.6394 - val_loss: 233.8448 - val_mean_squared_error: 233.8448\n",
      "Epoch 261/500\n",
      "452/526 [========================>.....] - ETA: 0s - loss: 242.5986 - mean_squared_error: 242.5986\n",
      "Epoch 00261: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 379us/step - loss: 242.1231 - mean_squared_error: 242.1231 - val_loss: 260.7206 - val_mean_squared_error: 260.7206\n",
      "Epoch 262/500\n",
      "446/526 [========================>.....] - ETA: 0s - loss: 235.1392 - mean_squared_error: 235.1392\n",
      "Epoch 00262: val_loss did not improve from 225.47670\n",
      "526/526 [==============================] - 0s 381us/step - loss: 236.8065 - mean_squared_error: 236.8065 - val_loss: 313.3807 - val_mean_squared_error: 313.3807\n",
      "Epoch 263/500\n",
      "446/526 [========================>.....] - ETA: 0s - loss: 248.6463 - mean_squared_error: 248.6463\n",
      "Epoch 00263: val_loss improved from 225.47670 to 214.70380, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 451us/step - loss: 246.1823 - mean_squared_error: 246.1823 - val_loss: 214.7038 - val_mean_squared_error: 214.7038\n",
      "Epoch 264/500\n",
      "426/526 [=======================>......] - ETA: 0s - loss: 250.0672 - mean_squared_error: 250.0672\n",
      "Epoch 00264: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 398us/step - loss: 252.5130 - mean_squared_error: 252.5130 - val_loss: 372.3428 - val_mean_squared_error: 372.3428\n",
      "Epoch 265/500\n",
      "427/526 [=======================>......] - ETA: 0s - loss: 248.6144 - mean_squared_error: 248.6144\n",
      "Epoch 00265: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 396us/step - loss: 244.3450 - mean_squared_error: 244.3450 - val_loss: 260.0904 - val_mean_squared_error: 260.0904\n",
      "Epoch 266/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 253.4726 - mean_squared_error: 253.4726\n",
      "Epoch 00266: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 394us/step - loss: 249.7177 - mean_squared_error: 249.7177 - val_loss: 243.4125 - val_mean_squared_error: 243.4125\n",
      "Epoch 267/500\n",
      "455/526 [========================>.....] - ETA: 0s - loss: 235.5134 - mean_squared_error: 235.5134\n",
      "Epoch 00267: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 377us/step - loss: 233.8008 - mean_squared_error: 233.8008 - val_loss: 230.8636 - val_mean_squared_error: 230.8636\n",
      "Epoch 268/500\n",
      "449/526 [========================>.....] - ETA: 0s - loss: 250.1927 - mean_squared_error: 250.1927\n",
      "Epoch 00268: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 381us/step - loss: 247.9093 - mean_squared_error: 247.9093 - val_loss: 226.8489 - val_mean_squared_error: 226.8489\n",
      "Epoch 269/500\n",
      "439/526 [========================>.....] - ETA: 0s - loss: 239.8040 - mean_squared_error: 239.8040\n",
      "Epoch 00269: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 388us/step - loss: 236.3510 - mean_squared_error: 236.3510 - val_loss: 241.4098 - val_mean_squared_error: 241.4098\n",
      "Epoch 270/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 239.2166 - mean_squared_error: 239.2166\n",
      "Epoch 00270: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 394us/step - loss: 236.0802 - mean_squared_error: 236.0802 - val_loss: 232.3833 - val_mean_squared_error: 232.3833\n",
      "Epoch 271/500\n",
      "437/526 [=======================>......] - ETA: 0s - loss: 240.6355 - mean_squared_error: 240.6355\n",
      "Epoch 00271: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 386us/step - loss: 239.6983 - mean_squared_error: 239.6983 - val_loss: 221.6795 - val_mean_squared_error: 221.6795\n",
      "Epoch 272/500\n",
      "456/526 [=========================>....] - ETA: 0s - loss: 251.2379 - mean_squared_error: 251.2379\n",
      "Epoch 00272: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 375us/step - loss: 252.8922 - mean_squared_error: 252.8922 - val_loss: 317.8329 - val_mean_squared_error: 317.8329\n",
      "Epoch 273/500\n",
      "449/526 [========================>.....] - ETA: 0s - loss: 245.8524 - mean_squared_error: 245.8524\n",
      "Epoch 00273: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 381us/step - loss: 244.7378 - mean_squared_error: 244.7378 - val_loss: 256.8772 - val_mean_squared_error: 256.8772\n",
      "Epoch 274/500\n",
      "447/526 [========================>.....] - ETA: 0s - loss: 238.2320 - mean_squared_error: 238.2320\n",
      "Epoch 00274: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 382us/step - loss: 234.9181 - mean_squared_error: 234.9181 - val_loss: 267.2426 - val_mean_squared_error: 267.2426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275/500\n",
      "443/526 [========================>.....] - ETA: 0s - loss: 238.9635 - mean_squared_error: 238.9635\n",
      "Epoch 00275: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 384us/step - loss: 239.0907 - mean_squared_error: 239.0907 - val_loss: 216.8045 - val_mean_squared_error: 216.8045\n",
      "Epoch 276/500\n",
      "448/526 [========================>.....] - ETA: 0s - loss: 232.5249 - mean_squared_error: 232.5249\n",
      "Epoch 00276: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 379us/step - loss: 233.9292 - mean_squared_error: 233.9292 - val_loss: 506.6071 - val_mean_squared_error: 506.6071\n",
      "Epoch 277/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 245.2328 - mean_squared_error: 245.2328\n",
      "Epoch 00277: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 392us/step - loss: 248.8752 - mean_squared_error: 248.8752 - val_loss: 251.1435 - val_mean_squared_error: 251.1435\n",
      "Epoch 278/500\n",
      "445/526 [========================>.....] - ETA: 0s - loss: 258.1709 - mean_squared_error: 258.1709\n",
      "Epoch 00278: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 381us/step - loss: 252.6235 - mean_squared_error: 252.6235 - val_loss: 242.7855 - val_mean_squared_error: 242.7855\n",
      "Epoch 279/500\n",
      "458/526 [=========================>....] - ETA: 0s - loss: 246.8205 - mean_squared_error: 246.8205\n",
      "Epoch 00279: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 375us/step - loss: 242.7051 - mean_squared_error: 242.7051 - val_loss: 236.8766 - val_mean_squared_error: 236.8766\n",
      "Epoch 280/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 237.0590 - mean_squared_error: 237.0590\n",
      "Epoch 00280: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 390us/step - loss: 235.4001 - mean_squared_error: 235.4001 - val_loss: 251.5773 - val_mean_squared_error: 251.5773\n",
      "Epoch 281/500\n",
      "448/526 [========================>.....] - ETA: 0s - loss: 237.1529 - mean_squared_error: 237.1529\n",
      "Epoch 00281: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 382us/step - loss: 234.5325 - mean_squared_error: 234.5325 - val_loss: 225.1856 - val_mean_squared_error: 225.1856\n",
      "Epoch 282/500\n",
      "443/526 [========================>.....] - ETA: 0s - loss: 229.7721 - mean_squared_error: 229.7721\n",
      "Epoch 00282: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 382us/step - loss: 246.9093 - mean_squared_error: 246.9093 - val_loss: 260.0425 - val_mean_squared_error: 260.0425\n",
      "Epoch 283/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 234.2518 - mean_squared_error: 234.2518\n",
      "Epoch 00283: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 397us/step - loss: 235.9646 - mean_squared_error: 235.9646 - val_loss: 246.2702 - val_mean_squared_error: 246.2702\n",
      "Epoch 284/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 259.9062 - mean_squared_error: 259.9062\n",
      "Epoch 00284: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 392us/step - loss: 255.3133 - mean_squared_error: 255.3133 - val_loss: 256.5368 - val_mean_squared_error: 256.5368\n",
      "Epoch 285/500\n",
      "442/526 [========================>.....] - ETA: 0s - loss: 237.1882 - mean_squared_error: 237.1882\n",
      "Epoch 00285: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 384us/step - loss: 235.9099 - mean_squared_error: 235.9099 - val_loss: 233.5518 - val_mean_squared_error: 233.5518\n",
      "Epoch 286/500\n",
      "442/526 [========================>.....] - ETA: 0s - loss: 237.3484 - mean_squared_error: 237.3484\n",
      "Epoch 00286: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 386us/step - loss: 234.6282 - mean_squared_error: 234.6282 - val_loss: 246.1245 - val_mean_squared_error: 246.1245\n",
      "Epoch 287/500\n",
      "435/526 [=======================>......] - ETA: 0s - loss: 245.6548 - mean_squared_error: 245.6548\n",
      "Epoch 00287: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 388us/step - loss: 243.0365 - mean_squared_error: 243.0365 - val_loss: 262.4415 - val_mean_squared_error: 262.4415\n",
      "Epoch 288/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 248.2756 - mean_squared_error: 248.2756\n",
      "Epoch 00288: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 390us/step - loss: 252.3785 - mean_squared_error: 252.3785 - val_loss: 223.4957 - val_mean_squared_error: 223.4957\n",
      "Epoch 289/500\n",
      "441/526 [========================>.....] - ETA: 0s - loss: 232.3744 - mean_squared_error: 232.3744\n",
      "Epoch 00289: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 384us/step - loss: 230.4692 - mean_squared_error: 230.4692 - val_loss: 222.0350 - val_mean_squared_error: 222.0350\n",
      "Epoch 290/500\n",
      "448/526 [========================>.....] - ETA: 0s - loss: 235.9595 - mean_squared_error: 235.9595\n",
      "Epoch 00290: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 381us/step - loss: 237.7603 - mean_squared_error: 237.7603 - val_loss: 227.0070 - val_mean_squared_error: 227.0070\n",
      "Epoch 291/500\n",
      "425/526 [=======================>......] - ETA: 0s - loss: 252.0359 - mean_squared_error: 252.0359\n",
      "Epoch 00291: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 396us/step - loss: 246.9915 - mean_squared_error: 246.9915 - val_loss: 425.0854 - val_mean_squared_error: 425.0854\n",
      "Epoch 292/500\n",
      "449/526 [========================>.....] - ETA: 0s - loss: 248.1591 - mean_squared_error: 248.1591\n",
      "Epoch 00292: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 381us/step - loss: 250.8295 - mean_squared_error: 250.8295 - val_loss: 276.6602 - val_mean_squared_error: 276.6602\n",
      "Epoch 293/500\n",
      "436/526 [=======================>......] - ETA: 0s - loss: 239.0926 - mean_squared_error: 239.0926\n",
      "Epoch 00293: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 386us/step - loss: 239.1089 - mean_squared_error: 239.1089 - val_loss: 247.8795 - val_mean_squared_error: 247.8795\n",
      "Epoch 294/500\n",
      "444/526 [========================>.....] - ETA: 0s - loss: 256.2648 - mean_squared_error: 256.2648\n",
      "Epoch 00294: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 384us/step - loss: 252.8018 - mean_squared_error: 252.8018 - val_loss: 231.5843 - val_mean_squared_error: 231.5843\n",
      "Epoch 295/500\n",
      "441/526 [========================>.....] - ETA: 0s - loss: 244.6565 - mean_squared_error: 244.6565\n",
      "Epoch 00295: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 384us/step - loss: 243.4106 - mean_squared_error: 243.4106 - val_loss: 230.0323 - val_mean_squared_error: 230.0323\n",
      "Epoch 296/500\n",
      "442/526 [========================>.....] - ETA: 0s - loss: 228.1555 - mean_squared_error: 228.1555\n",
      "Epoch 00296: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 384us/step - loss: 229.7961 - mean_squared_error: 229.7961 - val_loss: 220.4529 - val_mean_squared_error: 220.4529\n",
      "Epoch 297/500\n",
      "444/526 [========================>.....] - ETA: 0s - loss: 246.4550 - mean_squared_error: 246.4550\n",
      "Epoch 00297: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 384us/step - loss: 245.8092 - mean_squared_error: 245.8092 - val_loss: 277.0119 - val_mean_squared_error: 277.0119\n",
      "Epoch 298/500\n",
      "437/526 [=======================>......] - ETA: 0s - loss: 238.9574 - mean_squared_error: 238.9574\n",
      "Epoch 00298: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 386us/step - loss: 241.3148 - mean_squared_error: 241.3148 - val_loss: 289.0266 - val_mean_squared_error: 289.0266\n",
      "Epoch 299/500\n",
      "447/526 [========================>.....] - ETA: 0s - loss: 236.5403 - mean_squared_error: 236.5403\n",
      "Epoch 00299: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 382us/step - loss: 233.0017 - mean_squared_error: 233.0017 - val_loss: 238.1280 - val_mean_squared_error: 238.1280\n",
      "Epoch 300/500\n",
      "449/526 [========================>.....] - ETA: 0s - loss: 238.0053 - mean_squared_error: 238.0053\n",
      "Epoch 00300: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 381us/step - loss: 245.4153 - mean_squared_error: 245.4153 - val_loss: 243.5268 - val_mean_squared_error: 243.5268\n",
      "Epoch 301/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 236.4650 - mean_squared_error: 236.4650\n",
      "Epoch 00301: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 390us/step - loss: 236.6469 - mean_squared_error: 236.6469 - val_loss: 300.1234 - val_mean_squared_error: 300.1234\n",
      "Epoch 302/500\n",
      "433/526 [=======================>......] - ETA: 0s - loss: 270.5472 - mean_squared_error: 270.5472\n",
      "Epoch 00302: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 392us/step - loss: 265.9550 - mean_squared_error: 265.9550 - val_loss: 223.8580 - val_mean_squared_error: 223.8580\n",
      "Epoch 303/500\n",
      "442/526 [========================>.....] - ETA: 0s - loss: 231.6109 - mean_squared_error: 231.6109\n",
      "Epoch 00303: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 384us/step - loss: 229.1112 - mean_squared_error: 229.1112 - val_loss: 224.8709 - val_mean_squared_error: 224.8709\n",
      "Epoch 304/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 258.0213 - mean_squared_error: 258.0213\n",
      "Epoch 00304: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 394us/step - loss: 250.9526 - mean_squared_error: 250.9526 - val_loss: 249.9295 - val_mean_squared_error: 249.9295\n",
      "Epoch 305/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 227.2961 - mean_squared_error: 227.2961\n",
      "Epoch 00305: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 379us/step - loss: 230.8884 - mean_squared_error: 230.8884 - val_loss: 298.2898 - val_mean_squared_error: 298.2898\n",
      "Epoch 306/500\n",
      "442/526 [========================>.....] - ETA: 0s - loss: 229.9551 - mean_squared_error: 229.9551\n",
      "Epoch 00306: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 386us/step - loss: 232.7529 - mean_squared_error: 232.7529 - val_loss: 235.6772 - val_mean_squared_error: 235.6772\n",
      "Epoch 307/500\n",
      "437/526 [=======================>......] - ETA: 0s - loss: 244.0771 - mean_squared_error: 244.0771\n",
      "Epoch 00307: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 388us/step - loss: 238.0261 - mean_squared_error: 238.0261 - val_loss: 515.1820 - val_mean_squared_error: 515.1820\n",
      "Epoch 308/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 276.7194 - mean_squared_error: 276.7194\n",
      "Epoch 00308: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 375us/step - loss: 268.6819 - mean_squared_error: 268.6819 - val_loss: 278.1071 - val_mean_squared_error: 278.1071\n",
      "Epoch 309/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 225.3932 - mean_squared_error: 225.3932\n",
      "Epoch 00309: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 392us/step - loss: 234.7835 - mean_squared_error: 234.7835 - val_loss: 292.6505 - val_mean_squared_error: 292.6505\n",
      "Epoch 310/500\n",
      "440/526 [========================>.....] - ETA: 0s - loss: 251.0485 - mean_squared_error: 251.0485\n",
      "Epoch 00310: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 392us/step - loss: 250.5445 - mean_squared_error: 250.5445 - val_loss: 245.7546 - val_mean_squared_error: 245.7546\n",
      "Epoch 311/500\n",
      "435/526 [=======================>......] - ETA: 0s - loss: 230.5091 - mean_squared_error: 230.5091\n",
      "Epoch 00311: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 390us/step - loss: 232.6083 - mean_squared_error: 232.6083 - val_loss: 299.0386 - val_mean_squared_error: 299.0386\n",
      "Epoch 312/500\n",
      "435/526 [=======================>......] - ETA: 0s - loss: 237.7263 - mean_squared_error: 237.7263\n",
      "Epoch 00312: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 394us/step - loss: 247.9225 - mean_squared_error: 247.9225 - val_loss: 229.3922 - val_mean_squared_error: 229.3922\n",
      "Epoch 313/500\n",
      "421/526 [=======================>......] - ETA: 0s - loss: 234.7426 - mean_squared_error: 234.7426\n",
      "Epoch 00313: val_loss did not improve from 214.70380\n",
      "526/526 [==============================] - 0s 402us/step - loss: 234.1859 - mean_squared_error: 234.1859 - val_loss: 245.6712 - val_mean_squared_error: 245.6712\n",
      "Epoch 314/500\n",
      "435/526 [=======================>......] - ETA: 0s - loss: 257.5249 - mean_squared_error: 257.5249\n",
      "Epoch 00314: val_loss improved from 214.70380 to 212.93303, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 539us/step - loss: 249.5491 - mean_squared_error: 249.5491 - val_loss: 212.9330 - val_mean_squared_error: 212.9330\n",
      "Epoch 315/500\n",
      "419/526 [======================>.......] - ETA: 0s - loss: 243.4267 - mean_squared_error: 243.4267\n",
      "Epoch 00315: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 403us/step - loss: 239.6731 - mean_squared_error: 239.6731 - val_loss: 255.3227 - val_mean_squared_error: 255.3227\n",
      "Epoch 316/500\n",
      "431/526 [=======================>......] - ETA: 0s - loss: 236.4928 - mean_squared_error: 236.4928\n",
      "Epoch 00316: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 392us/step - loss: 234.0110 - mean_squared_error: 234.0110 - val_loss: 255.1045 - val_mean_squared_error: 255.1045\n",
      "Epoch 317/500\n",
      "443/526 [========================>.....] - ETA: 0s - loss: 239.8240 - mean_squared_error: 239.8240\n",
      "Epoch 00317: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 384us/step - loss: 237.0983 - mean_squared_error: 237.0983 - val_loss: 402.0080 - val_mean_squared_error: 402.0080\n",
      "Epoch 318/500\n",
      "451/526 [========================>.....] - ETA: 0s - loss: 242.7144 - mean_squared_error: 242.7144\n",
      "Epoch 00318: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 377us/step - loss: 240.9319 - mean_squared_error: 240.9319 - val_loss: 238.1408 - val_mean_squared_error: 238.1408\n",
      "Epoch 319/500\n",
      "452/526 [========================>.....] - ETA: 0s - loss: 243.4671 - mean_squared_error: 243.4671\n",
      "Epoch 00319: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 377us/step - loss: 239.8725 - mean_squared_error: 239.8725 - val_loss: 229.1024 - val_mean_squared_error: 229.1024\n",
      "Epoch 320/500\n",
      "440/526 [========================>.....] - ETA: 0s - loss: 229.5934 - mean_squared_error: 229.5934\n",
      "Epoch 00320: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 384us/step - loss: 229.3967 - mean_squared_error: 229.3967 - val_loss: 231.2745 - val_mean_squared_error: 231.2745\n",
      "Epoch 321/500\n",
      "444/526 [========================>.....] - ETA: 0s - loss: 241.4942 - mean_squared_error: 241.4942\n",
      "Epoch 00321: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 382us/step - loss: 239.4906 - mean_squared_error: 239.4906 - val_loss: 358.3980 - val_mean_squared_error: 358.3980\n",
      "Epoch 322/500\n",
      "446/526 [========================>.....] - ETA: 0s - loss: 233.3392 - mean_squared_error: 233.3392\n",
      "Epoch 00322: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 382us/step - loss: 230.0688 - mean_squared_error: 230.0688 - val_loss: 225.5999 - val_mean_squared_error: 225.5999\n",
      "Epoch 323/500\n",
      "450/526 [========================>.....] - ETA: 0s - loss: 229.7519 - mean_squared_error: 229.7519\n",
      "Epoch 00323: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 379us/step - loss: 236.1823 - mean_squared_error: 236.1823 - val_loss: 243.4683 - val_mean_squared_error: 243.4683\n",
      "Epoch 324/500\n",
      "451/526 [========================>.....] - ETA: 0s - loss: 229.6230 - mean_squared_error: 229.6230\n",
      "Epoch 00324: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 377us/step - loss: 229.8368 - mean_squared_error: 229.8368 - val_loss: 303.8819 - val_mean_squared_error: 303.8819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325/500\n",
      "450/526 [========================>.....] - ETA: 0s - loss: 234.1183 - mean_squared_error: 234.1183\n",
      "Epoch 00325: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 379us/step - loss: 236.0359 - mean_squared_error: 236.0359 - val_loss: 321.4800 - val_mean_squared_error: 321.4800\n",
      "Epoch 326/500\n",
      "458/526 [=========================>....] - ETA: 0s - loss: 236.5617 - mean_squared_error: 236.5617\n",
      "Epoch 00326: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 373us/step - loss: 232.2254 - mean_squared_error: 232.2254 - val_loss: 225.9644 - val_mean_squared_error: 225.9644\n",
      "Epoch 327/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 242.5057 - mean_squared_error: 242.5057\n",
      "Epoch 00327: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 377us/step - loss: 241.1563 - mean_squared_error: 241.1563 - val_loss: 222.2546 - val_mean_squared_error: 222.2546\n",
      "Epoch 328/500\n",
      "459/526 [=========================>....] - ETA: 0s - loss: 252.8725 - mean_squared_error: 252.8725\n",
      "Epoch 00328: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 371us/step - loss: 249.2742 - mean_squared_error: 249.2742 - val_loss: 229.3387 - val_mean_squared_error: 229.3387\n",
      "Epoch 329/500\n",
      "449/526 [========================>.....] - ETA: 0s - loss: 226.3006 - mean_squared_error: 226.3006\n",
      "Epoch 00329: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 379us/step - loss: 227.9586 - mean_squared_error: 227.9586 - val_loss: 226.5398 - val_mean_squared_error: 226.5398\n",
      "Epoch 330/500\n",
      "448/526 [========================>.....] - ETA: 0s - loss: 238.8593 - mean_squared_error: 238.8593\n",
      "Epoch 00330: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 379us/step - loss: 235.9829 - mean_squared_error: 235.9829 - val_loss: 296.2478 - val_mean_squared_error: 296.2478\n",
      "Epoch 331/500\n",
      "456/526 [=========================>....] - ETA: 0s - loss: 239.7209 - mean_squared_error: 239.7209\n",
      "Epoch 00331: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 375us/step - loss: 239.7738 - mean_squared_error: 239.7738 - val_loss: 248.1089 - val_mean_squared_error: 248.1089\n",
      "Epoch 332/500\n",
      "445/526 [========================>.....] - ETA: 0s - loss: 230.0910 - mean_squared_error: 230.0910\n",
      "Epoch 00332: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 384us/step - loss: 233.5480 - mean_squared_error: 233.5480 - val_loss: 237.5430 - val_mean_squared_error: 237.5430\n",
      "Epoch 333/500\n",
      "446/526 [========================>.....] - ETA: 0s - loss: 260.6797 - mean_squared_error: 260.6797\n",
      "Epoch 00333: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 381us/step - loss: 254.9471 - mean_squared_error: 254.9471 - val_loss: 325.3746 - val_mean_squared_error: 325.3746\n",
      "Epoch 334/500\n",
      "445/526 [========================>.....] - ETA: 0s - loss: 237.2590 - mean_squared_error: 237.2590\n",
      "Epoch 00334: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 382us/step - loss: 235.0089 - mean_squared_error: 235.0089 - val_loss: 224.9218 - val_mean_squared_error: 224.9218\n",
      "Epoch 335/500\n",
      "442/526 [========================>.....] - ETA: 0s - loss: 243.1490 - mean_squared_error: 243.1490\n",
      "Epoch 00335: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 384us/step - loss: 241.0313 - mean_squared_error: 241.0313 - val_loss: 231.3790 - val_mean_squared_error: 231.3790\n",
      "Epoch 336/500\n",
      "454/526 [========================>.....] - ETA: 0s - loss: 226.5238 - mean_squared_error: 226.5238\n",
      "Epoch 00336: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 377us/step - loss: 229.8040 - mean_squared_error: 229.8040 - val_loss: 361.7924 - val_mean_squared_error: 361.7924\n",
      "Epoch 337/500\n",
      "444/526 [========================>.....] - ETA: 0s - loss: 236.3577 - mean_squared_error: 236.3577\n",
      "Epoch 00337: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 382us/step - loss: 235.7600 - mean_squared_error: 235.7600 - val_loss: 232.6481 - val_mean_squared_error: 232.6481\n",
      "Epoch 338/500\n",
      "458/526 [=========================>....] - ETA: 0s - loss: 229.3803 - mean_squared_error: 229.3803\n",
      "Epoch 00338: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 373us/step - loss: 229.6670 - mean_squared_error: 229.6670 - val_loss: 226.1955 - val_mean_squared_error: 226.1955\n",
      "Epoch 339/500\n",
      "454/526 [========================>.....] - ETA: 0s - loss: 251.6068 - mean_squared_error: 251.6068\n",
      "Epoch 00339: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 377us/step - loss: 244.8534 - mean_squared_error: 244.8534 - val_loss: 241.4170 - val_mean_squared_error: 241.4170\n",
      "Epoch 340/500\n",
      "443/526 [========================>.....] - ETA: 0s - loss: 239.5498 - mean_squared_error: 239.5498\n",
      "Epoch 00340: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 382us/step - loss: 238.1047 - mean_squared_error: 238.1047 - val_loss: 261.4890 - val_mean_squared_error: 261.4890\n",
      "Epoch 341/500\n",
      "443/526 [========================>.....] - ETA: 0s - loss: 234.2264 - mean_squared_error: 234.2264\n",
      "Epoch 00341: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 385us/step - loss: 233.1053 - mean_squared_error: 233.1053 - val_loss: 238.2518 - val_mean_squared_error: 238.2518\n",
      "Epoch 342/500\n",
      "451/526 [========================>.....] - ETA: 0s - loss: 230.9432 - mean_squared_error: 230.9432\n",
      "Epoch 00342: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 379us/step - loss: 231.2249 - mean_squared_error: 231.2249 - val_loss: 253.5427 - val_mean_squared_error: 253.5427\n",
      "Epoch 343/500\n",
      "448/526 [========================>.....] - ETA: 0s - loss: 235.4239 - mean_squared_error: 235.4239\n",
      "Epoch 00343: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 381us/step - loss: 238.7072 - mean_squared_error: 238.7072 - val_loss: 231.0787 - val_mean_squared_error: 231.0787\n",
      "Epoch 344/500\n",
      "452/526 [========================>.....] - ETA: 0s - loss: 236.3279 - mean_squared_error: 236.3279\n",
      "Epoch 00344: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 379us/step - loss: 236.6596 - mean_squared_error: 236.6596 - val_loss: 250.1444 - val_mean_squared_error: 250.1444\n",
      "Epoch 345/500\n",
      "448/526 [========================>.....] - ETA: 0s - loss: 228.0465 - mean_squared_error: 228.0465\n",
      "Epoch 00345: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 379us/step - loss: 229.4161 - mean_squared_error: 229.4161 - val_loss: 234.6195 - val_mean_squared_error: 234.6195\n",
      "Epoch 346/500\n",
      "454/526 [========================>.....] - ETA: 0s - loss: 249.9122 - mean_squared_error: 249.9122\n",
      "Epoch 00346: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 375us/step - loss: 246.8328 - mean_squared_error: 246.8328 - val_loss: 246.0187 - val_mean_squared_error: 246.0187\n",
      "Epoch 347/500\n",
      "447/526 [========================>.....] - ETA: 0s - loss: 257.7958 - mean_squared_error: 257.7958\n",
      "Epoch 00347: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 381us/step - loss: 252.4011 - mean_squared_error: 252.4011 - val_loss: 218.1949 - val_mean_squared_error: 218.1949\n",
      "Epoch 348/500\n",
      "452/526 [========================>.....] - ETA: 0s - loss: 220.2856 - mean_squared_error: 220.2856\n",
      "Epoch 00348: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 377us/step - loss: 222.2999 - mean_squared_error: 222.2999 - val_loss: 254.4746 - val_mean_squared_error: 254.4746\n",
      "Epoch 349/500\n",
      "460/526 [=========================>....] - ETA: 0s - loss: 232.9146 - mean_squared_error: 232.9146\n",
      "Epoch 00349: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 371us/step - loss: 237.2536 - mean_squared_error: 237.2536 - val_loss: 511.2218 - val_mean_squared_error: 511.2218\n",
      "Epoch 350/500\n",
      "450/526 [========================>.....] - ETA: 0s - loss: 241.7783 - mean_squared_error: 241.7783\n",
      "Epoch 00350: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 379us/step - loss: 242.2784 - mean_squared_error: 242.2784 - val_loss: 294.5374 - val_mean_squared_error: 294.5374\n",
      "Epoch 351/500\n",
      "456/526 [=========================>....] - ETA: 0s - loss: 240.3386 - mean_squared_error: 240.3386\n",
      "Epoch 00351: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 375us/step - loss: 239.5759 - mean_squared_error: 239.5759 - val_loss: 438.4128 - val_mean_squared_error: 438.4128\n",
      "Epoch 352/500\n",
      "448/526 [========================>.....] - ETA: 0s - loss: 231.1117 - mean_squared_error: 231.1117\n",
      "Epoch 00352: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 381us/step - loss: 232.2531 - mean_squared_error: 232.2531 - val_loss: 234.6170 - val_mean_squared_error: 234.6170\n",
      "Epoch 353/500\n",
      "452/526 [========================>.....] - ETA: 0s - loss: 249.9301 - mean_squared_error: 249.9301\n",
      "Epoch 00353: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 379us/step - loss: 244.9252 - mean_squared_error: 244.9252 - val_loss: 247.4870 - val_mean_squared_error: 247.4870\n",
      "Epoch 354/500\n",
      "449/526 [========================>.....] - ETA: 0s - loss: 225.6848 - mean_squared_error: 225.6848\n",
      "Epoch 00354: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 377us/step - loss: 221.9601 - mean_squared_error: 221.9601 - val_loss: 249.1897 - val_mean_squared_error: 249.1897\n",
      "Epoch 355/500\n",
      "449/526 [========================>.....] - ETA: 0s - loss: 221.4499 - mean_squared_error: 221.4499\n",
      "Epoch 00355: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 379us/step - loss: 232.3723 - mean_squared_error: 232.3723 - val_loss: 285.4655 - val_mean_squared_error: 285.4655\n",
      "Epoch 356/500\n",
      "448/526 [========================>.....] - ETA: 0s - loss: 247.6409 - mean_squared_error: 247.6409\n",
      "Epoch 00356: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 381us/step - loss: 246.1712 - mean_squared_error: 246.1712 - val_loss: 234.1163 - val_mean_squared_error: 234.1163\n",
      "Epoch 357/500\n",
      "458/526 [=========================>....] - ETA: 0s - loss: 243.7403 - mean_squared_error: 243.7403\n",
      "Epoch 00357: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 373us/step - loss: 240.7749 - mean_squared_error: 240.7749 - val_loss: 213.8891 - val_mean_squared_error: 213.8891\n",
      "Epoch 358/500\n",
      "447/526 [========================>.....] - ETA: 0s - loss: 239.1276 - mean_squared_error: 239.1276\n",
      "Epoch 00358: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 381us/step - loss: 236.5215 - mean_squared_error: 236.5215 - val_loss: 224.2314 - val_mean_squared_error: 224.2314\n",
      "Epoch 359/500\n",
      "452/526 [========================>.....] - ETA: 0s - loss: 238.3388 - mean_squared_error: 238.3388\n",
      "Epoch 00359: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 377us/step - loss: 241.6559 - mean_squared_error: 241.6559 - val_loss: 326.6698 - val_mean_squared_error: 326.6698\n",
      "Epoch 360/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 229.8004 - mean_squared_error: 229.8004\n",
      "Epoch 00360: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 377us/step - loss: 228.9516 - mean_squared_error: 228.9516 - val_loss: 236.6891 - val_mean_squared_error: 236.6891\n",
      "Epoch 361/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 241.2606 - mean_squared_error: 241.2606\n",
      "Epoch 00361: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 377us/step - loss: 242.7160 - mean_squared_error: 242.7160 - val_loss: 228.9655 - val_mean_squared_error: 228.9655\n",
      "Epoch 362/500\n",
      "443/526 [========================>.....] - ETA: 0s - loss: 223.8535 - mean_squared_error: 223.8535\n",
      "Epoch 00362: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 384us/step - loss: 226.2695 - mean_squared_error: 226.2695 - val_loss: 247.8135 - val_mean_squared_error: 247.8135\n",
      "Epoch 363/500\n",
      "454/526 [========================>.....] - ETA: 0s - loss: 239.3906 - mean_squared_error: 239.3906\n",
      "Epoch 00363: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 375us/step - loss: 237.6299 - mean_squared_error: 237.6299 - val_loss: 282.0825 - val_mean_squared_error: 282.0825\n",
      "Epoch 364/500\n",
      "451/526 [========================>.....] - ETA: 0s - loss: 237.1946 - mean_squared_error: 237.1946\n",
      "Epoch 00364: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 377us/step - loss: 236.3110 - mean_squared_error: 236.3110 - val_loss: 259.1979 - val_mean_squared_error: 259.1979\n",
      "Epoch 365/500\n",
      "462/526 [=========================>....] - ETA: 0s - loss: 233.6025 - mean_squared_error: 233.6025\n",
      "Epoch 00365: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 371us/step - loss: 229.8833 - mean_squared_error: 229.8833 - val_loss: 223.0588 - val_mean_squared_error: 223.0588\n",
      "Epoch 366/500\n",
      "457/526 [=========================>....] - ETA: 0s - loss: 238.9410 - mean_squared_error: 238.9410\n",
      "Epoch 00366: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 373us/step - loss: 235.4361 - mean_squared_error: 235.4361 - val_loss: 224.1704 - val_mean_squared_error: 224.1704\n",
      "Epoch 367/500\n",
      "463/526 [=========================>....] - ETA: 0s - loss: 225.5857 - mean_squared_error: 225.5857\n",
      "Epoch 00367: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 369us/step - loss: 232.6012 - mean_squared_error: 232.6012 - val_loss: 451.9615 - val_mean_squared_error: 451.9615\n",
      "Epoch 368/500\n",
      "459/526 [=========================>....] - ETA: 0s - loss: 237.3521 - mean_squared_error: 237.3521\n",
      "Epoch 00368: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 369us/step - loss: 235.9493 - mean_squared_error: 235.9493 - val_loss: 220.0790 - val_mean_squared_error: 220.0790\n",
      "Epoch 369/500\n",
      "456/526 [=========================>....] - ETA: 0s - loss: 227.9338 - mean_squared_error: 227.9338\n",
      "Epoch 00369: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 375us/step - loss: 230.9665 - mean_squared_error: 230.9665 - val_loss: 236.0579 - val_mean_squared_error: 236.0579\n",
      "Epoch 370/500\n",
      "449/526 [========================>.....] - ETA: 0s - loss: 242.7410 - mean_squared_error: 242.7410\n",
      "Epoch 00370: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 379us/step - loss: 239.2521 - mean_squared_error: 239.2521 - val_loss: 249.2207 - val_mean_squared_error: 249.2207\n",
      "Epoch 371/500\n",
      "457/526 [=========================>....] - ETA: 0s - loss: 245.9875 - mean_squared_error: 245.9875\n",
      "Epoch 00371: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 373us/step - loss: 239.8383 - mean_squared_error: 239.8383 - val_loss: 246.9212 - val_mean_squared_error: 246.9212\n",
      "Epoch 372/500\n",
      "461/526 [=========================>....] - ETA: 0s - loss: 246.3980 - mean_squared_error: 246.3980\n",
      "Epoch 00372: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 369us/step - loss: 242.2041 - mean_squared_error: 242.2041 - val_loss: 225.0409 - val_mean_squared_error: 225.0409\n",
      "Epoch 373/500\n",
      "459/526 [=========================>....] - ETA: 0s - loss: 229.0889 - mean_squared_error: 229.0889\n",
      "Epoch 00373: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 371us/step - loss: 227.0853 - mean_squared_error: 227.0853 - val_loss: 267.4474 - val_mean_squared_error: 267.4474\n",
      "Epoch 374/500\n",
      "455/526 [========================>.....] - ETA: 0s - loss: 246.6656 - mean_squared_error: 246.6656\n",
      "Epoch 00374: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 373us/step - loss: 243.2220 - mean_squared_error: 243.2220 - val_loss: 235.6106 - val_mean_squared_error: 235.6106\n",
      "Epoch 375/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444/526 [========================>.....] - ETA: 0s - loss: 232.9761 - mean_squared_error: 232.9761\n",
      "Epoch 00375: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 382us/step - loss: 232.9666 - mean_squared_error: 232.9666 - val_loss: 276.2115 - val_mean_squared_error: 276.2115\n",
      "Epoch 376/500\n",
      "438/526 [=======================>......] - ETA: 0s - loss: 225.6826 - mean_squared_error: 225.6826\n",
      "Epoch 00376: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 388us/step - loss: 227.4521 - mean_squared_error: 227.4521 - val_loss: 224.3303 - val_mean_squared_error: 224.3303\n",
      "Epoch 377/500\n",
      "446/526 [========================>.....] - ETA: 0s - loss: 248.3457 - mean_squared_error: 248.3457\n",
      "Epoch 00377: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 381us/step - loss: 242.7788 - mean_squared_error: 242.7788 - val_loss: 230.3757 - val_mean_squared_error: 230.3757\n",
      "Epoch 378/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 231.9504 - mean_squared_error: 231.9504\n",
      "Epoch 00378: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 377us/step - loss: 238.8746 - mean_squared_error: 238.8746 - val_loss: 288.2391 - val_mean_squared_error: 288.2391\n",
      "Epoch 379/500\n",
      "462/526 [=========================>....] - ETA: 0s - loss: 224.5308 - mean_squared_error: 224.5308\n",
      "Epoch 00379: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 369us/step - loss: 222.4939 - mean_squared_error: 222.4939 - val_loss: 229.7297 - val_mean_squared_error: 229.7297\n",
      "Epoch 380/500\n",
      "455/526 [========================>.....] - ETA: 0s - loss: 226.0831 - mean_squared_error: 226.0831\n",
      "Epoch 00380: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 375us/step - loss: 227.9675 - mean_squared_error: 227.9675 - val_loss: 244.5618 - val_mean_squared_error: 244.5618\n",
      "Epoch 381/500\n",
      "445/526 [========================>.....] - ETA: 0s - loss: 238.3443 - mean_squared_error: 238.3443\n",
      "Epoch 00381: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 382us/step - loss: 235.6814 - mean_squared_error: 235.6814 - val_loss: 272.8630 - val_mean_squared_error: 272.8630\n",
      "Epoch 382/500\n",
      "448/526 [========================>.....] - ETA: 0s - loss: 236.2639 - mean_squared_error: 236.2639\n",
      "Epoch 00382: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 379us/step - loss: 232.7005 - mean_squared_error: 232.7005 - val_loss: 236.6711 - val_mean_squared_error: 236.6711\n",
      "Epoch 383/500\n",
      "449/526 [========================>.....] - ETA: 0s - loss: 222.7858 - mean_squared_error: 222.7858\n",
      "Epoch 00383: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 379us/step - loss: 227.9606 - mean_squared_error: 227.9606 - val_loss: 246.2354 - val_mean_squared_error: 246.2354\n",
      "Epoch 384/500\n",
      "442/526 [========================>.....] - ETA: 0s - loss: 238.7291 - mean_squared_error: 238.7291\n",
      "Epoch 00384: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 386us/step - loss: 236.3253 - mean_squared_error: 236.3253 - val_loss: 221.3011 - val_mean_squared_error: 221.3011\n",
      "Epoch 385/500\n",
      "451/526 [========================>.....] - ETA: 0s - loss: 230.4707 - mean_squared_error: 230.4707\n",
      "Epoch 00385: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 375us/step - loss: 232.8105 - mean_squared_error: 232.8105 - val_loss: 216.4633 - val_mean_squared_error: 216.4633\n",
      "Epoch 386/500\n",
      "456/526 [=========================>....] - ETA: 0s - loss: 235.1724 - mean_squared_error: 235.1724\n",
      "Epoch 00386: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 377us/step - loss: 234.2052 - mean_squared_error: 234.2052 - val_loss: 376.7291 - val_mean_squared_error: 376.7291\n",
      "Epoch 387/500\n",
      "455/526 [========================>.....] - ETA: 0s - loss: 241.6968 - mean_squared_error: 241.6968\n",
      "Epoch 00387: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 375us/step - loss: 238.9318 - mean_squared_error: 238.9318 - val_loss: 236.1062 - val_mean_squared_error: 236.1062\n",
      "Epoch 388/500\n",
      "462/526 [=========================>....] - ETA: 0s - loss: 240.0173 - mean_squared_error: 240.0173\n",
      "Epoch 00388: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 369us/step - loss: 242.2570 - mean_squared_error: 242.2570 - val_loss: 476.4001 - val_mean_squared_error: 476.4001\n",
      "Epoch 389/500\n",
      "445/526 [========================>.....] - ETA: 0s - loss: 236.1829 - mean_squared_error: 236.1829\n",
      "Epoch 00389: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 384us/step - loss: 233.5370 - mean_squared_error: 233.5370 - val_loss: 248.7154 - val_mean_squared_error: 248.7154\n",
      "Epoch 390/500\n",
      "448/526 [========================>.....] - ETA: 0s - loss: 227.5513 - mean_squared_error: 227.5513\n",
      "Epoch 00390: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 381us/step - loss: 225.1198 - mean_squared_error: 225.1198 - val_loss: 228.1745 - val_mean_squared_error: 228.1745\n",
      "Epoch 391/500\n",
      "446/526 [========================>.....] - ETA: 0s - loss: 227.2340 - mean_squared_error: 227.2340\n",
      "Epoch 00391: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 381us/step - loss: 231.3636 - mean_squared_error: 231.3636 - val_loss: 288.9820 - val_mean_squared_error: 288.9820\n",
      "Epoch 392/500\n",
      "457/526 [=========================>....] - ETA: 0s - loss: 224.9970 - mean_squared_error: 224.9970\n",
      "Epoch 00392: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 373us/step - loss: 227.5871 - mean_squared_error: 227.5871 - val_loss: 225.1326 - val_mean_squared_error: 225.1326\n",
      "Epoch 393/500\n",
      "451/526 [========================>.....] - ETA: 0s - loss: 228.6671 - mean_squared_error: 228.6671\n",
      "Epoch 00393: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 381us/step - loss: 231.1068 - mean_squared_error: 231.1068 - val_loss: 216.1411 - val_mean_squared_error: 216.1411\n",
      "Epoch 394/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 244.9396 - mean_squared_error: 244.9396\n",
      "Epoch 00394: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 398us/step - loss: 245.6719 - mean_squared_error: 245.6719 - val_loss: 248.4707 - val_mean_squared_error: 248.4707\n",
      "Epoch 395/500\n",
      "445/526 [========================>.....] - ETA: 0s - loss: 224.3259 - mean_squared_error: 224.3259\n",
      "Epoch 00395: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 381us/step - loss: 223.4762 - mean_squared_error: 223.4762 - val_loss: 218.8979 - val_mean_squared_error: 218.8979\n",
      "Epoch 396/500\n",
      "442/526 [========================>.....] - ETA: 0s - loss: 242.3665 - mean_squared_error: 242.3665\n",
      "Epoch 00396: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 386us/step - loss: 239.0539 - mean_squared_error: 239.0539 - val_loss: 509.1964 - val_mean_squared_error: 509.1964\n",
      "Epoch 397/500\n",
      "439/526 [========================>.....] - ETA: 0s - loss: 234.4620 - mean_squared_error: 234.4620\n",
      "Epoch 00397: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 384us/step - loss: 230.1115 - mean_squared_error: 230.1115 - val_loss: 240.8227 - val_mean_squared_error: 240.8227\n",
      "Epoch 398/500\n",
      "458/526 [=========================>....] - ETA: 0s - loss: 242.2674 - mean_squared_error: 242.2674\n",
      "Epoch 00398: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 373us/step - loss: 241.5134 - mean_squared_error: 241.5134 - val_loss: 232.8932 - val_mean_squared_error: 232.8932\n",
      "Epoch 399/500\n",
      "454/526 [========================>.....] - ETA: 0s - loss: 227.4029 - mean_squared_error: 227.4029\n",
      "Epoch 00399: val_loss did not improve from 212.93303\n",
      "526/526 [==============================] - 0s 382us/step - loss: 230.0145 - mean_squared_error: 230.0145 - val_loss: 238.6535 - val_mean_squared_error: 238.6535\n",
      "Epoch 400/500\n",
      "419/526 [======================>.......] - ETA: 0s - loss: 223.6826 - mean_squared_error: 223.6826\n",
      "Epoch 00400: val_loss improved from 212.93303 to 211.79543, saving model to model2.hdf5\n",
      "526/526 [==============================] - 0s 509us/step - loss: 224.4471 - mean_squared_error: 224.4471 - val_loss: 211.7954 - val_mean_squared_error: 211.7954\n",
      "Epoch 401/500\n",
      "448/526 [========================>.....] - ETA: 0s - loss: 235.8755 - mean_squared_error: 235.8755\n",
      "Epoch 00401: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 384us/step - loss: 234.5072 - mean_squared_error: 234.5072 - val_loss: 263.8820 - val_mean_squared_error: 263.8820\n",
      "Epoch 402/500\n",
      "447/526 [========================>.....] - ETA: 0s - loss: 222.7212 - mean_squared_error: 222.7212\n",
      "Epoch 00402: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 384us/step - loss: 221.6296 - mean_squared_error: 221.6296 - val_loss: 257.7747 - val_mean_squared_error: 257.7747\n",
      "Epoch 403/500\n",
      "439/526 [========================>.....] - ETA: 0s - loss: 236.5212 - mean_squared_error: 236.5212\n",
      "Epoch 00403: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 387us/step - loss: 234.0449 - mean_squared_error: 234.0449 - val_loss: 242.2600 - val_mean_squared_error: 242.2600\n",
      "Epoch 404/500\n",
      "442/526 [========================>.....] - ETA: 0s - loss: 242.9564 - mean_squared_error: 242.9564\n",
      "Epoch 00404: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 384us/step - loss: 242.1489 - mean_squared_error: 242.1489 - val_loss: 284.1245 - val_mean_squared_error: 284.1245\n",
      "Epoch 405/500\n",
      "452/526 [========================>.....] - ETA: 0s - loss: 227.8771 - mean_squared_error: 227.8771\n",
      "Epoch 00405: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 377us/step - loss: 229.9891 - mean_squared_error: 229.9891 - val_loss: 233.1101 - val_mean_squared_error: 233.1101\n",
      "Epoch 406/500\n",
      "446/526 [========================>.....] - ETA: 0s - loss: 240.9832 - mean_squared_error: 240.9832\n",
      "Epoch 00406: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 382us/step - loss: 238.6167 - mean_squared_error: 238.6167 - val_loss: 349.1488 - val_mean_squared_error: 349.1488\n",
      "Epoch 407/500\n",
      "449/526 [========================>.....] - ETA: 0s - loss: 225.1936 - mean_squared_error: 225.1936\n",
      "Epoch 00407: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 379us/step - loss: 229.6607 - mean_squared_error: 229.6607 - val_loss: 231.7679 - val_mean_squared_error: 231.7679\n",
      "Epoch 408/500\n",
      "441/526 [========================>.....] - ETA: 0s - loss: 236.9465 - mean_squared_error: 236.9465\n",
      "Epoch 00408: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 384us/step - loss: 231.6540 - mean_squared_error: 231.6540 - val_loss: 221.5698 - val_mean_squared_error: 221.5698\n",
      "Epoch 409/500\n",
      "424/526 [=======================>......] - ETA: 0s - loss: 230.3481 - mean_squared_error: 230.3481\n",
      "Epoch 00409: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 400us/step - loss: 232.5359 - mean_squared_error: 232.5359 - val_loss: 297.8119 - val_mean_squared_error: 297.8119\n",
      "Epoch 410/500\n",
      "441/526 [========================>.....] - ETA: 0s - loss: 236.6843 - mean_squared_error: 236.6843\n",
      "Epoch 00410: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 385us/step - loss: 231.9838 - mean_squared_error: 231.9838 - val_loss: 275.3951 - val_mean_squared_error: 275.3951\n",
      "Epoch 411/500\n",
      "451/526 [========================>.....] - ETA: 0s - loss: 256.7681 - mean_squared_error: 256.7681\n",
      "Epoch 00411: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 382us/step - loss: 258.8654 - mean_squared_error: 258.8654 - val_loss: 232.4577 - val_mean_squared_error: 232.4577\n",
      "Epoch 412/500\n",
      "442/526 [========================>.....] - ETA: 0s - loss: 220.9570 - mean_squared_error: 220.9570\n",
      "Epoch 00412: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 388us/step - loss: 223.5675 - mean_squared_error: 223.5675 - val_loss: 259.5702 - val_mean_squared_error: 259.5702\n",
      "Epoch 413/500\n",
      "442/526 [========================>.....] - ETA: 0s - loss: 238.8038 - mean_squared_error: 238.8038\n",
      "Epoch 00413: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 384us/step - loss: 235.9940 - mean_squared_error: 235.9940 - val_loss: 342.6726 - val_mean_squared_error: 342.6726\n",
      "Epoch 414/500\n",
      "440/526 [========================>.....] - ETA: 0s - loss: 233.7498 - mean_squared_error: 233.7498\n",
      "Epoch 00414: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 386us/step - loss: 233.9235 - mean_squared_error: 233.9235 - val_loss: 237.3545 - val_mean_squared_error: 237.3545\n",
      "Epoch 415/500\n",
      "444/526 [========================>.....] - ETA: 0s - loss: 241.0239 - mean_squared_error: 241.0239\n",
      "Epoch 00415: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 383us/step - loss: 238.5627 - mean_squared_error: 238.5627 - val_loss: 280.3050 - val_mean_squared_error: 280.3050\n",
      "Epoch 416/500\n",
      "450/526 [========================>.....] - ETA: 0s - loss: 236.4019 - mean_squared_error: 236.4019\n",
      "Epoch 00416: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 379us/step - loss: 233.5032 - mean_squared_error: 233.5032 - val_loss: 239.9008 - val_mean_squared_error: 239.9008\n",
      "Epoch 417/500\n",
      "453/526 [========================>.....] - ETA: 0s - loss: 222.5921 - mean_squared_error: 222.5921\n",
      "Epoch 00417: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 375us/step - loss: 221.9784 - mean_squared_error: 221.9784 - val_loss: 257.7779 - val_mean_squared_error: 257.7779\n",
      "Epoch 418/500\n",
      "437/526 [=======================>......] - ETA: 0s - loss: 254.0784 - mean_squared_error: 254.0784\n",
      "Epoch 00418: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 387us/step - loss: 245.8941 - mean_squared_error: 245.8941 - val_loss: 220.7835 - val_mean_squared_error: 220.7835\n",
      "Epoch 419/500\n",
      "443/526 [========================>.....] - ETA: 0s - loss: 222.6950 - mean_squared_error: 222.6950\n",
      "Epoch 00419: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 386us/step - loss: 218.0913 - mean_squared_error: 218.0913 - val_loss: 215.7978 - val_mean_squared_error: 215.7978\n",
      "Epoch 420/500\n",
      "435/526 [=======================>......] - ETA: 0s - loss: 230.7793 - mean_squared_error: 230.7793\n",
      "Epoch 00420: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 390us/step - loss: 229.8270 - mean_squared_error: 229.8270 - val_loss: 231.9370 - val_mean_squared_error: 231.9370\n",
      "Epoch 421/500\n",
      "446/526 [========================>.....] - ETA: 0s - loss: 233.6821 - mean_squared_error: 233.6821\n",
      "Epoch 00421: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 382us/step - loss: 231.6358 - mean_squared_error: 231.6358 - val_loss: 261.1896 - val_mean_squared_error: 261.1896\n",
      "Epoch 422/500\n",
      "436/526 [=======================>......] - ETA: 0s - loss: 241.5832 - mean_squared_error: 241.5832\n",
      "Epoch 00422: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 394us/step - loss: 236.4812 - mean_squared_error: 236.4812 - val_loss: 229.1442 - val_mean_squared_error: 229.1442\n",
      "Epoch 423/500\n",
      "440/526 [========================>.....] - ETA: 0s - loss: 242.8019 - mean_squared_error: 242.8019\n",
      "Epoch 00423: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 386us/step - loss: 237.7980 - mean_squared_error: 237.7980 - val_loss: 270.7956 - val_mean_squared_error: 270.7956\n",
      "Epoch 424/500\n",
      "446/526 [========================>.....] - ETA: 0s - loss: 230.5681 - mean_squared_error: 230.5681\n",
      "Epoch 00424: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 382us/step - loss: 234.0461 - mean_squared_error: 234.0461 - val_loss: 275.5619 - val_mean_squared_error: 275.5619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425/500\n",
      "445/526 [========================>.....] - ETA: 0s - loss: 225.6297 - mean_squared_error: 225.6297\n",
      "Epoch 00425: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 382us/step - loss: 223.7798 - mean_squared_error: 223.7798 - val_loss: 226.1863 - val_mean_squared_error: 226.1863\n",
      "Epoch 426/500\n",
      "449/526 [========================>.....] - ETA: 0s - loss: 226.3988 - mean_squared_error: 226.3988\n",
      "Epoch 00426: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 379us/step - loss: 224.6519 - mean_squared_error: 224.6519 - val_loss: 242.2802 - val_mean_squared_error: 242.2802\n",
      "Epoch 427/500\n",
      "404/526 [======================>.......] - ETA: 0s - loss: 236.9142 - mean_squared_error: 236.9142\n",
      "Epoch 00427: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 413us/step - loss: 237.8291 - mean_squared_error: 237.8291 - val_loss: 230.5564 - val_mean_squared_error: 230.5564\n",
      "Epoch 428/500\n",
      "435/526 [=======================>......] - ETA: 0s - loss: 257.4795 - mean_squared_error: 257.4795\n",
      "Epoch 00428: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 392us/step - loss: 248.5882 - mean_squared_error: 248.5882 - val_loss: 229.3579 - val_mean_squared_error: 229.3579\n",
      "Epoch 429/500\n",
      "436/526 [=======================>......] - ETA: 0s - loss: 225.8928 - mean_squared_error: 225.8928\n",
      "Epoch 00429: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 392us/step - loss: 226.7953 - mean_squared_error: 226.7953 - val_loss: 264.1273 - val_mean_squared_error: 264.1273\n",
      "Epoch 430/500\n",
      "442/526 [========================>.....] - ETA: 0s - loss: 224.0447 - mean_squared_error: 224.0447\n",
      "Epoch 00430: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 386us/step - loss: 224.3537 - mean_squared_error: 224.3537 - val_loss: 268.8825 - val_mean_squared_error: 268.8825\n",
      "Epoch 431/500\n",
      "442/526 [========================>.....] - ETA: 0s - loss: 240.3598 - mean_squared_error: 240.3598\n",
      "Epoch 00431: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 386us/step - loss: 234.4814 - mean_squared_error: 234.4814 - val_loss: 279.7275 - val_mean_squared_error: 279.7275\n",
      "Epoch 432/500\n",
      "440/526 [========================>.....] - ETA: 0s - loss: 214.8575 - mean_squared_error: 214.8575\n",
      "Epoch 00432: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 388us/step - loss: 221.5052 - mean_squared_error: 221.5052 - val_loss: 292.6430 - val_mean_squared_error: 292.6430\n",
      "Epoch 433/500\n",
      "436/526 [=======================>......] - ETA: 0s - loss: 230.8437 - mean_squared_error: 230.8437\n",
      "Epoch 00433: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 392us/step - loss: 232.3609 - mean_squared_error: 232.3609 - val_loss: 270.4094 - val_mean_squared_error: 270.4094\n",
      "Epoch 434/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 221.7180 - mean_squared_error: 221.7180\n",
      "Epoch 00434: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 394us/step - loss: 220.0330 - mean_squared_error: 220.0330 - val_loss: 294.4897 - val_mean_squared_error: 294.4897\n",
      "Epoch 435/500\n",
      "441/526 [========================>.....] - ETA: 0s - loss: 227.6597 - mean_squared_error: 227.6597\n",
      "Epoch 00435: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 386us/step - loss: 234.0550 - mean_squared_error: 234.0550 - val_loss: 229.4777 - val_mean_squared_error: 229.4777\n",
      "Epoch 436/500\n",
      "445/526 [========================>.....] - ETA: 0s - loss: 218.0168 - mean_squared_error: 218.0168\n",
      "Epoch 00436: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 382us/step - loss: 215.9027 - mean_squared_error: 215.9027 - val_loss: 233.0349 - val_mean_squared_error: 233.0349\n",
      "Epoch 437/500\n",
      "451/526 [========================>.....] - ETA: 0s - loss: 226.0744 - mean_squared_error: 226.0744\n",
      "Epoch 00437: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 379us/step - loss: 228.1873 - mean_squared_error: 228.1873 - val_loss: 225.1036 - val_mean_squared_error: 225.1036\n",
      "Epoch 438/500\n",
      "454/526 [========================>.....] - ETA: 0s - loss: 238.9987 - mean_squared_error: 238.9987\n",
      "Epoch 00438: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 377us/step - loss: 236.7927 - mean_squared_error: 236.7927 - val_loss: 227.8863 - val_mean_squared_error: 227.8863\n",
      "Epoch 439/500\n",
      "437/526 [=======================>......] - ETA: 0s - loss: 220.8655 - mean_squared_error: 220.8655\n",
      "Epoch 00439: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 388us/step - loss: 222.0818 - mean_squared_error: 222.0818 - val_loss: 243.1348 - val_mean_squared_error: 243.1348\n",
      "Epoch 440/500\n",
      "443/526 [========================>.....] - ETA: 0s - loss: 233.1047 - mean_squared_error: 233.1047\n",
      "Epoch 00440: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 386us/step - loss: 231.7675 - mean_squared_error: 231.7675 - val_loss: 238.0168 - val_mean_squared_error: 238.0168\n",
      "Epoch 441/500\n",
      "443/526 [========================>.....] - ETA: 0s - loss: 241.7617 - mean_squared_error: 241.7617\n",
      "Epoch 00441: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 384us/step - loss: 239.7828 - mean_squared_error: 239.7828 - val_loss: 229.3197 - val_mean_squared_error: 229.3197\n",
      "Epoch 442/500\n",
      "440/526 [========================>.....] - ETA: 0s - loss: 232.5816 - mean_squared_error: 232.5816\n",
      "Epoch 00442: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 386us/step - loss: 233.5937 - mean_squared_error: 233.5937 - val_loss: 287.2235 - val_mean_squared_error: 287.2235\n",
      "Epoch 443/500\n",
      "423/526 [=======================>......] - ETA: 0s - loss: 246.8242 - mean_squared_error: 246.8242\n",
      "Epoch 00443: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 398us/step - loss: 240.8043 - mean_squared_error: 240.8043 - val_loss: 274.5390 - val_mean_squared_error: 274.5390\n",
      "Epoch 444/500\n",
      "447/526 [========================>.....] - ETA: 0s - loss: 218.6683 - mean_squared_error: 218.6683\n",
      "Epoch 00444: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 382us/step - loss: 225.2656 - mean_squared_error: 225.2656 - val_loss: 331.8080 - val_mean_squared_error: 331.8080\n",
      "Epoch 445/500\n",
      "444/526 [========================>.....] - ETA: 0s - loss: 222.4754 - mean_squared_error: 222.4754\n",
      "Epoch 00445: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 382us/step - loss: 229.1793 - mean_squared_error: 229.1793 - val_loss: 246.8239 - val_mean_squared_error: 246.8239\n",
      "Epoch 446/500\n",
      "454/526 [========================>.....] - ETA: 0s - loss: 225.4592 - mean_squared_error: 225.4592\n",
      "Epoch 00446: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 375us/step - loss: 227.6834 - mean_squared_error: 227.6834 - val_loss: 362.4140 - val_mean_squared_error: 362.4140\n",
      "Epoch 447/500\n",
      "448/526 [========================>.....] - ETA: 0s - loss: 239.2250 - mean_squared_error: 239.2250\n",
      "Epoch 00447: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 381us/step - loss: 236.2086 - mean_squared_error: 236.2086 - val_loss: 244.0240 - val_mean_squared_error: 244.0240\n",
      "Epoch 448/500\n",
      "450/526 [========================>.....] - ETA: 0s - loss: 246.1981 - mean_squared_error: 246.1981\n",
      "Epoch 00448: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 381us/step - loss: 247.7436 - mean_squared_error: 247.7436 - val_loss: 230.6815 - val_mean_squared_error: 230.6815\n",
      "Epoch 449/500\n",
      "455/526 [========================>.....] - ETA: 0s - loss: 220.8337 - mean_squared_error: 220.8337\n",
      "Epoch 00449: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 375us/step - loss: 221.4316 - mean_squared_error: 221.4316 - val_loss: 234.3154 - val_mean_squared_error: 234.3154\n",
      "Epoch 450/500\n",
      "451/526 [========================>.....] - ETA: 0s - loss: 209.8865 - mean_squared_error: 209.8865\n",
      "Epoch 00450: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 377us/step - loss: 211.9800 - mean_squared_error: 211.9800 - val_loss: 225.1671 - val_mean_squared_error: 225.1671\n",
      "Epoch 451/500\n",
      "437/526 [=======================>......] - ETA: 0s - loss: 236.5781 - mean_squared_error: 236.5781\n",
      "Epoch 00451: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 386us/step - loss: 233.4634 - mean_squared_error: 233.4634 - val_loss: 236.3842 - val_mean_squared_error: 236.3842\n",
      "Epoch 452/500\n",
      "452/526 [========================>.....] - ETA: 0s - loss: 223.7227 - mean_squared_error: 223.7227\n",
      "Epoch 00452: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 379us/step - loss: 222.2279 - mean_squared_error: 222.2279 - val_loss: 223.4369 - val_mean_squared_error: 223.4369\n",
      "Epoch 453/500\n",
      "444/526 [========================>.....] - ETA: 0s - loss: 234.0971 - mean_squared_error: 234.0971\n",
      "Epoch 00453: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 381us/step - loss: 228.8662 - mean_squared_error: 228.8662 - val_loss: 221.5245 - val_mean_squared_error: 221.5245\n",
      "Epoch 454/500\n",
      "447/526 [========================>.....] - ETA: 0s - loss: 234.4691 - mean_squared_error: 234.4691\n",
      "Epoch 00454: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 382us/step - loss: 237.2038 - mean_squared_error: 237.2038 - val_loss: 266.9069 - val_mean_squared_error: 266.9069\n",
      "Epoch 455/500\n",
      "445/526 [========================>.....] - ETA: 0s - loss: 226.4961 - mean_squared_error: 226.4961\n",
      "Epoch 00455: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 382us/step - loss: 226.8407 - mean_squared_error: 226.8407 - val_loss: 294.2011 - val_mean_squared_error: 294.2011\n",
      "Epoch 456/500\n",
      "446/526 [========================>.....] - ETA: 0s - loss: 227.2617 - mean_squared_error: 227.2617\n",
      "Epoch 00456: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 382us/step - loss: 226.8481 - mean_squared_error: 226.8481 - val_loss: 311.3305 - val_mean_squared_error: 311.3305\n",
      "Epoch 457/500\n",
      "444/526 [========================>.....] - ETA: 0s - loss: 223.9931 - mean_squared_error: 223.9931\n",
      "Epoch 00457: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 386us/step - loss: 222.2265 - mean_squared_error: 222.2265 - val_loss: 237.0484 - val_mean_squared_error: 237.0484\n",
      "Epoch 458/500\n",
      "457/526 [=========================>....] - ETA: 0s - loss: 223.6088 - mean_squared_error: 223.6088\n",
      "Epoch 00458: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 375us/step - loss: 219.8102 - mean_squared_error: 219.8102 - val_loss: 225.5242 - val_mean_squared_error: 225.5242\n",
      "Epoch 459/500\n",
      "448/526 [========================>.....] - ETA: 0s - loss: 223.6410 - mean_squared_error: 223.6410\n",
      "Epoch 00459: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 379us/step - loss: 228.1015 - mean_squared_error: 228.1015 - val_loss: 218.2778 - val_mean_squared_error: 218.2778\n",
      "Epoch 460/500\n",
      "434/526 [=======================>......] - ETA: 0s - loss: 228.6610 - mean_squared_error: 228.6610\n",
      "Epoch 00460: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 394us/step - loss: 227.9452 - mean_squared_error: 227.9452 - val_loss: 284.4086 - val_mean_squared_error: 284.4086\n",
      "Epoch 461/500\n",
      "451/526 [========================>.....] - ETA: 0s - loss: 241.2751 - mean_squared_error: 241.2751\n",
      "Epoch 00461: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 379us/step - loss: 236.8730 - mean_squared_error: 236.8730 - val_loss: 248.8141 - val_mean_squared_error: 248.8141\n",
      "Epoch 462/500\n",
      "440/526 [========================>.....] - ETA: 0s - loss: 222.6641 - mean_squared_error: 222.6641\n",
      "Epoch 00462: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 390us/step - loss: 223.8564 - mean_squared_error: 223.8564 - val_loss: 405.3286 - val_mean_squared_error: 405.3286\n",
      "Epoch 463/500\n",
      "448/526 [========================>.....] - ETA: 0s - loss: 240.2324 - mean_squared_error: 240.2324\n",
      "Epoch 00463: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 382us/step - loss: 237.6387 - mean_squared_error: 237.6387 - val_loss: 235.9842 - val_mean_squared_error: 235.9842\n",
      "Epoch 464/500\n",
      "452/526 [========================>.....] - ETA: 0s - loss: 215.3188 - mean_squared_error: 215.3188\n",
      "Epoch 00464: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 379us/step - loss: 214.6734 - mean_squared_error: 214.6734 - val_loss: 216.8364 - val_mean_squared_error: 216.8364\n",
      "Epoch 465/500\n",
      "442/526 [========================>.....] - ETA: 0s - loss: 228.0046 - mean_squared_error: 228.0046\n",
      "Epoch 00465: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 384us/step - loss: 228.4870 - mean_squared_error: 228.4870 - val_loss: 242.7112 - val_mean_squared_error: 242.7112\n",
      "Epoch 466/500\n",
      "436/526 [=======================>......] - ETA: 0s - loss: 240.2180 - mean_squared_error: 240.2180\n",
      "Epoch 00466: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 386us/step - loss: 235.2196 - mean_squared_error: 235.2196 - val_loss: 263.8737 - val_mean_squared_error: 263.8737\n",
      "Epoch 467/500\n",
      "452/526 [========================>.....] - ETA: 0s - loss: 218.3609 - mean_squared_error: 218.3609\n",
      "Epoch 00467: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 377us/step - loss: 217.9483 - mean_squared_error: 217.9483 - val_loss: 218.9347 - val_mean_squared_error: 218.9347\n",
      "Epoch 468/500\n",
      "451/526 [========================>.....] - ETA: 0s - loss: 230.2255 - mean_squared_error: 230.2255\n",
      "Epoch 00468: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 381us/step - loss: 227.0031 - mean_squared_error: 227.0031 - val_loss: 315.2588 - val_mean_squared_error: 315.2588\n",
      "Epoch 469/500\n",
      "443/526 [========================>.....] - ETA: 0s - loss: 215.9261 - mean_squared_error: 215.9261\n",
      "Epoch 00469: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 384us/step - loss: 220.5396 - mean_squared_error: 220.5396 - val_loss: 251.1828 - val_mean_squared_error: 251.1828\n",
      "Epoch 470/500\n",
      "436/526 [=======================>......] - ETA: 0s - loss: 222.1921 - mean_squared_error: 222.1921\n",
      "Epoch 00470: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 386us/step - loss: 222.3235 - mean_squared_error: 222.3235 - val_loss: 235.2037 - val_mean_squared_error: 235.2037\n",
      "Epoch 471/500\n",
      "462/526 [=========================>....] - ETA: 0s - loss: 228.8416 - mean_squared_error: 228.8416\n",
      "Epoch 00471: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 369us/step - loss: 228.3427 - mean_squared_error: 228.3427 - val_loss: 233.0392 - val_mean_squared_error: 233.0392\n",
      "Epoch 472/500\n",
      "457/526 [=========================>....] - ETA: 0s - loss: 221.7556 - mean_squared_error: 221.7556\n",
      "Epoch 00472: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 373us/step - loss: 223.6742 - mean_squared_error: 223.6742 - val_loss: 223.5203 - val_mean_squared_error: 223.5203\n",
      "Epoch 473/500\n",
      "441/526 [========================>.....] - ETA: 0s - loss: 233.9668 - mean_squared_error: 233.9668\n",
      "Epoch 00473: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 382us/step - loss: 235.1324 - mean_squared_error: 235.1324 - val_loss: 241.4641 - val_mean_squared_error: 241.4641\n",
      "Epoch 474/500\n",
      "451/526 [========================>.....] - ETA: 0s - loss: 217.1698 - mean_squared_error: 217.1698\n",
      "Epoch 00474: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 377us/step - loss: 216.8978 - mean_squared_error: 216.8978 - val_loss: 232.0706 - val_mean_squared_error: 232.0706\n",
      "Epoch 475/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/526 [========================>.....] - ETA: 0s - loss: 220.9868 - mean_squared_error: 220.9868\n",
      "Epoch 00475: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 379us/step - loss: 223.1409 - mean_squared_error: 223.1409 - val_loss: 228.6304 - val_mean_squared_error: 228.6304\n",
      "Epoch 476/500\n",
      "446/526 [========================>.....] - ETA: 0s - loss: 215.5300 - mean_squared_error: 215.5300\n",
      "Epoch 00476: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 382us/step - loss: 216.5407 - mean_squared_error: 216.5407 - val_loss: 216.9460 - val_mean_squared_error: 216.9460\n",
      "Epoch 477/500\n",
      "440/526 [========================>.....] - ETA: 0s - loss: 220.4879 - mean_squared_error: 220.4879\n",
      "Epoch 00477: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 392us/step - loss: 220.4182 - mean_squared_error: 220.4182 - val_loss: 290.6028 - val_mean_squared_error: 290.6028\n",
      "Epoch 478/500\n",
      "439/526 [========================>.....] - ETA: 0s - loss: 250.4874 - mean_squared_error: 250.4874\n",
      "Epoch 00478: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 386us/step - loss: 247.3486 - mean_squared_error: 247.3486 - val_loss: 232.7725 - val_mean_squared_error: 232.7725\n",
      "Epoch 479/500\n",
      "451/526 [========================>.....] - ETA: 0s - loss: 226.5902 - mean_squared_error: 226.5902\n",
      "Epoch 00479: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 384us/step - loss: 232.2133 - mean_squared_error: 232.2133 - val_loss: 233.0886 - val_mean_squared_error: 233.0886\n",
      "Epoch 480/500\n",
      "432/526 [=======================>......] - ETA: 0s - loss: 239.5280 - mean_squared_error: 239.5280\n",
      "Epoch 00480: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 394us/step - loss: 238.1204 - mean_squared_error: 238.1204 - val_loss: 216.0320 - val_mean_squared_error: 216.0320\n",
      "Epoch 481/500\n",
      "449/526 [========================>.....] - ETA: 0s - loss: 222.1165 - mean_squared_error: 222.1165\n",
      "Epoch 00481: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 379us/step - loss: 220.5583 - mean_squared_error: 220.5583 - val_loss: 289.9983 - val_mean_squared_error: 289.9983\n",
      "Epoch 482/500\n",
      "448/526 [========================>.....] - ETA: 0s - loss: 217.9126 - mean_squared_error: 217.9126\n",
      "Epoch 00482: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 379us/step - loss: 218.0419 - mean_squared_error: 218.0419 - val_loss: 363.1694 - val_mean_squared_error: 363.1694\n",
      "Epoch 483/500\n",
      "450/526 [========================>.....] - ETA: 0s - loss: 233.5466 - mean_squared_error: 233.5466\n",
      "Epoch 00483: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 377us/step - loss: 229.4985 - mean_squared_error: 229.4985 - val_loss: 233.7583 - val_mean_squared_error: 233.7583\n",
      "Epoch 484/500\n",
      "449/526 [========================>.....] - ETA: 0s - loss: 226.8576 - mean_squared_error: 226.8576\n",
      "Epoch 00484: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 382us/step - loss: 230.3917 - mean_squared_error: 230.3917 - val_loss: 336.2575 - val_mean_squared_error: 336.2575\n",
      "Epoch 485/500\n",
      "434/526 [=======================>......] - ETA: 0s - loss: 235.5376 - mean_squared_error: 235.5376\n",
      "Epoch 00485: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 396us/step - loss: 238.0522 - mean_squared_error: 238.0522 - val_loss: 225.8786 - val_mean_squared_error: 225.8786\n",
      "Epoch 486/500\n",
      "437/526 [=======================>......] - ETA: 0s - loss: 209.8581 - mean_squared_error: 209.8581\n",
      "Epoch 00486: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 388us/step - loss: 209.6714 - mean_squared_error: 209.6714 - val_loss: 224.2086 - val_mean_squared_error: 224.2086\n",
      "Epoch 487/500\n",
      "444/526 [========================>.....] - ETA: 0s - loss: 244.5907 - mean_squared_error: 244.5907\n",
      "Epoch 00487: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 381us/step - loss: 239.0128 - mean_squared_error: 239.0128 - val_loss: 222.4140 - val_mean_squared_error: 222.4140\n",
      "Epoch 488/500\n",
      "441/526 [========================>.....] - ETA: 0s - loss: 222.8344 - mean_squared_error: 222.8344\n",
      "Epoch 00488: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 382us/step - loss: 223.3700 - mean_squared_error: 223.3700 - val_loss: 234.7101 - val_mean_squared_error: 234.7101\n",
      "Epoch 489/500\n",
      "449/526 [========================>.....] - ETA: 0s - loss: 214.5302 - mean_squared_error: 214.5302\n",
      "Epoch 00489: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 381us/step - loss: 227.6099 - mean_squared_error: 227.6099 - val_loss: 305.4039 - val_mean_squared_error: 305.4039\n",
      "Epoch 490/500\n",
      "439/526 [========================>.....] - ETA: 0s - loss: 219.2229 - mean_squared_error: 219.2229\n",
      "Epoch 00490: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 388us/step - loss: 220.6725 - mean_squared_error: 220.6725 - val_loss: 216.3731 - val_mean_squared_error: 216.3731\n",
      "Epoch 491/500\n",
      "447/526 [========================>.....] - ETA: 0s - loss: 226.8984 - mean_squared_error: 226.8984\n",
      "Epoch 00491: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 379us/step - loss: 225.1289 - mean_squared_error: 225.1289 - val_loss: 253.0369 - val_mean_squared_error: 253.0369\n",
      "Epoch 492/500\n",
      "441/526 [========================>.....] - ETA: 0s - loss: 222.6203 - mean_squared_error: 222.6203\n",
      "Epoch 00492: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 384us/step - loss: 224.6538 - mean_squared_error: 224.6538 - val_loss: 225.1420 - val_mean_squared_error: 225.1420\n",
      "Epoch 493/500\n",
      "438/526 [=======================>......] - ETA: 0s - loss: 233.2820 - mean_squared_error: 233.2820\n",
      "Epoch 00493: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 390us/step - loss: 231.2649 - mean_squared_error: 231.2649 - val_loss: 240.5637 - val_mean_squared_error: 240.5637\n",
      "Epoch 494/500\n",
      "442/526 [========================>.....] - ETA: 0s - loss: 221.1683 - mean_squared_error: 221.1683\n",
      "Epoch 00494: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 386us/step - loss: 231.0186 - mean_squared_error: 231.0186 - val_loss: 263.8239 - val_mean_squared_error: 263.8239\n",
      "Epoch 495/500\n",
      "440/526 [========================>.....] - ETA: 0s - loss: 227.7413 - mean_squared_error: 227.7413\n",
      "Epoch 00495: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 384us/step - loss: 225.2894 - mean_squared_error: 225.2894 - val_loss: 217.9819 - val_mean_squared_error: 217.9819\n",
      "Epoch 496/500\n",
      "440/526 [========================>.....] - ETA: 0s - loss: 227.7911 - mean_squared_error: 227.7911\n",
      "Epoch 00496: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 386us/step - loss: 232.3877 - mean_squared_error: 232.3877 - val_loss: 236.9230 - val_mean_squared_error: 236.9230\n",
      "Epoch 497/500\n",
      "442/526 [========================>.....] - ETA: 0s - loss: 223.0811 - mean_squared_error: 223.0811\n",
      "Epoch 00497: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 386us/step - loss: 218.9900 - mean_squared_error: 218.9900 - val_loss: 235.2407 - val_mean_squared_error: 235.2407\n",
      "Epoch 498/500\n",
      "429/526 [=======================>......] - ETA: 0s - loss: 219.7407 - mean_squared_error: 219.7407\n",
      "Epoch 00498: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 394us/step - loss: 224.3578 - mean_squared_error: 224.3578 - val_loss: 233.5280 - val_mean_squared_error: 233.5280\n",
      "Epoch 499/500\n",
      "441/526 [========================>.....] - ETA: 0s - loss: 236.5297 - mean_squared_error: 236.5297\n",
      "Epoch 00499: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 386us/step - loss: 251.0211 - mean_squared_error: 251.0211 - val_loss: 222.2602 - val_mean_squared_error: 222.2602\n",
      "Epoch 500/500\n",
      "437/526 [=======================>......] - ETA: 0s - loss: 215.6548 - mean_squared_error: 215.6548\n",
      "Epoch 00500: val_loss did not improve from 211.79543\n",
      "526/526 [==============================] - 0s 390us/step - loss: 214.6929 - mean_squared_error: 214.6929 - val_loss: 235.9047 - val_mean_squared_error: 235.9047\n"
     ]
    }
   ],
   "source": [
    "model2 = models.Sequential()\n",
    "model2.add(layers.Dense(256,activation=\"relu\",input_dim=81))\n",
    "model2.add(layers.Dense(1))\n",
    "model2.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    loss = losses.mean_squared_error,\n",
    "    metrics = ['mean_squared_error']\n",
    ")\n",
    "file_path = \"model2.hdf5\"\n",
    "checkpoint = ModelCheckpoint(file_path,monitor='val_loss', verbose=1,\n",
    "                             save_best_only=True,period=1)\n",
    "train_history2 = model2.fit(x_train,y_train,epochs=500,batch_size = 32,\n",
    "                            validation_data = (x_val,y_val),callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76a53ed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/500\n",
      "466/526 [=========================>....] - ETA: 0s - loss: 13454.8262 - mean_squared_error: 13454.8262\n",
      "Epoch 00001: val_loss improved from inf to 1046.02478, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 806us/step - loss: 12029.0547 - mean_squared_error: 12029.0547 - val_loss: 1046.0248 - val_mean_squared_error: 1046.0248\n",
      "Epoch 2/500\n",
      "470/526 [=========================>....] - ETA: 0s - loss: 722.6699 - mean_squared_error: 722.6699\n",
      "Epoch 00002: val_loss improved from 1046.02478 to 787.64496, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 542us/step - loss: 709.1683 - mean_squared_error: 709.1683 - val_loss: 787.6450 - val_mean_squared_error: 787.6450\n",
      "Epoch 3/500\n",
      "474/526 [==========================>...] - ETA: 0s - loss: 554.8463 - mean_squared_error: 554.8463\n",
      "Epoch 00003: val_loss improved from 787.64496 to 572.37836, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 546us/step - loss: 550.2642 - mean_squared_error: 550.2642 - val_loss: 572.3784 - val_mean_squared_error: 572.3784\n",
      "Epoch 4/500\n",
      "477/526 [==========================>...] - ETA: 0s - loss: 477.5404 - mean_squared_error: 477.5404\n",
      "Epoch 00004: val_loss improved from 572.37836 to 540.12274, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 609us/step - loss: 474.4894 - mean_squared_error: 474.4894 - val_loss: 540.1227 - val_mean_squared_error: 540.1227\n",
      "Epoch 5/500\n",
      "471/526 [=========================>....] - ETA: 0s - loss: 462.4249 - mean_squared_error: 462.4249\n",
      "Epoch 00005: val_loss improved from 540.12274 to 420.10431, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 658us/step - loss: 460.2282 - mean_squared_error: 460.2282 - val_loss: 420.1043 - val_mean_squared_error: 420.1043\n",
      "Epoch 6/500\n",
      "478/526 [==========================>...] - ETA: 0s - loss: 475.1634 - mean_squared_error: 475.1634\n",
      "Epoch 00006: val_loss improved from 420.10431 to 418.22595, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 639us/step - loss: 471.0473 - mean_squared_error: 471.0473 - val_loss: 418.2260 - val_mean_squared_error: 418.2260\n",
      "Epoch 7/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 446.2637 - mean_squared_error: 446.2637\n",
      "Epoch 00007: val_loss did not improve from 418.22595\n",
      "526/526 [==============================] - 0s 462us/step - loss: 441.0855 - mean_squared_error: 441.0855 - val_loss: 423.3244 - val_mean_squared_error: 423.3244\n",
      "Epoch 8/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 450.7987 - mean_squared_error: 450.7987\n",
      "Epoch 00008: val_loss improved from 418.22595 to 369.57077, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 648us/step - loss: 448.0240 - mean_squared_error: 448.0240 - val_loss: 369.5708 - val_mean_squared_error: 369.5708\n",
      "Epoch 9/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 506.5379 - mean_squared_error: 506.5379\n",
      "Epoch 00009: val_loss improved from 369.57077 to 367.32675, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 582us/step - loss: 499.3211 - mean_squared_error: 499.3211 - val_loss: 367.3268 - val_mean_squared_error: 367.3268\n",
      "Epoch 10/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 438.6573 - mean_squared_error: 438.6573\n",
      "Epoch 00010: val_loss improved from 367.32675 to 359.97906, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 582us/step - loss: 433.1002 - mean_squared_error: 433.1002 - val_loss: 359.9791 - val_mean_squared_error: 359.9791\n",
      "Epoch 11/500\n",
      "475/526 [==========================>...] - ETA: 0s - loss: 414.5970 - mean_squared_error: 414.5970\n",
      "Epoch 00011: val_loss did not improve from 359.97906\n",
      "526/526 [==============================] - 0s 470us/step - loss: 433.7778 - mean_squared_error: 433.7778 - val_loss: 922.0906 - val_mean_squared_error: 922.0906\n",
      "Epoch 12/500\n",
      "478/526 [==========================>...] - ETA: 0s - loss: 454.3928 - mean_squared_error: 454.3928\n",
      "Epoch 00012: val_loss improved from 359.97906 to 353.21359, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 603us/step - loss: 457.0516 - mean_squared_error: 457.0516 - val_loss: 353.2136 - val_mean_squared_error: 353.2136\n",
      "Epoch 13/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 414.2211 - mean_squared_error: 414.2211\n",
      "Epoch 00013: val_loss did not improve from 353.21359\n",
      "526/526 [==============================] - 0s 457us/step - loss: 410.0092 - mean_squared_error: 410.0092 - val_loss: 512.4548 - val_mean_squared_error: 512.4548\n",
      "Epoch 14/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 451.0807 - mean_squared_error: 451.0807\n",
      "Epoch 00014: val_loss did not improve from 353.21359\n",
      "526/526 [==============================] - 0s 459us/step - loss: 446.4001 - mean_squared_error: 446.4001 - val_loss: 390.4598 - val_mean_squared_error: 390.4598\n",
      "Epoch 15/500\n",
      "478/526 [==========================>...] - ETA: 0s - loss: 401.3382 - mean_squared_error: 401.3382\n",
      "Epoch 00015: val_loss improved from 353.21359 to 330.90469, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 647us/step - loss: 402.2860 - mean_squared_error: 402.2860 - val_loss: 330.9047 - val_mean_squared_error: 330.9047\n",
      "Epoch 16/500\n",
      "479/526 [==========================>...] - ETA: 0s - loss: 402.0977 - mean_squared_error: 402.0977\n",
      "Epoch 00016: val_loss did not improve from 330.90469\n",
      "526/526 [==============================] - 0s 464us/step - loss: 402.8336 - mean_squared_error: 402.8336 - val_loss: 461.1700 - val_mean_squared_error: 461.1700\n",
      "Epoch 17/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 401.8035 - mean_squared_error: 401.8035\n",
      "Epoch 00017: val_loss did not improve from 330.90469\n",
      "526/526 [==============================] - 0s 459us/step - loss: 405.2128 - mean_squared_error: 405.2128 - val_loss: 350.8169 - val_mean_squared_error: 350.8169\n",
      "Epoch 18/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 366.4042 - mean_squared_error: 366.4042\n",
      "Epoch 00018: val_loss did not improve from 330.90469\n",
      "526/526 [==============================] - 0s 460us/step - loss: 369.0612 - mean_squared_error: 369.0612 - val_loss: 348.6000 - val_mean_squared_error: 348.6000\n",
      "Epoch 19/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 440.0219 - mean_squared_error: 440.0219\n",
      "Epoch 00019: val_loss did not improve from 330.90469\n",
      "526/526 [==============================] - 0s 460us/step - loss: 434.7793 - mean_squared_error: 434.7793 - val_loss: 354.3969 - val_mean_squared_error: 354.3969\n",
      "Epoch 20/500\n",
      "476/526 [==========================>...] - ETA: 0s - loss: 350.1932 - mean_squared_error: 350.1932\n",
      "Epoch 00020: val_loss did not improve from 330.90469\n",
      "526/526 [==============================] - 0s 470us/step - loss: 349.7756 - mean_squared_error: 349.7756 - val_loss: 460.2762 - val_mean_squared_error: 460.2762\n",
      "Epoch 21/500\n",
      "475/526 [==========================>...] - ETA: 0s - loss: 422.0848 - mean_squared_error: 422.0848\n",
      "Epoch 00021: val_loss improved from 330.90469 to 323.16937, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 642us/step - loss: 421.3421 - mean_squared_error: 421.3421 - val_loss: 323.1694 - val_mean_squared_error: 323.1694\n",
      "Epoch 22/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 379.0008 - mean_squared_error: 379.0008\n",
      "Epoch 00022: val_loss did not improve from 323.16937\n",
      "526/526 [==============================] - 0s 462us/step - loss: 381.6849 - mean_squared_error: 381.6849 - val_loss: 412.7047 - val_mean_squared_error: 412.7047\n",
      "Epoch 23/500\n",
      "473/526 [=========================>....] - ETA: 0s - loss: 409.0585 - mean_squared_error: 409.0585\n",
      "Epoch 00023: val_loss did not improve from 323.16937\n",
      "526/526 [==============================] - 0s 476us/step - loss: 409.5208 - mean_squared_error: 409.5208 - val_loss: 342.0172 - val_mean_squared_error: 342.0172\n",
      "Epoch 24/500\n",
      "467/526 [=========================>....] - ETA: 0s - loss: 342.3897 - mean_squared_error: 342.3897\n",
      "Epoch 00024: val_loss improved from 323.16937 to 281.64462, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 607us/step - loss: 341.6721 - mean_squared_error: 341.6721 - val_loss: 281.6446 - val_mean_squared_error: 281.6446\n",
      "Epoch 25/500\n",
      "464/526 [=========================>....] - ETA: 0s - loss: 396.5146 - mean_squared_error: 396.5146\n",
      "Epoch 00025: val_loss did not improve from 281.64462\n",
      "526/526 [==============================] - 0s 478us/step - loss: 405.6179 - mean_squared_error: 405.6179 - val_loss: 372.6304 - val_mean_squared_error: 372.6304\n",
      "Epoch 26/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 346.1606 - mean_squared_error: 346.1606\n",
      "Epoch 00026: val_loss did not improve from 281.64462\n",
      "526/526 [==============================] - 0s 460us/step - loss: 349.4121 - mean_squared_error: 349.4121 - val_loss: 326.6002 - val_mean_squared_error: 326.6002\n",
      "Epoch 27/500\n",
      "476/526 [==========================>...] - ETA: 0s - loss: 371.0410 - mean_squared_error: 371.0410\n",
      "Epoch 00027: val_loss did not improve from 281.64462\n",
      "526/526 [==============================] - 0s 470us/step - loss: 373.0922 - mean_squared_error: 373.0922 - val_loss: 307.2486 - val_mean_squared_error: 307.2486\n",
      "Epoch 28/500\n",
      "475/526 [==========================>...] - ETA: 0s - loss: 378.5186 - mean_squared_error: 378.5186\n",
      "Epoch 00028: val_loss did not improve from 281.64462\n",
      "526/526 [==============================] - 0s 468us/step - loss: 369.9949 - mean_squared_error: 369.9949 - val_loss: 392.3270 - val_mean_squared_error: 392.3270\n",
      "Epoch 29/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 325.8646 - mean_squared_error: 325.8646\n",
      "Epoch 00029: val_loss did not improve from 281.64462\n",
      "526/526 [==============================] - 0s 457us/step - loss: 336.7456 - mean_squared_error: 336.7456 - val_loss: 789.1461 - val_mean_squared_error: 789.1461\n",
      "Epoch 30/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 330.0765 - mean_squared_error: 330.0765\n",
      "Epoch 00030: val_loss did not improve from 281.64462\n",
      "526/526 [==============================] - 0s 460us/step - loss: 332.6599 - mean_squared_error: 332.6599 - val_loss: 288.8863 - val_mean_squared_error: 288.8863\n",
      "Epoch 31/500\n",
      "476/526 [==========================>...] - ETA: 0s - loss: 341.6344 - mean_squared_error: 341.6344\n",
      "Epoch 00031: val_loss did not improve from 281.64462\n",
      "526/526 [==============================] - 0s 474us/step - loss: 346.6638 - mean_squared_error: 346.6638 - val_loss: 325.5947 - val_mean_squared_error: 325.5947\n",
      "Epoch 32/500\n",
      "479/526 [==========================>...] - ETA: 0s - loss: 327.7492 - mean_squared_error: 327.7492\n",
      "Epoch 00032: val_loss improved from 281.64462 to 262.21042, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 613us/step - loss: 327.0296 - mean_squared_error: 327.0296 - val_loss: 262.2104 - val_mean_squared_error: 262.2104\n",
      "Epoch 33/500\n",
      "471/526 [=========================>....] - ETA: 0s - loss: 352.1989 - mean_squared_error: 352.1989\n",
      "Epoch 00033: val_loss did not improve from 262.21042\n",
      "526/526 [==============================] - 0s 472us/step - loss: 357.1764 - mean_squared_error: 357.1764 - val_loss: 359.6845 - val_mean_squared_error: 359.6845\n",
      "Epoch 34/500\n",
      "477/526 [==========================>...] - ETA: 0s - loss: 358.0021 - mean_squared_error: 358.0021\n",
      "Epoch 00034: val_loss did not improve from 262.21042\n",
      "526/526 [==============================] - 0s 468us/step - loss: 357.0660 - mean_squared_error: 357.0660 - val_loss: 333.0005 - val_mean_squared_error: 333.0005\n",
      "Epoch 35/500\n",
      "479/526 [==========================>...] - ETA: 0s - loss: 320.4569 - mean_squared_error: 320.4569\n",
      "Epoch 00035: val_loss did not improve from 262.21042\n",
      "526/526 [==============================] - 0s 468us/step - loss: 332.6969 - mean_squared_error: 332.6969 - val_loss: 284.3181 - val_mean_squared_error: 284.3181\n",
      "Epoch 36/500\n",
      "474/526 [==========================>...] - ETA: 0s - loss: 334.5210 - mean_squared_error: 334.5210\n",
      "Epoch 00036: val_loss did not improve from 262.21042\n",
      "526/526 [==============================] - 0s 472us/step - loss: 346.0337 - mean_squared_error: 346.0337 - val_loss: 337.7981 - val_mean_squared_error: 337.7981\n",
      "Epoch 37/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 407.2488 - mean_squared_error: 407.2488\n",
      "Epoch 00037: val_loss improved from 262.21042 to 261.21494, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 575us/step - loss: 397.3324 - mean_squared_error: 397.3324 - val_loss: 261.2149 - val_mean_squared_error: 261.2149\n",
      "Epoch 38/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 325.2387 - mean_squared_error: 325.2387\n",
      "Epoch 00038: val_loss did not improve from 261.21494\n",
      "526/526 [==============================] - 0s 459us/step - loss: 323.2592 - mean_squared_error: 323.2592 - val_loss: 287.6026 - val_mean_squared_error: 287.6026\n",
      "Epoch 39/500\n",
      "480/526 [==========================>...] - ETA: 0s - loss: 325.2025 - mean_squared_error: 325.2025\n",
      "Epoch 00039: val_loss did not improve from 261.21494\n",
      "526/526 [==============================] - 0s 464us/step - loss: 329.1187 - mean_squared_error: 329.1187 - val_loss: 294.0817 - val_mean_squared_error: 294.0817\n",
      "Epoch 40/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 325.0027 - mean_squared_error: 325.0027\n",
      "Epoch 00040: val_loss did not improve from 261.21494\n",
      "526/526 [==============================] - 0s 459us/step - loss: 336.7202 - mean_squared_error: 336.7202 - val_loss: 309.3955 - val_mean_squared_error: 309.3955\n",
      "Epoch 41/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 315.4228 - mean_squared_error: 315.4228\n",
      "Epoch 00041: val_loss did not improve from 261.21494\n",
      "526/526 [==============================] - 0s 460us/step - loss: 310.6071 - mean_squared_error: 310.6071 - val_loss: 290.8497 - val_mean_squared_error: 290.8497\n",
      "Epoch 42/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 369.8564 - mean_squared_error: 369.8564\n",
      "Epoch 00042: val_loss did not improve from 261.21494\n",
      "526/526 [==============================] - 0s 459us/step - loss: 364.0028 - mean_squared_error: 364.0028 - val_loss: 370.5380 - val_mean_squared_error: 370.5380\n",
      "Epoch 43/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 327.7160 - mean_squared_error: 327.7160\n",
      "Epoch 00043: val_loss did not improve from 261.21494\n",
      "526/526 [==============================] - 0s 464us/step - loss: 325.4035 - mean_squared_error: 325.4035 - val_loss: 277.2771 - val_mean_squared_error: 277.2771\n",
      "Epoch 44/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 341.4594 - mean_squared_error: 341.4594\n",
      "Epoch 00044: val_loss did not improve from 261.21494\n",
      "526/526 [==============================] - 0s 460us/step - loss: 344.2610 - mean_squared_error: 344.2610 - val_loss: 804.8961 - val_mean_squared_error: 804.8961\n",
      "Epoch 45/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 332.7469 - mean_squared_error: 332.7469\n",
      "Epoch 00045: val_loss did not improve from 261.21494\n",
      "526/526 [==============================] - 0s 460us/step - loss: 343.6575 - mean_squared_error: 343.6575 - val_loss: 546.9045 - val_mean_squared_error: 546.9045\n",
      "Epoch 46/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 342.7213 - mean_squared_error: 342.7213\n",
      "Epoch 00046: val_loss did not improve from 261.21494\n",
      "526/526 [==============================] - 0s 466us/step - loss: 336.7434 - mean_squared_error: 336.7434 - val_loss: 278.3723 - val_mean_squared_error: 278.3723\n",
      "Epoch 47/500\n",
      "471/526 [=========================>....] - ETA: 0s - loss: 293.6514 - mean_squared_error: 293.6514\n",
      "Epoch 00047: val_loss did not improve from 261.21494\n",
      "526/526 [==============================] - 0s 474us/step - loss: 293.0834 - mean_squared_error: 293.0834 - val_loss: 266.3589 - val_mean_squared_error: 266.3589\n",
      "Epoch 48/500\n",
      "476/526 [==========================>...] - ETA: 0s - loss: 300.7610 - mean_squared_error: 300.7610\n",
      "Epoch 00048: val_loss did not improve from 261.21494\n",
      "526/526 [==============================] - 0s 470us/step - loss: 303.3600 - mean_squared_error: 303.3600 - val_loss: 283.8716 - val_mean_squared_error: 283.8716\n",
      "Epoch 49/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/526 [=========================>....] - ETA: 0s - loss: 318.2573 - mean_squared_error: 318.2573\n",
      "Epoch 00049: val_loss improved from 261.21494 to 243.86018, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 649us/step - loss: 312.0423 - mean_squared_error: 312.0423 - val_loss: 243.8602 - val_mean_squared_error: 243.8602\n",
      "Epoch 50/500\n",
      "478/526 [==========================>...] - ETA: 0s - loss: 358.8419 - mean_squared_error: 358.8419\n",
      "Epoch 00050: val_loss did not improve from 243.86018\n",
      "526/526 [==============================] - 0s 464us/step - loss: 353.2515 - mean_squared_error: 353.2515 - val_loss: 284.7650 - val_mean_squared_error: 284.7650\n",
      "Epoch 51/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 312.0789 - mean_squared_error: 312.0789\n",
      "Epoch 00051: val_loss did not improve from 243.86018\n",
      "526/526 [==============================] - 0s 462us/step - loss: 310.8452 - mean_squared_error: 310.8452 - val_loss: 309.8980 - val_mean_squared_error: 309.8980\n",
      "Epoch 52/500\n",
      "474/526 [==========================>...] - ETA: 0s - loss: 302.9806 - mean_squared_error: 302.9806\n",
      "Epoch 00052: val_loss did not improve from 243.86018\n",
      "526/526 [==============================] - 0s 470us/step - loss: 313.4914 - mean_squared_error: 313.4914 - val_loss: 966.4905 - val_mean_squared_error: 966.4905\n",
      "Epoch 53/500\n",
      "476/526 [==========================>...] - ETA: 0s - loss: 298.1462 - mean_squared_error: 298.1462\n",
      "Epoch 00053: val_loss did not improve from 243.86018\n",
      "526/526 [==============================] - 0s 470us/step - loss: 302.9757 - mean_squared_error: 302.9757 - val_loss: 621.1501 - val_mean_squared_error: 621.1501\n",
      "Epoch 54/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 369.6451 - mean_squared_error: 369.6451\n",
      "Epoch 00054: val_loss did not improve from 243.86018\n",
      "526/526 [==============================] - 0s 460us/step - loss: 362.5944 - mean_squared_error: 362.5944 - val_loss: 312.9559 - val_mean_squared_error: 312.9559\n",
      "Epoch 55/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 295.9051 - mean_squared_error: 295.9051\n",
      "Epoch 00055: val_loss did not improve from 243.86018\n",
      "526/526 [==============================] - 0s 460us/step - loss: 294.9042 - mean_squared_error: 294.9042 - val_loss: 296.3545 - val_mean_squared_error: 296.3545\n",
      "Epoch 56/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 305.0929 - mean_squared_error: 305.0929\n",
      "Epoch 00056: val_loss did not improve from 243.86018\n",
      "526/526 [==============================] - 0s 462us/step - loss: 303.2163 - mean_squared_error: 303.2163 - val_loss: 338.2048 - val_mean_squared_error: 338.2048\n",
      "Epoch 57/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 335.5792 - mean_squared_error: 335.5792\n",
      "Epoch 00057: val_loss did not improve from 243.86018\n",
      "526/526 [==============================] - 0s 462us/step - loss: 327.4457 - mean_squared_error: 327.4457 - val_loss: 255.3816 - val_mean_squared_error: 255.3816\n",
      "Epoch 58/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 280.4220 - mean_squared_error: 280.4220\n",
      "Epoch 00058: val_loss did not improve from 243.86018\n",
      "526/526 [==============================] - 0s 464us/step - loss: 284.6572 - mean_squared_error: 284.6572 - val_loss: 276.9720 - val_mean_squared_error: 276.9720\n",
      "Epoch 59/500\n",
      "480/526 [==========================>...] - ETA: 0s - loss: 294.7084 - mean_squared_error: 294.7084\n",
      "Epoch 00059: val_loss did not improve from 243.86018\n",
      "526/526 [==============================] - 0s 464us/step - loss: 305.8607 - mean_squared_error: 305.8607 - val_loss: 366.5295 - val_mean_squared_error: 366.5295\n",
      "Epoch 60/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 336.7568 - mean_squared_error: 336.7568\n",
      "Epoch 00060: val_loss did not improve from 243.86018\n",
      "526/526 [==============================] - 0s 462us/step - loss: 327.9147 - mean_squared_error: 327.9147 - val_loss: 250.8505 - val_mean_squared_error: 250.8505\n",
      "Epoch 61/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 307.6854 - mean_squared_error: 307.6854\n",
      "Epoch 00061: val_loss did not improve from 243.86018\n",
      "526/526 [==============================] - 0s 457us/step - loss: 305.0878 - mean_squared_error: 305.0878 - val_loss: 266.1226 - val_mean_squared_error: 266.1226\n",
      "Epoch 62/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 301.8297 - mean_squared_error: 301.8297\n",
      "Epoch 00062: val_loss did not improve from 243.86018\n",
      "526/526 [==============================] - 0s 459us/step - loss: 301.0748 - mean_squared_error: 301.0748 - val_loss: 283.4842 - val_mean_squared_error: 283.4842\n",
      "Epoch 63/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 305.6776 - mean_squared_error: 305.6776\n",
      "Epoch 00063: val_loss did not improve from 243.86018\n",
      "526/526 [==============================] - 0s 457us/step - loss: 301.5270 - mean_squared_error: 301.5270 - val_loss: 270.6395 - val_mean_squared_error: 270.6395\n",
      "Epoch 64/500\n",
      "472/526 [=========================>....] - ETA: 0s - loss: 283.2437 - mean_squared_error: 283.2437\n",
      "Epoch 00064: val_loss did not improve from 243.86018\n",
      "526/526 [==============================] - 0s 474us/step - loss: 280.4809 - mean_squared_error: 280.4809 - val_loss: 382.2468 - val_mean_squared_error: 382.2468\n",
      "Epoch 65/500\n",
      "467/526 [=========================>....] - ETA: 0s - loss: 286.4887 - mean_squared_error: 286.4887\n",
      "Epoch 00065: val_loss did not improve from 243.86018\n",
      "526/526 [==============================] - 0s 476us/step - loss: 294.7433 - mean_squared_error: 294.7433 - val_loss: 259.2942 - val_mean_squared_error: 259.2942\n",
      "Epoch 66/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 283.2377 - mean_squared_error: 283.2377\n",
      "Epoch 00066: val_loss did not improve from 243.86018\n",
      "526/526 [==============================] - 0s 460us/step - loss: 283.6817 - mean_squared_error: 283.6817 - val_loss: 249.0889 - val_mean_squared_error: 249.0889\n",
      "Epoch 67/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 306.4055 - mean_squared_error: 306.4055\n",
      "Epoch 00067: val_loss did not improve from 243.86018\n",
      "526/526 [==============================] - 0s 459us/step - loss: 306.9435 - mean_squared_error: 306.9435 - val_loss: 314.5187 - val_mean_squared_error: 314.5187\n",
      "Epoch 68/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 346.2928 - mean_squared_error: 346.2928\n",
      "Epoch 00068: val_loss did not improve from 243.86018\n",
      "526/526 [==============================] - 0s 457us/step - loss: 339.2902 - mean_squared_error: 339.2902 - val_loss: 274.5446 - val_mean_squared_error: 274.5446\n",
      "Epoch 69/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 321.4311 - mean_squared_error: 321.4311\n",
      "Epoch 00069: val_loss improved from 243.86018 to 243.02072, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 605us/step - loss: 323.7466 - mean_squared_error: 323.7466 - val_loss: 243.0207 - val_mean_squared_error: 243.0207\n",
      "Epoch 70/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 269.8358 - mean_squared_error: 269.8358\n",
      "Epoch 00070: val_loss did not improve from 243.02072\n",
      "526/526 [==============================] - 0s 459us/step - loss: 269.4045 - mean_squared_error: 269.4045 - val_loss: 314.9519 - val_mean_squared_error: 314.9519\n",
      "Epoch 71/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 319.0729 - mean_squared_error: 319.0729\n",
      "Epoch 00071: val_loss did not improve from 243.02072\n",
      "526/526 [==============================] - 0s 459us/step - loss: 312.9551 - mean_squared_error: 312.9551 - val_loss: 284.1486 - val_mean_squared_error: 284.1486\n",
      "Epoch 72/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 269.0299 - mean_squared_error: 269.0299\n",
      "Epoch 00072: val_loss did not improve from 243.02072\n",
      "526/526 [==============================] - 0s 462us/step - loss: 274.6601 - mean_squared_error: 274.6601 - val_loss: 476.6776 - val_mean_squared_error: 476.6776\n",
      "Epoch 73/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 305.4921 - mean_squared_error: 305.4921\n",
      "Epoch 00073: val_loss did not improve from 243.02072\n",
      "526/526 [==============================] - 0s 462us/step - loss: 302.6996 - mean_squared_error: 302.6996 - val_loss: 286.9737 - val_mean_squared_error: 286.9737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/500\n",
      "474/526 [==========================>...] - ETA: 0s - loss: 271.1498 - mean_squared_error: 271.1498\n",
      "Epoch 00074: val_loss did not improve from 243.02072\n",
      "526/526 [==============================] - 0s 466us/step - loss: 274.5123 - mean_squared_error: 274.5123 - val_loss: 311.2512 - val_mean_squared_error: 311.2512\n",
      "Epoch 75/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 312.6165 - mean_squared_error: 312.6165\n",
      "Epoch 00075: val_loss did not improve from 243.02072\n",
      "526/526 [==============================] - 0s 459us/step - loss: 315.9364 - mean_squared_error: 315.9364 - val_loss: 303.2460 - val_mean_squared_error: 303.2460\n",
      "Epoch 76/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 293.7810 - mean_squared_error: 293.7810\n",
      "Epoch 00076: val_loss did not improve from 243.02072\n",
      "526/526 [==============================] - 0s 459us/step - loss: 299.1914 - mean_squared_error: 299.1914 - val_loss: 347.2520 - val_mean_squared_error: 347.2520\n",
      "Epoch 77/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 272.3785 - mean_squared_error: 272.3785\n",
      "Epoch 00077: val_loss did not improve from 243.02072\n",
      "526/526 [==============================] - 0s 460us/step - loss: 268.1927 - mean_squared_error: 268.1927 - val_loss: 335.6884 - val_mean_squared_error: 335.6884\n",
      "Epoch 78/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 291.5108 - mean_squared_error: 291.5108\n",
      "Epoch 00078: val_loss did not improve from 243.02072\n",
      "526/526 [==============================] - 0s 460us/step - loss: 296.0022 - mean_squared_error: 296.0022 - val_loss: 272.8081 - val_mean_squared_error: 272.8081\n",
      "Epoch 79/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 288.1732 - mean_squared_error: 288.1732\n",
      "Epoch 00079: val_loss did not improve from 243.02072\n",
      "526/526 [==============================] - 0s 457us/step - loss: 289.4488 - mean_squared_error: 289.4488 - val_loss: 382.4261 - val_mean_squared_error: 382.4261\n",
      "Epoch 80/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 287.1953 - mean_squared_error: 287.1953\n",
      "Epoch 00080: val_loss did not improve from 243.02072\n",
      "526/526 [==============================] - 0s 459us/step - loss: 304.9408 - mean_squared_error: 304.9408 - val_loss: 311.3839 - val_mean_squared_error: 311.3839\n",
      "Epoch 81/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 301.4894 - mean_squared_error: 301.4894\n",
      "Epoch 00081: val_loss improved from 243.02072 to 243.00203, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 604us/step - loss: 300.5693 - mean_squared_error: 300.5693 - val_loss: 243.0020 - val_mean_squared_error: 243.0020\n",
      "Epoch 82/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 258.5190 - mean_squared_error: 258.5190\n",
      "Epoch 00082: val_loss did not improve from 243.00203\n",
      "526/526 [==============================] - 0s 455us/step - loss: 261.7452 - mean_squared_error: 261.7452 - val_loss: 273.0345 - val_mean_squared_error: 273.0345\n",
      "Epoch 83/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 276.1574 - mean_squared_error: 276.1574\n",
      "Epoch 00083: val_loss improved from 243.00203 to 241.30501, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 632us/step - loss: 277.0630 - mean_squared_error: 277.0630 - val_loss: 241.3050 - val_mean_squared_error: 241.3050\n",
      "Epoch 84/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 309.4843 - mean_squared_error: 309.4843\n",
      "Epoch 00084: val_loss did not improve from 241.30501\n",
      "526/526 [==============================] - 0s 455us/step - loss: 305.8216 - mean_squared_error: 305.8216 - val_loss: 291.8216 - val_mean_squared_error: 291.8216\n",
      "Epoch 85/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 263.7079 - mean_squared_error: 263.7079\n",
      "Epoch 00085: val_loss did not improve from 241.30501\n",
      "526/526 [==============================] - 0s 462us/step - loss: 270.7462 - mean_squared_error: 270.7462 - val_loss: 464.9872 - val_mean_squared_error: 464.9872\n",
      "Epoch 86/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 277.1566 - mean_squared_error: 277.1566\n",
      "Epoch 00086: val_loss did not improve from 241.30501\n",
      "526/526 [==============================] - 0s 462us/step - loss: 277.0373 - mean_squared_error: 277.0373 - val_loss: 302.4611 - val_mean_squared_error: 302.4611\n",
      "Epoch 87/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 268.6954 - mean_squared_error: 268.6954\n",
      "Epoch 00087: val_loss did not improve from 241.30501\n",
      "526/526 [==============================] - 0s 462us/step - loss: 267.3456 - mean_squared_error: 267.3456 - val_loss: 289.7207 - val_mean_squared_error: 289.7207\n",
      "Epoch 88/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 275.2876 - mean_squared_error: 275.2876\n",
      "Epoch 00088: val_loss did not improve from 241.30501\n",
      "526/526 [==============================] - 0s 457us/step - loss: 277.0517 - mean_squared_error: 277.0517 - val_loss: 283.6154 - val_mean_squared_error: 283.6154\n",
      "Epoch 89/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 288.5526 - mean_squared_error: 288.5526\n",
      "Epoch 00089: val_loss did not improve from 241.30501\n",
      "526/526 [==============================] - 0s 460us/step - loss: 290.8944 - mean_squared_error: 290.8944 - val_loss: 284.1017 - val_mean_squared_error: 284.1017\n",
      "Epoch 90/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 285.8200 - mean_squared_error: 285.8200\n",
      "Epoch 00090: val_loss improved from 241.30501 to 232.21490, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 624us/step - loss: 284.1227 - mean_squared_error: 284.1227 - val_loss: 232.2149 - val_mean_squared_error: 232.2149\n",
      "Epoch 91/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 256.2624 - mean_squared_error: 256.2624\n",
      "Epoch 00091: val_loss improved from 232.21490 to 231.76523, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 618us/step - loss: 256.5050 - mean_squared_error: 256.5050 - val_loss: 231.7652 - val_mean_squared_error: 231.7652\n",
      "Epoch 92/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 275.3706 - mean_squared_error: 275.3706\n",
      "Epoch 00092: val_loss did not improve from 231.76523\n",
      "526/526 [==============================] - 0s 460us/step - loss: 278.0231 - mean_squared_error: 278.0231 - val_loss: 272.6732 - val_mean_squared_error: 272.6732\n",
      "Epoch 93/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 279.6798 - mean_squared_error: 279.6798\n",
      "Epoch 00093: val_loss did not improve from 231.76523\n",
      "526/526 [==============================] - 0s 460us/step - loss: 276.6075 - mean_squared_error: 276.6075 - val_loss: 291.2342 - val_mean_squared_error: 291.2342\n",
      "Epoch 94/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 273.7687 - mean_squared_error: 273.7687\n",
      "Epoch 00094: val_loss improved from 231.76523 to 222.62215, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 670us/step - loss: 271.2942 - mean_squared_error: 271.2942 - val_loss: 222.6221 - val_mean_squared_error: 222.6221\n",
      "Epoch 95/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 283.5532 - mean_squared_error: 283.5532\n",
      "Epoch 00095: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 459us/step - loss: 283.6287 - mean_squared_error: 283.6287 - val_loss: 321.3258 - val_mean_squared_error: 321.3258\n",
      "Epoch 96/500\n",
      "478/526 [==========================>...] - ETA: 0s - loss: 264.3757 - mean_squared_error: 264.3757\n",
      "Epoch 00096: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 468us/step - loss: 264.6370 - mean_squared_error: 264.6370 - val_loss: 257.3346 - val_mean_squared_error: 257.3346\n",
      "Epoch 97/500\n",
      "480/526 [==========================>...] - ETA: 0s - loss: 272.9225 - mean_squared_error: 272.9225\n",
      "Epoch 00097: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 464us/step - loss: 272.3838 - mean_squared_error: 272.3838 - val_loss: 299.0319 - val_mean_squared_error: 299.0319\n",
      "Epoch 98/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 263.3788 - mean_squared_error: 263.3788\n",
      "Epoch 00098: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 460us/step - loss: 260.6259 - mean_squared_error: 260.6259 - val_loss: 308.9499 - val_mean_squared_error: 308.9499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 268.0264 - mean_squared_error: 268.0264\n",
      "Epoch 00099: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 460us/step - loss: 264.8582 - mean_squared_error: 264.8582 - val_loss: 268.6448 - val_mean_squared_error: 268.6448\n",
      "Epoch 100/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 261.6875 - mean_squared_error: 261.6875\n",
      "Epoch 00100: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 464us/step - loss: 259.8160 - mean_squared_error: 259.8160 - val_loss: 264.3177 - val_mean_squared_error: 264.3177\n",
      "Epoch 101/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 273.5508 - mean_squared_error: 273.5508\n",
      "Epoch 00101: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 464us/step - loss: 272.3805 - mean_squared_error: 272.3805 - val_loss: 305.2293 - val_mean_squared_error: 305.2293\n",
      "Epoch 102/500\n",
      "475/526 [==========================>...] - ETA: 0s - loss: 271.5401 - mean_squared_error: 271.5401\n",
      "Epoch 00102: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 470us/step - loss: 287.4068 - mean_squared_error: 287.4068 - val_loss: 288.1523 - val_mean_squared_error: 288.1523\n",
      "Epoch 103/500\n",
      "479/526 [==========================>...] - ETA: 0s - loss: 277.2273 - mean_squared_error: 277.2273\n",
      "Epoch 00103: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 464us/step - loss: 277.0197 - mean_squared_error: 277.0197 - val_loss: 260.0746 - val_mean_squared_error: 260.0746\n",
      "Epoch 104/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 258.7634 - mean_squared_error: 258.7634\n",
      "Epoch 00104: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 460us/step - loss: 256.9814 - mean_squared_error: 256.9814 - val_loss: 236.7461 - val_mean_squared_error: 236.7461\n",
      "Epoch 105/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 268.5062 - mean_squared_error: 268.5062\n",
      "Epoch 00105: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 462us/step - loss: 264.9350 - mean_squared_error: 264.9350 - val_loss: 250.8182 - val_mean_squared_error: 250.8182\n",
      "Epoch 106/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 280.9304 - mean_squared_error: 280.9304\n",
      "Epoch 00106: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 457us/step - loss: 282.3032 - mean_squared_error: 282.3032 - val_loss: 300.1660 - val_mean_squared_error: 300.1660\n",
      "Epoch 107/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 266.9383 - mean_squared_error: 266.9383\n",
      "Epoch 00107: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 460us/step - loss: 266.6797 - mean_squared_error: 266.6797 - val_loss: 266.5307 - val_mean_squared_error: 266.5307\n",
      "Epoch 108/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 264.7401 - mean_squared_error: 264.7401\n",
      "Epoch 00108: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 462us/step - loss: 266.1107 - mean_squared_error: 266.1107 - val_loss: 332.9299 - val_mean_squared_error: 332.9299\n",
      "Epoch 109/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 244.3116 - mean_squared_error: 244.3116\n",
      "Epoch 00109: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 462us/step - loss: 249.9208 - mean_squared_error: 249.9208 - val_loss: 272.3833 - val_mean_squared_error: 272.3833\n",
      "Epoch 110/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 268.3859 - mean_squared_error: 268.3859\n",
      "Epoch 00110: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 462us/step - loss: 266.3007 - mean_squared_error: 266.3007 - val_loss: 245.6707 - val_mean_squared_error: 245.6707\n",
      "Epoch 111/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 267.4093 - mean_squared_error: 267.4093\n",
      "Epoch 00111: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 460us/step - loss: 268.7473 - mean_squared_error: 268.7473 - val_loss: 293.7649 - val_mean_squared_error: 293.7649\n",
      "Epoch 112/500\n",
      "480/526 [==========================>...] - ETA: 0s - loss: 261.8812 - mean_squared_error: 261.8812\n",
      "Epoch 00112: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 464us/step - loss: 276.7739 - mean_squared_error: 276.7739 - val_loss: 299.3807 - val_mean_squared_error: 299.3807\n",
      "Epoch 113/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 246.4239 - mean_squared_error: 246.4239\n",
      "Epoch 00113: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 460us/step - loss: 247.6440 - mean_squared_error: 247.6440 - val_loss: 242.9406 - val_mean_squared_error: 242.9406\n",
      "Epoch 114/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 255.1421 - mean_squared_error: 255.1421\n",
      "Epoch 00114: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 459us/step - loss: 255.0499 - mean_squared_error: 255.0499 - val_loss: 302.4929 - val_mean_squared_error: 302.4929\n",
      "Epoch 115/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 263.4684 - mean_squared_error: 263.4684\n",
      "Epoch 00115: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 459us/step - loss: 262.1221 - mean_squared_error: 262.1221 - val_loss: 226.5772 - val_mean_squared_error: 226.5772\n",
      "Epoch 116/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 245.6380 - mean_squared_error: 245.6380\n",
      "Epoch 00116: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 459us/step - loss: 246.4441 - mean_squared_error: 246.4441 - val_loss: 327.4077 - val_mean_squared_error: 327.4077\n",
      "Epoch 117/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 265.2630 - mean_squared_error: 265.2630\n",
      "Epoch 00117: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 457us/step - loss: 262.2372 - mean_squared_error: 262.2372 - val_loss: 311.1850 - val_mean_squared_error: 311.1850\n",
      "Epoch 118/500\n",
      "480/526 [==========================>...] - ETA: 0s - loss: 297.8071 - mean_squared_error: 297.8071\n",
      "Epoch 00118: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 462us/step - loss: 295.7017 - mean_squared_error: 295.7017 - val_loss: 260.5919 - val_mean_squared_error: 260.5919\n",
      "Epoch 119/500\n",
      "480/526 [==========================>...] - ETA: 0s - loss: 255.9358 - mean_squared_error: 255.9358\n",
      "Epoch 00119: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 464us/step - loss: 255.8360 - mean_squared_error: 255.8360 - val_loss: 307.6166 - val_mean_squared_error: 307.6166\n",
      "Epoch 120/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 237.2661 - mean_squared_error: 237.2661\n",
      "Epoch 00120: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 460us/step - loss: 238.9794 - mean_squared_error: 238.9794 - val_loss: 262.6498 - val_mean_squared_error: 262.6498\n",
      "Epoch 121/500\n",
      "480/526 [==========================>...] - ETA: 0s - loss: 260.2003 - mean_squared_error: 260.2003\n",
      "Epoch 00121: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 464us/step - loss: 261.0699 - mean_squared_error: 261.0699 - val_loss: 250.0592 - val_mean_squared_error: 250.0592\n",
      "Epoch 122/500\n",
      "479/526 [==========================>...] - ETA: 0s - loss: 241.2579 - mean_squared_error: 241.2579\n",
      "Epoch 00122: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 468us/step - loss: 245.8538 - mean_squared_error: 245.8538 - val_loss: 261.0490 - val_mean_squared_error: 261.0490\n",
      "Epoch 123/500\n",
      "480/526 [==========================>...] - ETA: 0s - loss: 250.8904 - mean_squared_error: 250.8904\n",
      "Epoch 00123: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 464us/step - loss: 251.2280 - mean_squared_error: 251.2280 - val_loss: 367.3601 - val_mean_squared_error: 367.3601\n",
      "Epoch 124/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 270.5768 - mean_squared_error: 270.5768\n",
      "Epoch 00124: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 462us/step - loss: 268.9833 - mean_squared_error: 268.9833 - val_loss: 308.3368 - val_mean_squared_error: 308.3368\n",
      "Epoch 125/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 262.1076 - mean_squared_error: 262.1076\n",
      "Epoch 00125: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 457us/step - loss: 268.0742 - mean_squared_error: 268.0742 - val_loss: 412.9097 - val_mean_squared_error: 412.9097\n",
      "Epoch 126/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 255.3476 - mean_squared_error: 255.3476\n",
      "Epoch 00126: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 462us/step - loss: 255.4134 - mean_squared_error: 255.4134 - val_loss: 339.0832 - val_mean_squared_error: 339.0832\n",
      "Epoch 127/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 278.2507 - mean_squared_error: 278.2507\n",
      "Epoch 00127: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 462us/step - loss: 273.2425 - mean_squared_error: 273.2425 - val_loss: 226.0521 - val_mean_squared_error: 226.0521\n",
      "Epoch 128/500\n",
      "477/526 [==========================>...] - ETA: 0s - loss: 247.0452 - mean_squared_error: 247.0452\n",
      "Epoch 00128: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 466us/step - loss: 247.5490 - mean_squared_error: 247.5490 - val_loss: 230.8828 - val_mean_squared_error: 230.8828\n",
      "Epoch 129/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 260.6491 - mean_squared_error: 260.6491\n",
      "Epoch 00129: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 459us/step - loss: 259.0369 - mean_squared_error: 259.0369 - val_loss: 300.1005 - val_mean_squared_error: 300.1005\n",
      "Epoch 130/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 237.6198 - mean_squared_error: 237.6198\n",
      "Epoch 00130: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 460us/step - loss: 239.3175 - mean_squared_error: 239.3175 - val_loss: 267.7742 - val_mean_squared_error: 267.7742\n",
      "Epoch 131/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 259.1900 - mean_squared_error: 259.1900\n",
      "Epoch 00131: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 460us/step - loss: 264.0384 - mean_squared_error: 264.0384 - val_loss: 316.6879 - val_mean_squared_error: 316.6879\n",
      "Epoch 132/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 239.0188 - mean_squared_error: 239.0188\n",
      "Epoch 00132: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 460us/step - loss: 238.9046 - mean_squared_error: 238.9046 - val_loss: 242.5896 - val_mean_squared_error: 242.5896\n",
      "Epoch 133/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 243.5378 - mean_squared_error: 243.5378\n",
      "Epoch 00133: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 460us/step - loss: 240.9045 - mean_squared_error: 240.9045 - val_loss: 226.4063 - val_mean_squared_error: 226.4063\n",
      "Epoch 134/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 237.9528 - mean_squared_error: 237.9528\n",
      "Epoch 00134: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 462us/step - loss: 236.3531 - mean_squared_error: 236.3531 - val_loss: 315.6098 - val_mean_squared_error: 315.6098\n",
      "Epoch 135/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 277.7281 - mean_squared_error: 277.7281\n",
      "Epoch 00135: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 462us/step - loss: 273.5893 - mean_squared_error: 273.5893 - val_loss: 252.1592 - val_mean_squared_error: 252.1592\n",
      "Epoch 136/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 264.5939 - mean_squared_error: 264.5939\n",
      "Epoch 00136: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 462us/step - loss: 262.0009 - mean_squared_error: 262.0009 - val_loss: 277.6736 - val_mean_squared_error: 277.6736\n",
      "Epoch 137/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 252.4597 - mean_squared_error: 252.4597\n",
      "Epoch 00137: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 460us/step - loss: 252.1461 - mean_squared_error: 252.1461 - val_loss: 256.1536 - val_mean_squared_error: 256.1536\n",
      "Epoch 138/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 242.8212 - mean_squared_error: 242.8212\n",
      "Epoch 00138: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 457us/step - loss: 241.2805 - mean_squared_error: 241.2805 - val_loss: 235.9442 - val_mean_squared_error: 235.9442\n",
      "Epoch 139/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 233.9132 - mean_squared_error: 233.9132\n",
      "Epoch 00139: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 460us/step - loss: 235.4819 - mean_squared_error: 235.4819 - val_loss: 227.0924 - val_mean_squared_error: 227.0924\n",
      "Epoch 140/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 251.6823 - mean_squared_error: 251.6823\n",
      "Epoch 00140: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 460us/step - loss: 251.9526 - mean_squared_error: 251.9526 - val_loss: 251.7319 - val_mean_squared_error: 251.7319\n",
      "Epoch 141/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 247.5228 - mean_squared_error: 247.5228\n",
      "Epoch 00141: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 459us/step - loss: 247.7207 - mean_squared_error: 247.7207 - val_loss: 247.6110 - val_mean_squared_error: 247.6110\n",
      "Epoch 142/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 260.1215 - mean_squared_error: 260.1215\n",
      "Epoch 00142: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 459us/step - loss: 256.6536 - mean_squared_error: 256.6536 - val_loss: 265.1682 - val_mean_squared_error: 265.1682\n",
      "Epoch 143/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 244.4697 - mean_squared_error: 244.4697\n",
      "Epoch 00143: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 459us/step - loss: 243.1338 - mean_squared_error: 243.1338 - val_loss: 266.6249 - val_mean_squared_error: 266.6249\n",
      "Epoch 144/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 253.3803 - mean_squared_error: 253.3803\n",
      "Epoch 00144: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 462us/step - loss: 254.8008 - mean_squared_error: 254.8008 - val_loss: 225.7556 - val_mean_squared_error: 225.7556\n",
      "Epoch 145/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 245.5201 - mean_squared_error: 245.5201\n",
      "Epoch 00145: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 460us/step - loss: 243.1094 - mean_squared_error: 243.1094 - val_loss: 269.4217 - val_mean_squared_error: 269.4217\n",
      "Epoch 146/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 232.3892 - mean_squared_error: 232.3892\n",
      "Epoch 00146: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 462us/step - loss: 231.2694 - mean_squared_error: 231.2694 - val_loss: 265.6263 - val_mean_squared_error: 265.6263\n",
      "Epoch 147/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 245.1605 - mean_squared_error: 245.1605\n",
      "Epoch 00147: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 460us/step - loss: 245.0522 - mean_squared_error: 245.0522 - val_loss: 456.6838 - val_mean_squared_error: 456.6838\n",
      "Epoch 148/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 251.0859 - mean_squared_error: 251.0859\n",
      "Epoch 00148: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 462us/step - loss: 247.6088 - mean_squared_error: 247.6088 - val_loss: 249.4302 - val_mean_squared_error: 249.4302\n",
      "Epoch 149/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/526 [==========================>...] - ETA: 0s - loss: 238.0966 - mean_squared_error: 238.0966\n",
      "Epoch 00149: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 462us/step - loss: 236.0920 - mean_squared_error: 236.0920 - val_loss: 231.1578 - val_mean_squared_error: 231.1578\n",
      "Epoch 150/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 241.3213 - mean_squared_error: 241.3213\n",
      "Epoch 00150: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 460us/step - loss: 241.0093 - mean_squared_error: 241.0093 - val_loss: 228.3736 - val_mean_squared_error: 228.3736\n",
      "Epoch 151/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 235.7823 - mean_squared_error: 235.7823\n",
      "Epoch 00151: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 462us/step - loss: 239.3797 - mean_squared_error: 239.3797 - val_loss: 249.3077 - val_mean_squared_error: 249.3077\n",
      "Epoch 152/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 241.1485 - mean_squared_error: 241.1485\n",
      "Epoch 00152: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 462us/step - loss: 238.9096 - mean_squared_error: 238.9096 - val_loss: 332.2502 - val_mean_squared_error: 332.2502\n",
      "Epoch 153/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 246.2772 - mean_squared_error: 246.2772\n",
      "Epoch 00153: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 460us/step - loss: 249.1338 - mean_squared_error: 249.1338 - val_loss: 308.8603 - val_mean_squared_error: 308.8603\n",
      "Epoch 154/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 239.7375 - mean_squared_error: 239.7375\n",
      "Epoch 00154: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 462us/step - loss: 241.5926 - mean_squared_error: 241.5926 - val_loss: 256.9608 - val_mean_squared_error: 256.9608\n",
      "Epoch 155/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 248.7774 - mean_squared_error: 248.7774\n",
      "Epoch 00155: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 460us/step - loss: 253.0428 - mean_squared_error: 253.0428 - val_loss: 374.4040 - val_mean_squared_error: 374.4040\n",
      "Epoch 156/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 242.2908 - mean_squared_error: 242.2908\n",
      "Epoch 00156: val_loss did not improve from 222.62215\n",
      "526/526 [==============================] - 0s 462us/step - loss: 241.7757 - mean_squared_error: 241.7757 - val_loss: 250.1870 - val_mean_squared_error: 250.1870\n",
      "Epoch 157/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 248.0592 - mean_squared_error: 248.0592\n",
      "Epoch 00157: val_loss improved from 222.62215 to 222.16933, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 608us/step - loss: 246.3011 - mean_squared_error: 246.3011 - val_loss: 222.1693 - val_mean_squared_error: 222.1693\n",
      "Epoch 158/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 245.1685 - mean_squared_error: 245.1685\n",
      "Epoch 00158: val_loss did not improve from 222.16933\n",
      "526/526 [==============================] - 0s 459us/step - loss: 245.8363 - mean_squared_error: 245.8363 - val_loss: 223.9748 - val_mean_squared_error: 223.9748\n",
      "Epoch 159/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 235.7971 - mean_squared_error: 235.7971\n",
      "Epoch 00159: val_loss did not improve from 222.16933\n",
      "526/526 [==============================] - 0s 457us/step - loss: 240.7955 - mean_squared_error: 240.7955 - val_loss: 927.5490 - val_mean_squared_error: 927.5490\n",
      "Epoch 160/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 253.8349 - mean_squared_error: 253.8349\n",
      "Epoch 00160: val_loss did not improve from 222.16933\n",
      "526/526 [==============================] - 0s 460us/step - loss: 252.6388 - mean_squared_error: 252.6388 - val_loss: 244.1222 - val_mean_squared_error: 244.1222\n",
      "Epoch 161/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 232.1634 - mean_squared_error: 232.1634\n",
      "Epoch 00161: val_loss did not improve from 222.16933\n",
      "526/526 [==============================] - 0s 460us/step - loss: 230.1419 - mean_squared_error: 230.1419 - val_loss: 265.8243 - val_mean_squared_error: 265.8243\n",
      "Epoch 162/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 230.8491 - mean_squared_error: 230.8491\n",
      "Epoch 00162: val_loss improved from 222.16933 to 216.65637, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 635us/step - loss: 234.0114 - mean_squared_error: 234.0114 - val_loss: 216.6564 - val_mean_squared_error: 216.6564\n",
      "Epoch 163/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 243.7744 - mean_squared_error: 243.7744\n",
      "Epoch 00163: val_loss did not improve from 216.65637\n",
      "526/526 [==============================] - 0s 462us/step - loss: 244.9725 - mean_squared_error: 244.9725 - val_loss: 218.5583 - val_mean_squared_error: 218.5583\n",
      "Epoch 164/500\n",
      "477/526 [==========================>...] - ETA: 0s - loss: 219.7811 - mean_squared_error: 219.7811\n",
      "Epoch 00164: val_loss did not improve from 216.65637\n",
      "526/526 [==============================] - 0s 466us/step - loss: 221.2731 - mean_squared_error: 221.2731 - val_loss: 234.5535 - val_mean_squared_error: 234.5535\n",
      "Epoch 165/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 244.3251 - mean_squared_error: 244.3251\n",
      "Epoch 00165: val_loss improved from 216.65637 to 215.43727, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 633us/step - loss: 241.7329 - mean_squared_error: 241.7329 - val_loss: 215.4373 - val_mean_squared_error: 215.4373\n",
      "Epoch 166/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 224.4275 - mean_squared_error: 224.4275\n",
      "Epoch 00166: val_loss did not improve from 215.43727\n",
      "526/526 [==============================] - 0s 457us/step - loss: 224.1957 - mean_squared_error: 224.1957 - val_loss: 304.9073 - val_mean_squared_error: 304.9073\n",
      "Epoch 167/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 236.8527 - mean_squared_error: 236.8527\n",
      "Epoch 00167: val_loss did not improve from 215.43727\n",
      "526/526 [==============================] - 0s 460us/step - loss: 237.6630 - mean_squared_error: 237.6630 - val_loss: 276.8418 - val_mean_squared_error: 276.8418\n",
      "Epoch 168/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 237.8041 - mean_squared_error: 237.8041\n",
      "Epoch 00168: val_loss did not improve from 215.43727\n",
      "526/526 [==============================] - 0s 464us/step - loss: 237.3504 - mean_squared_error: 237.3504 - val_loss: 234.4882 - val_mean_squared_error: 234.4882\n",
      "Epoch 169/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 229.9768 - mean_squared_error: 229.9768\n",
      "Epoch 00169: val_loss did not improve from 215.43727\n",
      "526/526 [==============================] - 0s 464us/step - loss: 230.4391 - mean_squared_error: 230.4391 - val_loss: 219.3138 - val_mean_squared_error: 219.3138\n",
      "Epoch 170/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 234.6562 - mean_squared_error: 234.6562\n",
      "Epoch 00170: val_loss did not improve from 215.43727\n",
      "526/526 [==============================] - 0s 459us/step - loss: 236.7124 - mean_squared_error: 236.7124 - val_loss: 369.8547 - val_mean_squared_error: 369.8547\n",
      "Epoch 171/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 233.4006 - mean_squared_error: 233.4006\n",
      "Epoch 00171: val_loss did not improve from 215.43727\n",
      "526/526 [==============================] - 0s 462us/step - loss: 232.4355 - mean_squared_error: 232.4355 - val_loss: 344.1392 - val_mean_squared_error: 344.1392\n",
      "Epoch 172/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 244.6229 - mean_squared_error: 244.6229\n",
      "Epoch 00172: val_loss did not improve from 215.43727\n",
      "526/526 [==============================] - 0s 464us/step - loss: 241.6476 - mean_squared_error: 241.6476 - val_loss: 217.2860 - val_mean_squared_error: 217.2860\n",
      "Epoch 173/500\n",
      "477/526 [==========================>...] - ETA: 0s - loss: 225.6276 - mean_squared_error: 225.6276\n",
      "Epoch 00173: val_loss did not improve from 215.43727\n",
      "526/526 [==============================] - 0s 466us/step - loss: 225.2671 - mean_squared_error: 225.2671 - val_loss: 247.2658 - val_mean_squared_error: 247.2658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 242.5910 - mean_squared_error: 242.5910\n",
      "Epoch 00174: val_loss did not improve from 215.43727\n",
      "526/526 [==============================] - 0s 460us/step - loss: 241.7915 - mean_squared_error: 241.7915 - val_loss: 224.2339 - val_mean_squared_error: 224.2339\n",
      "Epoch 175/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 228.1952 - mean_squared_error: 228.1952\n",
      "Epoch 00175: val_loss did not improve from 215.43727\n",
      "526/526 [==============================] - 0s 460us/step - loss: 231.0958 - mean_squared_error: 231.0958 - val_loss: 248.7497 - val_mean_squared_error: 248.7497\n",
      "Epoch 176/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 233.3676 - mean_squared_error: 233.3676\n",
      "Epoch 00176: val_loss improved from 215.43727 to 211.55919, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 653us/step - loss: 231.8771 - mean_squared_error: 231.8771 - val_loss: 211.5592 - val_mean_squared_error: 211.5592\n",
      "Epoch 177/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 220.6521 - mean_squared_error: 220.6521\n",
      "Epoch 00177: val_loss did not improve from 211.55919\n",
      "526/526 [==============================] - 0s 459us/step - loss: 223.1497 - mean_squared_error: 223.1497 - val_loss: 228.0921 - val_mean_squared_error: 228.0921\n",
      "Epoch 178/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 226.9985 - mean_squared_error: 226.9985\n",
      "Epoch 00178: val_loss did not improve from 211.55919\n",
      "526/526 [==============================] - 0s 459us/step - loss: 228.5099 - mean_squared_error: 228.5099 - val_loss: 249.1107 - val_mean_squared_error: 249.1107\n",
      "Epoch 179/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 220.0639 - mean_squared_error: 220.0639\n",
      "Epoch 00179: val_loss did not improve from 211.55919\n",
      "526/526 [==============================] - 0s 459us/step - loss: 220.4306 - mean_squared_error: 220.4306 - val_loss: 267.8499 - val_mean_squared_error: 267.8499\n",
      "Epoch 180/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 234.3190 - mean_squared_error: 234.3190\n",
      "Epoch 00180: val_loss did not improve from 211.55919\n",
      "526/526 [==============================] - 0s 462us/step - loss: 234.2142 - mean_squared_error: 234.2142 - val_loss: 367.9974 - val_mean_squared_error: 367.9974\n",
      "Epoch 181/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 224.8062 - mean_squared_error: 224.8062\n",
      "Epoch 00181: val_loss did not improve from 211.55919\n",
      "526/526 [==============================] - 0s 459us/step - loss: 224.9126 - mean_squared_error: 224.9126 - val_loss: 223.8463 - val_mean_squared_error: 223.8463\n",
      "Epoch 182/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 224.5857 - mean_squared_error: 224.5857\n",
      "Epoch 00182: val_loss did not improve from 211.55919\n",
      "526/526 [==============================] - 0s 460us/step - loss: 224.8078 - mean_squared_error: 224.8078 - val_loss: 215.3683 - val_mean_squared_error: 215.3683\n",
      "Epoch 183/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 226.2622 - mean_squared_error: 226.2622\n",
      "Epoch 00183: val_loss did not improve from 211.55919\n",
      "526/526 [==============================] - 0s 462us/step - loss: 224.4683 - mean_squared_error: 224.4683 - val_loss: 235.4525 - val_mean_squared_error: 235.4525\n",
      "Epoch 184/500\n",
      "479/526 [==========================>...] - ETA: 0s - loss: 231.8900 - mean_squared_error: 231.8900\n",
      "Epoch 00184: val_loss did not improve from 211.55919\n",
      "526/526 [==============================] - 0s 466us/step - loss: 233.8566 - mean_squared_error: 233.8566 - val_loss: 263.5236 - val_mean_squared_error: 263.5236\n",
      "Epoch 185/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 224.9856 - mean_squared_error: 224.9856\n",
      "Epoch 00185: val_loss did not improve from 211.55919\n",
      "526/526 [==============================] - 0s 462us/step - loss: 225.0272 - mean_squared_error: 225.0272 - val_loss: 240.5580 - val_mean_squared_error: 240.5580\n",
      "Epoch 186/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 228.8203 - mean_squared_error: 228.8203\n",
      "Epoch 00186: val_loss did not improve from 211.55919\n",
      "526/526 [==============================] - 0s 460us/step - loss: 229.1506 - mean_squared_error: 229.1506 - val_loss: 302.3033 - val_mean_squared_error: 302.3033\n",
      "Epoch 187/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 226.5040 - mean_squared_error: 226.5040\n",
      "Epoch 00187: val_loss did not improve from 211.55919\n",
      "526/526 [==============================] - 0s 459us/step - loss: 223.9252 - mean_squared_error: 223.9252 - val_loss: 230.5340 - val_mean_squared_error: 230.5340\n",
      "Epoch 188/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 225.2560 - mean_squared_error: 225.2560\n",
      "Epoch 00188: val_loss did not improve from 211.55919\n",
      "526/526 [==============================] - 0s 462us/step - loss: 226.7907 - mean_squared_error: 226.7907 - val_loss: 240.8189 - val_mean_squared_error: 240.8189\n",
      "Epoch 189/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 224.4062 - mean_squared_error: 224.4062\n",
      "Epoch 00189: val_loss did not improve from 211.55919\n",
      "526/526 [==============================] - 0s 462us/step - loss: 222.4956 - mean_squared_error: 222.4956 - val_loss: 222.8737 - val_mean_squared_error: 222.8737\n",
      "Epoch 190/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 217.5466 - mean_squared_error: 217.5466\n",
      "Epoch 00190: val_loss did not improve from 211.55919\n",
      "526/526 [==============================] - 0s 459us/step - loss: 217.3657 - mean_squared_error: 217.3657 - val_loss: 282.4945 - val_mean_squared_error: 282.4945\n",
      "Epoch 191/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 226.1309 - mean_squared_error: 226.1309\n",
      "Epoch 00191: val_loss improved from 211.55919 to 210.10292, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 634us/step - loss: 223.1724 - mean_squared_error: 223.1724 - val_loss: 210.1029 - val_mean_squared_error: 210.1029\n",
      "Epoch 192/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 251.6299 - mean_squared_error: 251.6299\n",
      "Epoch 00192: val_loss improved from 210.10292 to 196.98758, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 630us/step - loss: 247.8226 - mean_squared_error: 247.8226 - val_loss: 196.9876 - val_mean_squared_error: 196.9876\n",
      "Epoch 193/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 226.4485 - mean_squared_error: 226.4485\n",
      "Epoch 00193: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 457us/step - loss: 222.4115 - mean_squared_error: 222.4115 - val_loss: 213.0315 - val_mean_squared_error: 213.0315\n",
      "Epoch 194/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 212.0596 - mean_squared_error: 212.0596\n",
      "Epoch 00194: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 459us/step - loss: 212.7859 - mean_squared_error: 212.7859 - val_loss: 251.6964 - val_mean_squared_error: 251.6964\n",
      "Epoch 195/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 209.2862 - mean_squared_error: 209.2862\n",
      "Epoch 00195: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 468us/step - loss: 211.1699 - mean_squared_error: 211.1699 - val_loss: 221.1546 - val_mean_squared_error: 221.1546\n",
      "Epoch 196/500\n",
      "479/526 [==========================>...] - ETA: 0s - loss: 238.2858 - mean_squared_error: 238.2858\n",
      "Epoch 00196: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 466us/step - loss: 234.9712 - mean_squared_error: 234.9712 - val_loss: 219.2118 - val_mean_squared_error: 219.2118\n",
      "Epoch 197/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 216.0408 - mean_squared_error: 216.0408\n",
      "Epoch 00197: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 459us/step - loss: 215.8671 - mean_squared_error: 215.8671 - val_loss: 205.8691 - val_mean_squared_error: 205.8691\n",
      "Epoch 198/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 210.0838 - mean_squared_error: 210.0838\n",
      "Epoch 00198: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 460us/step - loss: 213.2898 - mean_squared_error: 213.2898 - val_loss: 249.7361 - val_mean_squared_error: 249.7361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 226.2166 - mean_squared_error: 226.2166\n",
      "Epoch 00199: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 460us/step - loss: 222.8647 - mean_squared_error: 222.8647 - val_loss: 213.1577 - val_mean_squared_error: 213.1577\n",
      "Epoch 200/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 216.0956 - mean_squared_error: 216.0956\n",
      "Epoch 00200: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 464us/step - loss: 217.4004 - mean_squared_error: 217.4004 - val_loss: 294.3637 - val_mean_squared_error: 294.3637\n",
      "Epoch 201/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 216.4852 - mean_squared_error: 216.4852\n",
      "Epoch 00201: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 459us/step - loss: 217.5292 - mean_squared_error: 217.5292 - val_loss: 233.8231 - val_mean_squared_error: 233.8231\n",
      "Epoch 202/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 227.1078 - mean_squared_error: 227.1078\n",
      "Epoch 00202: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 457us/step - loss: 225.1359 - mean_squared_error: 225.1359 - val_loss: 224.8946 - val_mean_squared_error: 224.8946\n",
      "Epoch 203/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 207.4100 - mean_squared_error: 207.4100\n",
      "Epoch 00203: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 460us/step - loss: 209.7910 - mean_squared_error: 209.7910 - val_loss: 228.3905 - val_mean_squared_error: 228.3905\n",
      "Epoch 204/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 210.0215 - mean_squared_error: 210.0215\n",
      "Epoch 00204: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 460us/step - loss: 211.2462 - mean_squared_error: 211.2462 - val_loss: 206.6668 - val_mean_squared_error: 206.6668\n",
      "Epoch 205/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 210.1695 - mean_squared_error: 210.1695\n",
      "Epoch 00205: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 460us/step - loss: 210.7457 - mean_squared_error: 210.7457 - val_loss: 207.4166 - val_mean_squared_error: 207.4166\n",
      "Epoch 206/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 218.8436 - mean_squared_error: 218.8436\n",
      "Epoch 00206: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 460us/step - loss: 218.0529 - mean_squared_error: 218.0529 - val_loss: 268.7109 - val_mean_squared_error: 268.7109\n",
      "Epoch 207/500\n",
      "480/526 [==========================>...] - ETA: 0s - loss: 208.7841 - mean_squared_error: 208.7841\n",
      "Epoch 00207: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 462us/step - loss: 209.0468 - mean_squared_error: 209.0468 - val_loss: 238.8093 - val_mean_squared_error: 238.8093\n",
      "Epoch 208/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 210.8431 - mean_squared_error: 210.8431\n",
      "Epoch 00208: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 459us/step - loss: 212.6195 - mean_squared_error: 212.6195 - val_loss: 204.1826 - val_mean_squared_error: 204.1826\n",
      "Epoch 209/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 208.5882 - mean_squared_error: 208.5882\n",
      "Epoch 00209: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 460us/step - loss: 209.2334 - mean_squared_error: 209.2334 - val_loss: 206.5219 - val_mean_squared_error: 206.5219\n",
      "Epoch 210/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 221.5193 - mean_squared_error: 221.5193\n",
      "Epoch 00210: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 459us/step - loss: 224.2868 - mean_squared_error: 224.2868 - val_loss: 220.4499 - val_mean_squared_error: 220.4499\n",
      "Epoch 211/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 216.7693 - mean_squared_error: 216.7693\n",
      "Epoch 00211: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 462us/step - loss: 214.2922 - mean_squared_error: 214.2922 - val_loss: 206.3080 - val_mean_squared_error: 206.3080\n",
      "Epoch 212/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 211.6252 - mean_squared_error: 211.6252\n",
      "Epoch 00212: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 462us/step - loss: 214.1686 - mean_squared_error: 214.1686 - val_loss: 244.3228 - val_mean_squared_error: 244.3228\n",
      "Epoch 213/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 228.5705 - mean_squared_error: 228.5705\n",
      "Epoch 00213: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 464us/step - loss: 226.9478 - mean_squared_error: 226.9478 - val_loss: 220.4137 - val_mean_squared_error: 220.4137\n",
      "Epoch 214/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 215.2159 - mean_squared_error: 215.2159\n",
      "Epoch 00214: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 462us/step - loss: 216.3011 - mean_squared_error: 216.3011 - val_loss: 206.6753 - val_mean_squared_error: 206.6753\n",
      "Epoch 215/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 219.5763 - mean_squared_error: 219.5763\n",
      "Epoch 00215: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 462us/step - loss: 216.9561 - mean_squared_error: 216.9561 - val_loss: 260.0193 - val_mean_squared_error: 260.0193\n",
      "Epoch 216/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 212.5321 - mean_squared_error: 212.5321\n",
      "Epoch 00216: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 460us/step - loss: 211.5768 - mean_squared_error: 211.5768 - val_loss: 331.6480 - val_mean_squared_error: 331.6480\n",
      "Epoch 217/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 212.3502 - mean_squared_error: 212.3502\n",
      "Epoch 00217: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 459us/step - loss: 211.3934 - mean_squared_error: 211.3934 - val_loss: 228.8475 - val_mean_squared_error: 228.8475\n",
      "Epoch 218/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 210.9426 - mean_squared_error: 210.9426\n",
      "Epoch 00218: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 459us/step - loss: 212.1274 - mean_squared_error: 212.1274 - val_loss: 265.2395 - val_mean_squared_error: 265.2395\n",
      "Epoch 219/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 218.9946 - mean_squared_error: 218.9946\n",
      "Epoch 00219: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 459us/step - loss: 217.8158 - mean_squared_error: 217.8158 - val_loss: 220.6361 - val_mean_squared_error: 220.6361\n",
      "Epoch 220/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 210.3424 - mean_squared_error: 210.3424\n",
      "Epoch 00220: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 460us/step - loss: 208.1718 - mean_squared_error: 208.1718 - val_loss: 200.7926 - val_mean_squared_error: 200.7926\n",
      "Epoch 221/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 209.4881 - mean_squared_error: 209.4881\n",
      "Epoch 00221: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 460us/step - loss: 208.0352 - mean_squared_error: 208.0352 - val_loss: 222.1618 - val_mean_squared_error: 222.1618\n",
      "Epoch 222/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 210.6160 - mean_squared_error: 210.6160\n",
      "Epoch 00222: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 460us/step - loss: 210.0973 - mean_squared_error: 210.0973 - val_loss: 241.4931 - val_mean_squared_error: 241.4931\n",
      "Epoch 223/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 212.8622 - mean_squared_error: 212.8622\n",
      "Epoch 00223: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 459us/step - loss: 211.0218 - mean_squared_error: 211.0218 - val_loss: 218.0273 - val_mean_squared_error: 218.0273\n",
      "Epoch 224/500\n",
      "477/526 [==========================>...] - ETA: 0s - loss: 209.8451 - mean_squared_error: 209.8451\n",
      "Epoch 00224: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 466us/step - loss: 211.7782 - mean_squared_error: 211.7782 - val_loss: 234.8145 - val_mean_squared_error: 234.8145\n",
      "Epoch 225/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 213.3027 - mean_squared_error: 213.3027\n",
      "Epoch 00225: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 462us/step - loss: 217.7831 - mean_squared_error: 217.7831 - val_loss: 220.8849 - val_mean_squared_error: 220.8849\n",
      "Epoch 226/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 204.4353 - mean_squared_error: 204.4353\n",
      "Epoch 00226: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 464us/step - loss: 203.9597 - mean_squared_error: 203.9597 - val_loss: 207.6122 - val_mean_squared_error: 207.6122\n",
      "Epoch 227/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 199.6233 - mean_squared_error: 199.6233\n",
      "Epoch 00227: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 462us/step - loss: 198.7529 - mean_squared_error: 198.7529 - val_loss: 242.0230 - val_mean_squared_error: 242.0230\n",
      "Epoch 228/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 205.1274 - mean_squared_error: 205.1274\n",
      "Epoch 00228: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 460us/step - loss: 205.3744 - mean_squared_error: 205.3744 - val_loss: 236.5715 - val_mean_squared_error: 236.5715\n",
      "Epoch 229/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 212.6490 - mean_squared_error: 212.6490\n",
      "Epoch 00229: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 462us/step - loss: 210.4127 - mean_squared_error: 210.4127 - val_loss: 296.6323 - val_mean_squared_error: 296.6323\n",
      "Epoch 230/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 210.3427 - mean_squared_error: 210.3427\n",
      "Epoch 00230: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 462us/step - loss: 209.6045 - mean_squared_error: 209.6045 - val_loss: 272.1567 - val_mean_squared_error: 272.1567\n",
      "Epoch 231/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 201.2814 - mean_squared_error: 201.2814\n",
      "Epoch 00231: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 460us/step - loss: 201.9957 - mean_squared_error: 201.9957 - val_loss: 235.3549 - val_mean_squared_error: 235.3549\n",
      "Epoch 232/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 204.9423 - mean_squared_error: 204.9423\n",
      "Epoch 00232: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 464us/step - loss: 204.8530 - mean_squared_error: 204.8530 - val_loss: 222.8631 - val_mean_squared_error: 222.8631\n",
      "Epoch 233/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 206.2233 - mean_squared_error: 206.2233\n",
      "Epoch 00233: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 462us/step - loss: 204.7167 - mean_squared_error: 204.7167 - val_loss: 277.1438 - val_mean_squared_error: 277.1438\n",
      "Epoch 234/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 204.7020 - mean_squared_error: 204.7020\n",
      "Epoch 00234: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 459us/step - loss: 204.0274 - mean_squared_error: 204.0274 - val_loss: 217.5429 - val_mean_squared_error: 217.5429\n",
      "Epoch 235/500\n",
      "479/526 [==========================>...] - ETA: 0s - loss: 205.4573 - mean_squared_error: 205.4573\n",
      "Epoch 00235: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 466us/step - loss: 205.1573 - mean_squared_error: 205.1573 - val_loss: 251.2562 - val_mean_squared_error: 251.2562\n",
      "Epoch 236/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 204.9099 - mean_squared_error: 204.9099\n",
      "Epoch 00236: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 459us/step - loss: 205.2402 - mean_squared_error: 205.2402 - val_loss: 283.4659 - val_mean_squared_error: 283.4659\n",
      "Epoch 237/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 211.2668 - mean_squared_error: 211.2668\n",
      "Epoch 00237: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 462us/step - loss: 211.0896 - mean_squared_error: 211.0896 - val_loss: 219.1106 - val_mean_squared_error: 219.1106\n",
      "Epoch 238/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 190.9240 - mean_squared_error: 190.9240\n",
      "Epoch 00238: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 460us/step - loss: 191.7837 - mean_squared_error: 191.7837 - val_loss: 226.9107 - val_mean_squared_error: 226.9107\n",
      "Epoch 239/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 209.9265 - mean_squared_error: 209.9265\n",
      "Epoch 00239: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 464us/step - loss: 209.0644 - mean_squared_error: 209.0644 - val_loss: 208.9819 - val_mean_squared_error: 208.9819\n",
      "Epoch 240/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 195.7839 - mean_squared_error: 195.7839\n",
      "Epoch 00240: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 459us/step - loss: 195.1301 - mean_squared_error: 195.1301 - val_loss: 217.2825 - val_mean_squared_error: 217.2825\n",
      "Epoch 241/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 195.6285 - mean_squared_error: 195.6285\n",
      "Epoch 00241: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 457us/step - loss: 195.1692 - mean_squared_error: 195.1692 - val_loss: 202.2773 - val_mean_squared_error: 202.2773\n",
      "Epoch 242/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 203.2478 - mean_squared_error: 203.2478\n",
      "Epoch 00242: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 460us/step - loss: 202.9075 - mean_squared_error: 202.9075 - val_loss: 263.6588 - val_mean_squared_error: 263.6588\n",
      "Epoch 243/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 196.1481 - mean_squared_error: 196.1481\n",
      "Epoch 00243: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 459us/step - loss: 197.0116 - mean_squared_error: 197.0116 - val_loss: 212.7088 - val_mean_squared_error: 212.7088\n",
      "Epoch 244/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 204.2094 - mean_squared_error: 204.2094\n",
      "Epoch 00244: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 460us/step - loss: 202.9482 - mean_squared_error: 202.9482 - val_loss: 226.3184 - val_mean_squared_error: 226.3184\n",
      "Epoch 245/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 200.9825 - mean_squared_error: 200.9825\n",
      "Epoch 00245: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 460us/step - loss: 198.9500 - mean_squared_error: 198.9500 - val_loss: 277.7596 - val_mean_squared_error: 277.7596\n",
      "Epoch 246/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 205.2427 - mean_squared_error: 205.2427\n",
      "Epoch 00246: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 457us/step - loss: 205.4331 - mean_squared_error: 205.4331 - val_loss: 236.7328 - val_mean_squared_error: 236.7328\n",
      "Epoch 247/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 200.0663 - mean_squared_error: 200.0663\n",
      "Epoch 00247: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 459us/step - loss: 200.7455 - mean_squared_error: 200.7455 - val_loss: 199.0074 - val_mean_squared_error: 199.0074\n",
      "Epoch 248/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 198.5655 - mean_squared_error: 198.5655\n",
      "Epoch 00248: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 457us/step - loss: 203.9813 - mean_squared_error: 203.9813 - val_loss: 268.5193 - val_mean_squared_error: 268.5193\n",
      "Epoch 249/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489/526 [==========================>...] - ETA: 0s - loss: 192.9659 - mean_squared_error: 192.9659\n",
      "Epoch 00249: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 457us/step - loss: 194.1972 - mean_squared_error: 194.1972 - val_loss: 204.3315 - val_mean_squared_error: 204.3315\n",
      "Epoch 250/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 195.8001 - mean_squared_error: 195.8001\n",
      "Epoch 00250: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 459us/step - loss: 200.0637 - mean_squared_error: 200.0637 - val_loss: 224.1539 - val_mean_squared_error: 224.1539\n",
      "Epoch 251/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 194.8254 - mean_squared_error: 194.8254\n",
      "Epoch 00251: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 457us/step - loss: 193.2623 - mean_squared_error: 193.2623 - val_loss: 217.5061 - val_mean_squared_error: 217.5061\n",
      "Epoch 252/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 199.0313 - mean_squared_error: 199.0313\n",
      "Epoch 00252: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 462us/step - loss: 200.3114 - mean_squared_error: 200.3114 - val_loss: 206.9510 - val_mean_squared_error: 206.9510\n",
      "Epoch 253/500\n",
      "491/526 [===========================>..] - ETA: 0s - loss: 196.9038 - mean_squared_error: 196.9038\n",
      "Epoch 00253: val_loss did not improve from 196.98758\n",
      "526/526 [==============================] - 0s 455us/step - loss: 198.1303 - mean_squared_error: 198.1303 - val_loss: 210.8629 - val_mean_squared_error: 210.8629\n",
      "Epoch 254/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 205.6355 - mean_squared_error: 205.6355\n",
      "Epoch 00254: val_loss improved from 196.98758 to 192.49190, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 615us/step - loss: 204.9687 - mean_squared_error: 204.9687 - val_loss: 192.4919 - val_mean_squared_error: 192.4919\n",
      "Epoch 255/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 198.0934 - mean_squared_error: 198.0934\n",
      "Epoch 00255: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 459us/step - loss: 198.9346 - mean_squared_error: 198.9346 - val_loss: 262.6818 - val_mean_squared_error: 262.6818\n",
      "Epoch 256/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 192.4538 - mean_squared_error: 192.4538\n",
      "Epoch 00256: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 462us/step - loss: 194.9339 - mean_squared_error: 194.9339 - val_loss: 221.1246 - val_mean_squared_error: 221.1246\n",
      "Epoch 257/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 195.0692 - mean_squared_error: 195.0692\n",
      "Epoch 00257: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 462us/step - loss: 193.4803 - mean_squared_error: 193.4803 - val_loss: 202.3562 - val_mean_squared_error: 202.3562\n",
      "Epoch 258/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 197.7417 - mean_squared_error: 197.7417\n",
      "Epoch 00258: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 459us/step - loss: 196.1304 - mean_squared_error: 196.1304 - val_loss: 210.2494 - val_mean_squared_error: 210.2494\n",
      "Epoch 259/500\n",
      "479/526 [==========================>...] - ETA: 0s - loss: 197.7546 - mean_squared_error: 197.7546\n",
      "Epoch 00259: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 464us/step - loss: 195.3309 - mean_squared_error: 195.3309 - val_loss: 240.0747 - val_mean_squared_error: 240.0747\n",
      "Epoch 260/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 194.3052 - mean_squared_error: 194.3052\n",
      "Epoch 00260: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 460us/step - loss: 193.7740 - mean_squared_error: 193.7740 - val_loss: 211.5935 - val_mean_squared_error: 211.5935\n",
      "Epoch 261/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 203.1596 - mean_squared_error: 203.1596\n",
      "Epoch 00261: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 462us/step - loss: 202.4214 - mean_squared_error: 202.4214 - val_loss: 226.3463 - val_mean_squared_error: 226.3463\n",
      "Epoch 262/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 192.5925 - mean_squared_error: 192.5925\n",
      "Epoch 00262: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 459us/step - loss: 191.7477 - mean_squared_error: 191.7477 - val_loss: 214.1708 - val_mean_squared_error: 214.1708\n",
      "Epoch 263/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 192.6751 - mean_squared_error: 192.6751\n",
      "Epoch 00263: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 457us/step - loss: 193.2942 - mean_squared_error: 193.2942 - val_loss: 204.6135 - val_mean_squared_error: 204.6135\n",
      "Epoch 264/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 183.1102 - mean_squared_error: 183.1102\n",
      "Epoch 00264: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 459us/step - loss: 184.9201 - mean_squared_error: 184.9201 - val_loss: 202.4101 - val_mean_squared_error: 202.4101\n",
      "Epoch 265/500\n",
      "480/526 [==========================>...] - ETA: 0s - loss: 194.6426 - mean_squared_error: 194.6426\n",
      "Epoch 00265: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 464us/step - loss: 193.4829 - mean_squared_error: 193.4829 - val_loss: 238.4755 - val_mean_squared_error: 238.4755\n",
      "Epoch 266/500\n",
      "491/526 [===========================>..] - ETA: 0s - loss: 200.6051 - mean_squared_error: 200.6051\n",
      "Epoch 00266: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 455us/step - loss: 198.2508 - mean_squared_error: 198.2508 - val_loss: 275.1309 - val_mean_squared_error: 275.1309\n",
      "Epoch 267/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 190.9913 - mean_squared_error: 190.9913\n",
      "Epoch 00267: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 459us/step - loss: 193.4758 - mean_squared_error: 193.4758 - val_loss: 195.9981 - val_mean_squared_error: 195.9981\n",
      "Epoch 268/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 190.8713 - mean_squared_error: 190.8713\n",
      "Epoch 00268: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 464us/step - loss: 189.8222 - mean_squared_error: 189.8222 - val_loss: 227.4886 - val_mean_squared_error: 227.4886\n",
      "Epoch 269/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 194.3376 - mean_squared_error: 194.3376\n",
      "Epoch 00269: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 460us/step - loss: 191.4957 - mean_squared_error: 191.4957 - val_loss: 269.7758 - val_mean_squared_error: 269.7758\n",
      "Epoch 270/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 190.6716 - mean_squared_error: 190.6716\n",
      "Epoch 00270: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 460us/step - loss: 191.1527 - mean_squared_error: 191.1527 - val_loss: 203.2388 - val_mean_squared_error: 203.2388\n",
      "Epoch 271/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 194.5362 - mean_squared_error: 194.5362\n",
      "Epoch 00271: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 455us/step - loss: 195.9717 - mean_squared_error: 195.9717 - val_loss: 231.1510 - val_mean_squared_error: 231.1510\n",
      "Epoch 272/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 187.9837 - mean_squared_error: 187.9837\n",
      "Epoch 00272: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 459us/step - loss: 188.4950 - mean_squared_error: 188.4950 - val_loss: 212.2995 - val_mean_squared_error: 212.2995\n",
      "Epoch 273/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 194.0101 - mean_squared_error: 194.0101\n",
      "Epoch 00273: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 464us/step - loss: 194.1918 - mean_squared_error: 194.1918 - val_loss: 196.6934 - val_mean_squared_error: 196.6934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 188.1322 - mean_squared_error: 188.1322\n",
      "Epoch 00274: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 460us/step - loss: 188.5000 - mean_squared_error: 188.5000 - val_loss: 207.7697 - val_mean_squared_error: 207.7697\n",
      "Epoch 275/500\n",
      "491/526 [===========================>..] - ETA: 0s - loss: 195.5682 - mean_squared_error: 195.5682\n",
      "Epoch 00275: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 453us/step - loss: 196.9427 - mean_squared_error: 196.9427 - val_loss: 202.7530 - val_mean_squared_error: 202.7530\n",
      "Epoch 276/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 187.7980 - mean_squared_error: 187.7980\n",
      "Epoch 00276: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 457us/step - loss: 189.0212 - mean_squared_error: 189.0212 - val_loss: 209.1216 - val_mean_squared_error: 209.1216\n",
      "Epoch 277/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 195.7290 - mean_squared_error: 195.7290\n",
      "Epoch 00277: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 459us/step - loss: 195.1635 - mean_squared_error: 195.1635 - val_loss: 235.5259 - val_mean_squared_error: 235.5259\n",
      "Epoch 278/500\n",
      "493/526 [===========================>..] - ETA: 0s - loss: 196.1352 - mean_squared_error: 196.1352\n",
      "Epoch 00278: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 455us/step - loss: 195.2751 - mean_squared_error: 195.2751 - val_loss: 196.2318 - val_mean_squared_error: 196.2318\n",
      "Epoch 279/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 186.5640 - mean_squared_error: 186.5640\n",
      "Epoch 00279: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 459us/step - loss: 186.3336 - mean_squared_error: 186.3336 - val_loss: 197.3331 - val_mean_squared_error: 197.3331\n",
      "Epoch 280/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 188.6810 - mean_squared_error: 188.6810\n",
      "Epoch 00280: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 457us/step - loss: 187.8671 - mean_squared_error: 187.8671 - val_loss: 223.4779 - val_mean_squared_error: 223.4779\n",
      "Epoch 281/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 192.4503 - mean_squared_error: 192.4503\n",
      "Epoch 00281: val_loss did not improve from 192.49190\n",
      "526/526 [==============================] - 0s 459us/step - loss: 192.1250 - mean_squared_error: 192.1250 - val_loss: 195.0885 - val_mean_squared_error: 195.0885\n",
      "Epoch 282/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 196.7753 - mean_squared_error: 196.7753\n",
      "Epoch 00282: val_loss improved from 192.49190 to 188.33852, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 628us/step - loss: 194.0032 - mean_squared_error: 194.0032 - val_loss: 188.3385 - val_mean_squared_error: 188.3385\n",
      "Epoch 283/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 189.8211 - mean_squared_error: 189.8211\n",
      "Epoch 00283: val_loss did not improve from 188.33852\n",
      "526/526 [==============================] - 0s 459us/step - loss: 188.8385 - mean_squared_error: 188.8385 - val_loss: 199.6857 - val_mean_squared_error: 199.6857\n",
      "Epoch 284/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 185.9284 - mean_squared_error: 185.9284\n",
      "Epoch 00284: val_loss did not improve from 188.33852\n",
      "526/526 [==============================] - 0s 457us/step - loss: 184.8310 - mean_squared_error: 184.8310 - val_loss: 206.2602 - val_mean_squared_error: 206.2602\n",
      "Epoch 285/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 181.2970 - mean_squared_error: 181.2970\n",
      "Epoch 00285: val_loss did not improve from 188.33852\n",
      "526/526 [==============================] - 0s 460us/step - loss: 182.2650 - mean_squared_error: 182.2650 - val_loss: 188.4867 - val_mean_squared_error: 188.4867\n",
      "Epoch 286/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 186.2453 - mean_squared_error: 186.2453\n",
      "Epoch 00286: val_loss did not improve from 188.33852\n",
      "526/526 [==============================] - 0s 457us/step - loss: 186.3712 - mean_squared_error: 186.3712 - val_loss: 200.3848 - val_mean_squared_error: 200.3848\n",
      "Epoch 287/500\n",
      "491/526 [===========================>..] - ETA: 0s - loss: 185.5547 - mean_squared_error: 185.5547\n",
      "Epoch 00287: val_loss did not improve from 188.33852\n",
      "526/526 [==============================] - 0s 455us/step - loss: 186.3976 - mean_squared_error: 186.3976 - val_loss: 206.6029 - val_mean_squared_error: 206.6029\n",
      "Epoch 288/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 187.7105 - mean_squared_error: 187.7105\n",
      "Epoch 00288: val_loss did not improve from 188.33852\n",
      "526/526 [==============================] - 0s 457us/step - loss: 188.7499 - mean_squared_error: 188.7499 - val_loss: 220.6516 - val_mean_squared_error: 220.6516\n",
      "Epoch 289/500\n",
      "491/526 [===========================>..] - ETA: 0s - loss: 187.8204 - mean_squared_error: 187.8204\n",
      "Epoch 00289: val_loss did not improve from 188.33852\n",
      "526/526 [==============================] - 0s 459us/step - loss: 187.8343 - mean_squared_error: 187.8343 - val_loss: 200.3747 - val_mean_squared_error: 200.3747\n",
      "Epoch 290/500\n",
      "491/526 [===========================>..] - ETA: 0s - loss: 192.8264 - mean_squared_error: 192.8264\n",
      "Epoch 00290: val_loss improved from 188.33852 to 186.83830, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 603us/step - loss: 192.2792 - mean_squared_error: 192.2792 - val_loss: 186.8383 - val_mean_squared_error: 186.8383\n",
      "Epoch 291/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 185.4215 - mean_squared_error: 185.4215\n",
      "Epoch 00291: val_loss did not improve from 186.83830\n",
      "526/526 [==============================] - 0s 455us/step - loss: 186.2116 - mean_squared_error: 186.2116 - val_loss: 240.6245 - val_mean_squared_error: 240.6245\n",
      "Epoch 292/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 178.3551 - mean_squared_error: 178.3551\n",
      "Epoch 00292: val_loss did not improve from 186.83830\n",
      "526/526 [==============================] - 0s 459us/step - loss: 179.3375 - mean_squared_error: 179.3375 - val_loss: 189.8248 - val_mean_squared_error: 189.8248\n",
      "Epoch 293/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 184.4849 - mean_squared_error: 184.4849\n",
      "Epoch 00293: val_loss did not improve from 186.83830\n",
      "526/526 [==============================] - 0s 460us/step - loss: 185.8796 - mean_squared_error: 185.8796 - val_loss: 204.0622 - val_mean_squared_error: 204.0622\n",
      "Epoch 294/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 186.8726 - mean_squared_error: 186.8726\n",
      "Epoch 00294: val_loss did not improve from 186.83830\n",
      "526/526 [==============================] - 0s 459us/step - loss: 188.0731 - mean_squared_error: 188.0731 - val_loss: 261.4470 - val_mean_squared_error: 261.4470\n",
      "Epoch 295/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 185.3516 - mean_squared_error: 185.3516\n",
      "Epoch 00295: val_loss did not improve from 186.83830\n",
      "526/526 [==============================] - 0s 459us/step - loss: 184.5981 - mean_squared_error: 184.5981 - val_loss: 266.1335 - val_mean_squared_error: 266.1335\n",
      "Epoch 296/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 179.4680 - mean_squared_error: 179.4680\n",
      "Epoch 00296: val_loss did not improve from 186.83830\n",
      "526/526 [==============================] - 0s 457us/step - loss: 180.0254 - mean_squared_error: 180.0254 - val_loss: 216.4945 - val_mean_squared_error: 216.4945\n",
      "Epoch 297/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 182.5081 - mean_squared_error: 182.5081\n",
      "Epoch 00297: val_loss did not improve from 186.83830\n",
      "526/526 [==============================] - 0s 459us/step - loss: 182.0340 - mean_squared_error: 182.0340 - val_loss: 188.3846 - val_mean_squared_error: 188.3846\n",
      "Epoch 298/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 186.6090 - mean_squared_error: 186.6090\n",
      "Epoch 00298: val_loss did not improve from 186.83830\n",
      "526/526 [==============================] - 0s 460us/step - loss: 185.5635 - mean_squared_error: 185.5635 - val_loss: 199.3352 - val_mean_squared_error: 199.3352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 182.6784 - mean_squared_error: 182.6784\n",
      "Epoch 00299: val_loss did not improve from 186.83830\n",
      "526/526 [==============================] - 0s 460us/step - loss: 183.7990 - mean_squared_error: 183.7990 - val_loss: 213.5736 - val_mean_squared_error: 213.5736\n",
      "Epoch 300/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 186.4678 - mean_squared_error: 186.4678\n",
      "Epoch 00300: val_loss did not improve from 186.83830\n",
      "526/526 [==============================] - 0s 457us/step - loss: 185.8283 - mean_squared_error: 185.8283 - val_loss: 243.0733 - val_mean_squared_error: 243.0733\n",
      "Epoch 301/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 181.1498 - mean_squared_error: 181.1498\n",
      "Epoch 00301: val_loss did not improve from 186.83830\n",
      "526/526 [==============================] - 0s 455us/step - loss: 180.6643 - mean_squared_error: 180.6643 - val_loss: 196.9872 - val_mean_squared_error: 196.9872\n",
      "Epoch 302/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 181.1430 - mean_squared_error: 181.1430\n",
      "Epoch 00302: val_loss did not improve from 186.83830\n",
      "526/526 [==============================] - 0s 459us/step - loss: 180.8127 - mean_squared_error: 180.8127 - val_loss: 194.6764 - val_mean_squared_error: 194.6764\n",
      "Epoch 303/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 179.9355 - mean_squared_error: 179.9355\n",
      "Epoch 00303: val_loss did not improve from 186.83830\n",
      "526/526 [==============================] - 0s 457us/step - loss: 179.2776 - mean_squared_error: 179.2776 - val_loss: 228.2769 - val_mean_squared_error: 228.2769\n",
      "Epoch 304/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 185.5055 - mean_squared_error: 185.5055\n",
      "Epoch 00304: val_loss did not improve from 186.83830\n",
      "526/526 [==============================] - 0s 457us/step - loss: 187.1507 - mean_squared_error: 187.1507 - val_loss: 226.6213 - val_mean_squared_error: 226.6213\n",
      "Epoch 305/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 180.0163 - mean_squared_error: 180.0163\n",
      "Epoch 00305: val_loss did not improve from 186.83830\n",
      "526/526 [==============================] - 0s 459us/step - loss: 180.4025 - mean_squared_error: 180.4025 - val_loss: 244.3489 - val_mean_squared_error: 244.3489\n",
      "Epoch 306/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 176.9917 - mean_squared_error: 176.9917\n",
      "Epoch 00306: val_loss did not improve from 186.83830\n",
      "526/526 [==============================] - 0s 462us/step - loss: 177.3194 - mean_squared_error: 177.3194 - val_loss: 189.8911 - val_mean_squared_error: 189.8911\n",
      "Epoch 307/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 184.7183 - mean_squared_error: 184.7183\n",
      "Epoch 00307: val_loss did not improve from 186.83830\n",
      "526/526 [==============================] - 0s 462us/step - loss: 182.5774 - mean_squared_error: 182.5774 - val_loss: 202.3775 - val_mean_squared_error: 202.3775\n",
      "Epoch 308/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 181.9311 - mean_squared_error: 181.9311\n",
      "Epoch 00308: val_loss did not improve from 186.83830\n",
      "526/526 [==============================] - 0s 460us/step - loss: 180.2536 - mean_squared_error: 180.2536 - val_loss: 249.2954 - val_mean_squared_error: 249.2954\n",
      "Epoch 309/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 178.8125 - mean_squared_error: 178.8125\n",
      "Epoch 00309: val_loss did not improve from 186.83830\n",
      "526/526 [==============================] - 0s 459us/step - loss: 178.2789 - mean_squared_error: 178.2789 - val_loss: 201.1153 - val_mean_squared_error: 201.1153\n",
      "Epoch 310/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 182.5383 - mean_squared_error: 182.5383\n",
      "Epoch 00310: val_loss did not improve from 186.83830\n",
      "526/526 [==============================] - 0s 460us/step - loss: 183.8619 - mean_squared_error: 183.8619 - val_loss: 253.2785 - val_mean_squared_error: 253.2785\n",
      "Epoch 311/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 182.0833 - mean_squared_error: 182.0833\n",
      "Epoch 00311: val_loss did not improve from 186.83830\n",
      "526/526 [==============================] - 0s 457us/step - loss: 182.0619 - mean_squared_error: 182.0619 - val_loss: 199.5202 - val_mean_squared_error: 199.5202\n",
      "Epoch 312/500\n",
      "492/526 [===========================>..] - ETA: 0s - loss: 179.9504 - mean_squared_error: 179.9504\n",
      "Epoch 00312: val_loss improved from 186.83830 to 176.91170, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 616us/step - loss: 178.4559 - mean_squared_error: 178.4559 - val_loss: 176.9117 - val_mean_squared_error: 176.9117\n",
      "Epoch 313/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 179.0369 - mean_squared_error: 179.0369\n",
      "Epoch 00313: val_loss did not improve from 176.91170\n",
      "526/526 [==============================] - 0s 459us/step - loss: 178.6003 - mean_squared_error: 178.6003 - val_loss: 203.5973 - val_mean_squared_error: 203.5973\n",
      "Epoch 314/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 176.7831 - mean_squared_error: 176.7831\n",
      "Epoch 00314: val_loss did not improve from 176.91170\n",
      "526/526 [==============================] - 0s 462us/step - loss: 175.8761 - mean_squared_error: 175.8761 - val_loss: 235.3329 - val_mean_squared_error: 235.3329\n",
      "Epoch 315/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 178.5746 - mean_squared_error: 178.5746\n",
      "Epoch 00315: val_loss did not improve from 176.91170\n",
      "526/526 [==============================] - 0s 457us/step - loss: 178.2879 - mean_squared_error: 178.2879 - val_loss: 190.4314 - val_mean_squared_error: 190.4314\n",
      "Epoch 316/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 178.0900 - mean_squared_error: 178.0900\n",
      "Epoch 00316: val_loss did not improve from 176.91170\n",
      "526/526 [==============================] - 0s 457us/step - loss: 177.3546 - mean_squared_error: 177.3546 - val_loss: 189.5836 - val_mean_squared_error: 189.5836\n",
      "Epoch 317/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 175.0820 - mean_squared_error: 175.0820\n",
      "Epoch 00317: val_loss did not improve from 176.91170\n",
      "526/526 [==============================] - 0s 460us/step - loss: 175.9649 - mean_squared_error: 175.9649 - val_loss: 194.3033 - val_mean_squared_error: 194.3033\n",
      "Epoch 318/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 171.9176 - mean_squared_error: 171.9176\n",
      "Epoch 00318: val_loss did not improve from 176.91170\n",
      "526/526 [==============================] - 0s 459us/step - loss: 174.4715 - mean_squared_error: 174.4715 - val_loss: 277.6743 - val_mean_squared_error: 277.6743\n",
      "Epoch 319/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 177.1660 - mean_squared_error: 177.1660\n",
      "Epoch 00319: val_loss did not improve from 176.91170\n",
      "526/526 [==============================] - 0s 464us/step - loss: 178.9909 - mean_squared_error: 178.9909 - val_loss: 218.5451 - val_mean_squared_error: 218.5451\n",
      "Epoch 320/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 175.3338 - mean_squared_error: 175.3338\n",
      "Epoch 00320: val_loss did not improve from 176.91170\n",
      "526/526 [==============================] - 0s 457us/step - loss: 174.1364 - mean_squared_error: 174.1364 - val_loss: 178.0515 - val_mean_squared_error: 178.0515\n",
      "Epoch 321/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 178.1676 - mean_squared_error: 178.1676\n",
      "Epoch 00321: val_loss did not improve from 176.91170\n",
      "526/526 [==============================] - 0s 457us/step - loss: 178.1862 - mean_squared_error: 178.1862 - val_loss: 258.6990 - val_mean_squared_error: 258.6990\n",
      "Epoch 322/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 177.4816 - mean_squared_error: 177.4816\n",
      "Epoch 00322: val_loss did not improve from 176.91170\n",
      "526/526 [==============================] - 0s 462us/step - loss: 179.5277 - mean_squared_error: 179.5277 - val_loss: 186.9318 - val_mean_squared_error: 186.9318\n",
      "Epoch 323/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 171.4811 - mean_squared_error: 171.4811\n",
      "Epoch 00323: val_loss did not improve from 176.91170\n",
      "526/526 [==============================] - 0s 457us/step - loss: 175.4404 - mean_squared_error: 175.4404 - val_loss: 199.3458 - val_mean_squared_error: 199.3458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 324/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 171.5848 - mean_squared_error: 171.5848\n",
      "Epoch 00324: val_loss did not improve from 176.91170\n",
      "526/526 [==============================] - 0s 458us/step - loss: 171.4091 - mean_squared_error: 171.4091 - val_loss: 192.5858 - val_mean_squared_error: 192.5858\n",
      "Epoch 325/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 174.4350 - mean_squared_error: 174.4350\n",
      "Epoch 00325: val_loss did not improve from 176.91170\n",
      "526/526 [==============================] - 0s 459us/step - loss: 174.0094 - mean_squared_error: 174.0094 - val_loss: 206.7815 - val_mean_squared_error: 206.7815\n",
      "Epoch 326/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 179.3019 - mean_squared_error: 179.3019\n",
      "Epoch 00326: val_loss did not improve from 176.91170\n",
      "526/526 [==============================] - 0s 459us/step - loss: 177.6389 - mean_squared_error: 177.6389 - val_loss: 190.3689 - val_mean_squared_error: 190.3689\n",
      "Epoch 327/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 175.0949 - mean_squared_error: 175.0949\n",
      "Epoch 00327: val_loss did not improve from 176.91170\n",
      "526/526 [==============================] - 0s 459us/step - loss: 174.8055 - mean_squared_error: 174.8055 - val_loss: 216.5963 - val_mean_squared_error: 216.5963\n",
      "Epoch 328/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 171.4978 - mean_squared_error: 171.4978\n",
      "Epoch 00328: val_loss did not improve from 176.91170\n",
      "526/526 [==============================] - 0s 455us/step - loss: 172.1649 - mean_squared_error: 172.1649 - val_loss: 189.2634 - val_mean_squared_error: 189.2634\n",
      "Epoch 329/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 177.6253 - mean_squared_error: 177.6253\n",
      "Epoch 00329: val_loss did not improve from 176.91170\n",
      "526/526 [==============================] - 0s 457us/step - loss: 176.6638 - mean_squared_error: 176.6638 - val_loss: 231.2145 - val_mean_squared_error: 231.2145\n",
      "Epoch 330/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 185.6302 - mean_squared_error: 185.6302\n",
      "Epoch 00330: val_loss did not improve from 176.91170\n",
      "526/526 [==============================] - 0s 462us/step - loss: 182.8214 - mean_squared_error: 182.8214 - val_loss: 177.2595 - val_mean_squared_error: 177.2595\n",
      "Epoch 331/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 172.4131 - mean_squared_error: 172.4131\n",
      "Epoch 00331: val_loss did not improve from 176.91170\n",
      "526/526 [==============================] - 0s 460us/step - loss: 171.8815 - mean_squared_error: 171.8815 - val_loss: 185.4562 - val_mean_squared_error: 185.4562\n",
      "Epoch 332/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 171.2325 - mean_squared_error: 171.2325\n",
      "Epoch 00332: val_loss improved from 176.91170 to 176.86032, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 651us/step - loss: 171.4280 - mean_squared_error: 171.4280 - val_loss: 176.8603 - val_mean_squared_error: 176.8603\n",
      "Epoch 333/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 183.3142 - mean_squared_error: 183.3142\n",
      "Epoch 00333: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 464us/step - loss: 181.3389 - mean_squared_error: 181.3389 - val_loss: 210.9898 - val_mean_squared_error: 210.9898\n",
      "Epoch 334/500\n",
      "480/526 [==========================>...] - ETA: 0s - loss: 172.7328 - mean_squared_error: 172.7328\n",
      "Epoch 00334: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 464us/step - loss: 175.8480 - mean_squared_error: 175.8480 - val_loss: 191.3298 - val_mean_squared_error: 191.3298\n",
      "Epoch 335/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 179.1935 - mean_squared_error: 179.1935\n",
      "Epoch 00335: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 464us/step - loss: 177.7655 - mean_squared_error: 177.7655 - val_loss: 186.2050 - val_mean_squared_error: 186.2050\n",
      "Epoch 336/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 174.4117 - mean_squared_error: 174.4117\n",
      "Epoch 00336: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 464us/step - loss: 176.5674 - mean_squared_error: 176.5674 - val_loss: 186.0847 - val_mean_squared_error: 186.0847\n",
      "Epoch 337/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 170.7021 - mean_squared_error: 170.7021\n",
      "Epoch 00337: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 460us/step - loss: 172.0084 - mean_squared_error: 172.0084 - val_loss: 182.8286 - val_mean_squared_error: 182.8286\n",
      "Epoch 338/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 169.7744 - mean_squared_error: 169.7744\n",
      "Epoch 00338: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 460us/step - loss: 170.5550 - mean_squared_error: 170.5550 - val_loss: 185.5293 - val_mean_squared_error: 185.5293\n",
      "Epoch 339/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 174.8868 - mean_squared_error: 174.8868\n",
      "Epoch 00339: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 460us/step - loss: 173.6204 - mean_squared_error: 173.6204 - val_loss: 180.7624 - val_mean_squared_error: 180.7624\n",
      "Epoch 340/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 171.0495 - mean_squared_error: 171.0495\n",
      "Epoch 00340: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 462us/step - loss: 169.4484 - mean_squared_error: 169.4484 - val_loss: 201.0139 - val_mean_squared_error: 201.0139\n",
      "Epoch 341/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 169.4458 - mean_squared_error: 169.4458\n",
      "Epoch 00341: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 460us/step - loss: 168.0770 - mean_squared_error: 168.0770 - val_loss: 185.7269 - val_mean_squared_error: 185.7269\n",
      "Epoch 342/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 172.2783 - mean_squared_error: 172.2783\n",
      "Epoch 00342: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 459us/step - loss: 171.9737 - mean_squared_error: 171.9737 - val_loss: 203.8882 - val_mean_squared_error: 203.8882\n",
      "Epoch 343/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 169.2628 - mean_squared_error: 169.2628\n",
      "Epoch 00343: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 460us/step - loss: 171.2760 - mean_squared_error: 171.2760 - val_loss: 225.4763 - val_mean_squared_error: 225.4763\n",
      "Epoch 344/500\n",
      "479/526 [==========================>...] - ETA: 0s - loss: 167.9885 - mean_squared_error: 167.9885\n",
      "Epoch 00344: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 464us/step - loss: 168.4800 - mean_squared_error: 168.4800 - val_loss: 177.7570 - val_mean_squared_error: 177.7570\n",
      "Epoch 345/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 171.3944 - mean_squared_error: 171.3944\n",
      "Epoch 00345: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 457us/step - loss: 170.8111 - mean_squared_error: 170.8111 - val_loss: 188.7609 - val_mean_squared_error: 188.7609\n",
      "Epoch 346/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 170.4217 - mean_squared_error: 170.4217\n",
      "Epoch 00346: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 459us/step - loss: 169.7125 - mean_squared_error: 169.7125 - val_loss: 199.6357 - val_mean_squared_error: 199.6357\n",
      "Epoch 347/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 170.0729 - mean_squared_error: 170.0729\n",
      "Epoch 00347: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 459us/step - loss: 168.9708 - mean_squared_error: 168.9708 - val_loss: 215.5915 - val_mean_squared_error: 215.5915\n",
      "Epoch 348/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 165.3937 - mean_squared_error: 165.3937\n",
      "Epoch 00348: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 460us/step - loss: 165.4869 - mean_squared_error: 165.4869 - val_loss: 191.3628 - val_mean_squared_error: 191.3628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 167.1058 - mean_squared_error: 167.1058\n",
      "Epoch 00349: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 457us/step - loss: 166.8244 - mean_squared_error: 166.8244 - val_loss: 203.0825 - val_mean_squared_error: 203.0825\n",
      "Epoch 350/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 166.6651 - mean_squared_error: 166.6651\n",
      "Epoch 00350: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 457us/step - loss: 166.7542 - mean_squared_error: 166.7542 - val_loss: 178.8493 - val_mean_squared_error: 178.8493\n",
      "Epoch 351/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 166.2420 - mean_squared_error: 166.2420\n",
      "Epoch 00351: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 459us/step - loss: 168.5464 - mean_squared_error: 168.5464 - val_loss: 277.3770 - val_mean_squared_error: 277.3770\n",
      "Epoch 352/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 169.4461 - mean_squared_error: 169.4461\n",
      "Epoch 00352: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 464us/step - loss: 167.8152 - mean_squared_error: 167.8152 - val_loss: 182.6806 - val_mean_squared_error: 182.6806\n",
      "Epoch 353/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 167.6419 - mean_squared_error: 167.6419\n",
      "Epoch 00353: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 459us/step - loss: 168.5577 - mean_squared_error: 168.5577 - val_loss: 207.0735 - val_mean_squared_error: 207.0735\n",
      "Epoch 354/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 164.9849 - mean_squared_error: 164.9849\n",
      "Epoch 00354: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 460us/step - loss: 166.9744 - mean_squared_error: 166.9744 - val_loss: 196.3672 - val_mean_squared_error: 196.3672\n",
      "Epoch 355/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 164.7694 - mean_squared_error: 164.7694\n",
      "Epoch 00355: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 462us/step - loss: 164.4732 - mean_squared_error: 164.4732 - val_loss: 181.7214 - val_mean_squared_error: 181.7214\n",
      "Epoch 356/500\n",
      "491/526 [===========================>..] - ETA: 0s - loss: 167.6052 - mean_squared_error: 167.6052\n",
      "Epoch 00356: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 455us/step - loss: 166.9345 - mean_squared_error: 166.9345 - val_loss: 196.6957 - val_mean_squared_error: 196.6957\n",
      "Epoch 357/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 167.5419 - mean_squared_error: 167.5419\n",
      "Epoch 00357: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 459us/step - loss: 165.9304 - mean_squared_error: 165.9304 - val_loss: 215.7836 - val_mean_squared_error: 215.7836\n",
      "Epoch 358/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 166.3580 - mean_squared_error: 166.3580\n",
      "Epoch 00358: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 462us/step - loss: 165.6610 - mean_squared_error: 165.6610 - val_loss: 195.4927 - val_mean_squared_error: 195.4927\n",
      "Epoch 359/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 160.0860 - mean_squared_error: 160.0860\n",
      "Epoch 00359: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 460us/step - loss: 162.2837 - mean_squared_error: 162.2837 - val_loss: 195.0923 - val_mean_squared_error: 195.0923\n",
      "Epoch 360/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 168.0338 - mean_squared_error: 168.0338\n",
      "Epoch 00360: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 459us/step - loss: 166.7219 - mean_squared_error: 166.7219 - val_loss: 201.2629 - val_mean_squared_error: 201.2629\n",
      "Epoch 361/500\n",
      "478/526 [==========================>...] - ETA: 0s - loss: 164.8960 - mean_squared_error: 164.8960\n",
      "Epoch 00361: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 466us/step - loss: 162.7741 - mean_squared_error: 162.7741 - val_loss: 194.4432 - val_mean_squared_error: 194.4432\n",
      "Epoch 362/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 167.1331 - mean_squared_error: 167.1331\n",
      "Epoch 00362: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 459us/step - loss: 165.5770 - mean_squared_error: 165.5770 - val_loss: 182.6718 - val_mean_squared_error: 182.6718\n",
      "Epoch 363/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 159.7629 - mean_squared_error: 159.7629\n",
      "Epoch 00363: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 459us/step - loss: 161.2416 - mean_squared_error: 161.2416 - val_loss: 177.5641 - val_mean_squared_error: 177.5641\n",
      "Epoch 364/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 169.9073 - mean_squared_error: 169.9073\n",
      "Epoch 00364: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 457us/step - loss: 167.7187 - mean_squared_error: 167.7187 - val_loss: 183.7031 - val_mean_squared_error: 183.7031\n",
      "Epoch 365/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 162.7775 - mean_squared_error: 162.7775\n",
      "Epoch 00365: val_loss did not improve from 176.86032\n",
      "526/526 [==============================] - 0s 464us/step - loss: 162.8581 - mean_squared_error: 162.8581 - val_loss: 179.3168 - val_mean_squared_error: 179.3168\n",
      "Epoch 366/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 162.5384 - mean_squared_error: 162.5384\n",
      "Epoch 00366: val_loss improved from 176.86032 to 173.84520, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 616us/step - loss: 162.7457 - mean_squared_error: 162.7457 - val_loss: 173.8452 - val_mean_squared_error: 173.8452\n",
      "Epoch 367/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 164.2983 - mean_squared_error: 164.2983\n",
      "Epoch 00367: val_loss did not improve from 173.84520\n",
      "526/526 [==============================] - 0s 460us/step - loss: 164.4220 - mean_squared_error: 164.4220 - val_loss: 177.7998 - val_mean_squared_error: 177.7998\n",
      "Epoch 368/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 171.4165 - mean_squared_error: 171.4165\n",
      "Epoch 00368: val_loss did not improve from 173.84520\n",
      "526/526 [==============================] - 0s 462us/step - loss: 170.3710 - mean_squared_error: 170.3710 - val_loss: 197.3485 - val_mean_squared_error: 197.3485\n",
      "Epoch 369/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 158.2544 - mean_squared_error: 158.2544\n",
      "Epoch 00369: val_loss improved from 173.84520 to 167.86270, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 605us/step - loss: 158.2930 - mean_squared_error: 158.2930 - val_loss: 167.8627 - val_mean_squared_error: 167.8627\n",
      "Epoch 370/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 166.4969 - mean_squared_error: 166.4969\n",
      "Epoch 00370: val_loss did not improve from 167.86270\n",
      "526/526 [==============================] - 0s 462us/step - loss: 166.6068 - mean_squared_error: 166.6068 - val_loss: 192.3844 - val_mean_squared_error: 192.3844\n",
      "Epoch 371/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 159.4790 - mean_squared_error: 159.4790\n",
      "Epoch 00371: val_loss did not improve from 167.86270\n",
      "526/526 [==============================] - 0s 459us/step - loss: 160.5805 - mean_squared_error: 160.5805 - val_loss: 210.1019 - val_mean_squared_error: 210.1019\n",
      "Epoch 372/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 161.4104 - mean_squared_error: 161.4104\n",
      "Epoch 00372: val_loss did not improve from 167.86270\n",
      "526/526 [==============================] - 0s 457us/step - loss: 160.9890 - mean_squared_error: 160.9890 - val_loss: 179.8818 - val_mean_squared_error: 179.8818\n",
      "Epoch 373/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 163.4405 - mean_squared_error: 163.4405\n",
      "Epoch 00373: val_loss did not improve from 167.86270\n",
      "526/526 [==============================] - 0s 460us/step - loss: 162.1406 - mean_squared_error: 162.1406 - val_loss: 181.6110 - val_mean_squared_error: 181.6110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 374/500\n",
      "494/526 [===========================>..] - ETA: 0s - loss: 161.4644 - mean_squared_error: 161.4644\n",
      "Epoch 00374: val_loss did not improve from 167.86270\n",
      "526/526 [==============================] - 0s 453us/step - loss: 161.0136 - mean_squared_error: 161.0136 - val_loss: 185.0372 - val_mean_squared_error: 185.0372\n",
      "Epoch 375/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 158.2557 - mean_squared_error: 158.2557\n",
      "Epoch 00375: val_loss did not improve from 167.86270\n",
      "526/526 [==============================] - 0s 459us/step - loss: 158.8333 - mean_squared_error: 158.8333 - val_loss: 193.2602 - val_mean_squared_error: 193.2602\n",
      "Epoch 376/500\n",
      "492/526 [===========================>..] - ETA: 0s - loss: 163.7076 - mean_squared_error: 163.7076\n",
      "Epoch 00376: val_loss did not improve from 167.86270\n",
      "526/526 [==============================] - 0s 453us/step - loss: 162.2969 - mean_squared_error: 162.2969 - val_loss: 200.4580 - val_mean_squared_error: 200.4580\n",
      "Epoch 377/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 165.3592 - mean_squared_error: 165.3592\n",
      "Epoch 00377: val_loss did not improve from 167.86270\n",
      "526/526 [==============================] - 0s 460us/step - loss: 165.0102 - mean_squared_error: 165.0102 - val_loss: 189.6969 - val_mean_squared_error: 189.6969\n",
      "Epoch 378/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 159.4255 - mean_squared_error: 159.4255\n",
      "Epoch 00378: val_loss did not improve from 167.86270\n",
      "526/526 [==============================] - 0s 457us/step - loss: 159.6607 - mean_squared_error: 159.6607 - val_loss: 175.1880 - val_mean_squared_error: 175.1880\n",
      "Epoch 379/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 159.7501 - mean_squared_error: 159.7501\n",
      "Epoch 00379: val_loss did not improve from 167.86270\n",
      "526/526 [==============================] - 0s 459us/step - loss: 160.7693 - mean_squared_error: 160.7693 - val_loss: 199.5020 - val_mean_squared_error: 199.5020\n",
      "Epoch 380/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 160.9143 - mean_squared_error: 160.9143\n",
      "Epoch 00380: val_loss did not improve from 167.86270\n",
      "526/526 [==============================] - 0s 459us/step - loss: 161.0181 - mean_squared_error: 161.0181 - val_loss: 192.6628 - val_mean_squared_error: 192.6628\n",
      "Epoch 381/500\n",
      "491/526 [===========================>..] - ETA: 0s - loss: 164.0491 - mean_squared_error: 164.0491\n",
      "Epoch 00381: val_loss did not improve from 167.86270\n",
      "526/526 [==============================] - 0s 455us/step - loss: 164.4781 - mean_squared_error: 164.4781 - val_loss: 179.9193 - val_mean_squared_error: 179.9193\n",
      "Epoch 382/500\n",
      "473/526 [=========================>....] - ETA: 0s - loss: 156.6328 - mean_squared_error: 156.6328\n",
      "Epoch 00382: val_loss did not improve from 167.86270\n",
      "526/526 [==============================] - 0s 470us/step - loss: 158.0269 - mean_squared_error: 158.0269 - val_loss: 208.0806 - val_mean_squared_error: 208.0806\n",
      "Epoch 383/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 163.2042 - mean_squared_error: 163.2042\n",
      "Epoch 00383: val_loss did not improve from 167.86270\n",
      "526/526 [==============================] - 0s 459us/step - loss: 163.5153 - mean_squared_error: 163.5153 - val_loss: 198.1474 - val_mean_squared_error: 198.1474\n",
      "Epoch 384/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 161.6458 - mean_squared_error: 161.6458\n",
      "Epoch 00384: val_loss did not improve from 167.86270\n",
      "526/526 [==============================] - 0s 457us/step - loss: 162.3745 - mean_squared_error: 162.3745 - val_loss: 200.5373 - val_mean_squared_error: 200.5373\n",
      "Epoch 385/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 167.0146 - mean_squared_error: 167.0146\n",
      "Epoch 00385: val_loss did not improve from 167.86270\n",
      "526/526 [==============================] - 0s 457us/step - loss: 164.9152 - mean_squared_error: 164.9152 - val_loss: 169.8704 - val_mean_squared_error: 169.8704\n",
      "Epoch 386/500\n",
      "475/526 [==========================>...] - ETA: 0s - loss: 156.5172 - mean_squared_error: 156.5172\n",
      "Epoch 00386: val_loss did not improve from 167.86270\n",
      "526/526 [==============================] - 0s 472us/step - loss: 157.6936 - mean_squared_error: 157.6936 - val_loss: 172.4650 - val_mean_squared_error: 172.4650\n",
      "Epoch 387/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 161.5302 - mean_squared_error: 161.5302\n",
      "Epoch 00387: val_loss did not improve from 167.86270\n",
      "526/526 [==============================] - 0s 460us/step - loss: 160.9995 - mean_squared_error: 160.9995 - val_loss: 177.4005 - val_mean_squared_error: 177.4005\n",
      "Epoch 388/500\n",
      "492/526 [===========================>..] - ETA: 0s - loss: 159.2983 - mean_squared_error: 159.2983\n",
      "Epoch 00388: val_loss improved from 167.86270 to 167.54387, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 646us/step - loss: 159.5755 - mean_squared_error: 159.5755 - val_loss: 167.5439 - val_mean_squared_error: 167.5439\n",
      "Epoch 389/500\n",
      "491/526 [===========================>..] - ETA: 0s - loss: 156.8777 - mean_squared_error: 156.8777\n",
      "Epoch 00389: val_loss did not improve from 167.54387\n",
      "526/526 [==============================] - 0s 455us/step - loss: 157.1223 - mean_squared_error: 157.1223 - val_loss: 188.6100 - val_mean_squared_error: 188.6100\n",
      "Epoch 390/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 159.1627 - mean_squared_error: 159.1627\n",
      "Epoch 00390: val_loss did not improve from 167.54387\n",
      "526/526 [==============================] - 0s 459us/step - loss: 159.1371 - mean_squared_error: 159.1371 - val_loss: 171.5013 - val_mean_squared_error: 171.5013\n",
      "Epoch 391/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 162.5575 - mean_squared_error: 162.5575\n",
      "Epoch 00391: val_loss did not improve from 167.54387\n",
      "526/526 [==============================] - 0s 459us/step - loss: 162.2384 - mean_squared_error: 162.2384 - val_loss: 183.5081 - val_mean_squared_error: 183.5081\n",
      "Epoch 392/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 156.7701 - mean_squared_error: 156.7701\n",
      "Epoch 00392: val_loss did not improve from 167.54387\n",
      "526/526 [==============================] - 0s 460us/step - loss: 156.9420 - mean_squared_error: 156.9420 - val_loss: 181.5286 - val_mean_squared_error: 181.5286\n",
      "Epoch 393/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 156.8346 - mean_squared_error: 156.8346\n",
      "Epoch 00393: val_loss did not improve from 167.54387\n",
      "526/526 [==============================] - 0s 455us/step - loss: 158.7321 - mean_squared_error: 158.7321 - val_loss: 191.6927 - val_mean_squared_error: 191.6927\n",
      "Epoch 394/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 159.9865 - mean_squared_error: 159.9865\n",
      "Epoch 00394: val_loss did not improve from 167.54387\n",
      "526/526 [==============================] - 0s 457us/step - loss: 159.0995 - mean_squared_error: 159.0995 - val_loss: 195.1314 - val_mean_squared_error: 195.1314\n",
      "Epoch 395/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 154.4630 - mean_squared_error: 154.4630\n",
      "Epoch 00395: val_loss did not improve from 167.54387\n",
      "526/526 [==============================] - 0s 457us/step - loss: 156.5988 - mean_squared_error: 156.5988 - val_loss: 187.1311 - val_mean_squared_error: 187.1311\n",
      "Epoch 396/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 156.7320 - mean_squared_error: 156.7320\n",
      "Epoch 00396: val_loss improved from 167.54387 to 167.18558, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 611us/step - loss: 158.3239 - mean_squared_error: 158.3239 - val_loss: 167.1856 - val_mean_squared_error: 167.1856\n",
      "Epoch 397/500\n",
      "491/526 [===========================>..] - ETA: 0s - loss: 159.0345 - mean_squared_error: 159.0345\n",
      "Epoch 00397: val_loss did not improve from 167.18558\n",
      "526/526 [==============================] - 0s 453us/step - loss: 157.5563 - mean_squared_error: 157.5563 - val_loss: 170.9011 - val_mean_squared_error: 170.9011\n",
      "Epoch 398/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 152.7142 - mean_squared_error: 152.7142\n",
      "Epoch 00398: val_loss did not improve from 167.18558\n",
      "526/526 [==============================] - 0s 457us/step - loss: 154.5272 - mean_squared_error: 154.5272 - val_loss: 185.2099 - val_mean_squared_error: 185.2099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 154.8632 - mean_squared_error: 154.8632\n",
      "Epoch 00399: val_loss did not improve from 167.18558\n",
      "526/526 [==============================] - 0s 457us/step - loss: 155.0676 - mean_squared_error: 155.0676 - val_loss: 181.9279 - val_mean_squared_error: 181.9279\n",
      "Epoch 400/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 160.4801 - mean_squared_error: 160.4801\n",
      "Epoch 00400: val_loss did not improve from 167.18558\n",
      "526/526 [==============================] - 0s 459us/step - loss: 160.1287 - mean_squared_error: 160.1287 - val_loss: 173.1421 - val_mean_squared_error: 173.1421\n",
      "Epoch 401/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 154.2961 - mean_squared_error: 154.2961\n",
      "Epoch 00401: val_loss did not improve from 167.18558\n",
      "526/526 [==============================] - 0s 460us/step - loss: 156.4953 - mean_squared_error: 156.4953 - val_loss: 227.7485 - val_mean_squared_error: 227.7485\n",
      "Epoch 402/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 155.3993 - mean_squared_error: 155.3993\n",
      "Epoch 00402: val_loss did not improve from 167.18558\n",
      "526/526 [==============================] - 0s 460us/step - loss: 155.3101 - mean_squared_error: 155.3101 - val_loss: 180.8728 - val_mean_squared_error: 180.8728\n",
      "Epoch 403/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 154.2645 - mean_squared_error: 154.2645\n",
      "Epoch 00403: val_loss did not improve from 167.18558\n",
      "526/526 [==============================] - 0s 459us/step - loss: 154.9028 - mean_squared_error: 154.9028 - val_loss: 183.7839 - val_mean_squared_error: 183.7839\n",
      "Epoch 404/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 158.0201 - mean_squared_error: 158.0201\n",
      "Epoch 00404: val_loss did not improve from 167.18558\n",
      "526/526 [==============================] - 0s 455us/step - loss: 157.7832 - mean_squared_error: 157.7832 - val_loss: 173.7819 - val_mean_squared_error: 173.7819\n",
      "Epoch 405/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 162.4782 - mean_squared_error: 162.4782\n",
      "Epoch 00405: val_loss did not improve from 167.18558\n",
      "526/526 [==============================] - 0s 453us/step - loss: 160.5996 - mean_squared_error: 160.5996 - val_loss: 174.4507 - val_mean_squared_error: 174.4507\n",
      "Epoch 406/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 159.0596 - mean_squared_error: 159.0596\n",
      "Epoch 00406: val_loss did not improve from 167.18558\n",
      "526/526 [==============================] - 0s 455us/step - loss: 157.7781 - mean_squared_error: 157.7781 - val_loss: 215.6642 - val_mean_squared_error: 215.6642\n",
      "Epoch 407/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 158.3994 - mean_squared_error: 158.3994\n",
      "Epoch 00407: val_loss did not improve from 167.18558\n",
      "526/526 [==============================] - 0s 459us/step - loss: 160.6537 - mean_squared_error: 160.6537 - val_loss: 202.1988 - val_mean_squared_error: 202.1988\n",
      "Epoch 408/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 155.3062 - mean_squared_error: 155.3062\n",
      "Epoch 00408: val_loss did not improve from 167.18558\n",
      "526/526 [==============================] - 0s 455us/step - loss: 154.2271 - mean_squared_error: 154.2271 - val_loss: 180.2613 - val_mean_squared_error: 180.2613\n",
      "Epoch 409/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 151.8774 - mean_squared_error: 151.8774\n",
      "Epoch 00409: val_loss did not improve from 167.18558\n",
      "526/526 [==============================] - 0s 459us/step - loss: 151.8954 - mean_squared_error: 151.8954 - val_loss: 179.1933 - val_mean_squared_error: 179.1933\n",
      "Epoch 410/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 155.6283 - mean_squared_error: 155.6283\n",
      "Epoch 00410: val_loss did not improve from 167.18558\n",
      "526/526 [==============================] - 0s 457us/step - loss: 156.7247 - mean_squared_error: 156.7247 - val_loss: 195.6893 - val_mean_squared_error: 195.6893\n",
      "Epoch 411/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 155.2964 - mean_squared_error: 155.2964\n",
      "Epoch 00411: val_loss did not improve from 167.18558\n",
      "526/526 [==============================] - 0s 462us/step - loss: 155.7165 - mean_squared_error: 155.7165 - val_loss: 186.2145 - val_mean_squared_error: 186.2145\n",
      "Epoch 412/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 155.2047 - mean_squared_error: 155.2047\n",
      "Epoch 00412: val_loss did not improve from 167.18558\n",
      "526/526 [==============================] - 0s 459us/step - loss: 158.9122 - mean_squared_error: 158.9122 - val_loss: 206.5372 - val_mean_squared_error: 206.5372\n",
      "Epoch 413/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 154.5325 - mean_squared_error: 154.5325\n",
      "Epoch 00413: val_loss did not improve from 167.18558\n",
      "526/526 [==============================] - 0s 460us/step - loss: 156.0144 - mean_squared_error: 156.0144 - val_loss: 173.8091 - val_mean_squared_error: 173.8091\n",
      "Epoch 414/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 157.7650 - mean_squared_error: 157.7650\n",
      "Epoch 00414: val_loss improved from 167.18558 to 164.20284, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 613us/step - loss: 156.1544 - mean_squared_error: 156.1544 - val_loss: 164.2028 - val_mean_squared_error: 164.2028\n",
      "Epoch 415/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 148.0965 - mean_squared_error: 148.0965\n",
      "Epoch 00415: val_loss did not improve from 164.20284\n",
      "526/526 [==============================] - 0s 460us/step - loss: 149.3733 - mean_squared_error: 149.3733 - val_loss: 176.6003 - val_mean_squared_error: 176.6003\n",
      "Epoch 416/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 147.6349 - mean_squared_error: 147.6349\n",
      "Epoch 00416: val_loss improved from 164.20284 to 163.44670, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 668us/step - loss: 147.2236 - mean_squared_error: 147.2236 - val_loss: 163.4467 - val_mean_squared_error: 163.4467\n",
      "Epoch 417/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 151.6427 - mean_squared_error: 151.6427\n",
      "Epoch 00417: val_loss did not improve from 163.44670\n",
      "526/526 [==============================] - 0s 459us/step - loss: 153.4402 - mean_squared_error: 153.4402 - val_loss: 172.5495 - val_mean_squared_error: 172.5495\n",
      "Epoch 418/500\n",
      "478/526 [==========================>...] - ETA: 0s - loss: 151.7794 - mean_squared_error: 151.7794\n",
      "Epoch 00418: val_loss did not improve from 163.44670\n",
      "526/526 [==============================] - 0s 464us/step - loss: 151.0855 - mean_squared_error: 151.0855 - val_loss: 185.5947 - val_mean_squared_error: 185.5947\n",
      "Epoch 419/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 155.0026 - mean_squared_error: 155.0026\n",
      "Epoch 00419: val_loss did not improve from 163.44670\n",
      "526/526 [==============================] - 0s 462us/step - loss: 154.1830 - mean_squared_error: 154.1830 - val_loss: 182.1987 - val_mean_squared_error: 182.1987\n",
      "Epoch 420/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 151.1047 - mean_squared_error: 151.1047\n",
      "Epoch 00420: val_loss did not improve from 163.44670\n",
      "526/526 [==============================] - 0s 460us/step - loss: 152.3306 - mean_squared_error: 152.3306 - val_loss: 176.6198 - val_mean_squared_error: 176.6198\n",
      "Epoch 421/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 150.2573 - mean_squared_error: 150.2573\n",
      "Epoch 00421: val_loss did not improve from 163.44670\n",
      "526/526 [==============================] - 0s 462us/step - loss: 151.7526 - mean_squared_error: 151.7526 - val_loss: 168.4924 - val_mean_squared_error: 168.4924\n",
      "Epoch 422/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 154.1230 - mean_squared_error: 154.1230\n",
      "Epoch 00422: val_loss did not improve from 163.44670\n",
      "526/526 [==============================] - 0s 460us/step - loss: 154.1594 - mean_squared_error: 154.1594 - val_loss: 175.3377 - val_mean_squared_error: 175.3377\n",
      "Epoch 423/500\n",
      "480/526 [==========================>...] - ETA: 0s - loss: 153.0068 - mean_squared_error: 153.0068\n",
      "Epoch 00423: val_loss did not improve from 163.44670\n",
      "526/526 [==============================] - 0s 464us/step - loss: 152.5688 - mean_squared_error: 152.5688 - val_loss: 203.0146 - val_mean_squared_error: 203.0146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 424/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 152.5333 - mean_squared_error: 152.5333\n",
      "Epoch 00424: val_loss did not improve from 163.44670\n",
      "526/526 [==============================] - 0s 460us/step - loss: 152.4133 - mean_squared_error: 152.4133 - val_loss: 173.1885 - val_mean_squared_error: 173.1885\n",
      "Epoch 425/500\n",
      "495/526 [===========================>..] - ETA: 0s - loss: 152.0885 - mean_squared_error: 152.0885\n",
      "Epoch 00425: val_loss did not improve from 163.44670\n",
      "526/526 [==============================] - 0s 451us/step - loss: 154.6428 - mean_squared_error: 154.6428 - val_loss: 176.9368 - val_mean_squared_error: 176.9368\n",
      "Epoch 426/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 149.5692 - mean_squared_error: 149.5692\n",
      "Epoch 00426: val_loss did not improve from 163.44670\n",
      "526/526 [==============================] - 0s 459us/step - loss: 151.1133 - mean_squared_error: 151.1133 - val_loss: 175.4492 - val_mean_squared_error: 175.4492\n",
      "Epoch 427/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 152.2196 - mean_squared_error: 152.2196\n",
      "Epoch 00427: val_loss did not improve from 163.44670\n",
      "526/526 [==============================] - 0s 460us/step - loss: 151.7440 - mean_squared_error: 151.7440 - val_loss: 163.5211 - val_mean_squared_error: 163.5211\n",
      "Epoch 428/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 153.4402 - mean_squared_error: 153.4402\n",
      "Epoch 00428: val_loss did not improve from 163.44670\n",
      "526/526 [==============================] - 0s 457us/step - loss: 154.6956 - mean_squared_error: 154.6956 - val_loss: 170.3290 - val_mean_squared_error: 170.3290\n",
      "Epoch 429/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 151.7725 - mean_squared_error: 151.7725\n",
      "Epoch 00429: val_loss did not improve from 163.44670\n",
      "526/526 [==============================] - 0s 457us/step - loss: 151.7997 - mean_squared_error: 151.7997 - val_loss: 195.5778 - val_mean_squared_error: 195.5778\n",
      "Epoch 430/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 147.5609 - mean_squared_error: 147.5609\n",
      "Epoch 00430: val_loss improved from 163.44670 to 160.30418, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 603us/step - loss: 147.2650 - mean_squared_error: 147.2650 - val_loss: 160.3042 - val_mean_squared_error: 160.3042\n",
      "Epoch 431/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 148.0471 - mean_squared_error: 148.0471\n",
      "Epoch 00431: val_loss did not improve from 160.30418\n",
      "526/526 [==============================] - 0s 460us/step - loss: 149.3086 - mean_squared_error: 149.3086 - val_loss: 163.5586 - val_mean_squared_error: 163.5586\n",
      "Epoch 432/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 147.1227 - mean_squared_error: 147.1227\n",
      "Epoch 00432: val_loss did not improve from 160.30418\n",
      "526/526 [==============================] - 0s 457us/step - loss: 147.6602 - mean_squared_error: 147.6602 - val_loss: 173.7347 - val_mean_squared_error: 173.7347\n",
      "Epoch 433/500\n",
      "492/526 [===========================>..] - ETA: 0s - loss: 150.9251 - mean_squared_error: 150.9251\n",
      "Epoch 00433: val_loss did not improve from 160.30418\n",
      "526/526 [==============================] - 0s 455us/step - loss: 151.4001 - mean_squared_error: 151.4001 - val_loss: 196.3415 - val_mean_squared_error: 196.3415\n",
      "Epoch 434/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 155.0351 - mean_squared_error: 155.0351\n",
      "Epoch 00434: val_loss did not improve from 160.30418\n",
      "526/526 [==============================] - 0s 460us/step - loss: 155.2776 - mean_squared_error: 155.2776 - val_loss: 175.4653 - val_mean_squared_error: 175.4653\n",
      "Epoch 435/500\n",
      "479/526 [==========================>...] - ETA: 0s - loss: 149.8049 - mean_squared_error: 149.8049\n",
      "Epoch 00435: val_loss did not improve from 160.30418\n",
      "526/526 [==============================] - 0s 466us/step - loss: 150.6758 - mean_squared_error: 150.6758 - val_loss: 173.0188 - val_mean_squared_error: 173.0188\n",
      "Epoch 436/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 147.5975 - mean_squared_error: 147.5975\n",
      "Epoch 00436: val_loss did not improve from 160.30418\n",
      "526/526 [==============================] - 0s 460us/step - loss: 148.9893 - mean_squared_error: 148.9893 - val_loss: 177.3135 - val_mean_squared_error: 177.3135\n",
      "Epoch 437/500\n",
      "494/526 [===========================>..] - ETA: 0s - loss: 148.1012 - mean_squared_error: 148.1012\n",
      "Epoch 00437: val_loss did not improve from 160.30418\n",
      "526/526 [==============================] - 0s 455us/step - loss: 148.2915 - mean_squared_error: 148.2915 - val_loss: 212.0242 - val_mean_squared_error: 212.0242\n",
      "Epoch 438/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 150.1429 - mean_squared_error: 150.1429\n",
      "Epoch 00438: val_loss did not improve from 160.30418\n",
      "526/526 [==============================] - 0s 466us/step - loss: 150.5089 - mean_squared_error: 150.5089 - val_loss: 160.4216 - val_mean_squared_error: 160.4216\n",
      "Epoch 439/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 150.0674 - mean_squared_error: 150.0674\n",
      "Epoch 00439: val_loss did not improve from 160.30418\n",
      "526/526 [==============================] - 0s 459us/step - loss: 150.3414 - mean_squared_error: 150.3414 - val_loss: 169.5222 - val_mean_squared_error: 169.5222\n",
      "Epoch 440/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 155.8896 - mean_squared_error: 155.8896\n",
      "Epoch 00440: val_loss did not improve from 160.30418\n",
      "526/526 [==============================] - 0s 459us/step - loss: 155.6437 - mean_squared_error: 155.6437 - val_loss: 181.2943 - val_mean_squared_error: 181.2943\n",
      "Epoch 441/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 151.9500 - mean_squared_error: 151.9500\n",
      "Epoch 00441: val_loss did not improve from 160.30418\n",
      "526/526 [==============================] - 0s 460us/step - loss: 151.3079 - mean_squared_error: 151.3079 - val_loss: 177.5938 - val_mean_squared_error: 177.5938\n",
      "Epoch 442/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 145.8736 - mean_squared_error: 145.8736\n",
      "Epoch 00442: val_loss did not improve from 160.30418\n",
      "526/526 [==============================] - 0s 457us/step - loss: 145.8726 - mean_squared_error: 145.8726 - val_loss: 164.2063 - val_mean_squared_error: 164.2063\n",
      "Epoch 443/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 148.0210 - mean_squared_error: 148.0210\n",
      "Epoch 00443: val_loss did not improve from 160.30418\n",
      "526/526 [==============================] - 0s 459us/step - loss: 147.7559 - mean_squared_error: 147.7559 - val_loss: 166.2640 - val_mean_squared_error: 166.2640\n",
      "Epoch 444/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 150.4891 - mean_squared_error: 150.4891\n",
      "Epoch 00444: val_loss did not improve from 160.30418\n",
      "526/526 [==============================] - 0s 462us/step - loss: 151.2650 - mean_squared_error: 151.2650 - val_loss: 160.5312 - val_mean_squared_error: 160.5312\n",
      "Epoch 445/500\n",
      "493/526 [===========================>..] - ETA: 0s - loss: 150.7208 - mean_squared_error: 150.7208\n",
      "Epoch 00445: val_loss improved from 160.30418 to 159.75859, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 602us/step - loss: 151.0850 - mean_squared_error: 151.0850 - val_loss: 159.7586 - val_mean_squared_error: 159.7586\n",
      "Epoch 446/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 145.1751 - mean_squared_error: 145.1751\n",
      "Epoch 00446: val_loss did not improve from 159.75859\n",
      "526/526 [==============================] - 0s 460us/step - loss: 146.7583 - mean_squared_error: 146.7583 - val_loss: 166.7498 - val_mean_squared_error: 166.7498\n",
      "Epoch 447/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 151.0194 - mean_squared_error: 151.0194\n",
      "Epoch 00447: val_loss did not improve from 159.75859\n",
      "526/526 [==============================] - 0s 460us/step - loss: 149.5539 - mean_squared_error: 149.5539 - val_loss: 166.2289 - val_mean_squared_error: 166.2289\n",
      "Epoch 448/500\n",
      "477/526 [==========================>...] - ETA: 0s - loss: 150.2715 - mean_squared_error: 150.2715\n",
      "Epoch 00448: val_loss did not improve from 159.75859\n",
      "526/526 [==============================] - 0s 466us/step - loss: 148.2720 - mean_squared_error: 148.2720 - val_loss: 167.6759 - val_mean_squared_error: 167.6759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 150.5638 - mean_squared_error: 150.5638\n",
      "Epoch 00449: val_loss did not improve from 159.75859\n",
      "526/526 [==============================] - 0s 459us/step - loss: 150.6989 - mean_squared_error: 150.6989 - val_loss: 178.5679 - val_mean_squared_error: 178.5679\n",
      "Epoch 450/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 149.5574 - mean_squared_error: 149.5574\n",
      "Epoch 00450: val_loss did not improve from 159.75859\n",
      "526/526 [==============================] - 0s 459us/step - loss: 150.4148 - mean_squared_error: 150.4148 - val_loss: 178.6994 - val_mean_squared_error: 178.6994\n",
      "Epoch 451/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 148.0537 - mean_squared_error: 148.0537\n",
      "Epoch 00451: val_loss did not improve from 159.75859\n",
      "526/526 [==============================] - 0s 457us/step - loss: 147.5234 - mean_squared_error: 147.5234 - val_loss: 168.7859 - val_mean_squared_error: 168.7859\n",
      "Epoch 452/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 147.8495 - mean_squared_error: 147.8495\n",
      "Epoch 00452: val_loss did not improve from 159.75859\n",
      "526/526 [==============================] - 0s 459us/step - loss: 147.7230 - mean_squared_error: 147.7230 - val_loss: 169.0665 - val_mean_squared_error: 169.0665\n",
      "Epoch 453/500\n",
      "491/526 [===========================>..] - ETA: 0s - loss: 145.8903 - mean_squared_error: 145.8903\n",
      "Epoch 00453: val_loss did not improve from 159.75859\n",
      "526/526 [==============================] - 0s 455us/step - loss: 146.3534 - mean_squared_error: 146.3534 - val_loss: 168.0464 - val_mean_squared_error: 168.0464\n",
      "Epoch 454/500\n",
      "491/526 [===========================>..] - ETA: 0s - loss: 145.6517 - mean_squared_error: 145.6517\n",
      "Epoch 00454: val_loss did not improve from 159.75859\n",
      "526/526 [==============================] - 0s 455us/step - loss: 146.8157 - mean_squared_error: 146.8157 - val_loss: 168.9976 - val_mean_squared_error: 168.9976\n",
      "Epoch 455/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 146.8185 - mean_squared_error: 146.8185\n",
      "Epoch 00455: val_loss did not improve from 159.75859\n",
      "526/526 [==============================] - 0s 460us/step - loss: 151.4232 - mean_squared_error: 151.4232 - val_loss: 167.0641 - val_mean_squared_error: 167.0641\n",
      "Epoch 456/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 142.7019 - mean_squared_error: 142.7019\n",
      "Epoch 00456: val_loss did not improve from 159.75859\n",
      "526/526 [==============================] - 0s 460us/step - loss: 142.7524 - mean_squared_error: 142.7524 - val_loss: 161.6657 - val_mean_squared_error: 161.6657\n",
      "Epoch 457/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 144.9060 - mean_squared_error: 144.9060\n",
      "Epoch 00457: val_loss did not improve from 159.75859\n",
      "526/526 [==============================] - 0s 459us/step - loss: 144.6907 - mean_squared_error: 144.6907 - val_loss: 167.4024 - val_mean_squared_error: 167.4024\n",
      "Epoch 458/500\n",
      "492/526 [===========================>..] - ETA: 0s - loss: 147.9093 - mean_squared_error: 147.9093\n",
      "Epoch 00458: val_loss did not improve from 159.75859\n",
      "526/526 [==============================] - 0s 455us/step - loss: 147.4668 - mean_squared_error: 147.4668 - val_loss: 204.6573 - val_mean_squared_error: 204.6573\n",
      "Epoch 459/500\n",
      "480/526 [==========================>...] - ETA: 0s - loss: 151.1692 - mean_squared_error: 151.1692\n",
      "Epoch 00459: val_loss did not improve from 159.75859\n",
      "526/526 [==============================] - 0s 464us/step - loss: 150.8399 - mean_squared_error: 150.8399 - val_loss: 223.4684 - val_mean_squared_error: 223.4684\n",
      "Epoch 460/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 150.5513 - mean_squared_error: 150.5513\n",
      "Epoch 00460: val_loss did not improve from 159.75859\n",
      "526/526 [==============================] - 0s 464us/step - loss: 148.5037 - mean_squared_error: 148.5037 - val_loss: 169.0012 - val_mean_squared_error: 169.0012\n",
      "Epoch 461/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 144.2800 - mean_squared_error: 144.2800\n",
      "Epoch 00461: val_loss did not improve from 159.75859\n",
      "526/526 [==============================] - 0s 462us/step - loss: 145.5796 - mean_squared_error: 145.5796 - val_loss: 198.9314 - val_mean_squared_error: 198.9314\n",
      "Epoch 462/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 143.9442 - mean_squared_error: 143.9442\n",
      "Epoch 00462: val_loss did not improve from 159.75859\n",
      "526/526 [==============================] - 0s 460us/step - loss: 144.6249 - mean_squared_error: 144.6249 - val_loss: 171.4428 - val_mean_squared_error: 171.4428\n",
      "Epoch 463/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 145.7012 - mean_squared_error: 145.7012\n",
      "Epoch 00463: val_loss improved from 159.75859 to 157.68224, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 605us/step - loss: 145.1059 - mean_squared_error: 145.1059 - val_loss: 157.6822 - val_mean_squared_error: 157.6822\n",
      "Epoch 464/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 143.8572 - mean_squared_error: 143.8572\n",
      "Epoch 00464: val_loss did not improve from 157.68224\n",
      "526/526 [==============================] - 0s 457us/step - loss: 143.5314 - mean_squared_error: 143.5314 - val_loss: 167.3542 - val_mean_squared_error: 167.3542\n",
      "Epoch 465/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 143.4254 - mean_squared_error: 143.4254\n",
      "Epoch 00465: val_loss did not improve from 157.68224\n",
      "526/526 [==============================] - 0s 466us/step - loss: 144.7366 - mean_squared_error: 144.7366 - val_loss: 166.4128 - val_mean_squared_error: 166.4128\n",
      "Epoch 466/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 142.7259 - mean_squared_error: 142.7259\n",
      "Epoch 00466: val_loss did not improve from 157.68224\n",
      "526/526 [==============================] - 0s 460us/step - loss: 143.3686 - mean_squared_error: 143.3686 - val_loss: 228.9419 - val_mean_squared_error: 228.9419\n",
      "Epoch 467/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 146.3631 - mean_squared_error: 146.3631\n",
      "Epoch 00467: val_loss did not improve from 157.68224\n",
      "526/526 [==============================] - 0s 464us/step - loss: 146.6049 - mean_squared_error: 146.6049 - val_loss: 158.0648 - val_mean_squared_error: 158.0648\n",
      "Epoch 468/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 145.9391 - mean_squared_error: 145.9391\n",
      "Epoch 00468: val_loss did not improve from 157.68224\n",
      "526/526 [==============================] - 0s 460us/step - loss: 144.8165 - mean_squared_error: 144.8165 - val_loss: 162.7436 - val_mean_squared_error: 162.7436\n",
      "Epoch 469/500\n",
      "485/526 [==========================>...] - ETA: 0s - loss: 146.7619 - mean_squared_error: 146.7619\n",
      "Epoch 00469: val_loss did not improve from 157.68224\n",
      "526/526 [==============================] - 0s 459us/step - loss: 145.7296 - mean_squared_error: 145.7296 - val_loss: 186.8543 - val_mean_squared_error: 186.8543\n",
      "Epoch 470/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 145.4591 - mean_squared_error: 145.4591\n",
      "Epoch 00470: val_loss did not improve from 157.68224\n",
      "526/526 [==============================] - 0s 457us/step - loss: 145.2380 - mean_squared_error: 145.2380 - val_loss: 162.3504 - val_mean_squared_error: 162.3504\n",
      "Epoch 471/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 146.2750 - mean_squared_error: 146.2750\n",
      "Epoch 00471: val_loss did not improve from 157.68224\n",
      "526/526 [==============================] - 0s 457us/step - loss: 146.3403 - mean_squared_error: 146.3403 - val_loss: 164.6338 - val_mean_squared_error: 164.6338\n",
      "Epoch 472/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 144.1716 - mean_squared_error: 144.1716\n",
      "Epoch 00472: val_loss did not improve from 157.68224\n",
      "526/526 [==============================] - 0s 462us/step - loss: 145.2760 - mean_squared_error: 145.2760 - val_loss: 161.6171 - val_mean_squared_error: 161.6171\n",
      "Epoch 473/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 143.4627 - mean_squared_error: 143.4627\n",
      "Epoch 00473: val_loss did not improve from 157.68224\n",
      "526/526 [==============================] - 0s 457us/step - loss: 144.0602 - mean_squared_error: 144.0602 - val_loss: 178.3460 - val_mean_squared_error: 178.3460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 140.6090 - mean_squared_error: 140.6090\n",
      "Epoch 00474: val_loss did not improve from 157.68224\n",
      "526/526 [==============================] - 0s 459us/step - loss: 141.9344 - mean_squared_error: 141.9344 - val_loss: 168.1363 - val_mean_squared_error: 168.1363\n",
      "Epoch 475/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 143.0884 - mean_squared_error: 143.0884\n",
      "Epoch 00475: val_loss did not improve from 157.68224\n",
      "526/526 [==============================] - 0s 462us/step - loss: 142.2213 - mean_squared_error: 142.2213 - val_loss: 161.9871 - val_mean_squared_error: 161.9871\n",
      "Epoch 476/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 140.4365 - mean_squared_error: 140.4365\n",
      "Epoch 00476: val_loss did not improve from 157.68224\n",
      "526/526 [==============================] - 0s 459us/step - loss: 140.9655 - mean_squared_error: 140.9655 - val_loss: 160.3193 - val_mean_squared_error: 160.3193\n",
      "Epoch 477/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 142.5302 - mean_squared_error: 142.5302\n",
      "Epoch 00477: val_loss improved from 157.68224 to 157.46861, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 561us/step - loss: 141.8748 - mean_squared_error: 141.8748 - val_loss: 157.4686 - val_mean_squared_error: 157.4686\n",
      "Epoch 478/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 147.5801 - mean_squared_error: 147.5801\n",
      "Epoch 00478: val_loss did not improve from 157.46861\n",
      "526/526 [==============================] - 0s 459us/step - loss: 146.7452 - mean_squared_error: 146.7452 - val_loss: 173.2170 - val_mean_squared_error: 173.2170\n",
      "Epoch 479/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 144.8021 - mean_squared_error: 144.8021\n",
      "Epoch 00479: val_loss did not improve from 157.46861\n",
      "526/526 [==============================] - 0s 459us/step - loss: 144.8898 - mean_squared_error: 144.8898 - val_loss: 183.7698 - val_mean_squared_error: 183.7698\n",
      "Epoch 480/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 142.0600 - mean_squared_error: 142.0600\n",
      "Epoch 00480: val_loss did not improve from 157.46861\n",
      "526/526 [==============================] - 0s 460us/step - loss: 142.5499 - mean_squared_error: 142.5499 - val_loss: 158.0610 - val_mean_squared_error: 158.0610\n",
      "Epoch 481/500\n",
      "483/526 [==========================>...] - ETA: 0s - loss: 143.1851 - mean_squared_error: 143.1851\n",
      "Epoch 00481: val_loss did not improve from 157.46861\n",
      "526/526 [==============================] - 0s 460us/step - loss: 142.7602 - mean_squared_error: 142.7602 - val_loss: 184.6780 - val_mean_squared_error: 184.6780\n",
      "Epoch 482/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 144.8732 - mean_squared_error: 144.8732\n",
      "Epoch 00482: val_loss did not improve from 157.46861\n",
      "526/526 [==============================] - 0s 460us/step - loss: 144.6313 - mean_squared_error: 144.6313 - val_loss: 160.4481 - val_mean_squared_error: 160.4481\n",
      "Epoch 483/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 138.9691 - mean_squared_error: 138.9691\n",
      "Epoch 00483: val_loss did not improve from 157.46861\n",
      "526/526 [==============================] - 0s 457us/step - loss: 139.1393 - mean_squared_error: 139.1393 - val_loss: 166.6623 - val_mean_squared_error: 166.6623\n",
      "Epoch 484/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 147.6811 - mean_squared_error: 147.6811\n",
      "Epoch 00484: val_loss did not improve from 157.46861\n",
      "526/526 [==============================] - 0s 460us/step - loss: 147.6039 - mean_squared_error: 147.6039 - val_loss: 174.7559 - val_mean_squared_error: 174.7559\n",
      "Epoch 485/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 139.5575 - mean_squared_error: 139.5575\n",
      "Epoch 00485: val_loss did not improve from 157.46861\n",
      "526/526 [==============================] - 0s 462us/step - loss: 140.5883 - mean_squared_error: 140.5883 - val_loss: 184.5777 - val_mean_squared_error: 184.5777\n",
      "Epoch 486/500\n",
      "480/526 [==========================>...] - ETA: 0s - loss: 139.6901 - mean_squared_error: 139.6901\n",
      "Epoch 00486: val_loss did not improve from 157.46861\n",
      "526/526 [==============================] - 0s 464us/step - loss: 140.1708 - mean_squared_error: 140.1708 - val_loss: 158.4485 - val_mean_squared_error: 158.4485\n",
      "Epoch 487/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 142.7686 - mean_squared_error: 142.7686\n",
      "Epoch 00487: val_loss did not improve from 157.46861\n",
      "526/526 [==============================] - 0s 459us/step - loss: 141.6269 - mean_squared_error: 141.6269 - val_loss: 169.2651 - val_mean_squared_error: 169.2651\n",
      "Epoch 488/500\n",
      "480/526 [==========================>...] - ETA: 0s - loss: 141.7353 - mean_squared_error: 141.7353\n",
      "Epoch 00488: val_loss did not improve from 157.46861\n",
      "526/526 [==============================] - 0s 464us/step - loss: 143.1858 - mean_squared_error: 143.1858 - val_loss: 164.3686 - val_mean_squared_error: 164.3686\n",
      "Epoch 489/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 143.8746 - mean_squared_error: 143.8746\n",
      "Epoch 00489: val_loss did not improve from 157.46861\n",
      "526/526 [==============================] - 0s 459us/step - loss: 142.2369 - mean_squared_error: 142.2369 - val_loss: 161.2727 - val_mean_squared_error: 161.2727\n",
      "Epoch 490/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 142.2501 - mean_squared_error: 142.2501\n",
      "Epoch 00490: val_loss did not improve from 157.46861\n",
      "526/526 [==============================] - 0s 459us/step - loss: 142.0064 - mean_squared_error: 142.0064 - val_loss: 173.0466 - val_mean_squared_error: 173.0466\n",
      "Epoch 491/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 140.8166 - mean_squared_error: 140.8166\n",
      "Epoch 00491: val_loss did not improve from 157.46861\n",
      "526/526 [==============================] - 0s 459us/step - loss: 142.3871 - mean_squared_error: 142.3871 - val_loss: 183.8121 - val_mean_squared_error: 183.8121\n",
      "Epoch 492/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 140.0432 - mean_squared_error: 140.0432\n",
      "Epoch 00492: val_loss did not improve from 157.46861\n",
      "526/526 [==============================] - 0s 460us/step - loss: 140.4206 - mean_squared_error: 140.4206 - val_loss: 158.2993 - val_mean_squared_error: 158.2993\n",
      "Epoch 493/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 139.0676 - mean_squared_error: 139.0676\n",
      "Epoch 00493: val_loss did not improve from 157.46861\n",
      "526/526 [==============================] - 0s 459us/step - loss: 140.4041 - mean_squared_error: 140.4041 - val_loss: 171.5967 - val_mean_squared_error: 171.5967\n",
      "Epoch 494/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 139.4498 - mean_squared_error: 139.4498\n",
      "Epoch 00494: val_loss did not improve from 157.46861\n",
      "526/526 [==============================] - 0s 459us/step - loss: 138.3353 - mean_squared_error: 138.3353 - val_loss: 157.9341 - val_mean_squared_error: 157.9341\n",
      "Epoch 495/500\n",
      "484/526 [==========================>...] - ETA: 0s - loss: 136.5037 - mean_squared_error: 136.5037\n",
      "Epoch 00495: val_loss did not improve from 157.46861\n",
      "526/526 [==============================] - 0s 462us/step - loss: 136.5422 - mean_squared_error: 136.5422 - val_loss: 161.5970 - val_mean_squared_error: 161.5970\n",
      "Epoch 496/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 140.6524 - mean_squared_error: 140.6524\n",
      "Epoch 00496: val_loss did not improve from 157.46861\n",
      "526/526 [==============================] - 0s 460us/step - loss: 141.0321 - mean_squared_error: 141.0321 - val_loss: 174.9527 - val_mean_squared_error: 174.9527\n",
      "Epoch 497/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 137.1590 - mean_squared_error: 137.1590\n",
      "Epoch 00497: val_loss did not improve from 157.46861\n",
      "526/526 [==============================] - 0s 459us/step - loss: 137.6349 - mean_squared_error: 137.6349 - val_loss: 176.9046 - val_mean_squared_error: 176.9046\n",
      "Epoch 498/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 142.3067 - mean_squared_error: 142.3067\n",
      "Epoch 00498: val_loss did not improve from 157.46861\n",
      "526/526 [==============================] - 0s 464us/step - loss: 142.5948 - mean_squared_error: 142.5948 - val_loss: 167.0162 - val_mean_squared_error: 167.0162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/500\n",
      "479/526 [==========================>...] - ETA: 0s - loss: 136.2885 - mean_squared_error: 136.2885\n",
      "Epoch 00499: val_loss did not improve from 157.46861\n",
      "526/526 [==============================] - 0s 464us/step - loss: 136.8870 - mean_squared_error: 136.8870 - val_loss: 161.5036 - val_mean_squared_error: 161.5036\n",
      "Epoch 500/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 138.6522 - mean_squared_error: 138.6522\n",
      "Epoch 00500: val_loss improved from 157.46861 to 153.51118, saving model to model3.hdf5\n",
      "526/526 [==============================] - 0s 609us/step - loss: 138.2877 - mean_squared_error: 138.2877 - val_loss: 153.5112 - val_mean_squared_error: 153.5112\n"
     ]
    }
   ],
   "source": [
    "model3 = models.Sequential()\n",
    "model3.add(layers.Dense(256,activation=\"relu\",input_dim=81))\n",
    "model3.add(layers.Dense(128,activation=\"relu\"))\n",
    "model3.add(layers.Dense(1))\n",
    "model3.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    loss = losses.mean_squared_error,\n",
    "    metrics = ['mean_squared_error']\n",
    ")\n",
    "file_path = \"model3.hdf5\"\n",
    "checkpoint = ModelCheckpoint(file_path,monitor='val_loss', verbose=1,\n",
    "                             save_best_only=True,period=1)\n",
    "train_history3 = model3.fit(x_train,y_train,epochs=500,batch_size = 32,\n",
    "                            validation_data = (x_val,y_val),callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "129f7136",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 1298.5647 - mean_squared_error: 1296.7075\n",
      "Epoch 00001: val_loss improved from inf to 936.60742, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 790us/step - loss: 1285.7001 - mean_squared_error: 1283.8464 - val_loss: 936.6074 - val_mean_squared_error: 934.9078\n",
      "Epoch 2/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 562.8146 - mean_squared_error: 561.1738\n",
      "Epoch 00002: val_loss improved from 936.60742 to 601.59314, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 795us/step - loss: 563.0254 - mean_squared_error: 561.3857 - val_loss: 601.5931 - val_mean_squared_error: 599.9931\n",
      "Epoch 3/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 492.6719 - mean_squared_error: 491.0873\n",
      "Epoch 00003: val_loss improved from 601.59314 to 374.95169, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 719us/step - loss: 492.3849 - mean_squared_error: 490.8005 - val_loss: 374.9517 - val_mean_squared_error: 373.3776\n",
      "Epoch 4/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 504.9942 - mean_squared_error: 503.4243\n",
      "Epoch 00004: val_loss did not improve from 374.95169\n",
      "526/526 [==============================] - 0s 537us/step - loss: 500.9989 - mean_squared_error: 499.4291 - val_loss: 386.9847 - val_mean_squared_error: 385.4175\n",
      "Epoch 5/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 413.9395 - mean_squared_error: 412.3737\n",
      "Epoch 00005: val_loss did not improve from 374.95169\n",
      "526/526 [==============================] - 0s 539us/step - loss: 413.3123 - mean_squared_error: 411.7464 - val_loss: 391.7365 - val_mean_squared_error: 390.1724\n",
      "Epoch 6/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 416.9428 - mean_squared_error: 415.3798\n",
      "Epoch 00006: val_loss did not improve from 374.95169\n",
      "526/526 [==============================] - 0s 535us/step - loss: 415.2224 - mean_squared_error: 413.6594 - val_loss: 415.8346 - val_mean_squared_error: 414.2723\n",
      "Epoch 7/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 427.8488 - mean_squared_error: 426.2877\n",
      "Epoch 00007: val_loss improved from 374.95169 to 334.85037, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 706us/step - loss: 428.1198 - mean_squared_error: 426.5588 - val_loss: 334.8504 - val_mean_squared_error: 333.2901\n",
      "Epoch 8/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 445.0641 - mean_squared_error: 443.5046\n",
      "Epoch 00008: val_loss did not improve from 334.85037\n",
      "526/526 [==============================] - 0s 539us/step - loss: 447.1650 - mean_squared_error: 445.6055 - val_loss: 379.3788 - val_mean_squared_error: 377.8206\n",
      "Epoch 9/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 362.5432 - mean_squared_error: 360.9858\n",
      "Epoch 00009: val_loss did not improve from 334.85037\n",
      "526/526 [==============================] - 0s 535us/step - loss: 364.7673 - mean_squared_error: 363.2100 - val_loss: 475.4441 - val_mean_squared_error: 473.8879\n",
      "Epoch 10/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 372.6998 - mean_squared_error: 371.1447\n",
      "Epoch 00010: val_loss did not improve from 334.85037\n",
      "526/526 [==============================] - 0s 539us/step - loss: 373.7479 - mean_squared_error: 372.1928 - val_loss: 518.3742 - val_mean_squared_error: 516.8200\n",
      "Epoch 11/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 391.4720 - mean_squared_error: 389.9189\n",
      "Epoch 00011: val_loss did not improve from 334.85037\n",
      "526/526 [==============================] - 0s 540us/step - loss: 392.6647 - mean_squared_error: 391.1117 - val_loss: 344.3901 - val_mean_squared_error: 342.8380\n",
      "Epoch 12/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 402.1558 - mean_squared_error: 400.6051\n",
      "Epoch 00012: val_loss did not improve from 334.85037\n",
      "526/526 [==============================] - 0s 537us/step - loss: 402.4502 - mean_squared_error: 400.8995 - val_loss: 499.4589 - val_mean_squared_error: 497.9091\n",
      "Epoch 13/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 370.1725 - mean_squared_error: 368.6238\n",
      "Epoch 00013: val_loss improved from 334.85037 to 316.89163, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 672us/step - loss: 368.9510 - mean_squared_error: 367.4023 - val_loss: 316.8916 - val_mean_squared_error: 315.3443\n",
      "Epoch 14/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 385.3012 - mean_squared_error: 383.7546\n",
      "Epoch 00014: val_loss improved from 316.89163 to 284.87781, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 765us/step - loss: 382.8015 - mean_squared_error: 381.2549 - val_loss: 284.8778 - val_mean_squared_error: 283.3326\n",
      "Epoch 15/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 375.5150 - mean_squared_error: 373.9704\n",
      "Epoch 00015: val_loss did not improve from 284.87781\n",
      "526/526 [==============================] - 0s 533us/step - loss: 376.5358 - mean_squared_error: 374.9911 - val_loss: 582.6473 - val_mean_squared_error: 581.1046\n",
      "Epoch 16/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 344.1170 - mean_squared_error: 342.5753\n",
      "Epoch 00016: val_loss did not improve from 284.87781\n",
      "526/526 [==============================] - 0s 533us/step - loss: 345.9035 - mean_squared_error: 344.3618 - val_loss: 298.9889 - val_mean_squared_error: 297.4482\n",
      "Epoch 17/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 372.2619 - mean_squared_error: 370.7225\n",
      "Epoch 00017: val_loss did not improve from 284.87781\n",
      "526/526 [==============================] - 0s 539us/step - loss: 371.6196 - mean_squared_error: 370.0802 - val_loss: 358.7097 - val_mean_squared_error: 357.1716\n",
      "Epoch 18/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 325.6501 - mean_squared_error: 324.1128\n",
      "Epoch 00018: val_loss did not improve from 284.87781\n",
      "526/526 [==============================] - 0s 535us/step - loss: 324.1231 - mean_squared_error: 322.5858 - val_loss: 348.4930 - val_mean_squared_error: 346.9570\n",
      "Epoch 19/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 338.7106 - mean_squared_error: 337.1754\n",
      "Epoch 00019: val_loss did not improve from 284.87781\n",
      "526/526 [==============================] - 0s 535us/step - loss: 340.4503 - mean_squared_error: 338.9152 - val_loss: 370.0904 - val_mean_squared_error: 368.5567\n",
      "Epoch 20/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 338.2619 - mean_squared_error: 336.7292\n",
      "Epoch 00020: val_loss improved from 284.87781 to 283.20569, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 767us/step - loss: 338.2980 - mean_squared_error: 336.7653 - val_loss: 283.2057 - val_mean_squared_error: 281.6740\n",
      "Epoch 21/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 361.8272 - mean_squared_error: 360.2966\n",
      "Epoch 00021: val_loss did not improve from 283.20569\n",
      "526/526 [==============================] - 0s 537us/step - loss: 362.7442 - mean_squared_error: 361.2137 - val_loss: 426.7202 - val_mean_squared_error: 425.1909\n",
      "Epoch 22/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 334.0708 - mean_squared_error: 332.5425\n",
      "Epoch 00022: val_loss did not improve from 283.20569\n",
      "526/526 [==============================] - 0s 540us/step - loss: 334.4664 - mean_squared_error: 332.9381 - val_loss: 353.5444 - val_mean_squared_error: 352.0178\n",
      "Epoch 23/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 318.0994 - mean_squared_error: 316.5738\n",
      "Epoch 00023: val_loss did not improve from 283.20569\n",
      "526/526 [==============================] - 0s 537us/step - loss: 317.8167 - mean_squared_error: 316.2912 - val_loss: 406.5714 - val_mean_squared_error: 405.0473\n",
      "Epoch 24/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 334.9820 - mean_squared_error: 333.4589\n",
      "Epoch 00024: val_loss did not improve from 283.20569\n",
      "526/526 [==============================] - 0s 540us/step - loss: 334.0214 - mean_squared_error: 332.4983 - val_loss: 309.2058 - val_mean_squared_error: 307.6843\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516/526 [============================>.] - ETA: 0s - loss: 299.7035 - mean_squared_error: 298.1835\n",
      "Epoch 00025: val_loss did not improve from 283.20569\n",
      "526/526 [==============================] - 0s 535us/step - loss: 301.4528 - mean_squared_error: 299.9328 - val_loss: 363.1377 - val_mean_squared_error: 361.6191\n",
      "Epoch 26/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 304.9964 - mean_squared_error: 303.4792\n",
      "Epoch 00026: val_loss did not improve from 283.20569\n",
      "526/526 [==============================] - 0s 537us/step - loss: 304.7240 - mean_squared_error: 303.2068 - val_loss: 323.7941 - val_mean_squared_error: 322.2785\n",
      "Epoch 27/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 338.3136 - mean_squared_error: 336.7996\n",
      "Epoch 00027: val_loss improved from 283.20569 to 264.74582, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 677us/step - loss: 336.4954 - mean_squared_error: 334.9814 - val_loss: 264.7458 - val_mean_squared_error: 263.2331\n",
      "Epoch 28/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 282.9618 - mean_squared_error: 281.4506\n",
      "Epoch 00028: val_loss did not improve from 264.74582\n",
      "526/526 [==============================] - 0s 537us/step - loss: 283.7802 - mean_squared_error: 282.2692 - val_loss: 359.5033 - val_mean_squared_error: 357.9934\n",
      "Epoch 29/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 301.0015 - mean_squared_error: 299.4933\n",
      "Epoch 00029: val_loss improved from 264.74582 to 260.71259, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 784us/step - loss: 301.0428 - mean_squared_error: 299.5346 - val_loss: 260.7126 - val_mean_squared_error: 259.2059\n",
      "Epoch 30/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 308.4796 - mean_squared_error: 306.9744\n",
      "Epoch 00030: val_loss did not improve from 260.71259\n",
      "526/526 [==============================] - 0s 537us/step - loss: 307.5295 - mean_squared_error: 306.0244 - val_loss: 264.0158 - val_mean_squared_error: 262.5124\n",
      "Epoch 31/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 285.2535 - mean_squared_error: 283.7515\n",
      "Epoch 00031: val_loss did not improve from 260.71259\n",
      "526/526 [==============================] - 0s 542us/step - loss: 287.5963 - mean_squared_error: 286.0944 - val_loss: 306.6312 - val_mean_squared_error: 305.1312\n",
      "Epoch 32/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 303.3317 - mean_squared_error: 301.8336\n",
      "Epoch 00032: val_loss did not improve from 260.71259\n",
      "526/526 [==============================] - 0s 537us/step - loss: 302.5946 - mean_squared_error: 301.0965 - val_loss: 302.7944 - val_mean_squared_error: 301.2976\n",
      "Epoch 33/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 296.4827 - mean_squared_error: 294.9874\n",
      "Epoch 00033: val_loss did not improve from 260.71259\n",
      "526/526 [==============================] - 0s 537us/step - loss: 297.0438 - mean_squared_error: 295.5485 - val_loss: 310.7800 - val_mean_squared_error: 309.2866\n",
      "Epoch 34/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 282.4162 - mean_squared_error: 280.9243\n",
      "Epoch 00034: val_loss did not improve from 260.71259\n",
      "526/526 [==============================] - 0s 537us/step - loss: 281.6081 - mean_squared_error: 280.1163 - val_loss: 286.5735 - val_mean_squared_error: 285.0835\n",
      "Epoch 35/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 297.6128 - mean_squared_error: 296.1243\n",
      "Epoch 00035: val_loss did not improve from 260.71259\n",
      "526/526 [==============================] - 0s 539us/step - loss: 296.5972 - mean_squared_error: 295.1087 - val_loss: 326.5426 - val_mean_squared_error: 325.0556\n",
      "Epoch 36/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 289.7078 - mean_squared_error: 288.2226\n",
      "Epoch 00036: val_loss did not improve from 260.71259\n",
      "526/526 [==============================] - 0s 533us/step - loss: 289.7859 - mean_squared_error: 288.3007 - val_loss: 269.0178 - val_mean_squared_error: 267.5345\n",
      "Epoch 37/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 298.6530 - mean_squared_error: 297.1714\n",
      "Epoch 00037: val_loss did not improve from 260.71259\n",
      "526/526 [==============================] - 0s 542us/step - loss: 298.7858 - mean_squared_error: 297.3042 - val_loss: 324.4321 - val_mean_squared_error: 322.9523\n",
      "Epoch 38/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 286.7330 - mean_squared_error: 285.2548\n",
      "Epoch 00038: val_loss did not improve from 260.71259\n",
      "526/526 [==============================] - 0s 537us/step - loss: 285.2762 - mean_squared_error: 283.7980 - val_loss: 292.1485 - val_mean_squared_error: 290.6725\n",
      "Epoch 39/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 281.7988 - mean_squared_error: 280.3248\n",
      "Epoch 00039: val_loss did not improve from 260.71259\n",
      "526/526 [==============================] - 0s 537us/step - loss: 282.5773 - mean_squared_error: 281.1033 - val_loss: 361.3989 - val_mean_squared_error: 359.9266\n",
      "Epoch 40/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 292.5814 - mean_squared_error: 291.1110\n",
      "Epoch 00040: val_loss did not improve from 260.71259\n",
      "526/526 [==============================] - 0s 533us/step - loss: 292.0998 - mean_squared_error: 290.6295 - val_loss: 260.9492 - val_mean_squared_error: 259.4804\n",
      "Epoch 41/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 277.1793 - mean_squared_error: 275.7124\n",
      "Epoch 00041: val_loss improved from 260.71259 to 240.74149, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 763us/step - loss: 275.7820 - mean_squared_error: 274.3152 - val_loss: 240.7415 - val_mean_squared_error: 239.2760\n",
      "Epoch 42/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 268.9530 - mean_squared_error: 267.4893\n",
      "Epoch 00042: val_loss did not improve from 240.74149\n",
      "526/526 [==============================] - 0s 533us/step - loss: 269.5940 - mean_squared_error: 268.1303 - val_loss: 413.2622 - val_mean_squared_error: 411.8000\n",
      "Epoch 43/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 282.5086 - mean_squared_error: 281.0481\n",
      "Epoch 00043: val_loss did not improve from 240.74149\n",
      "526/526 [==============================] - 0s 537us/step - loss: 282.7445 - mean_squared_error: 281.2840 - val_loss: 281.2517 - val_mean_squared_error: 279.7931\n",
      "Epoch 44/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 255.2902 - mean_squared_error: 253.8332\n",
      "Epoch 00044: val_loss did not improve from 240.74149\n",
      "526/526 [==============================] - 0s 537us/step - loss: 256.2969 - mean_squared_error: 254.8400 - val_loss: 285.7793 - val_mean_squared_error: 284.3240\n",
      "Epoch 45/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 285.8853 - mean_squared_error: 284.4314\n",
      "Epoch 00045: val_loss did not improve from 240.74149\n",
      "526/526 [==============================] - 0s 542us/step - loss: 284.4851 - mean_squared_error: 283.0314 - val_loss: 280.4627 - val_mean_squared_error: 279.0105\n",
      "Epoch 46/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 266.8942 - mean_squared_error: 265.4433\n",
      "Epoch 00046: val_loss did not improve from 240.74149\n",
      "526/526 [==============================] - 0s 537us/step - loss: 266.7213 - mean_squared_error: 265.2705 - val_loss: 320.0436 - val_mean_squared_error: 318.5941\n",
      "Epoch 47/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 265.1442 - mean_squared_error: 263.6962\n",
      "Epoch 00047: val_loss did not improve from 240.74149\n",
      "526/526 [==============================] - 0s 535us/step - loss: 266.0367 - mean_squared_error: 264.5888 - val_loss: 374.4523 - val_mean_squared_error: 373.0059\n",
      "Epoch 48/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 273.7915 - mean_squared_error: 272.3463\n",
      "Epoch 00048: val_loss did not improve from 240.74149\n",
      "526/526 [==============================] - 0s 537us/step - loss: 275.3899 - mean_squared_error: 273.9446 - val_loss: 303.3216 - val_mean_squared_error: 301.8777\n",
      "Epoch 49/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 260.8741 - mean_squared_error: 259.4315\n",
      "Epoch 00049: val_loss did not improve from 240.74149\n",
      "526/526 [==============================] - 0s 535us/step - loss: 260.8488 - mean_squared_error: 259.4062 - val_loss: 245.7662 - val_mean_squared_error: 244.3251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 264.6659 - mean_squared_error: 263.2259\n",
      "Epoch 00050: val_loss did not improve from 240.74149\n",
      "526/526 [==============================] - 0s 533us/step - loss: 265.0235 - mean_squared_error: 263.5835 - val_loss: 259.2747 - val_mean_squared_error: 257.8361\n",
      "Epoch 51/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 253.5732 - mean_squared_error: 252.1354\n",
      "Epoch 00051: val_loss did not improve from 240.74149\n",
      "526/526 [==============================] - 0s 535us/step - loss: 253.2092 - mean_squared_error: 251.7715 - val_loss: 243.5749 - val_mean_squared_error: 242.1384\n",
      "Epoch 52/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 259.5090 - mean_squared_error: 258.0737\n",
      "Epoch 00052: val_loss did not improve from 240.74149\n",
      "526/526 [==============================] - 0s 537us/step - loss: 258.8655 - mean_squared_error: 257.4304 - val_loss: 363.7900 - val_mean_squared_error: 362.3557\n",
      "Epoch 53/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 251.3095 - mean_squared_error: 249.8760\n",
      "Epoch 00053: val_loss did not improve from 240.74149\n",
      "526/526 [==============================] - 0s 537us/step - loss: 250.5285 - mean_squared_error: 249.0951 - val_loss: 300.8843 - val_mean_squared_error: 299.4523\n",
      "Epoch 54/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 263.1374 - mean_squared_error: 261.7060\n",
      "Epoch 00054: val_loss did not improve from 240.74149\n",
      "526/526 [==============================] - 0s 533us/step - loss: 263.2402 - mean_squared_error: 261.8088 - val_loss: 382.3527 - val_mean_squared_error: 380.9221\n",
      "Epoch 55/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 259.0226 - mean_squared_error: 257.5929\n",
      "Epoch 00055: val_loss improved from 240.74149 to 227.95886, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 704us/step - loss: 259.5843 - mean_squared_error: 258.1547 - val_loss: 227.9589 - val_mean_squared_error: 226.5300\n",
      "Epoch 56/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 259.9778 - mean_squared_error: 258.5494\n",
      "Epoch 00056: val_loss did not improve from 227.95886\n",
      "526/526 [==============================] - 0s 533us/step - loss: 259.5700 - mean_squared_error: 258.1418 - val_loss: 247.4084 - val_mean_squared_error: 245.9806\n",
      "Epoch 57/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 250.9041 - mean_squared_error: 249.4766\n",
      "Epoch 00057: val_loss improved from 227.95886 to 227.17648, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 711us/step - loss: 250.8853 - mean_squared_error: 249.4578 - val_loss: 227.1765 - val_mean_squared_error: 225.7496\n",
      "Epoch 58/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 249.8109 - mean_squared_error: 248.3843\n",
      "Epoch 00058: val_loss did not improve from 227.17648\n",
      "526/526 [==============================] - 0s 535us/step - loss: 250.3448 - mean_squared_error: 248.9182 - val_loss: 248.1496 - val_mean_squared_error: 246.7229\n",
      "Epoch 59/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 242.5978 - mean_squared_error: 241.1714\n",
      "Epoch 00059: val_loss did not improve from 227.17648\n",
      "526/526 [==============================] - 0s 537us/step - loss: 242.8564 - mean_squared_error: 241.4299 - val_loss: 244.1803 - val_mean_squared_error: 242.7539\n",
      "Epoch 60/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 246.2043 - mean_squared_error: 244.7778\n",
      "Epoch 00060: val_loss did not improve from 227.17648\n",
      "526/526 [==============================] - 0s 535us/step - loss: 246.2332 - mean_squared_error: 244.8067 - val_loss: 229.1073 - val_mean_squared_error: 227.6809\n",
      "Epoch 61/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 245.0311 - mean_squared_error: 243.6047\n",
      "Epoch 00061: val_loss did not improve from 227.17648\n",
      "526/526 [==============================] - 0s 537us/step - loss: 243.8231 - mean_squared_error: 242.3968 - val_loss: 278.2669 - val_mean_squared_error: 276.8407\n",
      "Epoch 62/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 246.1908 - mean_squared_error: 244.7649\n",
      "Epoch 00062: val_loss did not improve from 227.17648\n",
      "526/526 [==============================] - 0s 540us/step - loss: 246.8703 - mean_squared_error: 245.4444 - val_loss: 237.6393 - val_mean_squared_error: 236.2132\n",
      "Epoch 63/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 245.6531 - mean_squared_error: 244.2273\n",
      "Epoch 00063: val_loss did not improve from 227.17648\n",
      "526/526 [==============================] - 0s 535us/step - loss: 245.3050 - mean_squared_error: 243.8792 - val_loss: 275.5895 - val_mean_squared_error: 274.1638\n",
      "Epoch 64/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 240.1825 - mean_squared_error: 238.7564\n",
      "Epoch 00064: val_loss did not improve from 227.17648\n",
      "526/526 [==============================] - 0s 535us/step - loss: 239.5267 - mean_squared_error: 238.1006 - val_loss: 234.9748 - val_mean_squared_error: 233.5484\n",
      "Epoch 65/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 236.7328 - mean_squared_error: 235.3066\n",
      "Epoch 00065: val_loss did not improve from 227.17648\n",
      "526/526 [==============================] - 0s 537us/step - loss: 237.3272 - mean_squared_error: 235.9010 - val_loss: 276.4084 - val_mean_squared_error: 274.9823\n",
      "Epoch 66/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 242.4943 - mean_squared_error: 241.0676\n",
      "Epoch 00066: val_loss improved from 227.17648 to 226.94377, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 757us/step - loss: 242.2339 - mean_squared_error: 240.8072 - val_loss: 226.9438 - val_mean_squared_error: 225.5170\n",
      "Epoch 67/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 233.1590 - mean_squared_error: 231.7321\n",
      "Epoch 00067: val_loss did not improve from 226.94377\n",
      "526/526 [==============================] - 0s 533us/step - loss: 233.8148 - mean_squared_error: 232.3880 - val_loss: 244.8435 - val_mean_squared_error: 243.4163\n",
      "Epoch 68/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 240.0628 - mean_squared_error: 238.6353\n",
      "Epoch 00068: val_loss did not improve from 226.94377\n",
      "526/526 [==============================] - 0s 539us/step - loss: 241.0934 - mean_squared_error: 239.6659 - val_loss: 228.1629 - val_mean_squared_error: 226.7351\n",
      "Epoch 69/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 232.1360 - mean_squared_error: 230.7083\n",
      "Epoch 00069: val_loss did not improve from 226.94377\n",
      "526/526 [==============================] - 0s 537us/step - loss: 232.3405 - mean_squared_error: 230.9128 - val_loss: 281.7230 - val_mean_squared_error: 280.2952\n",
      "Epoch 70/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 233.1527 - mean_squared_error: 231.7246\n",
      "Epoch 00070: val_loss improved from 226.94377 to 223.86673, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 737us/step - loss: 232.7212 - mean_squared_error: 231.2931 - val_loss: 223.8667 - val_mean_squared_error: 222.4383\n",
      "Epoch 71/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 229.9003 - mean_squared_error: 228.4715\n",
      "Epoch 00071: val_loss did not improve from 223.86673\n",
      "526/526 [==============================] - 0s 535us/step - loss: 230.4151 - mean_squared_error: 228.9862 - val_loss: 243.2376 - val_mean_squared_error: 241.8085\n",
      "Epoch 72/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 224.3425 - mean_squared_error: 222.9130\n",
      "Epoch 00072: val_loss improved from 223.86673 to 216.41327, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 763us/step - loss: 224.0861 - mean_squared_error: 222.6565 - val_loss: 216.4133 - val_mean_squared_error: 214.9837\n",
      "Epoch 73/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 231.8982 - mean_squared_error: 230.4684\n",
      "Epoch 00073: val_loss did not improve from 216.41327\n",
      "526/526 [==============================] - 0s 539us/step - loss: 231.9890 - mean_squared_error: 230.5591 - val_loss: 245.4429 - val_mean_squared_error: 244.0128\n",
      "Epoch 74/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 227.0346 - mean_squared_error: 225.6042\n",
      "Epoch 00074: val_loss did not improve from 216.41327\n",
      "526/526 [==============================] - 0s 539us/step - loss: 226.6972 - mean_squared_error: 225.2668 - val_loss: 271.9763 - val_mean_squared_error: 270.5457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 227.6302 - mean_squared_error: 226.1989\n",
      "Epoch 00075: val_loss improved from 216.41327 to 212.61093, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 795us/step - loss: 227.7900 - mean_squared_error: 226.3587 - val_loss: 212.6109 - val_mean_squared_error: 211.1795\n",
      "Epoch 76/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 229.9531 - mean_squared_error: 228.5212\n",
      "Epoch 00076: val_loss did not improve from 212.61093\n",
      "526/526 [==============================] - 0s 535us/step - loss: 229.3193 - mean_squared_error: 227.8874 - val_loss: 232.4573 - val_mean_squared_error: 231.0250\n",
      "Epoch 77/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 231.1305 - mean_squared_error: 229.6976\n",
      "Epoch 00077: val_loss did not improve from 212.61093\n",
      "526/526 [==============================] - 0s 539us/step - loss: 230.2371 - mean_squared_error: 228.8042 - val_loss: 223.1498 - val_mean_squared_error: 221.7163\n",
      "Epoch 78/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 224.2604 - mean_squared_error: 222.8264\n",
      "Epoch 00078: val_loss did not improve from 212.61093\n",
      "526/526 [==============================] - 0s 537us/step - loss: 222.5798 - mean_squared_error: 221.1458 - val_loss: 243.5284 - val_mean_squared_error: 242.0942\n",
      "Epoch 79/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 230.7733 - mean_squared_error: 229.3386\n",
      "Epoch 00079: val_loss did not improve from 212.61093\n",
      "526/526 [==============================] - 0s 537us/step - loss: 231.0638 - mean_squared_error: 229.6292 - val_loss: 239.1920 - val_mean_squared_error: 237.7570\n",
      "Epoch 80/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 221.2830 - mean_squared_error: 219.8473\n",
      "Epoch 00080: val_loss did not improve from 212.61093\n",
      "526/526 [==============================] - 0s 535us/step - loss: 221.2195 - mean_squared_error: 219.7838 - val_loss: 249.0008 - val_mean_squared_error: 247.5646\n",
      "Epoch 81/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 216.6670 - mean_squared_error: 215.2306\n",
      "Epoch 00081: val_loss did not improve from 212.61093\n",
      "526/526 [==============================] - 0s 537us/step - loss: 216.9474 - mean_squared_error: 215.5110 - val_loss: 282.9789 - val_mean_squared_error: 281.5417\n",
      "Epoch 82/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 224.5776 - mean_squared_error: 223.1393\n",
      "Epoch 00082: val_loss did not improve from 212.61093\n",
      "526/526 [==============================] - 0s 537us/step - loss: 224.1185 - mean_squared_error: 222.6803 - val_loss: 242.4394 - val_mean_squared_error: 241.0007\n",
      "Epoch 83/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 214.5472 - mean_squared_error: 213.1074\n",
      "Epoch 00083: val_loss did not improve from 212.61093\n",
      "526/526 [==============================] - 0s 537us/step - loss: 215.4710 - mean_squared_error: 214.0312 - val_loss: 242.6336 - val_mean_squared_error: 241.1931\n",
      "Epoch 84/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 222.3276 - mean_squared_error: 220.8866\n",
      "Epoch 00084: val_loss did not improve from 212.61093\n",
      "526/526 [==============================] - 0s 535us/step - loss: 223.3257 - mean_squared_error: 221.8847 - val_loss: 244.0159 - val_mean_squared_error: 242.5744\n",
      "Epoch 85/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 219.4910 - mean_squared_error: 218.0488\n",
      "Epoch 00085: val_loss did not improve from 212.61093\n",
      "526/526 [==============================] - 0s 537us/step - loss: 219.7269 - mean_squared_error: 218.2847 - val_loss: 240.4310 - val_mean_squared_error: 238.9883\n",
      "Epoch 86/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 218.9026 - mean_squared_error: 217.4595\n",
      "Epoch 00086: val_loss did not improve from 212.61093\n",
      "526/526 [==============================] - 0s 535us/step - loss: 218.3150 - mean_squared_error: 216.8717 - val_loss: 236.6609 - val_mean_squared_error: 235.2179\n",
      "Epoch 87/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 213.2243 - mean_squared_error: 211.7805\n",
      "Epoch 00087: val_loss did not improve from 212.61093\n",
      "526/526 [==============================] - 0s 533us/step - loss: 213.3629 - mean_squared_error: 211.9191 - val_loss: 257.2926 - val_mean_squared_error: 255.8483\n",
      "Epoch 88/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 219.7321 - mean_squared_error: 218.2875\n",
      "Epoch 00088: val_loss improved from 212.61093 to 206.41708, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 767us/step - loss: 219.5964 - mean_squared_error: 218.1517 - val_loss: 206.4171 - val_mean_squared_error: 204.9717\n",
      "Epoch 89/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 214.1272 - mean_squared_error: 212.6811\n",
      "Epoch 00089: val_loss did not improve from 206.41708\n",
      "526/526 [==============================] - 0s 533us/step - loss: 214.0819 - mean_squared_error: 212.6358 - val_loss: 241.8665 - val_mean_squared_error: 240.4201\n",
      "Epoch 90/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 211.5601 - mean_squared_error: 210.1132\n",
      "Epoch 00090: val_loss did not improve from 206.41708\n",
      "526/526 [==============================] - 0s 537us/step - loss: 211.5117 - mean_squared_error: 210.0647 - val_loss: 209.4933 - val_mean_squared_error: 208.0457\n",
      "Epoch 91/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 211.5031 - mean_squared_error: 210.0547\n",
      "Epoch 00091: val_loss improved from 206.41708 to 205.84491, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 764us/step - loss: 212.1534 - mean_squared_error: 210.7050 - val_loss: 205.8449 - val_mean_squared_error: 204.3961\n",
      "Epoch 92/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 209.1152 - mean_squared_error: 207.6658\n",
      "Epoch 00092: val_loss improved from 205.84491 to 203.93701, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 811us/step - loss: 209.4375 - mean_squared_error: 207.9881 - val_loss: 203.9370 - val_mean_squared_error: 202.4869\n",
      "Epoch 93/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 212.5139 - mean_squared_error: 211.0625\n",
      "Epoch 00093: val_loss did not improve from 203.93701\n",
      "526/526 [==============================] - 0s 533us/step - loss: 212.5652 - mean_squared_error: 211.1139 - val_loss: 243.7107 - val_mean_squared_error: 242.2586\n",
      "Epoch 94/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 207.7026 - mean_squared_error: 206.2501\n",
      "Epoch 00094: val_loss improved from 203.93701 to 201.96393, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 759us/step - loss: 207.5544 - mean_squared_error: 206.1019 - val_loss: 201.9639 - val_mean_squared_error: 200.5105\n",
      "Epoch 95/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 210.0919 - mean_squared_error: 208.6376\n",
      "Epoch 00095: val_loss did not improve from 201.96393\n",
      "526/526 [==============================] - 0s 531us/step - loss: 210.9224 - mean_squared_error: 209.4681 - val_loss: 215.3037 - val_mean_squared_error: 213.8487\n",
      "Epoch 96/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 204.7349 - mean_squared_error: 203.2794\n",
      "Epoch 00096: val_loss did not improve from 201.96393\n",
      "526/526 [==============================] - 0s 537us/step - loss: 204.6605 - mean_squared_error: 203.2049 - val_loss: 203.7420 - val_mean_squared_error: 202.2857\n",
      "Epoch 97/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 206.8013 - mean_squared_error: 205.3443\n",
      "Epoch 00097: val_loss did not improve from 201.96393\n",
      "526/526 [==============================] - 0s 537us/step - loss: 206.9816 - mean_squared_error: 205.5246 - val_loss: 234.3883 - val_mean_squared_error: 232.9305\n",
      "Epoch 98/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 204.7914 - mean_squared_error: 203.3328\n",
      "Epoch 00098: val_loss did not improve from 201.96393\n",
      "526/526 [==============================] - 0s 535us/step - loss: 204.7384 - mean_squared_error: 203.2798 - val_loss: 231.1162 - val_mean_squared_error: 229.6569\n",
      "Epoch 99/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 205.4232 - mean_squared_error: 203.9636\n",
      "Epoch 00099: val_loss did not improve from 201.96393\n",
      "526/526 [==============================] - 0s 542us/step - loss: 205.3524 - mean_squared_error: 203.8927 - val_loss: 215.2134 - val_mean_squared_error: 213.7528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 204.4797 - mean_squared_error: 203.0182\n",
      "Epoch 00100: val_loss did not improve from 201.96393\n",
      "526/526 [==============================] - 0s 533us/step - loss: 203.9351 - mean_squared_error: 202.4737 - val_loss: 227.3864 - val_mean_squared_error: 225.9241\n",
      "Epoch 101/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 205.2566 - mean_squared_error: 203.7929\n",
      "Epoch 00101: val_loss did not improve from 201.96393\n",
      "526/526 [==============================] - 0s 533us/step - loss: 205.0468 - mean_squared_error: 203.5832 - val_loss: 252.8015 - val_mean_squared_error: 251.3371\n",
      "Epoch 102/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 200.9245 - mean_squared_error: 199.4595\n",
      "Epoch 00102: val_loss improved from 201.96393 to 197.47766, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 731us/step - loss: 200.6863 - mean_squared_error: 199.2213 - val_loss: 197.4777 - val_mean_squared_error: 196.0114\n",
      "Epoch 103/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 196.1246 - mean_squared_error: 194.6575\n",
      "Epoch 00103: val_loss improved from 197.47766 to 190.46925, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 715us/step - loss: 196.7405 - mean_squared_error: 195.2734 - val_loss: 190.4693 - val_mean_squared_error: 189.0019\n",
      "Epoch 104/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 199.5081 - mean_squared_error: 198.0395\n",
      "Epoch 00104: val_loss did not improve from 190.46925\n",
      "526/526 [==============================] - 0s 533us/step - loss: 199.2013 - mean_squared_error: 197.7327 - val_loss: 194.3674 - val_mean_squared_error: 192.8979\n",
      "Epoch 105/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 203.5602 - mean_squared_error: 202.0900\n",
      "Epoch 00105: val_loss did not improve from 190.46925\n",
      "526/526 [==============================] - 0s 535us/step - loss: 203.5386 - mean_squared_error: 202.0683 - val_loss: 208.7483 - val_mean_squared_error: 207.2769\n",
      "Epoch 106/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 202.4570 - mean_squared_error: 200.9848\n",
      "Epoch 00106: val_loss did not improve from 190.46925\n",
      "526/526 [==============================] - 0s 540us/step - loss: 201.8397 - mean_squared_error: 200.3675 - val_loss: 197.5955 - val_mean_squared_error: 196.1220\n",
      "Epoch 107/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 198.7984 - mean_squared_error: 197.3237\n",
      "Epoch 00107: val_loss did not improve from 190.46925\n",
      "526/526 [==============================] - 0s 537us/step - loss: 198.6056 - mean_squared_error: 197.1308 - val_loss: 195.6357 - val_mean_squared_error: 194.1601\n",
      "Epoch 108/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 195.7914 - mean_squared_error: 194.3147\n",
      "Epoch 00108: val_loss did not improve from 190.46925\n",
      "526/526 [==============================] - 0s 535us/step - loss: 196.0050 - mean_squared_error: 194.5283 - val_loss: 223.7751 - val_mean_squared_error: 222.2974\n",
      "Epoch 109/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 193.4032 - mean_squared_error: 191.9243\n",
      "Epoch 00109: val_loss did not improve from 190.46925\n",
      "526/526 [==============================] - 0s 535us/step - loss: 194.0647 - mean_squared_error: 192.5858 - val_loss: 201.7322 - val_mean_squared_error: 200.2524\n",
      "Epoch 110/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 197.5835 - mean_squared_error: 196.1025\n",
      "Epoch 00110: val_loss did not improve from 190.46925\n",
      "526/526 [==============================] - 0s 539us/step - loss: 196.9685 - mean_squared_error: 195.4875 - val_loss: 197.0823 - val_mean_squared_error: 195.6008\n",
      "Epoch 111/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 190.7458 - mean_squared_error: 189.2635\n",
      "Epoch 00111: val_loss did not improve from 190.46925\n",
      "526/526 [==============================] - 0s 535us/step - loss: 191.0807 - mean_squared_error: 189.5983 - val_loss: 231.0536 - val_mean_squared_error: 229.5698\n",
      "Epoch 112/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 191.8371 - mean_squared_error: 190.3525\n",
      "Epoch 00112: val_loss did not improve from 190.46925\n",
      "526/526 [==============================] - 0s 537us/step - loss: 191.6158 - mean_squared_error: 190.1312 - val_loss: 193.3884 - val_mean_squared_error: 191.9033\n",
      "Epoch 113/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 196.2361 - mean_squared_error: 194.7499\n",
      "Epoch 00113: val_loss did not improve from 190.46925\n",
      "526/526 [==============================] - 0s 539us/step - loss: 196.5912 - mean_squared_error: 195.1049 - val_loss: 203.1482 - val_mean_squared_error: 201.6609\n",
      "Epoch 114/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 190.5086 - mean_squared_error: 189.0205\n",
      "Epoch 00114: val_loss did not improve from 190.46925\n",
      "526/526 [==============================] - 0s 537us/step - loss: 190.5132 - mean_squared_error: 189.0250 - val_loss: 190.6099 - val_mean_squared_error: 189.1205\n",
      "Epoch 115/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 193.3623 - mean_squared_error: 191.8722\n",
      "Epoch 00115: val_loss did not improve from 190.46925\n",
      "526/526 [==============================] - 0s 535us/step - loss: 193.6734 - mean_squared_error: 192.1833 - val_loss: 206.3012 - val_mean_squared_error: 204.8103\n",
      "Epoch 116/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 187.8236 - mean_squared_error: 186.3319\n",
      "Epoch 00116: val_loss improved from 190.46925 to 189.13167, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 729us/step - loss: 187.8438 - mean_squared_error: 186.3521 - val_loss: 189.1317 - val_mean_squared_error: 187.6391\n",
      "Epoch 117/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 195.3206 - mean_squared_error: 193.8268\n",
      "Epoch 00117: val_loss improved from 189.13167 to 187.38916, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 807us/step - loss: 194.5246 - mean_squared_error: 193.0307 - val_loss: 187.3892 - val_mean_squared_error: 185.8941\n",
      "Epoch 118/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 192.1052 - mean_squared_error: 190.6090\n",
      "Epoch 00118: val_loss did not improve from 187.38916\n",
      "526/526 [==============================] - 0s 537us/step - loss: 192.1317 - mean_squared_error: 190.6354 - val_loss: 198.0200 - val_mean_squared_error: 196.5233\n",
      "Epoch 119/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 187.1622 - mean_squared_error: 185.6645\n",
      "Epoch 00119: val_loss did not improve from 187.38916\n",
      "526/526 [==============================] - 0s 540us/step - loss: 188.2510 - mean_squared_error: 186.7533 - val_loss: 226.0206 - val_mean_squared_error: 224.5218\n",
      "Epoch 120/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 188.7331 - mean_squared_error: 187.2331\n",
      "Epoch 00120: val_loss did not improve from 187.38916\n",
      "526/526 [==============================] - 0s 539us/step - loss: 189.1589 - mean_squared_error: 187.6588 - val_loss: 189.8650 - val_mean_squared_error: 188.3639\n",
      "Epoch 121/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 190.4706 - mean_squared_error: 188.9680\n",
      "Epoch 00121: val_loss did not improve from 187.38916\n",
      "526/526 [==============================] - 0s 535us/step - loss: 189.9175 - mean_squared_error: 188.4148 - val_loss: 197.5149 - val_mean_squared_error: 196.0111\n",
      "Epoch 122/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 191.4909 - mean_squared_error: 189.9860\n",
      "Epoch 00122: val_loss did not improve from 187.38916\n",
      "526/526 [==============================] - 0s 535us/step - loss: 191.8076 - mean_squared_error: 190.3026 - val_loss: 219.0536 - val_mean_squared_error: 217.5473\n",
      "Epoch 123/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 193.6047 - mean_squared_error: 192.0969\n",
      "Epoch 00123: val_loss did not improve from 187.38916\n",
      "526/526 [==============================] - 0s 539us/step - loss: 193.4588 - mean_squared_error: 191.9510 - val_loss: 225.2522 - val_mean_squared_error: 223.7431\n",
      "Epoch 124/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 182.9656 - mean_squared_error: 181.4550\n",
      "Epoch 00124: val_loss did not improve from 187.38916\n",
      "526/526 [==============================] - 0s 537us/step - loss: 182.9862 - mean_squared_error: 181.4755 - val_loss: 187.4292 - val_mean_squared_error: 185.9174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 187.9588 - mean_squared_error: 186.4458\n",
      "Epoch 00125: val_loss did not improve from 187.38916\n",
      "526/526 [==============================] - 0s 533us/step - loss: 187.9123 - mean_squared_error: 186.3993 - val_loss: 220.9669 - val_mean_squared_error: 219.4523\n",
      "Epoch 126/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 187.6851 - mean_squared_error: 186.1693\n",
      "Epoch 00126: val_loss improved from 187.38916 to 183.69907, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 698us/step - loss: 187.3021 - mean_squared_error: 185.7863 - val_loss: 183.6991 - val_mean_squared_error: 182.1819\n",
      "Epoch 127/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 180.4380 - mean_squared_error: 178.9203\n",
      "Epoch 00127: val_loss did not improve from 183.69907\n",
      "526/526 [==============================] - 0s 542us/step - loss: 180.4428 - mean_squared_error: 178.9251 - val_loss: 188.2168 - val_mean_squared_error: 186.6978\n",
      "Epoch 128/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 182.7469 - mean_squared_error: 181.2263\n",
      "Epoch 00128: val_loss improved from 183.69907 to 181.26044, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 749us/step - loss: 183.2441 - mean_squared_error: 181.7234 - val_loss: 181.2604 - val_mean_squared_error: 179.7388\n",
      "Epoch 129/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 180.0971 - mean_squared_error: 178.5744\n",
      "Epoch 00129: val_loss did not improve from 181.26044\n",
      "526/526 [==============================] - 0s 537us/step - loss: 180.2909 - mean_squared_error: 178.7681 - val_loss: 181.5403 - val_mean_squared_error: 180.0162\n",
      "Epoch 130/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 182.8021 - mean_squared_error: 181.2769\n",
      "Epoch 00130: val_loss did not improve from 181.26044\n",
      "526/526 [==============================] - 0s 542us/step - loss: 182.5235 - mean_squared_error: 180.9982 - val_loss: 184.3379 - val_mean_squared_error: 182.8114\n",
      "Epoch 131/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 182.5385 - mean_squared_error: 181.0108\n",
      "Epoch 00131: val_loss did not improve from 181.26044\n",
      "526/526 [==============================] - 0s 535us/step - loss: 182.1703 - mean_squared_error: 180.6425 - val_loss: 201.8371 - val_mean_squared_error: 200.3078\n",
      "Epoch 132/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 177.9231 - mean_squared_error: 176.3927\n",
      "Epoch 00132: val_loss improved from 181.26044 to 179.82919, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 697us/step - loss: 178.4449 - mean_squared_error: 176.9145 - val_loss: 179.8292 - val_mean_squared_error: 178.2976\n",
      "Epoch 133/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 183.2056 - mean_squared_error: 181.6731\n",
      "Epoch 00133: val_loss did not improve from 179.82919\n",
      "526/526 [==============================] - 0s 535us/step - loss: 182.3779 - mean_squared_error: 180.8454 - val_loss: 195.2159 - val_mean_squared_error: 193.6822\n",
      "Epoch 134/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 177.8312 - mean_squared_error: 176.2964\n",
      "Epoch 00134: val_loss did not improve from 179.82919\n",
      "526/526 [==============================] - 0s 539us/step - loss: 177.7767 - mean_squared_error: 176.2418 - val_loss: 197.9501 - val_mean_squared_error: 196.4140\n",
      "Epoch 135/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 178.3096 - mean_squared_error: 176.7722\n",
      "Epoch 00135: val_loss improved from 179.82919 to 179.71750, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 786us/step - loss: 178.0378 - mean_squared_error: 176.5004 - val_loss: 179.7175 - val_mean_squared_error: 178.1794\n",
      "Epoch 136/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 179.8503 - mean_squared_error: 178.3106\n",
      "Epoch 00136: val_loss did not improve from 179.71750\n",
      "526/526 [==============================] - 0s 539us/step - loss: 180.2957 - mean_squared_error: 178.7560 - val_loss: 185.1102 - val_mean_squared_error: 183.5694\n",
      "Epoch 137/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 176.2708 - mean_squared_error: 174.7292\n",
      "Epoch 00137: val_loss did not improve from 179.71750\n",
      "526/526 [==============================] - 0s 542us/step - loss: 176.1439 - mean_squared_error: 174.6022 - val_loss: 183.7136 - val_mean_squared_error: 182.1706\n",
      "Epoch 138/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 179.1904 - mean_squared_error: 177.6460\n",
      "Epoch 00138: val_loss did not improve from 179.71750\n",
      "526/526 [==============================] - 0s 537us/step - loss: 179.0008 - mean_squared_error: 177.4564 - val_loss: 186.7451 - val_mean_squared_error: 185.1998\n",
      "Epoch 139/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 177.6915 - mean_squared_error: 176.1446\n",
      "Epoch 00139: val_loss did not improve from 179.71750\n",
      "526/526 [==============================] - 0s 537us/step - loss: 177.8664 - mean_squared_error: 176.3194 - val_loss: 182.1476 - val_mean_squared_error: 180.5994\n",
      "Epoch 140/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 175.7799 - mean_squared_error: 174.2306\n",
      "Epoch 00140: val_loss improved from 179.71750 to 178.96912, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 723us/step - loss: 176.1059 - mean_squared_error: 174.5566 - val_loss: 178.9691 - val_mean_squared_error: 177.4187\n",
      "Epoch 141/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 172.9626 - mean_squared_error: 171.4108\n",
      "Epoch 00141: val_loss did not improve from 178.96912\n",
      "526/526 [==============================] - 0s 537us/step - loss: 173.1515 - mean_squared_error: 171.5997 - val_loss: 182.1170 - val_mean_squared_error: 180.5640\n",
      "Epoch 142/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 174.2144 - mean_squared_error: 172.6607\n",
      "Epoch 00142: val_loss improved from 178.96912 to 177.78557, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 592us/step - loss: 174.3415 - mean_squared_error: 172.7878 - val_loss: 177.7856 - val_mean_squared_error: 176.2307\n",
      "Epoch 143/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 175.1495 - mean_squared_error: 173.5934\n",
      "Epoch 00143: val_loss did not improve from 177.78557\n",
      "526/526 [==============================] - 0s 539us/step - loss: 175.5560 - mean_squared_error: 173.9999 - val_loss: 181.1466 - val_mean_squared_error: 179.5889\n",
      "Epoch 144/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 179.1037 - mean_squared_error: 177.5453\n",
      "Epoch 00144: val_loss did not improve from 177.78557\n",
      "526/526 [==============================] - 0s 539us/step - loss: 178.5606 - mean_squared_error: 177.0022 - val_loss: 183.8905 - val_mean_squared_error: 182.3304\n",
      "Epoch 145/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 172.7318 - mean_squared_error: 171.1706\n",
      "Epoch 00145: val_loss improved from 177.78557 to 169.38359, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 761us/step - loss: 171.8228 - mean_squared_error: 170.2616 - val_loss: 169.3836 - val_mean_squared_error: 167.8208\n",
      "Epoch 146/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 169.7225 - mean_squared_error: 168.1588\n",
      "Epoch 00146: val_loss did not improve from 169.38359\n",
      "526/526 [==============================] - 0s 539us/step - loss: 169.8897 - mean_squared_error: 168.3259 - val_loss: 181.8695 - val_mean_squared_error: 180.3044\n",
      "Epoch 147/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 167.9268 - mean_squared_error: 166.3604\n",
      "Epoch 00147: val_loss did not improve from 169.38359\n",
      "526/526 [==============================] - 0s 539us/step - loss: 167.6165 - mean_squared_error: 166.0500 - val_loss: 194.7478 - val_mean_squared_error: 193.1800\n",
      "Epoch 148/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 174.3792 - mean_squared_error: 172.8097\n",
      "Epoch 00148: val_loss did not improve from 169.38359\n",
      "526/526 [==============================] - 0s 539us/step - loss: 174.4528 - mean_squared_error: 172.8832 - val_loss: 180.1066 - val_mean_squared_error: 178.5352\n",
      "Epoch 149/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 171.4367 - mean_squared_error: 169.8640\n",
      "Epoch 00149: val_loss did not improve from 169.38359\n",
      "526/526 [==============================] - 0s 537us/step - loss: 171.2654 - mean_squared_error: 169.6926 - val_loss: 186.9869 - val_mean_squared_error: 185.4126\n",
      "Epoch 150/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 171.5758 - mean_squared_error: 170.0002\n",
      "Epoch 00150: val_loss did not improve from 169.38359\n",
      "526/526 [==============================] - 0s 539us/step - loss: 171.4221 - mean_squared_error: 169.8464 - val_loss: 181.8169 - val_mean_squared_error: 180.2397\n",
      "Epoch 151/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 174.5246 - mean_squared_error: 172.9461\n",
      "Epoch 00151: val_loss improved from 169.38359 to 167.13347, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 679us/step - loss: 173.6068 - mean_squared_error: 172.0282 - val_loss: 167.1335 - val_mean_squared_error: 165.5533\n",
      "Epoch 152/500\n",
      "503/526 [===========================>..] - ETA: 0s - loss: 167.1059 - mean_squared_error: 165.5245\n",
      "Epoch 00152: val_loss did not improve from 167.13347\n",
      "526/526 [==============================] - 0s 552us/step - loss: 167.3541 - mean_squared_error: 165.7726 - val_loss: 177.4925 - val_mean_squared_error: 175.9098\n",
      "Epoch 153/500\n",
      "494/526 [===========================>..] - ETA: 0s - loss: 167.9626 - mean_squared_error: 166.3784\n",
      "Epoch 00153: val_loss did not improve from 167.13347\n",
      "526/526 [==============================] - 0s 559us/step - loss: 167.9193 - mean_squared_error: 166.3350 - val_loss: 190.6776 - val_mean_squared_error: 189.0921\n",
      "Epoch 154/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 167.2379 - mean_squared_error: 165.6509\n",
      "Epoch 00154: val_loss did not improve from 167.13347\n",
      "526/526 [==============================] - 0s 561us/step - loss: 167.7812 - mean_squared_error: 166.1940 - val_loss: 169.4081 - val_mean_squared_error: 167.8196\n",
      "Epoch 155/500\n",
      "505/526 [===========================>..] - ETA: 0s - loss: 168.3173 - mean_squared_error: 166.7274\n",
      "Epoch 00155: val_loss improved from 167.13347 to 166.41551, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 744us/step - loss: 167.9854 - mean_squared_error: 166.3955 - val_loss: 166.4155 - val_mean_squared_error: 164.8235\n",
      "Epoch 156/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 170.2604 - mean_squared_error: 168.6669\n",
      "Epoch 00156: val_loss did not improve from 166.41551\n",
      "526/526 [==============================] - 0s 563us/step - loss: 169.8356 - mean_squared_error: 168.2420 - val_loss: 206.4745 - val_mean_squared_error: 204.8792\n",
      "Epoch 157/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 167.2237 - mean_squared_error: 165.6271\n",
      "Epoch 00157: val_loss improved from 166.41551 to 163.08730, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 767us/step - loss: 166.4878 - mean_squared_error: 164.8912 - val_loss: 163.0873 - val_mean_squared_error: 161.4893\n",
      "Epoch 158/500\n",
      "505/526 [===========================>..] - ETA: 0s - loss: 168.5438 - mean_squared_error: 166.9443\n",
      "Epoch 00158: val_loss did not improve from 163.08730\n",
      "526/526 [==============================] - 0s 546us/step - loss: 167.8391 - mean_squared_error: 166.2396 - val_loss: 194.6236 - val_mean_squared_error: 193.0222\n",
      "Epoch 159/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 166.0703 - mean_squared_error: 164.4677\n",
      "Epoch 00159: val_loss did not improve from 163.08730\n",
      "526/526 [==============================] - 0s 540us/step - loss: 165.2655 - mean_squared_error: 163.6629 - val_loss: 214.8171 - val_mean_squared_error: 213.2132\n",
      "Epoch 160/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 164.7123 - mean_squared_error: 163.1071\n",
      "Epoch 00160: val_loss did not improve from 163.08730\n",
      "526/526 [==============================] - 0s 539us/step - loss: 166.0241 - mean_squared_error: 164.4189 - val_loss: 184.6346 - val_mean_squared_error: 183.0276\n",
      "Epoch 161/500\n",
      "497/526 [===========================>..] - ETA: 0s - loss: 165.1024 - mean_squared_error: 163.4941\n",
      "Epoch 00161: val_loss did not improve from 163.08730\n",
      "526/526 [==============================] - 0s 554us/step - loss: 165.5561 - mean_squared_error: 163.9477 - val_loss: 208.1304 - val_mean_squared_error: 206.5204\n",
      "Epoch 162/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 162.7293 - mean_squared_error: 161.1178\n",
      "Epoch 00162: val_loss did not improve from 163.08730\n",
      "526/526 [==============================] - 0s 540us/step - loss: 162.7108 - mean_squared_error: 161.0992 - val_loss: 165.5128 - val_mean_squared_error: 163.8996\n",
      "Epoch 163/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 162.6841 - mean_squared_error: 161.0694\n",
      "Epoch 00163: val_loss did not improve from 163.08730\n",
      "526/526 [==============================] - 0s 539us/step - loss: 162.4494 - mean_squared_error: 160.8346 - val_loss: 167.6062 - val_mean_squared_error: 165.9896\n",
      "Epoch 164/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 160.4173 - mean_squared_error: 158.7990\n",
      "Epoch 00164: val_loss did not improve from 163.08730\n",
      "526/526 [==============================] - 0s 535us/step - loss: 159.8697 - mean_squared_error: 158.2513 - val_loss: 169.2332 - val_mean_squared_error: 167.6135\n",
      "Epoch 165/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 160.7691 - mean_squared_error: 159.1483\n",
      "Epoch 00165: val_loss did not improve from 163.08730\n",
      "526/526 [==============================] - 0s 537us/step - loss: 160.7319 - mean_squared_error: 159.1110 - val_loss: 171.1744 - val_mean_squared_error: 169.5522\n",
      "Epoch 166/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 159.4901 - mean_squared_error: 157.8667\n",
      "Epoch 00166: val_loss did not improve from 163.08730\n",
      "526/526 [==============================] - 0s 537us/step - loss: 159.8312 - mean_squared_error: 158.2078 - val_loss: 177.0250 - val_mean_squared_error: 175.4005\n",
      "Epoch 167/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 164.1399 - mean_squared_error: 162.5135\n",
      "Epoch 00167: val_loss did not improve from 163.08730\n",
      "526/526 [==============================] - 0s 540us/step - loss: 164.5724 - mean_squared_error: 162.9460 - val_loss: 226.2252 - val_mean_squared_error: 224.5978\n",
      "Epoch 168/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 161.1346 - mean_squared_error: 159.5058\n",
      "Epoch 00168: val_loss improved from 163.08730 to 161.42239, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 615us/step - loss: 161.5811 - mean_squared_error: 159.9523 - val_loss: 161.4224 - val_mean_squared_error: 159.7923\n",
      "Epoch 169/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 156.0475 - mean_squared_error: 154.4163\n",
      "Epoch 00169: val_loss did not improve from 161.42239\n",
      "526/526 [==============================] - 0s 540us/step - loss: 156.3643 - mean_squared_error: 154.7330 - val_loss: 163.4075 - val_mean_squared_error: 161.7748\n",
      "Epoch 170/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 157.2796 - mean_squared_error: 155.6455\n",
      "Epoch 00170: val_loss did not improve from 161.42239\n",
      "526/526 [==============================] - 0s 542us/step - loss: 158.6083 - mean_squared_error: 156.9742 - val_loss: 178.7804 - val_mean_squared_error: 177.1448\n",
      "Epoch 171/500\n",
      "499/526 [===========================>..] - ETA: 0s - loss: 165.3376 - mean_squared_error: 163.7006\n",
      "Epoch 00171: val_loss did not improve from 161.42239\n",
      "526/526 [==============================] - 0s 552us/step - loss: 165.0644 - mean_squared_error: 163.4273 - val_loss: 163.4912 - val_mean_squared_error: 161.8529\n",
      "Epoch 172/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 155.8548 - mean_squared_error: 154.2156\n",
      "Epoch 00172: val_loss did not improve from 161.42239\n",
      "526/526 [==============================] - 0s 540us/step - loss: 156.2183 - mean_squared_error: 154.5791 - val_loss: 184.6461 - val_mean_squared_error: 183.0053\n",
      "Epoch 173/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 160.8637 - mean_squared_error: 159.2212\n",
      "Epoch 00173: val_loss did not improve from 161.42239\n",
      "526/526 [==============================] - 0s 540us/step - loss: 160.5369 - mean_squared_error: 158.8944 - val_loss: 175.2970 - val_mean_squared_error: 173.6530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 157.5768 - mean_squared_error: 155.9316\n",
      "Epoch 00174: val_loss did not improve from 161.42239\n",
      "526/526 [==============================] - 0s 539us/step - loss: 157.5125 - mean_squared_error: 155.8673 - val_loss: 163.1797 - val_mean_squared_error: 161.5325\n",
      "Epoch 175/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 158.7337 - mean_squared_error: 157.0851\n",
      "Epoch 00175: val_loss did not improve from 161.42239\n",
      "526/526 [==============================] - 0s 537us/step - loss: 159.4506 - mean_squared_error: 157.8020 - val_loss: 163.7845 - val_mean_squared_error: 162.1346\n",
      "Epoch 176/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 157.8642 - mean_squared_error: 156.2127\n",
      "Epoch 00176: val_loss did not improve from 161.42239\n",
      "526/526 [==============================] - 0s 537us/step - loss: 157.2182 - mean_squared_error: 155.5667 - val_loss: 170.6510 - val_mean_squared_error: 168.9982\n",
      "Epoch 177/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 156.1372 - mean_squared_error: 154.4830\n",
      "Epoch 00177: val_loss did not improve from 161.42239\n",
      "526/526 [==============================] - 0s 539us/step - loss: 155.5299 - mean_squared_error: 153.8757 - val_loss: 162.4187 - val_mean_squared_error: 160.7631\n",
      "Epoch 178/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 154.1989 - mean_squared_error: 152.5419\n",
      "Epoch 00178: val_loss did not improve from 161.42239\n",
      "526/526 [==============================] - 0s 540us/step - loss: 153.9492 - mean_squared_error: 152.2922 - val_loss: 167.7055 - val_mean_squared_error: 166.0472\n",
      "Epoch 179/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 155.7765 - mean_squared_error: 154.1167\n",
      "Epoch 00179: val_loss improved from 161.42239 to 160.97530, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 754us/step - loss: 155.8837 - mean_squared_error: 154.2239 - val_loss: 160.9753 - val_mean_squared_error: 159.3143\n",
      "Epoch 180/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 156.2309 - mean_squared_error: 154.5685\n",
      "Epoch 00180: val_loss did not improve from 160.97530\n",
      "526/526 [==============================] - 0s 539us/step - loss: 156.3566 - mean_squared_error: 154.6942 - val_loss: 164.7921 - val_mean_squared_error: 163.1282\n",
      "Epoch 181/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 152.0576 - mean_squared_error: 150.3929\n",
      "Epoch 00181: val_loss improved from 160.97530 to 157.87680, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 748us/step - loss: 151.9803 - mean_squared_error: 150.3155 - val_loss: 157.8768 - val_mean_squared_error: 156.2108\n",
      "Epoch 182/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 155.5697 - mean_squared_error: 153.9023\n",
      "Epoch 00182: val_loss did not improve from 157.87680\n",
      "526/526 [==============================] - 0s 540us/step - loss: 155.2713 - mean_squared_error: 153.6039 - val_loss: 160.5387 - val_mean_squared_error: 158.8700\n",
      "Epoch 183/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 157.4547 - mean_squared_error: 155.7842\n",
      "Epoch 00183: val_loss improved from 157.87680 to 154.37895, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 775us/step - loss: 156.6511 - mean_squared_error: 154.9806 - val_loss: 154.3790 - val_mean_squared_error: 152.7068\n",
      "Epoch 184/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 154.9105 - mean_squared_error: 153.2366\n",
      "Epoch 00184: val_loss did not improve from 154.37895\n",
      "526/526 [==============================] - 0s 539us/step - loss: 154.9558 - mean_squared_error: 153.2818 - val_loss: 187.7783 - val_mean_squared_error: 186.1030\n",
      "Epoch 185/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 150.7347 - mean_squared_error: 149.0582\n",
      "Epoch 00185: val_loss did not improve from 154.37895\n",
      "526/526 [==============================] - 0s 537us/step - loss: 150.7369 - mean_squared_error: 149.0604 - val_loss: 158.1252 - val_mean_squared_error: 156.4475\n",
      "Epoch 186/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 151.3914 - mean_squared_error: 149.7126\n",
      "Epoch 00186: val_loss did not improve from 154.37895\n",
      "526/526 [==============================] - 0s 535us/step - loss: 151.7541 - mean_squared_error: 150.0753 - val_loss: 182.6356 - val_mean_squared_error: 180.9554\n",
      "Epoch 187/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 151.9456 - mean_squared_error: 150.2643\n",
      "Epoch 00187: val_loss did not improve from 154.37895\n",
      "526/526 [==============================] - 0s 537us/step - loss: 151.9795 - mean_squared_error: 150.2982 - val_loss: 187.0764 - val_mean_squared_error: 185.3934\n",
      "Epoch 188/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 155.0376 - mean_squared_error: 153.3529\n",
      "Epoch 00188: val_loss did not improve from 154.37895\n",
      "526/526 [==============================] - 0s 540us/step - loss: 155.3597 - mean_squared_error: 153.6749 - val_loss: 163.5862 - val_mean_squared_error: 161.8996\n",
      "Epoch 189/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 147.2352 - mean_squared_error: 145.5473\n",
      "Epoch 00189: val_loss did not improve from 154.37895\n",
      "526/526 [==============================] - 0s 540us/step - loss: 147.4545 - mean_squared_error: 145.7666 - val_loss: 188.8930 - val_mean_squared_error: 187.2040\n",
      "Epoch 190/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 149.5770 - mean_squared_error: 147.8865\n",
      "Epoch 00190: val_loss did not improve from 154.37895\n",
      "526/526 [==============================] - 0s 539us/step - loss: 150.1696 - mean_squared_error: 148.4792 - val_loss: 172.5552 - val_mean_squared_error: 170.8633\n",
      "Epoch 191/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 151.0409 - mean_squared_error: 149.3476\n",
      "Epoch 00191: val_loss did not improve from 154.37895\n",
      "526/526 [==============================] - 0s 539us/step - loss: 150.3062 - mean_squared_error: 148.6129 - val_loss: 186.3284 - val_mean_squared_error: 184.6332\n",
      "Epoch 192/500\n",
      "503/526 [===========================>..] - ETA: 0s - loss: 151.7470 - mean_squared_error: 150.0503\n",
      "Epoch 00192: val_loss did not improve from 154.37895\n",
      "526/526 [==============================] - 0s 550us/step - loss: 152.3660 - mean_squared_error: 150.6693 - val_loss: 154.7748 - val_mean_squared_error: 153.0768\n",
      "Epoch 193/500\n",
      "506/526 [===========================>..] - ETA: 0s - loss: 150.7411 - mean_squared_error: 149.0418\n",
      "Epoch 00193: val_loss improved from 154.37895 to 154.31606, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 681us/step - loss: 150.2018 - mean_squared_error: 148.5024 - val_loss: 154.3161 - val_mean_squared_error: 152.6156\n",
      "Epoch 194/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 150.2323 - mean_squared_error: 148.5304\n",
      "Epoch 00194: val_loss did not improve from 154.31606\n",
      "526/526 [==============================] - 0s 539us/step - loss: 149.7316 - mean_squared_error: 148.0296 - val_loss: 158.2385 - val_mean_squared_error: 156.5355\n",
      "Epoch 195/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 150.2971 - mean_squared_error: 148.5926\n",
      "Epoch 00195: val_loss did not improve from 154.31606\n",
      "526/526 [==============================] - 0s 544us/step - loss: 151.8485 - mean_squared_error: 150.1439 - val_loss: 181.5666 - val_mean_squared_error: 179.8606\n",
      "Epoch 196/500\n",
      "505/526 [===========================>..] - ETA: 0s - loss: 148.0562 - mean_squared_error: 146.3486\n",
      "Epoch 00196: val_loss did not improve from 154.31606\n",
      "526/526 [==============================] - 0s 546us/step - loss: 147.4447 - mean_squared_error: 145.7370 - val_loss: 159.3295 - val_mean_squared_error: 157.6204\n",
      "Epoch 197/500\n",
      "501/526 [===========================>..] - ETA: 0s - loss: 148.4344 - mean_squared_error: 146.7242\n",
      "Epoch 00197: val_loss did not improve from 154.31606\n",
      "526/526 [==============================] - 0s 550us/step - loss: 149.3742 - mean_squared_error: 147.6639 - val_loss: 180.3123 - val_mean_squared_error: 178.6004\n",
      "Epoch 198/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 152.3085 - mean_squared_error: 150.5949\n",
      "Epoch 00198: val_loss did not improve from 154.31606\n",
      "526/526 [==============================] - 0s 540us/step - loss: 151.1584 - mean_squared_error: 149.4447 - val_loss: 169.5241 - val_mean_squared_error: 167.8090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 143.9383 - mean_squared_error: 142.2222\n",
      "Epoch 00199: val_loss did not improve from 154.31606\n",
      "526/526 [==============================] - 0s 537us/step - loss: 144.4090 - mean_squared_error: 142.6927 - val_loss: 172.5236 - val_mean_squared_error: 170.8064\n",
      "Epoch 200/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 151.8526 - mean_squared_error: 150.1335\n",
      "Epoch 00200: val_loss did not improve from 154.31606\n",
      "526/526 [==============================] - 0s 539us/step - loss: 151.1560 - mean_squared_error: 149.4369 - val_loss: 156.6377 - val_mean_squared_error: 154.9171\n",
      "Epoch 201/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 147.1522 - mean_squared_error: 145.4302\n",
      "Epoch 00201: val_loss did not improve from 154.31606\n",
      "526/526 [==============================] - 0s 537us/step - loss: 146.8555 - mean_squared_error: 145.1335 - val_loss: 178.8748 - val_mean_squared_error: 177.1512\n",
      "Epoch 202/500\n",
      "506/526 [===========================>..] - ETA: 0s - loss: 145.4091 - mean_squared_error: 143.6843\n",
      "Epoch 00202: val_loss did not improve from 154.31606\n",
      "526/526 [==============================] - 0s 544us/step - loss: 145.4629 - mean_squared_error: 143.7380 - val_loss: 175.1059 - val_mean_squared_error: 173.3797\n",
      "Epoch 203/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 143.6641 - mean_squared_error: 141.9368\n",
      "Epoch 00203: val_loss did not improve from 154.31606\n",
      "526/526 [==============================] - 0s 537us/step - loss: 144.2157 - mean_squared_error: 142.4884 - val_loss: 164.0270 - val_mean_squared_error: 162.2981\n",
      "Epoch 204/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 146.1697 - mean_squared_error: 144.4396\n",
      "Epoch 00204: val_loss did not improve from 154.31606\n",
      "526/526 [==============================] - 0s 535us/step - loss: 146.0623 - mean_squared_error: 144.3321 - val_loss: 176.9222 - val_mean_squared_error: 175.1905\n",
      "Epoch 205/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 145.8701 - mean_squared_error: 144.1370\n",
      "Epoch 00205: val_loss improved from 154.31606 to 153.46681, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 710us/step - loss: 145.7533 - mean_squared_error: 144.0202 - val_loss: 153.4668 - val_mean_squared_error: 151.7328\n",
      "Epoch 206/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 143.9091 - mean_squared_error: 142.1736\n",
      "Epoch 00206: val_loss did not improve from 153.46681\n",
      "526/526 [==============================] - 0s 539us/step - loss: 144.2932 - mean_squared_error: 142.5577 - val_loss: 210.6632 - val_mean_squared_error: 208.9263\n",
      "Epoch 207/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 145.6018 - mean_squared_error: 143.8632\n",
      "Epoch 00207: val_loss did not improve from 153.46681\n",
      "526/526 [==============================] - 0s 537us/step - loss: 145.5718 - mean_squared_error: 143.8332 - val_loss: 160.9505 - val_mean_squared_error: 159.2109\n",
      "Epoch 208/500\n",
      "506/526 [===========================>..] - ETA: 0s - loss: 143.2580 - mean_squared_error: 141.5173\n",
      "Epoch 00208: val_loss improved from 153.46681 to 148.54169, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 702us/step - loss: 142.7231 - mean_squared_error: 140.9822 - val_loss: 148.5417 - val_mean_squared_error: 146.7998\n",
      "Epoch 209/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 141.2168 - mean_squared_error: 139.4737\n",
      "Epoch 00209: val_loss did not improve from 148.54169\n",
      "526/526 [==============================] - 0s 544us/step - loss: 140.6002 - mean_squared_error: 138.8570 - val_loss: 158.3438 - val_mean_squared_error: 156.5993\n",
      "Epoch 210/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 145.1237 - mean_squared_error: 143.3780\n",
      "Epoch 00210: val_loss did not improve from 148.54169\n",
      "526/526 [==============================] - 0s 542us/step - loss: 145.1860 - mean_squared_error: 143.4402 - val_loss: 164.3377 - val_mean_squared_error: 162.5904\n",
      "Epoch 211/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 144.3468 - mean_squared_error: 142.5982\n",
      "Epoch 00211: val_loss did not improve from 148.54169\n",
      "526/526 [==============================] - 0s 544us/step - loss: 143.5365 - mean_squared_error: 141.7879 - val_loss: 181.2875 - val_mean_squared_error: 179.5373\n",
      "Epoch 212/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 144.4288 - mean_squared_error: 142.6776\n",
      "Epoch 00212: val_loss did not improve from 148.54169\n",
      "526/526 [==============================] - 0s 540us/step - loss: 144.6861 - mean_squared_error: 142.9348 - val_loss: 150.5869 - val_mean_squared_error: 148.8340\n",
      "Epoch 213/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 140.6770 - mean_squared_error: 138.9232\n",
      "Epoch 00213: val_loss improved from 148.54169 to 147.60855, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 708us/step - loss: 140.1991 - mean_squared_error: 138.4453 - val_loss: 147.6086 - val_mean_squared_error: 145.8537\n",
      "Epoch 214/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 138.0332 - mean_squared_error: 136.2773\n",
      "Epoch 00214: val_loss did not improve from 147.60855\n",
      "526/526 [==============================] - 0s 540us/step - loss: 137.8969 - mean_squared_error: 136.1408 - val_loss: 151.2022 - val_mean_squared_error: 149.4449\n",
      "Epoch 215/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 142.3218 - mean_squared_error: 140.5628\n",
      "Epoch 00215: val_loss did not improve from 147.60855\n",
      "526/526 [==============================] - 0s 542us/step - loss: 142.0147 - mean_squared_error: 140.2557 - val_loss: 153.3929 - val_mean_squared_error: 151.6324\n",
      "Epoch 216/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 138.9683 - mean_squared_error: 137.2068\n",
      "Epoch 00216: val_loss did not improve from 147.60855\n",
      "526/526 [==============================] - 0s 535us/step - loss: 139.3472 - mean_squared_error: 137.5858 - val_loss: 172.4393 - val_mean_squared_error: 170.6763\n",
      "Epoch 217/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 140.1649 - mean_squared_error: 138.4007\n",
      "Epoch 00217: val_loss did not improve from 147.60855\n",
      "526/526 [==============================] - 0s 544us/step - loss: 140.5837 - mean_squared_error: 138.8194 - val_loss: 154.9821 - val_mean_squared_error: 153.2167\n",
      "Epoch 218/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 137.7178 - mean_squared_error: 135.9512\n",
      "Epoch 00218: val_loss did not improve from 147.60855\n",
      "526/526 [==============================] - 0s 539us/step - loss: 137.6430 - mean_squared_error: 135.8763 - val_loss: 151.3361 - val_mean_squared_error: 149.5682\n",
      "Epoch 219/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 139.4040 - mean_squared_error: 137.6350\n",
      "Epoch 00219: val_loss improved from 147.60855 to 146.64813, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 691us/step - loss: 139.7098 - mean_squared_error: 137.9408 - val_loss: 146.6481 - val_mean_squared_error: 144.8777\n",
      "Epoch 220/500\n",
      "503/526 [===========================>..] - ETA: 0s - loss: 139.5655 - mean_squared_error: 137.7938\n",
      "Epoch 00220: val_loss did not improve from 146.64813\n",
      "526/526 [==============================] - 0s 548us/step - loss: 140.3183 - mean_squared_error: 138.5465 - val_loss: 159.0702 - val_mean_squared_error: 157.2966\n",
      "Epoch 221/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 139.0648 - mean_squared_error: 137.2901\n",
      "Epoch 00221: val_loss did not improve from 146.64813\n",
      "526/526 [==============================] - 0s 544us/step - loss: 139.0448 - mean_squared_error: 137.2700 - val_loss: 157.5639 - val_mean_squared_error: 155.7877\n",
      "Epoch 222/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 137.1408 - mean_squared_error: 135.3634\n",
      "Epoch 00222: val_loss did not improve from 146.64813\n",
      "526/526 [==============================] - 0s 544us/step - loss: 137.7725 - mean_squared_error: 135.9951 - val_loss: 149.9264 - val_mean_squared_error: 148.1480\n",
      "Epoch 223/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 136.0056 - mean_squared_error: 134.2261\n",
      "Epoch 00223: val_loss did not improve from 146.64813\n",
      "526/526 [==============================] - 0s 542us/step - loss: 135.8342 - mean_squared_error: 134.0547 - val_loss: 160.4826 - val_mean_squared_error: 158.7015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 137.7718 - mean_squared_error: 135.9894\n",
      "Epoch 00224: val_loss did not improve from 146.64813\n",
      "526/526 [==============================] - 0s 540us/step - loss: 137.4093 - mean_squared_error: 135.6270 - val_loss: 156.4299 - val_mean_squared_error: 154.6461\n",
      "Epoch 225/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 139.7379 - mean_squared_error: 137.9527\n",
      "Epoch 00225: val_loss did not improve from 146.64813\n",
      "526/526 [==============================] - 0s 542us/step - loss: 139.1691 - mean_squared_error: 137.3839 - val_loss: 166.3662 - val_mean_squared_error: 164.5794\n",
      "Epoch 226/500\n",
      "503/526 [===========================>..] - ETA: 0s - loss: 136.9584 - mean_squared_error: 135.1704\n",
      "Epoch 00226: val_loss did not improve from 146.64813\n",
      "526/526 [==============================] - 0s 548us/step - loss: 136.7126 - mean_squared_error: 134.9246 - val_loss: 164.8398 - val_mean_squared_error: 163.0503\n",
      "Epoch 227/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 135.6558 - mean_squared_error: 133.8652\n",
      "Epoch 00227: val_loss did not improve from 146.64813\n",
      "526/526 [==============================] - 0s 539us/step - loss: 135.9646 - mean_squared_error: 134.1739 - val_loss: 169.6902 - val_mean_squared_error: 167.8981\n",
      "Epoch 228/500\n",
      "506/526 [===========================>..] - ETA: 0s - loss: 137.3170 - mean_squared_error: 135.5239\n",
      "Epoch 00228: val_loss did not improve from 146.64813\n",
      "526/526 [==============================] - 0s 544us/step - loss: 137.1322 - mean_squared_error: 135.3391 - val_loss: 161.2241 - val_mean_squared_error: 159.4299\n",
      "Epoch 229/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 134.1452 - mean_squared_error: 132.3496\n",
      "Epoch 00229: val_loss did not improve from 146.64813\n",
      "526/526 [==============================] - 0s 542us/step - loss: 133.9117 - mean_squared_error: 132.1161 - val_loss: 155.7346 - val_mean_squared_error: 153.9377\n",
      "Epoch 230/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 134.5937 - mean_squared_error: 132.7958\n",
      "Epoch 00230: val_loss did not improve from 146.64813\n",
      "526/526 [==============================] - 0s 542us/step - loss: 135.1001 - mean_squared_error: 133.3022 - val_loss: 148.5744 - val_mean_squared_error: 146.7750\n",
      "Epoch 231/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 133.8542 - mean_squared_error: 132.0532\n",
      "Epoch 00231: val_loss did not improve from 146.64813\n",
      "526/526 [==============================] - 0s 537us/step - loss: 133.6323 - mean_squared_error: 131.8312 - val_loss: 173.5986 - val_mean_squared_error: 171.7961\n",
      "Epoch 232/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 136.9368 - mean_squared_error: 135.1333\n",
      "Epoch 00232: val_loss did not improve from 146.64813\n",
      "526/526 [==============================] - 0s 540us/step - loss: 137.0552 - mean_squared_error: 135.2517 - val_loss: 163.6886 - val_mean_squared_error: 161.8841\n",
      "Epoch 233/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 134.7164 - mean_squared_error: 132.9107\n",
      "Epoch 00233: val_loss improved from 146.64813 to 142.49541, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 786us/step - loss: 134.5798 - mean_squared_error: 132.7740 - val_loss: 142.4954 - val_mean_squared_error: 140.6884\n",
      "Epoch 234/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 137.0896 - mean_squared_error: 135.2811\n",
      "Epoch 00234: val_loss did not improve from 142.49541\n",
      "526/526 [==============================] - 0s 540us/step - loss: 136.9620 - mean_squared_error: 135.1535 - val_loss: 166.7619 - val_mean_squared_error: 164.9520\n",
      "Epoch 235/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 132.4839 - mean_squared_error: 130.6730\n",
      "Epoch 00235: val_loss improved from 142.49541 to 141.77385, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 712us/step - loss: 132.7950 - mean_squared_error: 130.9840 - val_loss: 141.7738 - val_mean_squared_error: 139.9616\n",
      "Epoch 236/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 132.9453 - mean_squared_error: 131.1320\n",
      "Epoch 00236: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 542us/step - loss: 133.4297 - mean_squared_error: 131.6164 - val_loss: 153.1775 - val_mean_squared_error: 151.3629\n",
      "Epoch 237/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 132.7316 - mean_squared_error: 130.9158\n",
      "Epoch 00237: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 539us/step - loss: 133.3132 - mean_squared_error: 131.4973 - val_loss: 157.8539 - val_mean_squared_error: 156.0366\n",
      "Epoch 238/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 133.9745 - mean_squared_error: 132.1561\n",
      "Epoch 00238: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 540us/step - loss: 134.9092 - mean_squared_error: 133.0907 - val_loss: 148.2172 - val_mean_squared_error: 146.3974\n",
      "Epoch 239/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 132.1668 - mean_squared_error: 130.3456\n",
      "Epoch 00239: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 539us/step - loss: 132.1066 - mean_squared_error: 130.2854 - val_loss: 193.4947 - val_mean_squared_error: 191.6722\n",
      "Epoch 240/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 135.2955 - mean_squared_error: 133.4716\n",
      "Epoch 00240: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 542us/step - loss: 134.6654 - mean_squared_error: 132.8415 - val_loss: 153.4646 - val_mean_squared_error: 151.6394\n",
      "Epoch 241/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 132.8533 - mean_squared_error: 131.0268\n",
      "Epoch 00241: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 540us/step - loss: 133.3759 - mean_squared_error: 131.5493 - val_loss: 156.1446 - val_mean_squared_error: 154.3167\n",
      "Epoch 242/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 133.1030 - mean_squared_error: 131.2739\n",
      "Epoch 00242: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 539us/step - loss: 132.9404 - mean_squared_error: 131.1113 - val_loss: 143.0823 - val_mean_squared_error: 141.2523\n",
      "Epoch 243/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 131.8387 - mean_squared_error: 130.0074\n",
      "Epoch 00243: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 539us/step - loss: 132.2046 - mean_squared_error: 130.3732 - val_loss: 161.1293 - val_mean_squared_error: 159.2970\n",
      "Epoch 244/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 133.3291 - mean_squared_error: 131.4952\n",
      "Epoch 00244: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 537us/step - loss: 133.5590 - mean_squared_error: 131.7250 - val_loss: 151.2531 - val_mean_squared_error: 149.4178\n",
      "Epoch 245/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 133.5253 - mean_squared_error: 131.6888\n",
      "Epoch 00245: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 539us/step - loss: 134.5745 - mean_squared_error: 132.7380 - val_loss: 148.6566 - val_mean_squared_error: 146.8184\n",
      "Epoch 246/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 134.2742 - mean_squared_error: 132.4350\n",
      "Epoch 00246: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 539us/step - loss: 134.0927 - mean_squared_error: 132.2535 - val_loss: 153.6196 - val_mean_squared_error: 151.7788\n",
      "Epoch 247/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 127.7034 - mean_squared_error: 125.8615\n",
      "Epoch 00247: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 540us/step - loss: 128.0465 - mean_squared_error: 126.2045 - val_loss: 155.0175 - val_mean_squared_error: 153.1746\n",
      "Epoch 248/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 130.3620 - mean_squared_error: 128.5176\n",
      "Epoch 00248: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 539us/step - loss: 130.1632 - mean_squared_error: 128.3187 - val_loss: 158.5324 - val_mean_squared_error: 156.6865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 129.0176 - mean_squared_error: 127.1706\n",
      "Epoch 00249: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 535us/step - loss: 130.3620 - mean_squared_error: 128.5150 - val_loss: 173.4666 - val_mean_squared_error: 171.6187\n",
      "Epoch 250/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 132.0226 - mean_squared_error: 130.1735\n",
      "Epoch 00250: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 535us/step - loss: 132.5619 - mean_squared_error: 130.7127 - val_loss: 151.6361 - val_mean_squared_error: 149.7862\n",
      "Epoch 251/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 132.8401 - mean_squared_error: 130.9887\n",
      "Epoch 00251: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 539us/step - loss: 132.8261 - mean_squared_error: 130.9746 - val_loss: 156.0081 - val_mean_squared_error: 154.1549\n",
      "Epoch 252/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 131.1466 - mean_squared_error: 129.2926\n",
      "Epoch 00252: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 537us/step - loss: 131.1797 - mean_squared_error: 129.3257 - val_loss: 146.8756 - val_mean_squared_error: 145.0205\n",
      "Epoch 253/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 128.9242 - mean_squared_error: 127.0680\n",
      "Epoch 00253: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 537us/step - loss: 128.8911 - mean_squared_error: 127.0349 - val_loss: 145.7826 - val_mean_squared_error: 143.9250\n",
      "Epoch 254/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 131.1890 - mean_squared_error: 129.3303\n",
      "Epoch 00254: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 542us/step - loss: 130.6002 - mean_squared_error: 128.7415 - val_loss: 142.2698 - val_mean_squared_error: 140.4099\n",
      "Epoch 255/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 129.2590 - mean_squared_error: 127.3978\n",
      "Epoch 00255: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 539us/step - loss: 129.7778 - mean_squared_error: 127.9166 - val_loss: 166.0970 - val_mean_squared_error: 164.2346\n",
      "Epoch 256/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 130.0470 - mean_squared_error: 128.1837\n",
      "Epoch 00256: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 537us/step - loss: 130.1266 - mean_squared_error: 128.2634 - val_loss: 152.5298 - val_mean_squared_error: 150.6653\n",
      "Epoch 257/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 128.3847 - mean_squared_error: 126.5188\n",
      "Epoch 00257: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 537us/step - loss: 127.9436 - mean_squared_error: 126.0776 - val_loss: 158.7234 - val_mean_squared_error: 156.8565\n",
      "Epoch 258/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 128.6050 - mean_squared_error: 126.7368\n",
      "Epoch 00258: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 540us/step - loss: 128.3335 - mean_squared_error: 126.4652 - val_loss: 154.9794 - val_mean_squared_error: 153.1098\n",
      "Epoch 259/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 129.4758 - mean_squared_error: 127.6052\n",
      "Epoch 00259: val_loss did not improve from 141.77385\n",
      "526/526 [==============================] - 0s 537us/step - loss: 128.9965 - mean_squared_error: 127.1259 - val_loss: 153.6271 - val_mean_squared_error: 151.7554\n",
      "Epoch 260/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 124.8703 - mean_squared_error: 122.9973\n",
      "Epoch 00260: val_loss improved from 141.77385 to 137.68665, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 692us/step - loss: 124.7833 - mean_squared_error: 122.9104 - val_loss: 137.6866 - val_mean_squared_error: 135.8127\n",
      "Epoch 261/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 128.1855 - mean_squared_error: 126.3105\n",
      "Epoch 00261: val_loss did not improve from 137.68665\n",
      "526/526 [==============================] - 0s 539us/step - loss: 128.5490 - mean_squared_error: 126.6739 - val_loss: 157.5727 - val_mean_squared_error: 155.6964\n",
      "Epoch 262/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 128.8396 - mean_squared_error: 126.9620\n",
      "Epoch 00262: val_loss did not improve from 137.68665\n",
      "526/526 [==============================] - 0s 539us/step - loss: 128.6557 - mean_squared_error: 126.7781 - val_loss: 145.9101 - val_mean_squared_error: 144.0314\n",
      "Epoch 263/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 124.6668 - mean_squared_error: 122.7871\n",
      "Epoch 00263: val_loss did not improve from 137.68665\n",
      "526/526 [==============================] - 0s 539us/step - loss: 124.7867 - mean_squared_error: 122.9070 - val_loss: 151.7744 - val_mean_squared_error: 149.8936\n",
      "Epoch 264/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 127.1844 - mean_squared_error: 125.3025\n",
      "Epoch 00264: val_loss did not improve from 137.68665\n",
      "526/526 [==============================] - 0s 539us/step - loss: 127.4434 - mean_squared_error: 125.5613 - val_loss: 153.0610 - val_mean_squared_error: 151.1777\n",
      "Epoch 265/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 125.5802 - mean_squared_error: 123.6961\n",
      "Epoch 00265: val_loss did not improve from 137.68665\n",
      "526/526 [==============================] - 0s 540us/step - loss: 126.5104 - mean_squared_error: 124.6262 - val_loss: 149.2040 - val_mean_squared_error: 147.3191\n",
      "Epoch 266/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 127.6170 - mean_squared_error: 125.7304\n",
      "Epoch 00266: val_loss did not improve from 137.68665\n",
      "526/526 [==============================] - 0s 539us/step - loss: 127.2092 - mean_squared_error: 125.3225 - val_loss: 153.6078 - val_mean_squared_error: 151.7202\n",
      "Epoch 267/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 123.3332 - mean_squared_error: 121.4442\n",
      "Epoch 00267: val_loss did not improve from 137.68665\n",
      "526/526 [==============================] - 0s 537us/step - loss: 123.8556 - mean_squared_error: 121.9666 - val_loss: 174.6270 - val_mean_squared_error: 172.7368\n",
      "Epoch 268/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 126.5692 - mean_squared_error: 124.6780\n",
      "Epoch 00268: val_loss did not improve from 137.68665\n",
      "526/526 [==============================] - 0s 537us/step - loss: 126.2948 - mean_squared_error: 124.4036 - val_loss: 140.0043 - val_mean_squared_error: 138.1119\n",
      "Epoch 269/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 125.3980 - mean_squared_error: 123.5039\n",
      "Epoch 00269: val_loss did not improve from 137.68665\n",
      "526/526 [==============================] - 0s 539us/step - loss: 125.4726 - mean_squared_error: 123.5784 - val_loss: 151.3861 - val_mean_squared_error: 149.4907\n",
      "Epoch 270/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 126.7689 - mean_squared_error: 124.8724\n",
      "Epoch 00270: val_loss did not improve from 137.68665\n",
      "526/526 [==============================] - 0s 542us/step - loss: 126.5999 - mean_squared_error: 124.7034 - val_loss: 139.2864 - val_mean_squared_error: 137.3887\n",
      "Epoch 271/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 122.3500 - mean_squared_error: 120.4509\n",
      "Epoch 00271: val_loss did not improve from 137.68665\n",
      "526/526 [==============================] - 0s 537us/step - loss: 123.2921 - mean_squared_error: 121.3930 - val_loss: 161.1593 - val_mean_squared_error: 159.2593\n",
      "Epoch 272/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 126.2425 - mean_squared_error: 124.3416\n",
      "Epoch 00272: val_loss did not improve from 137.68665\n",
      "526/526 [==============================] - 0s 540us/step - loss: 126.5288 - mean_squared_error: 124.6279 - val_loss: 145.6072 - val_mean_squared_error: 143.7052\n",
      "Epoch 273/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 124.3197 - mean_squared_error: 122.4167\n",
      "Epoch 00273: val_loss did not improve from 137.68665\n",
      "526/526 [==============================] - 0s 540us/step - loss: 124.7997 - mean_squared_error: 122.8967 - val_loss: 145.5779 - val_mean_squared_error: 143.6737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 125.3995 - mean_squared_error: 123.4939\n",
      "Epoch 00274: val_loss did not improve from 137.68665\n",
      "526/526 [==============================] - 0s 535us/step - loss: 125.7701 - mean_squared_error: 123.8645 - val_loss: 139.5866 - val_mean_squared_error: 137.6798\n",
      "Epoch 275/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 121.6600 - mean_squared_error: 119.7522\n",
      "Epoch 00275: val_loss improved from 137.68665 to 134.27138, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 738us/step - loss: 121.9086 - mean_squared_error: 120.0008 - val_loss: 134.2714 - val_mean_squared_error: 132.3624\n",
      "Epoch 276/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 125.7948 - mean_squared_error: 123.8847\n",
      "Epoch 00276: val_loss did not improve from 134.27138\n",
      "526/526 [==============================] - 0s 539us/step - loss: 125.6388 - mean_squared_error: 123.7286 - val_loss: 148.1697 - val_mean_squared_error: 146.2577\n",
      "Epoch 277/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 126.6188 - mean_squared_error: 124.7054\n",
      "Epoch 00277: val_loss did not improve from 134.27138\n",
      "526/526 [==============================] - 0s 537us/step - loss: 126.3114 - mean_squared_error: 124.3980 - val_loss: 143.4635 - val_mean_squared_error: 141.5491\n",
      "Epoch 278/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 125.7405 - mean_squared_error: 123.8247\n",
      "Epoch 00278: val_loss did not improve from 134.27138\n",
      "526/526 [==============================] - 0s 537us/step - loss: 125.5754 - mean_squared_error: 123.6595 - val_loss: 144.7529 - val_mean_squared_error: 142.8359\n",
      "Epoch 279/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 126.4870 - mean_squared_error: 124.5688\n",
      "Epoch 00279: val_loss did not improve from 134.27138\n",
      "526/526 [==============================] - 0s 540us/step - loss: 127.1037 - mean_squared_error: 125.1855 - val_loss: 160.5206 - val_mean_squared_error: 158.6007\n",
      "Epoch 280/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 122.4519 - mean_squared_error: 120.5308\n",
      "Epoch 00280: val_loss improved from 134.27138 to 133.33377, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 755us/step - loss: 122.5516 - mean_squared_error: 120.6304 - val_loss: 133.3338 - val_mean_squared_error: 131.4117\n",
      "Epoch 281/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 120.1265 - mean_squared_error: 118.2035\n",
      "Epoch 00281: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 533us/step - loss: 119.9690 - mean_squared_error: 118.0460 - val_loss: 142.3499 - val_mean_squared_error: 140.4257\n",
      "Epoch 282/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 123.3322 - mean_squared_error: 121.4067\n",
      "Epoch 00282: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 539us/step - loss: 123.0719 - mean_squared_error: 121.1465 - val_loss: 149.2385 - val_mean_squared_error: 147.3122\n",
      "Epoch 283/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 126.7339 - mean_squared_error: 124.8060\n",
      "Epoch 00283: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 539us/step - loss: 126.7337 - mean_squared_error: 124.8057 - val_loss: 150.0428 - val_mean_squared_error: 148.1133\n",
      "Epoch 284/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 119.6872 - mean_squared_error: 117.7567\n",
      "Epoch 00284: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 537us/step - loss: 119.8500 - mean_squared_error: 117.9194 - val_loss: 139.6259 - val_mean_squared_error: 137.6945\n",
      "Epoch 285/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 119.9297 - mean_squared_error: 117.9972\n",
      "Epoch 00285: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 537us/step - loss: 119.9486 - mean_squared_error: 118.0161 - val_loss: 186.8607 - val_mean_squared_error: 184.9272\n",
      "Epoch 286/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 120.0796 - mean_squared_error: 118.1451\n",
      "Epoch 00286: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 540us/step - loss: 120.6529 - mean_squared_error: 118.7183 - val_loss: 151.1283 - val_mean_squared_error: 149.1930\n",
      "Epoch 287/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 119.7456 - mean_squared_error: 117.8095\n",
      "Epoch 00287: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 539us/step - loss: 119.7362 - mean_squared_error: 117.8000 - val_loss: 138.1472 - val_mean_squared_error: 136.2101\n",
      "Epoch 288/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 121.5562 - mean_squared_error: 119.6181\n",
      "Epoch 00288: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 539us/step - loss: 121.7406 - mean_squared_error: 119.8025 - val_loss: 144.0537 - val_mean_squared_error: 142.1146\n",
      "Epoch 289/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 119.9706 - mean_squared_error: 118.0306\n",
      "Epoch 00289: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 537us/step - loss: 119.7380 - mean_squared_error: 117.7979 - val_loss: 143.2967 - val_mean_squared_error: 141.3560\n",
      "Epoch 290/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 121.7886 - mean_squared_error: 119.8466\n",
      "Epoch 00290: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 539us/step - loss: 122.3124 - mean_squared_error: 120.3703 - val_loss: 139.9415 - val_mean_squared_error: 137.9983\n",
      "Epoch 291/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 119.5193 - mean_squared_error: 117.5746\n",
      "Epoch 00291: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 539us/step - loss: 119.8597 - mean_squared_error: 117.9149 - val_loss: 154.7836 - val_mean_squared_error: 152.8378\n",
      "Epoch 292/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 123.3271 - mean_squared_error: 121.3803\n",
      "Epoch 00292: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 539us/step - loss: 123.5140 - mean_squared_error: 121.5672 - val_loss: 147.7282 - val_mean_squared_error: 145.7803\n",
      "Epoch 293/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 121.5819 - mean_squared_error: 119.6326\n",
      "Epoch 00293: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 539us/step - loss: 120.9741 - mean_squared_error: 119.0248 - val_loss: 144.0121 - val_mean_squared_error: 142.0616\n",
      "Epoch 294/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 120.1038 - mean_squared_error: 118.1520\n",
      "Epoch 00294: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 539us/step - loss: 120.6671 - mean_squared_error: 118.7152 - val_loss: 136.5252 - val_mean_squared_error: 134.5720\n",
      "Epoch 295/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 117.5628 - mean_squared_error: 115.6087\n",
      "Epoch 00295: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 539us/step - loss: 117.7542 - mean_squared_error: 115.8002 - val_loss: 143.2921 - val_mean_squared_error: 141.3372\n",
      "Epoch 296/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 121.7783 - mean_squared_error: 119.8217\n",
      "Epoch 00296: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 537us/step - loss: 121.4710 - mean_squared_error: 119.5144 - val_loss: 140.0824 - val_mean_squared_error: 138.1248\n",
      "Epoch 297/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 118.5898 - mean_squared_error: 116.6313\n",
      "Epoch 00297: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 537us/step - loss: 118.7045 - mean_squared_error: 116.7460 - val_loss: 145.9232 - val_mean_squared_error: 143.9638\n",
      "Epoch 298/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 118.3555 - mean_squared_error: 116.3949\n",
      "Epoch 00298: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 535us/step - loss: 118.4218 - mean_squared_error: 116.4612 - val_loss: 139.8172 - val_mean_squared_error: 137.8552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 120.9115 - mean_squared_error: 118.9485\n",
      "Epoch 00299: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 540us/step - loss: 120.9955 - mean_squared_error: 119.0324 - val_loss: 144.6225 - val_mean_squared_error: 142.6583\n",
      "Epoch 300/500\n",
      "504/526 [===========================>..] - ETA: 0s - loss: 119.6720 - mean_squared_error: 117.7068\n",
      "Epoch 00300: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 546us/step - loss: 119.7720 - mean_squared_error: 117.8068 - val_loss: 153.0467 - val_mean_squared_error: 151.0804\n",
      "Epoch 301/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 120.6491 - mean_squared_error: 118.6813\n",
      "Epoch 00301: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 539us/step - loss: 121.5055 - mean_squared_error: 119.5376 - val_loss: 138.0818 - val_mean_squared_error: 136.1131\n",
      "Epoch 302/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 119.8223 - mean_squared_error: 117.8521\n",
      "Epoch 00302: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 537us/step - loss: 119.5146 - mean_squared_error: 117.5444 - val_loss: 137.6117 - val_mean_squared_error: 135.6404\n",
      "Epoch 303/500\n",
      "501/526 [===========================>..] - ETA: 0s - loss: 115.9876 - mean_squared_error: 114.0156\n",
      "Epoch 00303: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 552us/step - loss: 116.4526 - mean_squared_error: 114.4805 - val_loss: 143.3736 - val_mean_squared_error: 141.4002\n",
      "Epoch 304/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 121.6041 - mean_squared_error: 119.6296\n",
      "Epoch 00304: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 540us/step - loss: 121.2261 - mean_squared_error: 119.2515 - val_loss: 136.8088 - val_mean_squared_error: 134.8330\n",
      "Epoch 305/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 115.9285 - mean_squared_error: 113.9518\n",
      "Epoch 00305: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 537us/step - loss: 116.2419 - mean_squared_error: 114.2651 - val_loss: 139.7774 - val_mean_squared_error: 137.7999\n",
      "Epoch 306/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 118.7630 - mean_squared_error: 116.7843\n",
      "Epoch 00306: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 535us/step - loss: 118.9006 - mean_squared_error: 116.9220 - val_loss: 156.4578 - val_mean_squared_error: 154.4785\n",
      "Epoch 307/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 120.4198 - mean_squared_error: 118.4391\n",
      "Epoch 00307: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 540us/step - loss: 120.4456 - mean_squared_error: 118.4649 - val_loss: 142.8128 - val_mean_squared_error: 140.8307\n",
      "Epoch 308/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 116.3182 - mean_squared_error: 114.3352\n",
      "Epoch 00308: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 535us/step - loss: 116.6419 - mean_squared_error: 114.6589 - val_loss: 139.6361 - val_mean_squared_error: 137.6525\n",
      "Epoch 309/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 119.5970 - mean_squared_error: 117.6123\n",
      "Epoch 00309: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 535us/step - loss: 120.0408 - mean_squared_error: 118.0562 - val_loss: 146.9123 - val_mean_squared_error: 144.9266\n",
      "Epoch 310/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 117.4157 - mean_squared_error: 115.4289\n",
      "Epoch 00310: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 537us/step - loss: 117.4511 - mean_squared_error: 115.4642 - val_loss: 147.9745 - val_mean_squared_error: 145.9865\n",
      "Epoch 311/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 114.2444 - mean_squared_error: 112.2553\n",
      "Epoch 00311: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 535us/step - loss: 114.4610 - mean_squared_error: 112.4718 - val_loss: 142.2839 - val_mean_squared_error: 140.2943\n",
      "Epoch 312/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 116.4341 - mean_squared_error: 114.4432\n",
      "Epoch 00312: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 539us/step - loss: 116.3493 - mean_squared_error: 114.3583 - val_loss: 136.5160 - val_mean_squared_error: 134.5236\n",
      "Epoch 313/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 119.5384 - mean_squared_error: 117.5451\n",
      "Epoch 00313: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 533us/step - loss: 119.8725 - mean_squared_error: 117.8792 - val_loss: 145.8815 - val_mean_squared_error: 143.8873\n",
      "Epoch 314/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 116.7222 - mean_squared_error: 114.7273\n",
      "Epoch 00314: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 537us/step - loss: 116.5004 - mean_squared_error: 114.5055 - val_loss: 145.3746 - val_mean_squared_error: 143.3789\n",
      "Epoch 315/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 114.8481 - mean_squared_error: 112.8514\n",
      "Epoch 00315: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 539us/step - loss: 115.2922 - mean_squared_error: 113.2955 - val_loss: 201.7569 - val_mean_squared_error: 199.7597\n",
      "Epoch 316/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 118.5827 - mean_squared_error: 116.5841\n",
      "Epoch 00316: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 537us/step - loss: 118.7813 - mean_squared_error: 116.7827 - val_loss: 135.8027 - val_mean_squared_error: 133.8030\n",
      "Epoch 317/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 117.9244 - mean_squared_error: 115.9233\n",
      "Epoch 00317: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 537us/step - loss: 118.0000 - mean_squared_error: 115.9989 - val_loss: 146.5165 - val_mean_squared_error: 144.5145\n",
      "Epoch 318/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 114.6030 - mean_squared_error: 112.6000\n",
      "Epoch 00318: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 537us/step - loss: 115.1889 - mean_squared_error: 113.1860 - val_loss: 144.9588 - val_mean_squared_error: 142.9552\n",
      "Epoch 319/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 112.7963 - mean_squared_error: 110.7918\n",
      "Epoch 00319: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 540us/step - loss: 114.2829 - mean_squared_error: 112.2784 - val_loss: 136.9741 - val_mean_squared_error: 134.9688\n",
      "Epoch 320/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 112.7650 - mean_squared_error: 110.7582\n",
      "Epoch 00320: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 535us/step - loss: 112.7655 - mean_squared_error: 110.7587 - val_loss: 133.8168 - val_mean_squared_error: 131.8091\n",
      "Epoch 321/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 116.7353 - mean_squared_error: 114.7268\n",
      "Epoch 00321: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 540us/step - loss: 116.3369 - mean_squared_error: 114.3284 - val_loss: 149.2153 - val_mean_squared_error: 147.2060\n",
      "Epoch 322/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 118.9677 - mean_squared_error: 116.9575\n",
      "Epoch 00322: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 537us/step - loss: 118.6871 - mean_squared_error: 116.6768 - val_loss: 134.3767 - val_mean_squared_error: 132.3655\n",
      "Epoch 323/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 113.9033 - mean_squared_error: 111.8911\n",
      "Epoch 00323: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 537us/step - loss: 113.5225 - mean_squared_error: 111.5103 - val_loss: 146.1108 - val_mean_squared_error: 144.0975\n",
      "Epoch 324/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 114.9404 - mean_squared_error: 112.9258\n",
      "Epoch 00324: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 537us/step - loss: 115.2098 - mean_squared_error: 113.1952 - val_loss: 145.9190 - val_mean_squared_error: 143.9031\n",
      "Epoch 325/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 116.4337 - mean_squared_error: 114.4166\n",
      "Epoch 00325: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 533us/step - loss: 116.5847 - mean_squared_error: 114.5676 - val_loss: 134.7795 - val_mean_squared_error: 132.7612\n",
      "Epoch 326/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 118.4704 - mean_squared_error: 116.4510\n",
      "Epoch 00326: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 540us/step - loss: 119.2107 - mean_squared_error: 117.1912 - val_loss: 150.9570 - val_mean_squared_error: 148.9367\n",
      "Epoch 327/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 111.8863 - mean_squared_error: 109.8649\n",
      "Epoch 00327: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 537us/step - loss: 111.4619 - mean_squared_error: 109.4405 - val_loss: 152.9950 - val_mean_squared_error: 150.9726\n",
      "Epoch 328/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 114.5122 - mean_squared_error: 112.4890\n",
      "Epoch 00328: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 540us/step - loss: 114.6668 - mean_squared_error: 112.6436 - val_loss: 152.1144 - val_mean_squared_error: 150.0902\n",
      "Epoch 329/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 113.8520 - mean_squared_error: 111.8268\n",
      "Epoch 00329: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 539us/step - loss: 113.7422 - mean_squared_error: 111.7170 - val_loss: 136.4530 - val_mean_squared_error: 134.4269\n",
      "Epoch 330/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 113.0496 - mean_squared_error: 111.0224\n",
      "Epoch 00330: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 540us/step - loss: 113.1836 - mean_squared_error: 111.1564 - val_loss: 153.6673 - val_mean_squared_error: 151.6392\n",
      "Epoch 331/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 113.7406 - mean_squared_error: 111.7115\n",
      "Epoch 00331: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 537us/step - loss: 113.4724 - mean_squared_error: 111.4433 - val_loss: 150.8221 - val_mean_squared_error: 148.7922\n",
      "Epoch 332/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 113.3270 - mean_squared_error: 111.2959\n",
      "Epoch 00332: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 535us/step - loss: 113.2579 - mean_squared_error: 111.2267 - val_loss: 173.4830 - val_mean_squared_error: 171.4506\n",
      "Epoch 333/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 114.4934 - mean_squared_error: 112.4598\n",
      "Epoch 00333: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 537us/step - loss: 114.7187 - mean_squared_error: 112.6851 - val_loss: 156.2563 - val_mean_squared_error: 154.2220\n",
      "Epoch 334/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 113.4795 - mean_squared_error: 111.4438\n",
      "Epoch 00334: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 537us/step - loss: 113.2850 - mean_squared_error: 111.2494 - val_loss: 138.9117 - val_mean_squared_error: 136.8748\n",
      "Epoch 335/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 116.4511 - mean_squared_error: 114.4134\n",
      "Epoch 00335: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 537us/step - loss: 116.9469 - mean_squared_error: 114.9092 - val_loss: 150.5920 - val_mean_squared_error: 148.5530\n",
      "Epoch 336/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 113.2755 - mean_squared_error: 111.2357\n",
      "Epoch 00336: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 535us/step - loss: 113.3028 - mean_squared_error: 111.2630 - val_loss: 165.0520 - val_mean_squared_error: 163.0115\n",
      "Epoch 337/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 112.8935 - mean_squared_error: 110.8522\n",
      "Epoch 00337: val_loss did not improve from 133.33377\n",
      "526/526 [==============================] - 0s 539us/step - loss: 112.8529 - mean_squared_error: 110.8116 - val_loss: 139.0558 - val_mean_squared_error: 137.0137\n",
      "Epoch 338/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 111.7911 - mean_squared_error: 109.7478\n",
      "Epoch 00338: val_loss improved from 133.33377 to 127.87207, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 652us/step - loss: 111.6918 - mean_squared_error: 109.6484 - val_loss: 127.8721 - val_mean_squared_error: 125.8276\n",
      "Epoch 339/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 114.9232 - mean_squared_error: 112.8777\n",
      "Epoch 00339: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 537us/step - loss: 114.7383 - mean_squared_error: 112.6927 - val_loss: 139.9218 - val_mean_squared_error: 137.8756\n",
      "Epoch 340/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 113.8414 - mean_squared_error: 111.7941\n",
      "Epoch 00340: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 542us/step - loss: 114.0085 - mean_squared_error: 111.9612 - val_loss: 128.3709 - val_mean_squared_error: 126.3224\n",
      "Epoch 341/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 112.7641 - mean_squared_error: 110.7149\n",
      "Epoch 00341: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 540us/step - loss: 113.1078 - mean_squared_error: 111.0586 - val_loss: 156.5097 - val_mean_squared_error: 154.4600\n",
      "Epoch 342/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 111.3451 - mean_squared_error: 109.2941\n",
      "Epoch 00342: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 542us/step - loss: 111.5477 - mean_squared_error: 109.4966 - val_loss: 144.5346 - val_mean_squared_error: 142.4826\n",
      "Epoch 343/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 110.0681 - mean_squared_error: 108.0151\n",
      "Epoch 00343: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 539us/step - loss: 110.2271 - mean_squared_error: 108.1741 - val_loss: 143.6328 - val_mean_squared_error: 141.5790\n",
      "Epoch 344/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 113.1051 - mean_squared_error: 111.0503\n",
      "Epoch 00344: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 539us/step - loss: 113.3002 - mean_squared_error: 111.2454 - val_loss: 141.5752 - val_mean_squared_error: 139.5200\n",
      "Epoch 345/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 111.2060 - mean_squared_error: 109.1498\n",
      "Epoch 00345: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 539us/step - loss: 111.6594 - mean_squared_error: 109.6032 - val_loss: 137.5792 - val_mean_squared_error: 135.5217\n",
      "Epoch 346/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 113.4045 - mean_squared_error: 111.3461\n",
      "Epoch 00346: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 537us/step - loss: 113.3445 - mean_squared_error: 111.2861 - val_loss: 134.6065 - val_mean_squared_error: 132.5470\n",
      "Epoch 347/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 112.5727 - mean_squared_error: 110.5121\n",
      "Epoch 00347: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 542us/step - loss: 112.3034 - mean_squared_error: 110.2429 - val_loss: 131.7872 - val_mean_squared_error: 129.7256\n",
      "Epoch 348/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 110.4462 - mean_squared_error: 108.3836\n",
      "Epoch 00348: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 540us/step - loss: 110.5532 - mean_squared_error: 108.4907 - val_loss: 135.0992 - val_mean_squared_error: 133.0356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 111.4429 - mean_squared_error: 109.3784\n",
      "Epoch 00349: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 540us/step - loss: 112.1121 - mean_squared_error: 110.0475 - val_loss: 148.3236 - val_mean_squared_error: 146.2580\n",
      "Epoch 350/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 110.0362 - mean_squared_error: 107.9696\n",
      "Epoch 00350: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 540us/step - loss: 110.1997 - mean_squared_error: 108.1331 - val_loss: 145.0753 - val_mean_squared_error: 143.0076\n",
      "Epoch 351/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 109.2698 - mean_squared_error: 107.2011\n",
      "Epoch 00351: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 540us/step - loss: 109.1793 - mean_squared_error: 107.1105 - val_loss: 143.9791 - val_mean_squared_error: 141.9092\n",
      "Epoch 352/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 110.2844 - mean_squared_error: 108.2136\n",
      "Epoch 00352: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 542us/step - loss: 110.0266 - mean_squared_error: 107.9559 - val_loss: 155.2198 - val_mean_squared_error: 153.1479\n",
      "Epoch 353/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 112.6594 - mean_squared_error: 110.5867\n",
      "Epoch 00353: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 537us/step - loss: 112.3979 - mean_squared_error: 110.3252 - val_loss: 132.6974 - val_mean_squared_error: 130.6239\n",
      "Epoch 354/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 110.3272 - mean_squared_error: 108.2525\n",
      "Epoch 00354: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 540us/step - loss: 110.2022 - mean_squared_error: 108.1276 - val_loss: 153.3527 - val_mean_squared_error: 151.2774\n",
      "Epoch 355/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 111.3275 - mean_squared_error: 109.2509\n",
      "Epoch 00355: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 540us/step - loss: 111.1184 - mean_squared_error: 109.0417 - val_loss: 150.1513 - val_mean_squared_error: 148.0735\n",
      "Epoch 356/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 109.2695 - mean_squared_error: 107.1910\n",
      "Epoch 00356: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 537us/step - loss: 109.6064 - mean_squared_error: 107.5278 - val_loss: 130.2218 - val_mean_squared_error: 128.1422\n",
      "Epoch 357/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 111.3595 - mean_squared_error: 109.2792\n",
      "Epoch 00357: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 535us/step - loss: 111.3163 - mean_squared_error: 109.2359 - val_loss: 134.1527 - val_mean_squared_error: 132.0711\n",
      "Epoch 358/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 108.4087 - mean_squared_error: 106.3264\n",
      "Epoch 00358: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 535us/step - loss: 108.9007 - mean_squared_error: 106.8184 - val_loss: 148.6849 - val_mean_squared_error: 146.6015\n",
      "Epoch 359/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 111.3409 - mean_squared_error: 109.2569\n",
      "Epoch 00359: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 540us/step - loss: 111.4939 - mean_squared_error: 109.4099 - val_loss: 149.1607 - val_mean_squared_error: 147.0754\n",
      "Epoch 360/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 106.5919 - mean_squared_error: 104.5057\n",
      "Epoch 00360: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 537us/step - loss: 106.9438 - mean_squared_error: 104.8576 - val_loss: 130.0751 - val_mean_squared_error: 127.9882\n",
      "Epoch 361/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 111.1776 - mean_squared_error: 109.0897\n",
      "Epoch 00361: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 535us/step - loss: 110.7122 - mean_squared_error: 108.6244 - val_loss: 137.1399 - val_mean_squared_error: 135.0510\n",
      "Epoch 362/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 108.2905 - mean_squared_error: 106.2004\n",
      "Epoch 00362: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 539us/step - loss: 108.5068 - mean_squared_error: 106.4167 - val_loss: 139.8201 - val_mean_squared_error: 137.7291\n",
      "Epoch 363/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 108.0554 - mean_squared_error: 105.9636\n",
      "Epoch 00363: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 540us/step - loss: 108.4400 - mean_squared_error: 106.3482 - val_loss: 141.4524 - val_mean_squared_error: 139.3595\n",
      "Epoch 364/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 106.2184 - mean_squared_error: 104.1248\n",
      "Epoch 00364: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 540us/step - loss: 106.7230 - mean_squared_error: 104.6294 - val_loss: 143.1444 - val_mean_squared_error: 141.0500\n",
      "Epoch 365/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 112.3090 - mean_squared_error: 110.2137\n",
      "Epoch 00365: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 537us/step - loss: 112.4179 - mean_squared_error: 110.3226 - val_loss: 162.9255 - val_mean_squared_error: 160.8295\n",
      "Epoch 366/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 111.9464 - mean_squared_error: 109.8488\n",
      "Epoch 00366: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 544us/step - loss: 111.6055 - mean_squared_error: 109.5079 - val_loss: 145.9679 - val_mean_squared_error: 143.8693\n",
      "Epoch 367/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 111.1590 - mean_squared_error: 109.0595\n",
      "Epoch 00367: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 542us/step - loss: 111.6920 - mean_squared_error: 109.5924 - val_loss: 153.4702 - val_mean_squared_error: 151.3697\n",
      "Epoch 368/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 108.9614 - mean_squared_error: 106.8602\n",
      "Epoch 00368: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 542us/step - loss: 108.8763 - mean_squared_error: 106.7751 - val_loss: 139.6438 - val_mean_squared_error: 137.5418\n",
      "Epoch 369/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 106.8956 - mean_squared_error: 104.7928\n",
      "Epoch 00369: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 540us/step - loss: 106.6587 - mean_squared_error: 104.5559 - val_loss: 129.7807 - val_mean_squared_error: 127.6772\n",
      "Epoch 370/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 106.7673 - mean_squared_error: 104.6629\n",
      "Epoch 00370: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 542us/step - loss: 107.2978 - mean_squared_error: 105.1933 - val_loss: 146.1703 - val_mean_squared_error: 144.0650\n",
      "Epoch 371/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 110.0441 - mean_squared_error: 107.9373\n",
      "Epoch 00371: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 540us/step - loss: 110.3374 - mean_squared_error: 108.2306 - val_loss: 138.2359 - val_mean_squared_error: 136.1276\n",
      "Epoch 372/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 106.5562 - mean_squared_error: 104.4469\n",
      "Epoch 00372: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 540us/step - loss: 107.0208 - mean_squared_error: 104.9115 - val_loss: 142.4630 - val_mean_squared_error: 140.3529\n",
      "Epoch 373/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 107.6856 - mean_squared_error: 105.5748\n",
      "Epoch 00373: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 542us/step - loss: 108.2607 - mean_squared_error: 106.1499 - val_loss: 149.4008 - val_mean_squared_error: 147.2890\n",
      "Epoch 374/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 110.8995 - mean_squared_error: 108.7864\n",
      "Epoch 00374: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 542us/step - loss: 111.3131 - mean_squared_error: 109.1999 - val_loss: 142.5589 - val_mean_squared_error: 140.4448\n",
      "Epoch 375/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 112.5275 - mean_squared_error: 110.4122\n",
      "Epoch 00375: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 544us/step - loss: 111.9366 - mean_squared_error: 109.8213 - val_loss: 154.5579 - val_mean_squared_error: 152.4417\n",
      "Epoch 376/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 106.3971 - mean_squared_error: 104.2803\n",
      "Epoch 00376: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 537us/step - loss: 106.2323 - mean_squared_error: 104.1155 - val_loss: 153.2805 - val_mean_squared_error: 151.1624\n",
      "Epoch 377/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 108.3801 - mean_squared_error: 106.2611\n",
      "Epoch 00377: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 540us/step - loss: 108.2146 - mean_squared_error: 106.0955 - val_loss: 134.8661 - val_mean_squared_error: 132.7461\n",
      "Epoch 378/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 106.3886 - mean_squared_error: 104.2676\n",
      "Epoch 00378: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 537us/step - loss: 107.0555 - mean_squared_error: 104.9345 - val_loss: 144.0968 - val_mean_squared_error: 141.9751\n",
      "Epoch 379/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 108.1192 - mean_squared_error: 105.9965\n",
      "Epoch 00379: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 537us/step - loss: 108.1195 - mean_squared_error: 105.9967 - val_loss: 136.9190 - val_mean_squared_error: 134.7953\n",
      "Epoch 380/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 109.0799 - mean_squared_error: 106.9555\n",
      "Epoch 00380: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 537us/step - loss: 109.0896 - mean_squared_error: 106.9651 - val_loss: 134.8178 - val_mean_squared_error: 132.6923\n",
      "Epoch 381/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 108.5812 - mean_squared_error: 106.4549\n",
      "Epoch 00381: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 542us/step - loss: 108.5376 - mean_squared_error: 106.4113 - val_loss: 146.2098 - val_mean_squared_error: 144.0826\n",
      "Epoch 382/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 107.5101 - mean_squared_error: 105.3820\n",
      "Epoch 00382: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 539us/step - loss: 107.3785 - mean_squared_error: 105.2504 - val_loss: 138.6127 - val_mean_squared_error: 136.4839\n",
      "Epoch 383/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 108.9147 - mean_squared_error: 106.7848\n",
      "Epoch 00383: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 544us/step - loss: 108.1353 - mean_squared_error: 106.0052 - val_loss: 152.9524 - val_mean_squared_error: 150.8212\n",
      "Epoch 384/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 105.4249 - mean_squared_error: 103.2931\n",
      "Epoch 00384: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 544us/step - loss: 105.6750 - mean_squared_error: 103.5432 - val_loss: 160.1805 - val_mean_squared_error: 158.0479\n",
      "Epoch 385/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 107.3297 - mean_squared_error: 105.1962\n",
      "Epoch 00385: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 542us/step - loss: 107.0063 - mean_squared_error: 104.8728 - val_loss: 134.2209 - val_mean_squared_error: 132.0866\n",
      "Epoch 386/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 106.8650 - mean_squared_error: 104.7297\n",
      "Epoch 00386: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 540us/step - loss: 106.8245 - mean_squared_error: 104.6891 - val_loss: 134.2439 - val_mean_squared_error: 132.1075\n",
      "Epoch 387/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 105.1546 - mean_squared_error: 103.0172\n",
      "Epoch 00387: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 540us/step - loss: 105.3644 - mean_squared_error: 103.2269 - val_loss: 142.1586 - val_mean_squared_error: 140.0203\n",
      "Epoch 388/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 106.2166 - mean_squared_error: 104.0773\n",
      "Epoch 00388: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 540us/step - loss: 106.8223 - mean_squared_error: 104.6830 - val_loss: 163.8731 - val_mean_squared_error: 161.7330\n",
      "Epoch 389/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 108.4451 - mean_squared_error: 106.3040\n",
      "Epoch 00389: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 540us/step - loss: 108.1013 - mean_squared_error: 105.9602 - val_loss: 146.5138 - val_mean_squared_error: 144.3715\n",
      "Epoch 390/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 106.6676 - mean_squared_error: 104.5246\n",
      "Epoch 00390: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 542us/step - loss: 106.8657 - mean_squared_error: 104.7227 - val_loss: 139.6916 - val_mean_squared_error: 137.5476\n",
      "Epoch 391/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 105.1146 - mean_squared_error: 102.9701\n",
      "Epoch 00391: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 540us/step - loss: 105.3068 - mean_squared_error: 103.1624 - val_loss: 192.8626 - val_mean_squared_error: 190.7174\n",
      "Epoch 392/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 105.9184 - mean_squared_error: 103.7722\n",
      "Epoch 00392: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 542us/step - loss: 106.2150 - mean_squared_error: 104.0687 - val_loss: 136.6195 - val_mean_squared_error: 134.4724\n",
      "Epoch 393/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 106.1382 - mean_squared_error: 103.9894\n",
      "Epoch 00393: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 537us/step - loss: 105.9529 - mean_squared_error: 103.8041 - val_loss: 136.9849 - val_mean_squared_error: 134.8350\n",
      "Epoch 394/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 106.8890 - mean_squared_error: 104.7383\n",
      "Epoch 00394: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 539us/step - loss: 107.3834 - mean_squared_error: 105.2327 - val_loss: 150.5625 - val_mean_squared_error: 148.4110\n",
      "Epoch 395/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 106.7806 - mean_squared_error: 104.6282\n",
      "Epoch 00395: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 542us/step - loss: 106.9961 - mean_squared_error: 104.8436 - val_loss: 143.7424 - val_mean_squared_error: 141.5889\n",
      "Epoch 396/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 104.4079 - mean_squared_error: 102.2534\n",
      "Epoch 00396: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 539us/step - loss: 104.5651 - mean_squared_error: 102.4106 - val_loss: 135.1777 - val_mean_squared_error: 133.0225\n",
      "Epoch 397/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 107.9414 - mean_squared_error: 105.7849\n",
      "Epoch 00397: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 537us/step - loss: 107.7228 - mean_squared_error: 105.5662 - val_loss: 135.4644 - val_mean_squared_error: 133.3070\n",
      "Epoch 398/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 105.2936 - mean_squared_error: 103.1353\n",
      "Epoch 00398: val_loss did not improve from 127.87207\n",
      "526/526 [==============================] - 0s 540us/step - loss: 105.5815 - mean_squared_error: 103.4232 - val_loss: 128.8843 - val_mean_squared_error: 126.7249\n",
      "Epoch 399/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/526 [============================>.] - ETA: 0s - loss: 106.3571 - mean_squared_error: 104.1971\n",
      "Epoch 00399: val_loss improved from 127.87207 to 127.77440, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 733us/step - loss: 105.9602 - mean_squared_error: 103.8002 - val_loss: 127.7744 - val_mean_squared_error: 125.6135\n",
      "Epoch 400/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 107.6757 - mean_squared_error: 105.5138\n",
      "Epoch 00400: val_loss improved from 127.77440 to 126.44707, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 731us/step - loss: 107.2790 - mean_squared_error: 105.1171 - val_loss: 126.4471 - val_mean_squared_error: 124.2847\n",
      "Epoch 401/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 104.4509 - mean_squared_error: 102.2878\n",
      "Epoch 00401: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 533us/step - loss: 104.4551 - mean_squared_error: 102.2920 - val_loss: 134.3801 - val_mean_squared_error: 132.2161\n",
      "Epoch 402/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 105.7066 - mean_squared_error: 103.5413\n",
      "Epoch 00402: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 537us/step - loss: 105.3781 - mean_squared_error: 103.2129 - val_loss: 134.3867 - val_mean_squared_error: 132.2205\n",
      "Epoch 403/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 105.5307 - mean_squared_error: 103.3639\n",
      "Epoch 00403: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 533us/step - loss: 105.2348 - mean_squared_error: 103.0680 - val_loss: 137.4585 - val_mean_squared_error: 135.2911\n",
      "Epoch 404/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 105.2603 - mean_squared_error: 103.0921\n",
      "Epoch 00404: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 535us/step - loss: 105.8754 - mean_squared_error: 103.7071 - val_loss: 153.0567 - val_mean_squared_error: 150.8876\n",
      "Epoch 405/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 108.2622 - mean_squared_error: 106.0924\n",
      "Epoch 00405: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 539us/step - loss: 107.8155 - mean_squared_error: 105.6456 - val_loss: 135.9840 - val_mean_squared_error: 133.8133\n",
      "Epoch 406/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 104.6538 - mean_squared_error: 102.4826\n",
      "Epoch 00406: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 537us/step - loss: 104.4751 - mean_squared_error: 102.3038 - val_loss: 142.7591 - val_mean_squared_error: 140.5871\n",
      "Epoch 407/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 103.5608 - mean_squared_error: 101.3879\n",
      "Epoch 00407: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 533us/step - loss: 103.4653 - mean_squared_error: 101.2925 - val_loss: 132.8251 - val_mean_squared_error: 130.6517\n",
      "Epoch 408/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 104.8037 - mean_squared_error: 102.6296\n",
      "Epoch 00408: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 537us/step - loss: 104.7688 - mean_squared_error: 102.5947 - val_loss: 148.7262 - val_mean_squared_error: 146.5512\n",
      "Epoch 409/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 103.7368 - mean_squared_error: 101.5611\n",
      "Epoch 00409: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 542us/step - loss: 103.4814 - mean_squared_error: 101.3056 - val_loss: 130.7259 - val_mean_squared_error: 128.5495\n",
      "Epoch 410/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 102.6699 - mean_squared_error: 100.4927\n",
      "Epoch 00410: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 539us/step - loss: 102.5170 - mean_squared_error: 100.3398 - val_loss: 134.2448 - val_mean_squared_error: 132.0667\n",
      "Epoch 411/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 102.7838 - mean_squared_error: 100.6049\n",
      "Epoch 00411: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 539us/step - loss: 103.0853 - mean_squared_error: 100.9063 - val_loss: 136.3044 - val_mean_squared_error: 134.1246\n",
      "Epoch 412/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 104.1788 - mean_squared_error: 101.9979\n",
      "Epoch 00412: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 539us/step - loss: 104.4540 - mean_squared_error: 102.2730 - val_loss: 139.6387 - val_mean_squared_error: 137.4568\n",
      "Epoch 413/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 103.4702 - mean_squared_error: 101.2875\n",
      "Epoch 00413: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 540us/step - loss: 103.5782 - mean_squared_error: 101.3954 - val_loss: 130.8535 - val_mean_squared_error: 128.6699\n",
      "Epoch 414/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 105.4409 - mean_squared_error: 103.2567\n",
      "Epoch 00414: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 535us/step - loss: 105.3560 - mean_squared_error: 103.1718 - val_loss: 138.5190 - val_mean_squared_error: 136.3342\n",
      "Epoch 415/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 103.2529 - mean_squared_error: 101.0672\n",
      "Epoch 00415: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 539us/step - loss: 103.0637 - mean_squared_error: 100.8779 - val_loss: 129.0012 - val_mean_squared_error: 126.8148\n",
      "Epoch 416/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 106.4097 - mean_squared_error: 104.2226\n",
      "Epoch 00416: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 540us/step - loss: 106.2557 - mean_squared_error: 104.0685 - val_loss: 137.3629 - val_mean_squared_error: 135.1748\n",
      "Epoch 417/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 103.5396 - mean_squared_error: 101.3508\n",
      "Epoch 00417: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 539us/step - loss: 103.7512 - mean_squared_error: 101.5624 - val_loss: 143.4510 - val_mean_squared_error: 141.2609\n",
      "Epoch 418/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 104.7504 - mean_squared_error: 102.5599\n",
      "Epoch 00418: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 542us/step - loss: 104.6528 - mean_squared_error: 102.4623 - val_loss: 144.2694 - val_mean_squared_error: 142.0779\n",
      "Epoch 419/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 103.9846 - mean_squared_error: 101.7926\n",
      "Epoch 00419: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 539us/step - loss: 104.3302 - mean_squared_error: 102.1382 - val_loss: 135.5280 - val_mean_squared_error: 133.3353\n",
      "Epoch 420/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 104.5140 - mean_squared_error: 102.3203\n",
      "Epoch 00420: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 540us/step - loss: 104.0740 - mean_squared_error: 101.8802 - val_loss: 130.4136 - val_mean_squared_error: 128.2189\n",
      "Epoch 421/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 104.2637 - mean_squared_error: 102.0680\n",
      "Epoch 00421: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 535us/step - loss: 103.8757 - mean_squared_error: 101.6799 - val_loss: 139.7287 - val_mean_squared_error: 137.5323\n",
      "Epoch 422/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 101.7332 - mean_squared_error: 99.5361\n",
      "Epoch 00422: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 539us/step - loss: 101.4304 - mean_squared_error: 99.2333 - val_loss: 133.3675 - val_mean_squared_error: 131.1694\n",
      "Epoch 423/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 102.3813 - mean_squared_error: 100.1829\n",
      "Epoch 00423: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 535us/step - loss: 101.9334 - mean_squared_error: 99.7349 - val_loss: 127.7543 - val_mean_squared_error: 125.5549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 424/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 108.2314 - mean_squared_error: 106.0309\n",
      "Epoch 00424: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 539us/step - loss: 107.9642 - mean_squared_error: 105.7637 - val_loss: 155.7003 - val_mean_squared_error: 153.4986\n",
      "Epoch 425/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 102.3708 - mean_squared_error: 100.1680\n",
      "Epoch 00425: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 537us/step - loss: 102.0863 - mean_squared_error: 99.8836 - val_loss: 139.8047 - val_mean_squared_error: 137.6012\n",
      "Epoch 426/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 104.8696 - mean_squared_error: 102.6655\n",
      "Epoch 00426: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 537us/step - loss: 104.4350 - mean_squared_error: 102.2309 - val_loss: 136.2667 - val_mean_squared_error: 134.0616\n",
      "Epoch 427/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 99.0650 - mean_squared_error: 96.8591\n",
      "Epoch 00427: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 540us/step - loss: 100.9554 - mean_squared_error: 98.7495 - val_loss: 136.9877 - val_mean_squared_error: 134.7814\n",
      "Epoch 428/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 103.7089 - mean_squared_error: 101.5014\n",
      "Epoch 00428: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 537us/step - loss: 103.6289 - mean_squared_error: 101.4214 - val_loss: 130.8849 - val_mean_squared_error: 128.6766\n",
      "Epoch 429/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 102.8538 - mean_squared_error: 100.6444\n",
      "Epoch 00429: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 539us/step - loss: 103.0037 - mean_squared_error: 100.7944 - val_loss: 144.5174 - val_mean_squared_error: 142.3072\n",
      "Epoch 430/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 102.3592 - mean_squared_error: 100.1481\n",
      "Epoch 00430: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 539us/step - loss: 101.5912 - mean_squared_error: 99.3801 - val_loss: 141.9491 - val_mean_squared_error: 139.7370\n",
      "Epoch 431/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 102.9343 - mean_squared_error: 100.7216\n",
      "Epoch 00431: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 540us/step - loss: 102.5289 - mean_squared_error: 100.3163 - val_loss: 127.6977 - val_mean_squared_error: 125.4843\n",
      "Epoch 432/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 100.5601 - mean_squared_error: 98.3457\n",
      "Epoch 00432: val_loss did not improve from 126.44707\n",
      "526/526 [==============================] - 0s 542us/step - loss: 100.8998 - mean_squared_error: 98.6854 - val_loss: 139.2595 - val_mean_squared_error: 137.0440\n",
      "Epoch 433/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 102.3441 - mean_squared_error: 100.1279\n",
      "Epoch 00433: val_loss improved from 126.44707 to 125.72202, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 676us/step - loss: 101.8139 - mean_squared_error: 99.5976 - val_loss: 125.7220 - val_mean_squared_error: 123.5052\n",
      "Epoch 434/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 102.0605 - mean_squared_error: 99.8430 \n",
      "Epoch 00434: val_loss did not improve from 125.72202\n",
      "526/526 [==============================] - 0s 539us/step - loss: 102.1678 - mean_squared_error: 99.9503 - val_loss: 136.1645 - val_mean_squared_error: 133.9456\n",
      "Epoch 435/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 102.8680 - mean_squared_error: 100.6482\n",
      "Epoch 00435: val_loss did not improve from 125.72202\n",
      "526/526 [==============================] - 0s 535us/step - loss: 102.8497 - mean_squared_error: 100.6298 - val_loss: 129.8694 - val_mean_squared_error: 127.6492\n",
      "Epoch 436/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 100.8517 - mean_squared_error: 98.6306\n",
      "Epoch 00436: val_loss did not improve from 125.72202\n",
      "526/526 [==============================] - 0s 539us/step - loss: 100.8958 - mean_squared_error: 98.6747 - val_loss: 170.1933 - val_mean_squared_error: 167.9716\n",
      "Epoch 437/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 100.7728 - mean_squared_error: 98.5499\n",
      "Epoch 00437: val_loss improved from 125.72202 to 124.96656, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 759us/step - loss: 100.3539 - mean_squared_error: 98.1310 - val_loss: 124.9666 - val_mean_squared_error: 122.7426\n",
      "Epoch 438/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 105.8972 - mean_squared_error: 103.6722\n",
      "Epoch 00438: val_loss did not improve from 124.96656\n",
      "526/526 [==============================] - 0s 540us/step - loss: 106.1098 - mean_squared_error: 103.8849 - val_loss: 138.8619 - val_mean_squared_error: 136.6359\n",
      "Epoch 439/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 104.1797 - mean_squared_error: 101.9528\n",
      "Epoch 00439: val_loss did not improve from 124.96656\n",
      "526/526 [==============================] - 0s 539us/step - loss: 103.9590 - mean_squared_error: 101.7321 - val_loss: 136.9650 - val_mean_squared_error: 134.7369\n",
      "Epoch 440/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 103.6972 - mean_squared_error: 101.4684\n",
      "Epoch 00440: val_loss did not improve from 124.96656\n",
      "526/526 [==============================] - 0s 539us/step - loss: 103.4375 - mean_squared_error: 101.2086 - val_loss: 135.7544 - val_mean_squared_error: 133.5248\n",
      "Epoch 441/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 100.3976 - mean_squared_error: 98.1670\n",
      "Epoch 00441: val_loss did not improve from 124.96656\n",
      "526/526 [==============================] - 0s 539us/step - loss: 100.6104 - mean_squared_error: 98.3798 - val_loss: 144.4925 - val_mean_squared_error: 142.2614\n",
      "Epoch 442/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 101.3406 - mean_squared_error: 99.1084\n",
      "Epoch 00442: val_loss did not improve from 124.96656\n",
      "526/526 [==============================] - 0s 533us/step - loss: 101.1504 - mean_squared_error: 98.9182 - val_loss: 140.9459 - val_mean_squared_error: 138.7127\n",
      "Epoch 443/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 102.1999 - mean_squared_error: 99.9661\n",
      "Epoch 00443: val_loss did not improve from 124.96656\n",
      "526/526 [==============================] - 0s 539us/step - loss: 102.2717 - mean_squared_error: 100.0379 - val_loss: 129.7487 - val_mean_squared_error: 127.5144\n",
      "Epoch 444/500\n",
      "506/526 [===========================>..] - ETA: 0s - loss: 99.4303 - mean_squared_error: 97.1950\n",
      "Epoch 00444: val_loss did not improve from 124.96656\n",
      "526/526 [==============================] - 0s 544us/step - loss: 99.5772 - mean_squared_error: 97.3419 - val_loss: 135.3159 - val_mean_squared_error: 133.0800\n",
      "Epoch 445/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 99.6297 - mean_squared_error: 97.3926\n",
      "Epoch 00445: val_loss did not improve from 124.96656\n",
      "526/526 [==============================] - 0s 542us/step - loss: 100.6512 - mean_squared_error: 98.4141 - val_loss: 149.2256 - val_mean_squared_error: 146.9876\n",
      "Epoch 446/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 105.2527 - mean_squared_error: 103.0137\n",
      "Epoch 00446: val_loss did not improve from 124.96656\n",
      "526/526 [==============================] - 0s 537us/step - loss: 105.5979 - mean_squared_error: 103.3590 - val_loss: 138.5846 - val_mean_squared_error: 136.3449\n",
      "Epoch 447/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 101.4891 - mean_squared_error: 99.2484\n",
      "Epoch 00447: val_loss did not improve from 124.96656\n",
      "526/526 [==============================] - 0s 537us/step - loss: 101.5620 - mean_squared_error: 99.3214 - val_loss: 145.4345 - val_mean_squared_error: 143.1930\n",
      "Epoch 448/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 101.1499 - mean_squared_error: 98.9072 \n",
      "Epoch 00448: val_loss did not improve from 124.96656\n",
      "526/526 [==============================] - 0s 540us/step - loss: 101.1082 - mean_squared_error: 98.8655 - val_loss: 131.8695 - val_mean_squared_error: 129.6261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 100.4815 - mean_squared_error: 98.2374\n",
      "Epoch 00449: val_loss did not improve from 124.96656\n",
      "526/526 [==============================] - 0s 539us/step - loss: 100.3712 - mean_squared_error: 98.1271 - val_loss: 132.3496 - val_mean_squared_error: 130.1048\n",
      "Epoch 450/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 98.7406 - mean_squared_error: 96.4947\n",
      "Epoch 00450: val_loss did not improve from 124.96656\n",
      "526/526 [==============================] - 0s 537us/step - loss: 99.0538 - mean_squared_error: 96.8078 - val_loss: 135.4431 - val_mean_squared_error: 133.1955\n",
      "Epoch 451/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 102.8637 - mean_squared_error: 100.6152\n",
      "Epoch 00451: val_loss did not improve from 124.96656\n",
      "526/526 [==============================] - 0s 535us/step - loss: 102.7797 - mean_squared_error: 100.5312 - val_loss: 137.8927 - val_mean_squared_error: 135.6436\n",
      "Epoch 452/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 101.3212 - mean_squared_error: 99.0713\n",
      "Epoch 00452: val_loss did not improve from 124.96656\n",
      "526/526 [==============================] - 0s 537us/step - loss: 101.3098 - mean_squared_error: 99.0599 - val_loss: 134.7935 - val_mean_squared_error: 132.5423\n",
      "Epoch 453/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 102.3417 - mean_squared_error: 100.0898\n",
      "Epoch 00453: val_loss did not improve from 124.96656\n",
      "526/526 [==============================] - 0s 540us/step - loss: 102.2666 - mean_squared_error: 100.0146 - val_loss: 130.4162 - val_mean_squared_error: 128.1631\n",
      "Epoch 454/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 101.2611 - mean_squared_error: 99.0075\n",
      "Epoch 00454: val_loss did not improve from 124.96656\n",
      "526/526 [==============================] - 0s 537us/step - loss: 100.8781 - mean_squared_error: 98.6245 - val_loss: 130.5202 - val_mean_squared_error: 128.2661\n",
      "Epoch 455/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 99.0059 - mean_squared_error: 96.7510\n",
      "Epoch 00455: val_loss improved from 124.96656 to 124.14775, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 669us/step - loss: 99.2504 - mean_squared_error: 96.9954 - val_loss: 124.1478 - val_mean_squared_error: 121.8916\n",
      "Epoch 456/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 100.1649 - mean_squared_error: 97.9080\n",
      "Epoch 00456: val_loss did not improve from 124.14775\n",
      "526/526 [==============================] - 0s 540us/step - loss: 100.2562 - mean_squared_error: 97.9993 - val_loss: 136.6146 - val_mean_squared_error: 134.3569\n",
      "Epoch 457/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 99.3638 - mean_squared_error: 97.1052\n",
      "Epoch 00457: val_loss did not improve from 124.14775\n",
      "526/526 [==============================] - 0s 537us/step - loss: 99.3307 - mean_squared_error: 97.0721 - val_loss: 134.7433 - val_mean_squared_error: 132.4842\n",
      "Epoch 458/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 99.3423 - mean_squared_error: 97.0822\n",
      "Epoch 00458: val_loss did not improve from 124.14775\n",
      "526/526 [==============================] - 0s 539us/step - loss: 99.5985 - mean_squared_error: 97.3383 - val_loss: 128.0942 - val_mean_squared_error: 125.8333\n",
      "Epoch 459/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 98.6723 - mean_squared_error: 96.4105\n",
      "Epoch 00459: val_loss did not improve from 124.14775\n",
      "526/526 [==============================] - 0s 537us/step - loss: 98.7283 - mean_squared_error: 96.4665 - val_loss: 128.1611 - val_mean_squared_error: 125.8987\n",
      "Epoch 460/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 99.8772 - mean_squared_error: 97.6138 \n",
      "Epoch 00460: val_loss improved from 124.14775 to 121.42061, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 710us/step - loss: 100.0214 - mean_squared_error: 97.7580 - val_loss: 121.4206 - val_mean_squared_error: 119.1566\n",
      "Epoch 461/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 99.0267 - mean_squared_error: 96.7616 \n",
      "Epoch 00461: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 539us/step - loss: 98.8690 - mean_squared_error: 96.6038 - val_loss: 133.3665 - val_mean_squared_error: 131.1006\n",
      "Epoch 462/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 99.5170 - mean_squared_error: 97.2501\n",
      "Epoch 00462: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 537us/step - loss: 99.3121 - mean_squared_error: 97.0452 - val_loss: 134.3980 - val_mean_squared_error: 132.1306\n",
      "Epoch 463/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 98.9947 - mean_squared_error: 96.7266\n",
      "Epoch 00463: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 540us/step - loss: 99.0316 - mean_squared_error: 96.7635 - val_loss: 138.8704 - val_mean_squared_error: 136.6015\n",
      "Epoch 464/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 101.0347 - mean_squared_error: 98.7647\n",
      "Epoch 00464: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 537us/step - loss: 101.8071 - mean_squared_error: 99.5371 - val_loss: 144.9884 - val_mean_squared_error: 142.7173\n",
      "Epoch 465/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 101.6477 - mean_squared_error: 99.3757\n",
      "Epoch 00465: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 540us/step - loss: 101.3339 - mean_squared_error: 99.0618 - val_loss: 132.7885 - val_mean_squared_error: 130.5157\n",
      "Epoch 466/500\n",
      "499/526 [===========================>..] - ETA: 0s - loss: 98.6113 - mean_squared_error: 96.3377\n",
      "Epoch 00466: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 552us/step - loss: 98.6790 - mean_squared_error: 96.4054 - val_loss: 144.9311 - val_mean_squared_error: 142.6566\n",
      "Epoch 467/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 98.0244 - mean_squared_error: 95.7488 \n",
      "Epoch 00467: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 542us/step - loss: 97.7558 - mean_squared_error: 95.4802 - val_loss: 132.4938 - val_mean_squared_error: 130.2176\n",
      "Epoch 468/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 102.0848 - mean_squared_error: 99.8074\n",
      "Epoch 00468: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 539us/step - loss: 102.3958 - mean_squared_error: 100.1183 - val_loss: 152.0781 - val_mean_squared_error: 149.7995\n",
      "Epoch 469/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 99.7798 - mean_squared_error: 97.5006 \n",
      "Epoch 00469: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 537us/step - loss: 100.4036 - mean_squared_error: 98.1244 - val_loss: 134.1745 - val_mean_squared_error: 131.8944\n",
      "Epoch 470/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 100.5774 - mean_squared_error: 98.2970\n",
      "Epoch 00470: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 540us/step - loss: 101.2920 - mean_squared_error: 99.0115 - val_loss: 126.5377 - val_mean_squared_error: 124.2566\n",
      "Epoch 471/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 98.0502 - mean_squared_error: 95.7684\n",
      "Epoch 00471: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 540us/step - loss: 98.3163 - mean_squared_error: 96.0345 - val_loss: 134.7676 - val_mean_squared_error: 132.4852\n",
      "Epoch 472/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 99.9061 - mean_squared_error: 97.6229\n",
      "Epoch 00472: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 539us/step - loss: 99.6568 - mean_squared_error: 97.3735 - val_loss: 125.4911 - val_mean_squared_error: 123.2072\n",
      "Epoch 473/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 98.5265 - mean_squared_error: 96.2418\n",
      "Epoch 00473: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 539us/step - loss: 98.6584 - mean_squared_error: 96.3737 - val_loss: 149.1914 - val_mean_squared_error: 146.9059\n",
      "Epoch 474/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 96.5862 - mean_squared_error: 94.2998\n",
      "Epoch 00474: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 539us/step - loss: 97.3108 - mean_squared_error: 95.0244 - val_loss: 142.0338 - val_mean_squared_error: 139.7463\n",
      "Epoch 475/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 97.4604 - mean_squared_error: 95.1725\n",
      "Epoch 00475: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 539us/step - loss: 97.1274 - mean_squared_error: 94.8396 - val_loss: 125.4001 - val_mean_squared_error: 123.1113\n",
      "Epoch 476/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 97.3419 - mean_squared_error: 95.0525\n",
      "Epoch 00476: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 539us/step - loss: 97.5537 - mean_squared_error: 95.2642 - val_loss: 128.4922 - val_mean_squared_error: 126.2019\n",
      "Epoch 477/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 98.7855 - mean_squared_error: 96.4948\n",
      "Epoch 00477: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 540us/step - loss: 99.9760 - mean_squared_error: 97.6852 - val_loss: 142.1942 - val_mean_squared_error: 139.9030\n",
      "Epoch 478/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 101.1167 - mean_squared_error: 98.8244\n",
      "Epoch 00478: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 542us/step - loss: 101.2368 - mean_squared_error: 98.9444 - val_loss: 137.9729 - val_mean_squared_error: 135.6798\n",
      "Epoch 479/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 99.5675 - mean_squared_error: 97.2735 \n",
      "Epoch 00479: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 535us/step - loss: 99.6669 - mean_squared_error: 97.3730 - val_loss: 134.3409 - val_mean_squared_error: 132.0462\n",
      "Epoch 480/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 96.0926 - mean_squared_error: 93.7973\n",
      "Epoch 00480: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 540us/step - loss: 96.0652 - mean_squared_error: 93.7698 - val_loss: 130.2410 - val_mean_squared_error: 127.9447\n",
      "Epoch 481/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 101.3801 - mean_squared_error: 99.0826\n",
      "Epoch 00481: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 539us/step - loss: 101.1652 - mean_squared_error: 98.8677 - val_loss: 133.3960 - val_mean_squared_error: 131.0975\n",
      "Epoch 482/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 97.1889 - mean_squared_error: 94.8898\n",
      "Epoch 00482: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 539us/step - loss: 97.7096 - mean_squared_error: 95.4105 - val_loss: 126.4967 - val_mean_squared_error: 124.1971\n",
      "Epoch 483/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 96.3533 - mean_squared_error: 94.0532\n",
      "Epoch 00483: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 537us/step - loss: 96.1640 - mean_squared_error: 93.8639 - val_loss: 133.2852 - val_mean_squared_error: 130.9848\n",
      "Epoch 484/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 98.3538 - mean_squared_error: 96.0526\n",
      "Epoch 00484: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 540us/step - loss: 98.8333 - mean_squared_error: 96.5320 - val_loss: 126.7974 - val_mean_squared_error: 124.4953\n",
      "Epoch 485/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 98.1245 - mean_squared_error: 95.8212\n",
      "Epoch 00485: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 539us/step - loss: 98.0921 - mean_squared_error: 95.7887 - val_loss: 138.6136 - val_mean_squared_error: 136.3092\n",
      "Epoch 486/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 96.2238 - mean_squared_error: 93.9188\n",
      "Epoch 00486: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 542us/step - loss: 97.1937 - mean_squared_error: 94.8888 - val_loss: 136.4168 - val_mean_squared_error: 134.1111\n",
      "Epoch 487/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 98.4997 - mean_squared_error: 96.1932 \n",
      "Epoch 00487: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 539us/step - loss: 98.7358 - mean_squared_error: 96.4293 - val_loss: 124.5071 - val_mean_squared_error: 122.1997\n",
      "Epoch 488/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 96.7964 - mean_squared_error: 94.4882\n",
      "Epoch 00488: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 540us/step - loss: 96.4923 - mean_squared_error: 94.1842 - val_loss: 128.0480 - val_mean_squared_error: 125.7395\n",
      "Epoch 489/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 96.9974 - mean_squared_error: 94.6879\n",
      "Epoch 00489: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 539us/step - loss: 97.6366 - mean_squared_error: 95.3271 - val_loss: 130.0092 - val_mean_squared_error: 127.6990\n",
      "Epoch 490/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 97.7627 - mean_squared_error: 95.4514\n",
      "Epoch 00490: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 537us/step - loss: 97.3023 - mean_squared_error: 94.9910 - val_loss: 126.9087 - val_mean_squared_error: 124.5969\n",
      "Epoch 491/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 96.4524 - mean_squared_error: 94.1395\n",
      "Epoch 00491: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 537us/step - loss: 96.5965 - mean_squared_error: 94.2837 - val_loss: 134.1026 - val_mean_squared_error: 131.7891\n",
      "Epoch 492/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 96.5260 - mean_squared_error: 94.2117\n",
      "Epoch 00492: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 540us/step - loss: 96.6276 - mean_squared_error: 94.3132 - val_loss: 123.5993 - val_mean_squared_error: 121.2846\n",
      "Epoch 493/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 96.4530 - mean_squared_error: 94.1377\n",
      "Epoch 00493: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 539us/step - loss: 96.3018 - mean_squared_error: 93.9865 - val_loss: 129.8236 - val_mean_squared_error: 127.5076\n",
      "Epoch 494/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 98.4255 - mean_squared_error: 96.1091\n",
      "Epoch 00494: val_loss did not improve from 121.42061\n",
      "526/526 [==============================] - 0s 546us/step - loss: 98.1342 - mean_squared_error: 95.8177 - val_loss: 124.5842 - val_mean_squared_error: 122.2669\n",
      "Epoch 495/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 96.6987 - mean_squared_error: 94.3807\n",
      "Epoch 00495: val_loss improved from 121.42061 to 118.92934, saving model to model4.hdf5\n",
      "526/526 [==============================] - 0s 732us/step - loss: 96.2983 - mean_squared_error: 93.9803 - val_loss: 118.9293 - val_mean_squared_error: 116.6106\n",
      "Epoch 496/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 98.4040 - mean_squared_error: 96.0845\n",
      "Epoch 00496: val_loss did not improve from 118.92934\n",
      "526/526 [==============================] - 0s 540us/step - loss: 98.7075 - mean_squared_error: 96.3879 - val_loss: 130.4202 - val_mean_squared_error: 128.0996\n",
      "Epoch 497/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 96.6001 - mean_squared_error: 94.2788\n",
      "Epoch 00497: val_loss did not improve from 118.92934\n",
      "526/526 [==============================] - 0s 539us/step - loss: 96.5565 - mean_squared_error: 94.2351 - val_loss: 123.8396 - val_mean_squared_error: 121.5176\n",
      "Epoch 498/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 100.9583 - mean_squared_error: 98.6357\n",
      "Epoch 00498: val_loss did not improve from 118.92934\n",
      "526/526 [==============================] - 0s 537us/step - loss: 100.6497 - mean_squared_error: 98.3271 - val_loss: 132.9312 - val_mean_squared_error: 130.6073\n",
      "Epoch 499/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508/526 [===========================>..] - ETA: 0s - loss: 96.0426 - mean_squared_error: 93.7179\n",
      "Epoch 00499: val_loss did not improve from 118.92934\n",
      "526/526 [==============================] - 0s 542us/step - loss: 95.7961 - mean_squared_error: 93.4714 - val_loss: 144.9539 - val_mean_squared_error: 142.6286\n",
      "Epoch 500/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 95.3606 - mean_squared_error: 93.0349\n",
      "Epoch 00500: val_loss did not improve from 118.92934\n",
      "526/526 [==============================] - 0s 539us/step - loss: 95.2375 - mean_squared_error: 92.9118 - val_loss: 131.6003 - val_mean_squared_error: 129.2739\n"
     ]
    }
   ],
   "source": [
    "model4 = models.Sequential()\n",
    "model4.add(layers.Dense(256,activation=\"relu\",kernel_regularizer=regularizers.l2(0.005),input_dim=81))\n",
    "model4.add(layers.Dense(128,activation=\"relu\",kernel_regularizer=regularizers.l2(0.005)))\n",
    "model4.add(layers.Dense(128,activation=\"relu\",kernel_regularizer=regularizers.l2(0.005)))\n",
    "model4.add(layers.Dense(1))\n",
    "model4.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    loss = losses.mean_squared_error,\n",
    "    metrics = ['mean_squared_error']\n",
    ")\n",
    "file_path = \"model4.hdf5\"\n",
    "checkpoint = ModelCheckpoint(file_path,monitor='val_loss', verbose=1,\n",
    "                             save_best_only=True,period=1)\n",
    "train_history4 = model4.fit(x_train,y_train,epochs=500,batch_size = 32,\n",
    "                            validation_data = (x_val,y_val),callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a9cb103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 4185.5264 - mean_squared_error: 4164.3105\n",
      "Epoch 00001: val_loss improved from inf to 658.16937, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 933us/step - loss: 4127.1987 - mean_squared_error: 4106.0127 - val_loss: 658.1694 - val_mean_squared_error: 638.7418\n",
      "Epoch 2/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 568.0451 - mean_squared_error: 549.6063\n",
      "Epoch 00002: val_loss improved from 658.16937 to 484.88010, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 784us/step - loss: 566.5416 - mean_squared_error: 548.1157 - val_loss: 484.8801 - val_mean_squared_error: 467.1358\n",
      "Epoch 3/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 477.1453 - mean_squared_error: 459.6022\n",
      "Epoch 00003: val_loss improved from 484.88010 to 397.84381, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 752us/step - loss: 477.2976 - mean_squared_error: 459.7577 - val_loss: 397.8438 - val_mean_squared_error: 380.3993\n",
      "Epoch 4/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 426.1269 - mean_squared_error: 408.7232\n",
      "Epoch 00004: val_loss did not improve from 397.84381\n",
      "526/526 [==============================] - 0s 540us/step - loss: 424.9918 - mean_squared_error: 407.5894 - val_loss: 419.6299 - val_mean_squared_error: 402.2728\n",
      "Epoch 5/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 435.1188 - mean_squared_error: 417.8092\n",
      "Epoch 00005: val_loss improved from 397.84381 to 385.18002, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 662us/step - loss: 435.1704 - mean_squared_error: 417.8620 - val_loss: 385.1800 - val_mean_squared_error: 367.9188\n",
      "Epoch 6/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 444.1137 - mean_squared_error: 426.8938\n",
      "Epoch 00006: val_loss did not improve from 385.18002\n",
      "526/526 [==============================] - 0s 535us/step - loss: 442.8718 - mean_squared_error: 425.6526 - val_loss: 409.4615 - val_mean_squared_error: 392.2837\n",
      "Epoch 7/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 446.5198 - mean_squared_error: 429.3820\n",
      "Epoch 00007: val_loss improved from 385.18002 to 357.43546, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 764us/step - loss: 448.2866 - mean_squared_error: 431.1501 - val_loss: 357.4355 - val_mean_squared_error: 340.3412\n",
      "Epoch 8/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 470.2113 - mean_squared_error: 453.1564\n",
      "Epoch 00008: val_loss did not improve from 357.43546\n",
      "526/526 [==============================] - 0s 539us/step - loss: 468.8481 - mean_squared_error: 451.7941 - val_loss: 365.3806 - val_mean_squared_error: 348.3668\n",
      "Epoch 9/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 386.6362 - mean_squared_error: 369.6598\n",
      "Epoch 00009: val_loss improved from 357.43546 to 335.04358, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 772us/step - loss: 386.5395 - mean_squared_error: 369.5643 - val_loss: 335.0436 - val_mean_squared_error: 318.1092\n",
      "Epoch 10/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 368.3720 - mean_squared_error: 351.4788\n",
      "Epoch 00010: val_loss did not improve from 335.04358\n",
      "526/526 [==============================] - 0s 544us/step - loss: 369.8101 - mean_squared_error: 352.9184 - val_loss: 445.1308 - val_mean_squared_error: 428.2819\n",
      "Epoch 11/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 379.0435 - mean_squared_error: 362.2352\n",
      "Epoch 00011: val_loss did not improve from 335.04358\n",
      "526/526 [==============================] - 0s 539us/step - loss: 378.4514 - mean_squared_error: 361.6442 - val_loss: 398.8614 - val_mean_squared_error: 382.0974\n",
      "Epoch 12/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 402.9720 - mean_squared_error: 386.2490\n",
      "Epoch 00012: val_loss did not improve from 335.04358\n",
      "526/526 [==============================] - 0s 539us/step - loss: 405.2042 - mean_squared_error: 388.4822 - val_loss: 485.6312 - val_mean_squared_error: 468.9527\n",
      "Epoch 13/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 396.7824 - mean_squared_error: 380.1392\n",
      "Epoch 00013: val_loss did not improve from 335.04358\n",
      "526/526 [==============================] - 0s 544us/step - loss: 395.8246 - mean_squared_error: 379.1827 - val_loss: 350.6661 - val_mean_squared_error: 334.0640\n",
      "Epoch 14/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 338.3658 - mean_squared_error: 321.8047\n",
      "Epoch 00014: val_loss did not improve from 335.04358\n",
      "526/526 [==============================] - 0s 537us/step - loss: 338.1456 - mean_squared_error: 321.5854 - val_loss: 363.9094 - val_mean_squared_error: 347.3851\n",
      "Epoch 15/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 385.5769 - mean_squared_error: 369.0942\n",
      "Epoch 00015: val_loss did not improve from 335.04358\n",
      "526/526 [==============================] - 0s 539us/step - loss: 383.9370 - mean_squared_error: 367.4553 - val_loss: 380.4407 - val_mean_squared_error: 363.9991\n",
      "Epoch 16/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 346.3023 - mean_squared_error: 329.9002\n",
      "Epoch 00016: val_loss did not improve from 335.04358\n",
      "526/526 [==============================] - 0s 537us/step - loss: 345.7038 - mean_squared_error: 329.3024 - val_loss: 422.9455 - val_mean_squared_error: 406.5811\n",
      "Epoch 17/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 330.5278 - mean_squared_error: 314.2027\n",
      "Epoch 00017: val_loss improved from 335.04358 to 298.61838, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 805us/step - loss: 331.3916 - mean_squared_error: 315.0679 - val_loss: 298.6184 - val_mean_squared_error: 282.3371\n",
      "Epoch 18/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 331.3217 - mean_squared_error: 315.0826\n",
      "Epoch 00018: val_loss did not improve from 298.61838\n",
      "526/526 [==============================] - 0s 539us/step - loss: 331.9357 - mean_squared_error: 315.6977 - val_loss: 381.8266 - val_mean_squared_error: 365.6284\n",
      "Epoch 19/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 344.2132 - mean_squared_error: 328.0544\n",
      "Epoch 00019: val_loss did not improve from 298.61838\n",
      "526/526 [==============================] - 0s 540us/step - loss: 343.6341 - mean_squared_error: 327.4764 - val_loss: 428.1732 - val_mean_squared_error: 412.0578\n",
      "Epoch 20/500\n",
      "506/526 [===========================>..] - ETA: 0s - loss: 354.9257 - mean_squared_error: 338.8480\n",
      "Epoch 00020: val_loss improved from 298.61838 to 291.65845, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 719us/step - loss: 352.1920 - mean_squared_error: 336.1161 - val_loss: 291.6584 - val_mean_squared_error: 275.6288\n",
      "Epoch 21/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 330.6660 - mean_squared_error: 314.6814\n",
      "Epoch 00021: val_loss did not improve from 291.65845\n",
      "526/526 [==============================] - 0s 542us/step - loss: 329.5469 - mean_squared_error: 313.5637 - val_loss: 314.0271 - val_mean_squared_error: 298.0879\n",
      "Epoch 22/500\n",
      "504/526 [===========================>..] - ETA: 0s - loss: 331.9608 - mean_squared_error: 316.0644\n",
      "Epoch 00022: val_loss improved from 291.65845 to 283.98923, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 761us/step - loss: 329.6945 - mean_squared_error: 313.7999 - val_loss: 283.9892 - val_mean_squared_error: 268.1393\n",
      "Epoch 23/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 311.1817 - mean_squared_error: 295.3722\n",
      "Epoch 00023: val_loss improved from 283.98923 to 275.06793, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 709us/step - loss: 311.3394 - mean_squared_error: 295.5314 - val_loss: 275.0679 - val_mean_squared_error: 259.3036\n",
      "Epoch 24/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 335.4789 - mean_squared_error: 319.7542\n",
      "Epoch 00024: val_loss did not improve from 275.06793\n",
      "526/526 [==============================] - 0s 542us/step - loss: 333.6579 - mean_squared_error: 317.9345 - val_loss: 281.1760 - val_mean_squared_error: 265.4983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 301.7913 - mean_squared_error: 286.1574\n",
      "Epoch 00025: val_loss did not improve from 275.06793\n",
      "526/526 [==============================] - 0s 542us/step - loss: 303.7250 - mean_squared_error: 288.0926 - val_loss: 277.4336 - val_mean_squared_error: 261.8473\n",
      "Epoch 26/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 307.4333 - mean_squared_error: 291.8926\n",
      "Epoch 00026: val_loss did not improve from 275.06793\n",
      "526/526 [==============================] - 0s 540us/step - loss: 306.9437 - mean_squared_error: 291.4044 - val_loss: 283.9955 - val_mean_squared_error: 268.4999\n",
      "Epoch 27/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 310.0744 - mean_squared_error: 294.6250\n",
      "Epoch 00027: val_loss improved from 275.06793 to 274.85873, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 746us/step - loss: 311.5310 - mean_squared_error: 296.0825 - val_loss: 274.8587 - val_mean_squared_error: 259.4584\n",
      "Epoch 28/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 312.3201 - mean_squared_error: 296.9633\n",
      "Epoch 00028: val_loss did not improve from 274.85873\n",
      "526/526 [==============================] - 0s 539us/step - loss: 312.2262 - mean_squared_error: 296.8706 - val_loss: 314.6461 - val_mean_squared_error: 299.3370\n",
      "Epoch 29/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 307.4682 - mean_squared_error: 292.2009\n",
      "Epoch 00029: val_loss did not improve from 274.85873\n",
      "526/526 [==============================] - 0s 542us/step - loss: 309.3456 - mean_squared_error: 294.0797 - val_loss: 393.2126 - val_mean_squared_error: 377.9934\n",
      "Epoch 30/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 296.1093 - mean_squared_error: 280.9400\n",
      "Epoch 00030: val_loss improved from 274.85873 to 273.61050, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 778us/step - loss: 295.8109 - mean_squared_error: 280.6434 - val_loss: 273.6105 - val_mean_squared_error: 258.4954\n",
      "Epoch 31/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 292.5900 - mean_squared_error: 277.5183\n",
      "Epoch 00031: val_loss did not improve from 273.61050\n",
      "526/526 [==============================] - 0s 542us/step - loss: 293.9106 - mean_squared_error: 278.8404 - val_loss: 290.5850 - val_mean_squared_error: 275.5622\n",
      "Epoch 32/500\n",
      "506/526 [===========================>..] - ETA: 0s - loss: 296.1244 - mean_squared_error: 281.1484\n",
      "Epoch 00032: val_loss did not improve from 273.61050\n",
      "526/526 [==============================] - 0s 544us/step - loss: 296.2641 - mean_squared_error: 281.2897 - val_loss: 298.2218 - val_mean_squared_error: 283.2908\n",
      "Epoch 33/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 284.5452 - mean_squared_error: 269.6608\n",
      "Epoch 00033: val_loss did not improve from 273.61050\n",
      "526/526 [==============================] - 0s 544us/step - loss: 286.3148 - mean_squared_error: 271.4322 - val_loss: 300.8489 - val_mean_squared_error: 286.0125\n",
      "Epoch 34/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 290.5132 - mean_squared_error: 275.7243\n",
      "Epoch 00034: val_loss did not improve from 273.61050\n",
      "526/526 [==============================] - 0s 539us/step - loss: 289.1134 - mean_squared_error: 274.3258 - val_loss: 313.1172 - val_mean_squared_error: 298.3824\n",
      "Epoch 35/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 271.3218 - mean_squared_error: 256.6342\n",
      "Epoch 00035: val_loss did not improve from 273.61050\n",
      "526/526 [==============================] - 0s 537us/step - loss: 272.5220 - mean_squared_error: 257.8354 - val_loss: 295.5623 - val_mean_squared_error: 280.9237\n",
      "Epoch 36/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 292.5349 - mean_squared_error: 277.9387\n",
      "Epoch 00036: val_loss did not improve from 273.61050\n",
      "526/526 [==============================] - 0s 539us/step - loss: 291.3636 - mean_squared_error: 276.7686 - val_loss: 320.4937 - val_mean_squared_error: 305.9451\n",
      "Epoch 37/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 281.3450 - mean_squared_error: 266.8416\n",
      "Epoch 00037: val_loss did not improve from 273.61050\n",
      "526/526 [==============================] - 0s 539us/step - loss: 281.4995 - mean_squared_error: 266.9973 - val_loss: 322.8532 - val_mean_squared_error: 308.4014\n",
      "Epoch 38/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 275.4094 - mean_squared_error: 261.0042\n",
      "Epoch 00038: val_loss did not improve from 273.61050\n",
      "526/526 [==============================] - 0s 539us/step - loss: 277.2596 - mean_squared_error: 262.8556 - val_loss: 277.6646 - val_mean_squared_error: 263.3089\n",
      "Epoch 39/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 270.0986 - mean_squared_error: 255.7877\n",
      "Epoch 00039: val_loss improved from 273.61050 to 268.45279, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 795us/step - loss: 270.5994 - mean_squared_error: 256.2895 - val_loss: 268.4528 - val_mean_squared_error: 254.1868\n",
      "Epoch 40/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 287.6031 - mean_squared_error: 273.3827\n",
      "Epoch 00040: val_loss improved from 268.45279 to 264.95053, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 695us/step - loss: 288.3928 - mean_squared_error: 274.1738 - val_loss: 264.9505 - val_mean_squared_error: 250.7791\n",
      "Epoch 41/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 271.7584 - mean_squared_error: 257.6318\n",
      "Epoch 00041: val_loss did not improve from 264.95053\n",
      "526/526 [==============================] - 0s 539us/step - loss: 272.2000 - mean_squared_error: 258.0747 - val_loss: 290.0260 - val_mean_squared_error: 275.9459\n",
      "Epoch 42/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 275.1202 - mean_squared_error: 261.0845\n",
      "Epoch 00042: val_loss improved from 264.95053 to 241.75311, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 782us/step - loss: 274.2978 - mean_squared_error: 260.2636 - val_loss: 241.7531 - val_mean_squared_error: 227.7659\n",
      "Epoch 43/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 267.5312 - mean_squared_error: 253.5819\n",
      "Epoch 00043: val_loss did not improve from 241.75311\n",
      "526/526 [==============================] - 0s 539us/step - loss: 268.9491 - mean_squared_error: 255.0008 - val_loss: 273.9449 - val_mean_squared_error: 260.0383\n",
      "Epoch 44/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 267.4138 - mean_squared_error: 253.5470\n",
      "Epoch 00044: val_loss did not improve from 241.75311\n",
      "526/526 [==============================] - 0s 540us/step - loss: 268.4488 - mean_squared_error: 254.5831 - val_loss: 246.3358 - val_mean_squared_error: 232.5126\n",
      "Epoch 45/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 263.6370 - mean_squared_error: 249.8475\n",
      "Epoch 00045: val_loss improved from 241.75311 to 238.22650, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 805us/step - loss: 264.5469 - mean_squared_error: 250.7585 - val_loss: 238.2265 - val_mean_squared_error: 224.4750\n",
      "Epoch 46/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 264.7275 - mean_squared_error: 251.0170\n",
      "Epoch 00046: val_loss did not improve from 238.22650\n",
      "526/526 [==============================] - 0s 537us/step - loss: 265.5331 - mean_squared_error: 251.8236 - val_loss: 312.5172 - val_mean_squared_error: 298.8465\n",
      "Epoch 47/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 262.9120 - mean_squared_error: 249.2682\n",
      "Epoch 00047: val_loss did not improve from 238.22650\n",
      "526/526 [==============================] - 0s 537us/step - loss: 262.3737 - mean_squared_error: 248.7307 - val_loss: 249.6034 - val_mean_squared_error: 235.9987\n",
      "Epoch 48/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 252.7412 - mean_squared_error: 239.1758\n",
      "Epoch 00048: val_loss did not improve from 238.22650\n",
      "526/526 [==============================] - 0s 539us/step - loss: 252.1460 - mean_squared_error: 238.5816 - val_loss: 258.1686 - val_mean_squared_error: 244.6443\n",
      "Epoch 49/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 265.3618 - mean_squared_error: 251.8723\n",
      "Epoch 00049: val_loss did not improve from 238.22650\n",
      "526/526 [==============================] - 0s 542us/step - loss: 265.6315 - mean_squared_error: 252.1432 - val_loss: 273.8581 - val_mean_squared_error: 260.4080\n",
      "Epoch 50/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 256.7822 - mean_squared_error: 243.3712\n",
      "Epoch 00050: val_loss did not improve from 238.22650\n",
      "526/526 [==============================] - 0s 535us/step - loss: 257.3123 - mean_squared_error: 243.9020 - val_loss: 272.9241 - val_mean_squared_error: 259.5516\n",
      "Epoch 51/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 258.4326 - mean_squared_error: 245.0992\n",
      "Epoch 00051: val_loss did not improve from 238.22650\n",
      "526/526 [==============================] - 0s 537us/step - loss: 258.0669 - mean_squared_error: 244.7346 - val_loss: 264.8376 - val_mean_squared_error: 251.5507\n",
      "Epoch 52/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 252.1082 - mean_squared_error: 238.8606\n",
      "Epoch 00052: val_loss did not improve from 238.22650\n",
      "526/526 [==============================] - 0s 539us/step - loss: 252.4079 - mean_squared_error: 239.1612 - val_loss: 260.8233 - val_mean_squared_error: 247.6140\n",
      "Epoch 53/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 260.4085 - mean_squared_error: 247.2383\n",
      "Epoch 00053: val_loss did not improve from 238.22650\n",
      "526/526 [==============================] - 0s 542us/step - loss: 261.4131 - mean_squared_error: 248.2441 - val_loss: 248.4261 - val_mean_squared_error: 235.2937\n",
      "Epoch 54/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 256.3857 - mean_squared_error: 243.2961\n",
      "Epoch 00054: val_loss did not improve from 238.22650\n",
      "526/526 [==============================] - 0s 539us/step - loss: 256.6291 - mean_squared_error: 243.5405 - val_loss: 292.7940 - val_mean_squared_error: 279.7455\n",
      "Epoch 55/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 249.3446 - mean_squared_error: 236.3293\n",
      "Epoch 00055: val_loss improved from 238.22650 to 233.47243, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 803us/step - loss: 249.7832 - mean_squared_error: 236.7690 - val_loss: 233.4724 - val_mean_squared_error: 220.4974\n",
      "Epoch 56/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 244.1692 - mean_squared_error: 231.2317\n",
      "Epoch 00056: val_loss did not improve from 233.47243\n",
      "526/526 [==============================] - 0s 542us/step - loss: 243.1637 - mean_squared_error: 230.2274 - val_loss: 279.8556 - val_mean_squared_error: 266.9530\n",
      "Epoch 57/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 252.3993 - mean_squared_error: 239.5241\n",
      "Epoch 00057: val_loss did not improve from 233.47243\n",
      "526/526 [==============================] - 0s 539us/step - loss: 252.1846 - mean_squared_error: 239.3102 - val_loss: 309.3308 - val_mean_squared_error: 296.4893\n",
      "Epoch 58/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 248.3407 - mean_squared_error: 235.5331\n",
      "Epoch 00058: val_loss did not improve from 233.47243\n",
      "526/526 [==============================] - 0s 539us/step - loss: 247.5635 - mean_squared_error: 234.7565 - val_loss: 313.9623 - val_mean_squared_error: 301.1820\n",
      "Epoch 59/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 243.0225 - mean_squared_error: 230.2731\n",
      "Epoch 00059: val_loss did not improve from 233.47243\n",
      "526/526 [==============================] - 0s 540us/step - loss: 243.5018 - mean_squared_error: 230.7534 - val_loss: 240.7140 - val_mean_squared_error: 227.9949\n",
      "Epoch 60/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 242.8894 - mean_squared_error: 230.1986\n",
      "Epoch 00060: val_loss did not improve from 233.47243\n",
      "526/526 [==============================] - 0s 542us/step - loss: 242.3011 - mean_squared_error: 229.6112 - val_loss: 252.5178 - val_mean_squared_error: 239.8564\n",
      "Epoch 61/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 240.7377 - mean_squared_error: 228.1000\n",
      "Epoch 00061: val_loss did not improve from 233.47243\n",
      "526/526 [==============================] - 0s 539us/step - loss: 240.9444 - mean_squared_error: 228.3073 - val_loss: 245.4336 - val_mean_squared_error: 232.8215\n",
      "Epoch 62/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 241.0463 - mean_squared_error: 228.4647\n",
      "Epoch 00062: val_loss improved from 233.47243 to 232.08781, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 732us/step - loss: 240.8642 - mean_squared_error: 228.2832 - val_loss: 232.0878 - val_mean_squared_error: 219.5352\n",
      "Epoch 63/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 241.2812 - mean_squared_error: 228.7548\n",
      "Epoch 00063: val_loss did not improve from 232.08781\n",
      "526/526 [==============================] - 0s 544us/step - loss: 241.0066 - mean_squared_error: 228.4811 - val_loss: 249.9264 - val_mean_squared_error: 237.4261\n",
      "Epoch 64/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 252.0938 - mean_squared_error: 239.6253\n",
      "Epoch 00064: val_loss did not improve from 232.08781\n",
      "526/526 [==============================] - 0s 542us/step - loss: 251.3785 - mean_squared_error: 238.9109 - val_loss: 262.3379 - val_mean_squared_error: 249.9023\n",
      "Epoch 65/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 242.0311 - mean_squared_error: 229.6215\n",
      "Epoch 00065: val_loss did not improve from 232.08781\n",
      "526/526 [==============================] - 0s 540us/step - loss: 241.5325 - mean_squared_error: 229.1236 - val_loss: 250.9658 - val_mean_squared_error: 238.5821\n",
      "Epoch 66/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 233.9080 - mean_squared_error: 221.5549\n",
      "Epoch 00066: val_loss did not improve from 232.08781\n",
      "526/526 [==============================] - 0s 542us/step - loss: 233.9598 - mean_squared_error: 221.6077 - val_loss: 248.9988 - val_mean_squared_error: 236.6773\n",
      "Epoch 67/500\n",
      "505/526 [===========================>..] - ETA: 0s - loss: 247.7796 - mean_squared_error: 235.4776\n",
      "Epoch 00067: val_loss did not improve from 232.08781\n",
      "526/526 [==============================] - 0s 546us/step - loss: 248.0538 - mean_squared_error: 235.7525 - val_loss: 260.7806 - val_mean_squared_error: 248.4982\n",
      "Epoch 68/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 238.9933 - mean_squared_error: 226.7370\n",
      "Epoch 00068: val_loss did not improve from 232.08781\n",
      "526/526 [==============================] - 0s 539us/step - loss: 238.3994 - mean_squared_error: 226.1438 - val_loss: 240.5109 - val_mean_squared_error: 228.2825\n",
      "Epoch 69/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 238.1783 - mean_squared_error: 225.9675\n",
      "Epoch 00069: val_loss did not improve from 232.08781\n",
      "526/526 [==============================] - 0s 539us/step - loss: 237.2347 - mean_squared_error: 225.0243 - val_loss: 238.2499 - val_mean_squared_error: 226.0572\n",
      "Epoch 70/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 232.5347 - mean_squared_error: 220.3633\n",
      "Epoch 00070: val_loss did not improve from 232.08781\n",
      "526/526 [==============================] - 0s 539us/step - loss: 233.5109 - mean_squared_error: 221.3403 - val_loss: 281.2468 - val_mean_squared_error: 269.1045\n",
      "Epoch 71/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 231.8530 - mean_squared_error: 219.7278\n",
      "Epoch 00071: val_loss did not improve from 232.08781\n",
      "526/526 [==============================] - 0s 542us/step - loss: 231.6077 - mean_squared_error: 219.4832 - val_loss: 237.9097 - val_mean_squared_error: 225.8045\n",
      "Epoch 72/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 227.8945 - mean_squared_error: 215.8041\n",
      "Epoch 00072: val_loss did not improve from 232.08781\n",
      "526/526 [==============================] - 0s 539us/step - loss: 227.6048 - mean_squared_error: 215.5149 - val_loss: 258.4437 - val_mean_squared_error: 246.3712\n",
      "Epoch 73/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 228.9246 - mean_squared_error: 216.8734\n",
      "Epoch 00073: val_loss did not improve from 232.08781\n",
      "526/526 [==============================] - 0s 542us/step - loss: 229.2468 - mean_squared_error: 217.1963 - val_loss: 259.4077 - val_mean_squared_error: 247.3771\n",
      "Epoch 74/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508/526 [===========================>..] - ETA: 0s - loss: 235.8539 - mean_squared_error: 223.8369\n",
      "Epoch 00074: val_loss did not improve from 232.08781\n",
      "526/526 [==============================] - 0s 542us/step - loss: 235.8884 - mean_squared_error: 223.8719 - val_loss: 241.3847 - val_mean_squared_error: 229.3818\n",
      "Epoch 75/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 230.4618 - mean_squared_error: 218.4735\n",
      "Epoch 00075: val_loss improved from 232.08781 to 227.56624, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 767us/step - loss: 230.6526 - mean_squared_error: 218.6645 - val_loss: 227.5662 - val_mean_squared_error: 215.5851\n",
      "Epoch 76/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 229.5392 - mean_squared_error: 217.5784\n",
      "Epoch 00076: val_loss improved from 227.56624 to 221.27219, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 727us/step - loss: 229.1596 - mean_squared_error: 217.1993 - val_loss: 221.2722 - val_mean_squared_error: 209.3313\n",
      "Epoch 77/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 230.9813 - mean_squared_error: 219.0570\n",
      "Epoch 00077: val_loss did not improve from 221.27219\n",
      "526/526 [==============================] - 0s 537us/step - loss: 231.7929 - mean_squared_error: 219.8689 - val_loss: 238.2346 - val_mean_squared_error: 226.3275\n",
      "Epoch 78/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 228.7042 - mean_squared_error: 216.8094\n",
      "Epoch 00078: val_loss did not improve from 221.27219\n",
      "526/526 [==============================] - 0s 539us/step - loss: 229.0986 - mean_squared_error: 217.2042 - val_loss: 339.5080 - val_mean_squared_error: 327.6289\n",
      "Epoch 79/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 224.7799 - mean_squared_error: 212.9123\n",
      "Epoch 00079: val_loss did not improve from 221.27219\n",
      "526/526 [==============================] - 0s 540us/step - loss: 225.0478 - mean_squared_error: 213.1803 - val_loss: 239.7600 - val_mean_squared_error: 227.8968\n",
      "Epoch 80/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 228.5397 - mean_squared_error: 216.6974\n",
      "Epoch 00080: val_loss did not improve from 221.27219\n",
      "526/526 [==============================] - 0s 540us/step - loss: 227.8873 - mean_squared_error: 216.0456 - val_loss: 243.3076 - val_mean_squared_error: 231.4854\n",
      "Epoch 81/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 221.0879 - mean_squared_error: 209.2798\n",
      "Epoch 00081: val_loss did not improve from 221.27219\n",
      "526/526 [==============================] - 0s 540us/step - loss: 222.7341 - mean_squared_error: 210.9264 - val_loss: 260.8022 - val_mean_squared_error: 249.0123\n",
      "Epoch 82/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 225.8845 - mean_squared_error: 214.1057\n",
      "Epoch 00082: val_loss did not improve from 221.27219\n",
      "526/526 [==============================] - 0s 537us/step - loss: 225.7006 - mean_squared_error: 213.9221 - val_loss: 271.2413 - val_mean_squared_error: 259.4743\n",
      "Epoch 83/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 230.0091 - mean_squared_error: 218.2499\n",
      "Epoch 00083: val_loss did not improve from 221.27219\n",
      "526/526 [==============================] - 0s 539us/step - loss: 229.0640 - mean_squared_error: 217.3048 - val_loss: 249.3219 - val_mean_squared_error: 237.5657\n",
      "Epoch 84/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 228.2535 - mean_squared_error: 216.5090\n",
      "Epoch 00084: val_loss improved from 221.27219 to 217.34657, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 755us/step - loss: 227.7354 - mean_squared_error: 215.9913 - val_loss: 217.3466 - val_mean_squared_error: 205.6139\n",
      "Epoch 85/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 224.0229 - mean_squared_error: 212.3063\n",
      "Epoch 00085: val_loss did not improve from 217.34657\n",
      "526/526 [==============================] - 0s 539us/step - loss: 223.6931 - mean_squared_error: 211.9771 - val_loss: 233.5713 - val_mean_squared_error: 221.8755\n",
      "Epoch 86/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 224.9650 - mean_squared_error: 213.2831\n",
      "Epoch 00086: val_loss did not improve from 217.34657\n",
      "526/526 [==============================] - 0s 539us/step - loss: 223.9784 - mean_squared_error: 212.2969 - val_loss: 237.6432 - val_mean_squared_error: 225.9753\n",
      "Epoch 87/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 221.9515 - mean_squared_error: 210.2979\n",
      "Epoch 00087: val_loss did not improve from 217.34657\n",
      "526/526 [==============================] - 0s 544us/step - loss: 222.5595 - mean_squared_error: 210.9064 - val_loss: 234.7923 - val_mean_squared_error: 223.1560\n",
      "Epoch 88/500\n",
      "506/526 [===========================>..] - ETA: 0s - loss: 221.2209 - mean_squared_error: 209.5916\n",
      "Epoch 00088: val_loss did not improve from 217.34657\n",
      "526/526 [==============================] - 0s 544us/step - loss: 221.9909 - mean_squared_error: 210.3622 - val_loss: 286.6407 - val_mean_squared_error: 275.0267\n",
      "Epoch 89/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 218.6311 - mean_squared_error: 207.0320\n",
      "Epoch 00089: val_loss did not improve from 217.34657\n",
      "526/526 [==============================] - 0s 540us/step - loss: 218.1369 - mean_squared_error: 206.5383 - val_loss: 221.5301 - val_mean_squared_error: 209.9503\n",
      "Epoch 90/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 218.9707 - mean_squared_error: 207.4084\n",
      "Epoch 00090: val_loss did not improve from 217.34657\n",
      "526/526 [==============================] - 0s 542us/step - loss: 219.9589 - mean_squared_error: 208.3971 - val_loss: 282.3770 - val_mean_squared_error: 270.8328\n",
      "Epoch 91/500\n",
      "505/526 [===========================>..] - ETA: 0s - loss: 219.9255 - mean_squared_error: 208.3952\n",
      "Epoch 00091: val_loss did not improve from 217.34657\n",
      "526/526 [==============================] - 0s 546us/step - loss: 220.0114 - mean_squared_error: 208.4813 - val_loss: 262.2335 - val_mean_squared_error: 250.7136\n",
      "Epoch 92/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 218.8551 - mean_squared_error: 207.3442\n",
      "Epoch 00092: val_loss did not improve from 217.34657\n",
      "526/526 [==============================] - 0s 542us/step - loss: 218.8531 - mean_squared_error: 207.3428 - val_loss: 233.1487 - val_mean_squared_error: 221.6576\n",
      "Epoch 93/500\n",
      "503/526 [===========================>..] - ETA: 0s - loss: 219.1470 - mean_squared_error: 207.6693\n",
      "Epoch 00093: val_loss did not improve from 217.34657\n",
      "526/526 [==============================] - 0s 548us/step - loss: 218.6684 - mean_squared_error: 207.1909 - val_loss: 229.5767 - val_mean_squared_error: 218.1035\n",
      "Epoch 94/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 219.8817 - mean_squared_error: 208.4266\n",
      "Epoch 00094: val_loss did not improve from 217.34657\n",
      "526/526 [==============================] - 0s 544us/step - loss: 220.6512 - mean_squared_error: 209.1965 - val_loss: 244.2836 - val_mean_squared_error: 232.8427\n",
      "Epoch 95/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 214.1512 - mean_squared_error: 202.7243\n",
      "Epoch 00095: val_loss did not improve from 217.34657\n",
      "526/526 [==============================] - 0s 542us/step - loss: 214.3089 - mean_squared_error: 202.8820 - val_loss: 244.2192 - val_mean_squared_error: 232.7948\n",
      "Epoch 96/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 214.0983 - mean_squared_error: 202.6864\n",
      "Epoch 00096: val_loss did not improve from 217.34657\n",
      "526/526 [==============================] - 0s 542us/step - loss: 215.5121 - mean_squared_error: 204.1002 - val_loss: 225.3402 - val_mean_squared_error: 213.9278\n",
      "Epoch 97/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 218.9745 - mean_squared_error: 207.5750\n",
      "Epoch 00097: val_loss did not improve from 217.34657\n",
      "526/526 [==============================] - 0s 539us/step - loss: 219.5971 - mean_squared_error: 208.1976 - val_loss: 220.9118 - val_mean_squared_error: 209.5138\n",
      "Epoch 98/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 212.2885 - mean_squared_error: 200.9051\n",
      "Epoch 00098: val_loss improved from 217.34657 to 210.07965, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 787us/step - loss: 211.9938 - mean_squared_error: 200.6106 - val_loss: 210.0797 - val_mean_squared_error: 198.7043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 215.1595 - mean_squared_error: 203.7933\n",
      "Epoch 00099: val_loss did not improve from 210.07965\n",
      "526/526 [==============================] - 0s 539us/step - loss: 216.5283 - mean_squared_error: 205.1624 - val_loss: 261.4953 - val_mean_squared_error: 250.1373\n",
      "Epoch 100/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 217.2457 - mean_squared_error: 205.8943\n",
      "Epoch 00100: val_loss did not improve from 210.07965\n",
      "526/526 [==============================] - 0s 535us/step - loss: 217.1622 - mean_squared_error: 205.8110 - val_loss: 222.3927 - val_mean_squared_error: 211.0475\n",
      "Epoch 101/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 218.0630 - mean_squared_error: 206.7201\n",
      "Epoch 00101: val_loss did not improve from 210.07965\n",
      "526/526 [==============================] - 0s 539us/step - loss: 217.8800 - mean_squared_error: 206.5369 - val_loss: 219.6397 - val_mean_squared_error: 208.2928\n",
      "Epoch 102/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 210.5208 - mean_squared_error: 199.1804\n",
      "Epoch 00102: val_loss improved from 210.07965 to 202.11974, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 774us/step - loss: 209.6308 - mean_squared_error: 198.2906 - val_loss: 202.1197 - val_mean_squared_error: 190.7863\n",
      "Epoch 103/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 215.3091 - mean_squared_error: 203.9882\n",
      "Epoch 00103: val_loss did not improve from 202.11974\n",
      "526/526 [==============================] - 0s 537us/step - loss: 215.1703 - mean_squared_error: 203.8496 - val_loss: 218.3897 - val_mean_squared_error: 207.0796\n",
      "Epoch 104/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 206.5109 - mean_squared_error: 195.2028\n",
      "Epoch 00104: val_loss did not improve from 202.11974\n",
      "526/526 [==============================] - 0s 540us/step - loss: 207.0192 - mean_squared_error: 195.7113 - val_loss: 240.4896 - val_mean_squared_error: 229.1921\n",
      "Epoch 105/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 210.9302 - mean_squared_error: 199.6408\n",
      "Epoch 00105: val_loss did not improve from 202.11974\n",
      "526/526 [==============================] - 0s 537us/step - loss: 210.8069 - mean_squared_error: 199.5175 - val_loss: 246.6344 - val_mean_squared_error: 235.3481\n",
      "Epoch 106/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 211.3186 - mean_squared_error: 200.0347\n",
      "Epoch 00106: val_loss did not improve from 202.11974\n",
      "526/526 [==============================] - 0s 537us/step - loss: 211.7392 - mean_squared_error: 200.4553 - val_loss: 217.3680 - val_mean_squared_error: 206.0867\n",
      "Epoch 107/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 205.1044 - mean_squared_error: 193.8349\n",
      "Epoch 00107: val_loss did not improve from 202.11974\n",
      "526/526 [==============================] - 0s 540us/step - loss: 205.7689 - mean_squared_error: 194.4996 - val_loss: 210.3960 - val_mean_squared_error: 199.1323\n",
      "Epoch 108/500\n",
      "504/526 [===========================>..] - ETA: 0s - loss: 208.9657 - mean_squared_error: 197.7126\n",
      "Epoch 00108: val_loss did not improve from 202.11974\n",
      "526/526 [==============================] - 0s 546us/step - loss: 208.8519 - mean_squared_error: 197.5993 - val_loss: 226.4814 - val_mean_squared_error: 215.2410\n",
      "Epoch 109/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 207.1643 - mean_squared_error: 195.9277\n",
      "Epoch 00109: val_loss did not improve from 202.11974\n",
      "526/526 [==============================] - 0s 539us/step - loss: 206.2040 - mean_squared_error: 194.9676 - val_loss: 209.1551 - val_mean_squared_error: 197.9262\n",
      "Epoch 110/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 205.5333 - mean_squared_error: 194.3148\n",
      "Epoch 00110: val_loss did not improve from 202.11974\n",
      "526/526 [==============================] - 0s 539us/step - loss: 204.8183 - mean_squared_error: 193.6002 - val_loss: 251.4223 - val_mean_squared_error: 240.2161\n",
      "Epoch 111/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 203.7600 - mean_squared_error: 192.5597\n",
      "Epoch 00111: val_loss did not improve from 202.11974\n",
      "526/526 [==============================] - 0s 542us/step - loss: 205.4474 - mean_squared_error: 194.2474 - val_loss: 203.5349 - val_mean_squared_error: 192.3415\n",
      "Epoch 112/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 207.0049 - mean_squared_error: 195.8151\n",
      "Epoch 00112: val_loss did not improve from 202.11974\n",
      "526/526 [==============================] - 0s 544us/step - loss: 208.5084 - mean_squared_error: 197.3189 - val_loss: 270.4731 - val_mean_squared_error: 259.2945\n",
      "Epoch 113/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 202.6888 - mean_squared_error: 191.5208\n",
      "Epoch 00113: val_loss did not improve from 202.11974\n",
      "526/526 [==============================] - 0s 540us/step - loss: 203.5541 - mean_squared_error: 192.3864 - val_loss: 233.8794 - val_mean_squared_error: 222.7192\n",
      "Epoch 114/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 202.0609 - mean_squared_error: 190.9113\n",
      "Epoch 00114: val_loss did not improve from 202.11974\n",
      "526/526 [==============================] - 0s 539us/step - loss: 202.8246 - mean_squared_error: 191.6750 - val_loss: 232.2325 - val_mean_squared_error: 221.0854\n",
      "Epoch 115/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 204.3467 - mean_squared_error: 193.2053\n",
      "Epoch 00115: val_loss did not improve from 202.11974\n",
      "526/526 [==============================] - 0s 540us/step - loss: 203.1212 - mean_squared_error: 191.9800 - val_loss: 228.4065 - val_mean_squared_error: 217.2725\n",
      "Epoch 116/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 201.2146 - mean_squared_error: 190.0836\n",
      "Epoch 00116: val_loss did not improve from 202.11974\n",
      "526/526 [==============================] - 0s 540us/step - loss: 201.8336 - mean_squared_error: 190.7026 - val_loss: 218.0884 - val_mean_squared_error: 206.9581\n",
      "Epoch 117/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 201.3227 - mean_squared_error: 190.2048\n",
      "Epoch 00117: val_loss did not improve from 202.11974\n",
      "526/526 [==============================] - 0s 540us/step - loss: 201.2460 - mean_squared_error: 190.1282 - val_loss: 211.9900 - val_mean_squared_error: 200.8772\n",
      "Epoch 118/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 201.0052 - mean_squared_error: 189.8926\n",
      "Epoch 00118: val_loss improved from 202.11974 to 200.42795, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 818us/step - loss: 201.1009 - mean_squared_error: 189.9886 - val_loss: 200.4279 - val_mean_squared_error: 189.3226\n",
      "Epoch 119/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 200.8320 - mean_squared_error: 189.7275\n",
      "Epoch 00119: val_loss did not improve from 200.42795\n",
      "526/526 [==============================] - 0s 539us/step - loss: 201.2376 - mean_squared_error: 190.1332 - val_loss: 280.2299 - val_mean_squared_error: 269.1296\n",
      "Epoch 120/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 201.0595 - mean_squared_error: 189.9612\n",
      "Epoch 00120: val_loss did not improve from 200.42795\n",
      "526/526 [==============================] - 0s 540us/step - loss: 201.6077 - mean_squared_error: 190.5094 - val_loss: 225.6880 - val_mean_squared_error: 214.5891\n",
      "Epoch 121/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 199.2033 - mean_squared_error: 188.1093\n",
      "Epoch 00121: val_loss improved from 200.42795 to 198.98285, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 790us/step - loss: 198.7590 - mean_squared_error: 187.6652 - val_loss: 198.9828 - val_mean_squared_error: 187.8959\n",
      "Epoch 122/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 201.2441 - mean_squared_error: 190.1564\n",
      "Epoch 00122: val_loss did not improve from 198.98285\n",
      "526/526 [==============================] - 0s 540us/step - loss: 200.6996 - mean_squared_error: 189.6117 - val_loss: 203.0505 - val_mean_squared_error: 191.9536\n",
      "Epoch 123/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 200.3614 - mean_squared_error: 189.2782\n",
      "Epoch 00123: val_loss did not improve from 198.98285\n",
      "526/526 [==============================] - 0s 542us/step - loss: 199.8508 - mean_squared_error: 188.7679 - val_loss: 225.4709 - val_mean_squared_error: 214.3972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 202.9253 - mean_squared_error: 191.8572\n",
      "Epoch 00124: val_loss did not improve from 198.98285\n",
      "526/526 [==============================] - 0s 540us/step - loss: 201.5317 - mean_squared_error: 190.4637 - val_loss: 203.0224 - val_mean_squared_error: 191.9593\n",
      "Epoch 125/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 200.4429 - mean_squared_error: 189.3902\n",
      "Epoch 00125: val_loss did not improve from 198.98285\n",
      "526/526 [==============================] - 0s 539us/step - loss: 199.8878 - mean_squared_error: 188.8354 - val_loss: 254.9596 - val_mean_squared_error: 243.9159\n",
      "Epoch 126/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 197.5199 - mean_squared_error: 186.4729\n",
      "Epoch 00126: val_loss did not improve from 198.98285\n",
      "526/526 [==============================] - 0s 539us/step - loss: 197.5835 - mean_squared_error: 186.5366 - val_loss: 220.5798 - val_mean_squared_error: 209.5359\n",
      "Epoch 127/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 197.9669 - mean_squared_error: 186.9264\n",
      "Epoch 00127: val_loss did not improve from 198.98285\n",
      "526/526 [==============================] - 0s 539us/step - loss: 197.9039 - mean_squared_error: 186.8634 - val_loss: 223.8781 - val_mean_squared_error: 212.8375\n",
      "Epoch 128/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 196.2225 - mean_squared_error: 185.1795\n",
      "Epoch 00128: val_loss did not improve from 198.98285\n",
      "526/526 [==============================] - 0s 540us/step - loss: 195.4158 - mean_squared_error: 184.3728 - val_loss: 206.1181 - val_mean_squared_error: 195.0719\n",
      "Epoch 129/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 194.9496 - mean_squared_error: 183.8990\n",
      "Epoch 00129: val_loss improved from 198.98285 to 195.35146, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 793us/step - loss: 194.6512 - mean_squared_error: 183.6008 - val_loss: 195.3515 - val_mean_squared_error: 184.3051\n",
      "Epoch 130/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 195.7432 - mean_squared_error: 184.7057\n",
      "Epoch 00130: val_loss did not improve from 195.35146\n",
      "526/526 [==============================] - 0s 539us/step - loss: 195.8202 - mean_squared_error: 184.7828 - val_loss: 214.1574 - val_mean_squared_error: 203.1277\n",
      "Epoch 131/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 193.9953 - mean_squared_error: 182.9670\n",
      "Epoch 00131: val_loss did not improve from 195.35146\n",
      "526/526 [==============================] - 0s 540us/step - loss: 194.3042 - mean_squared_error: 183.2758 - val_loss: 197.9925 - val_mean_squared_error: 186.9647\n",
      "Epoch 132/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 196.1377 - mean_squared_error: 185.1037\n",
      "Epoch 00132: val_loss did not improve from 195.35146\n",
      "526/526 [==============================] - 0s 544us/step - loss: 196.6868 - mean_squared_error: 185.6526 - val_loss: 209.7112 - val_mean_squared_error: 198.6728\n",
      "Epoch 133/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 192.1597 - mean_squared_error: 181.1280\n",
      "Epoch 00133: val_loss improved from 195.35146 to 191.85872, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 695us/step - loss: 191.9566 - mean_squared_error: 180.9250 - val_loss: 191.8587 - val_mean_squared_error: 180.8304\n",
      "Epoch 134/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 190.4158 - mean_squared_error: 179.3695\n",
      "Epoch 00134: val_loss did not improve from 191.85872\n",
      "526/526 [==============================] - 0s 544us/step - loss: 189.9104 - mean_squared_error: 178.8639 - val_loss: 199.2323 - val_mean_squared_error: 188.1823\n",
      "Epoch 135/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 189.8136 - mean_squared_error: 178.7738\n",
      "Epoch 00135: val_loss did not improve from 191.85872\n",
      "526/526 [==============================] - 0s 544us/step - loss: 189.8165 - mean_squared_error: 178.7771 - val_loss: 204.8874 - val_mean_squared_error: 193.8591\n",
      "Epoch 136/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 194.0347 - mean_squared_error: 182.9992\n",
      "Epoch 00136: val_loss did not improve from 191.85872\n",
      "526/526 [==============================] - 0s 540us/step - loss: 193.5156 - mean_squared_error: 182.4804 - val_loss: 198.8123 - val_mean_squared_error: 187.7845\n",
      "Epoch 137/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 191.1812 - mean_squared_error: 180.1606\n",
      "Epoch 00137: val_loss did not improve from 191.85872\n",
      "526/526 [==============================] - 0s 542us/step - loss: 192.2059 - mean_squared_error: 181.1855 - val_loss: 212.0728 - val_mean_squared_error: 201.0585\n",
      "Epoch 138/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 191.1691 - mean_squared_error: 180.1558\n",
      "Epoch 00138: val_loss did not improve from 191.85872\n",
      "526/526 [==============================] - 0s 542us/step - loss: 190.5273 - mean_squared_error: 179.5141 - val_loss: 228.2602 - val_mean_squared_error: 217.2505\n",
      "Epoch 139/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 190.6945 - mean_squared_error: 179.6941\n",
      "Epoch 00139: val_loss did not improve from 191.85872\n",
      "526/526 [==============================] - 0s 544us/step - loss: 190.5657 - mean_squared_error: 179.5652 - val_loss: 207.6885 - val_mean_squared_error: 196.6863\n",
      "Epoch 140/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 190.9671 - mean_squared_error: 179.9748\n",
      "Epoch 00140: val_loss did not improve from 191.85872\n",
      "526/526 [==============================] - 0s 539us/step - loss: 190.1267 - mean_squared_error: 179.1346 - val_loss: 203.2191 - val_mean_squared_error: 192.2343\n",
      "Epoch 141/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 188.3891 - mean_squared_error: 177.4017\n",
      "Epoch 00141: val_loss did not improve from 191.85872\n",
      "526/526 [==============================] - 0s 544us/step - loss: 187.3580 - mean_squared_error: 176.3706 - val_loss: 203.6626 - val_mean_squared_error: 192.6747\n",
      "Epoch 142/500\n",
      "505/526 [===========================>..] - ETA: 0s - loss: 189.0725 - mean_squared_error: 178.0883\n",
      "Epoch 00142: val_loss did not improve from 191.85872\n",
      "526/526 [==============================] - 0s 546us/step - loss: 188.1868 - mean_squared_error: 177.2026 - val_loss: 192.0345 - val_mean_squared_error: 181.0499\n",
      "Epoch 143/500\n",
      "505/526 [===========================>..] - ETA: 0s - loss: 187.3729 - mean_squared_error: 176.3889\n",
      "Epoch 00143: val_loss did not improve from 191.85872\n",
      "526/526 [==============================] - 0s 546us/step - loss: 185.9743 - mean_squared_error: 174.9901 - val_loss: 208.9567 - val_mean_squared_error: 197.9678\n",
      "Epoch 144/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 187.5866 - mean_squared_error: 176.5938\n",
      "Epoch 00144: val_loss improved from 191.85872 to 180.48344, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 814us/step - loss: 187.1561 - mean_squared_error: 176.1633 - val_loss: 180.4834 - val_mean_squared_error: 169.4895\n",
      "Epoch 145/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 187.9291 - mean_squared_error: 176.9381\n",
      "Epoch 00145: val_loss did not improve from 180.48344\n",
      "526/526 [==============================] - 0s 540us/step - loss: 188.5497 - mean_squared_error: 177.5588 - val_loss: 202.6735 - val_mean_squared_error: 191.6856\n",
      "Epoch 146/500\n",
      "504/526 [===========================>..] - ETA: 0s - loss: 185.8656 - mean_squared_error: 174.8719\n",
      "Epoch 00146: val_loss did not improve from 180.48344\n",
      "526/526 [==============================] - 0s 548us/step - loss: 185.4987 - mean_squared_error: 174.5049 - val_loss: 222.0284 - val_mean_squared_error: 211.0316\n",
      "Epoch 147/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 186.7284 - mean_squared_error: 175.7389\n",
      "Epoch 00147: val_loss did not improve from 180.48344\n",
      "526/526 [==============================] - 0s 542us/step - loss: 186.8344 - mean_squared_error: 175.8448 - val_loss: 191.4125 - val_mean_squared_error: 180.4209\n",
      "Epoch 148/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 180.2634 - mean_squared_error: 169.2737\n",
      "Epoch 00148: val_loss did not improve from 180.48344\n",
      "526/526 [==============================] - 0s 542us/step - loss: 180.2934 - mean_squared_error: 169.3039 - val_loss: 194.6653 - val_mean_squared_error: 183.6776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 182.3865 - mean_squared_error: 171.3931\n",
      "Epoch 00149: val_loss did not improve from 180.48344\n",
      "526/526 [==============================] - 0s 540us/step - loss: 181.8605 - mean_squared_error: 170.8671 - val_loss: 181.2558 - val_mean_squared_error: 170.2610\n",
      "Epoch 150/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 183.6640 - mean_squared_error: 172.6810\n",
      "Epoch 00150: val_loss did not improve from 180.48344\n",
      "526/526 [==============================] - 0s 537us/step - loss: 183.8401 - mean_squared_error: 172.8573 - val_loss: 180.9998 - val_mean_squared_error: 170.0296\n",
      "Epoch 151/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 177.5070 - mean_squared_error: 166.5449\n",
      "Epoch 00151: val_loss did not improve from 180.48344\n",
      "526/526 [==============================] - 0s 539us/step - loss: 177.8980 - mean_squared_error: 166.9359 - val_loss: 195.2850 - val_mean_squared_error: 184.3227\n",
      "Epoch 152/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 180.6907 - mean_squared_error: 169.7276\n",
      "Epoch 00152: val_loss did not improve from 180.48344\n",
      "526/526 [==============================] - 0s 540us/step - loss: 180.3793 - mean_squared_error: 169.4163 - val_loss: 180.7619 - val_mean_squared_error: 169.8046\n",
      "Epoch 153/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 182.6683 - mean_squared_error: 171.7098\n",
      "Epoch 00153: val_loss did not improve from 180.48344\n",
      "526/526 [==============================] - 0s 542us/step - loss: 182.0523 - mean_squared_error: 171.0935 - val_loss: 193.2626 - val_mean_squared_error: 182.2984\n",
      "Epoch 154/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 183.7063 - mean_squared_error: 172.7404\n",
      "Epoch 00154: val_loss did not improve from 180.48344\n",
      "526/526 [==============================] - 0s 544us/step - loss: 183.3820 - mean_squared_error: 172.4160 - val_loss: 221.8525 - val_mean_squared_error: 210.8851\n",
      "Epoch 155/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 179.9967 - mean_squared_error: 169.0263\n",
      "Epoch 00155: val_loss did not improve from 180.48344\n",
      "526/526 [==============================] - 0s 539us/step - loss: 180.1786 - mean_squared_error: 169.2080 - val_loss: 194.8353 - val_mean_squared_error: 183.8626\n",
      "Epoch 156/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 180.6102 - mean_squared_error: 169.6368\n",
      "Epoch 00156: val_loss did not improve from 180.48344\n",
      "526/526 [==============================] - 0s 542us/step - loss: 180.2509 - mean_squared_error: 169.2775 - val_loss: 186.1966 - val_mean_squared_error: 175.2240\n",
      "Epoch 157/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 176.8848 - mean_squared_error: 165.9112\n",
      "Epoch 00157: val_loss did not improve from 180.48344\n",
      "526/526 [==============================] - 0s 539us/step - loss: 177.0240 - mean_squared_error: 166.0504 - val_loss: 202.9353 - val_mean_squared_error: 191.9606\n",
      "Epoch 158/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 178.0640 - mean_squared_error: 167.0878\n",
      "Epoch 00158: val_loss improved from 180.48344 to 177.49780, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 795us/step - loss: 178.5171 - mean_squared_error: 167.5410 - val_loss: 177.4978 - val_mean_squared_error: 166.5257\n",
      "Epoch 159/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 174.7202 - mean_squared_error: 163.7433\n",
      "Epoch 00159: val_loss did not improve from 177.49780\n",
      "526/526 [==============================] - 0s 539us/step - loss: 174.9796 - mean_squared_error: 164.0027 - val_loss: 179.6492 - val_mean_squared_error: 168.6734\n",
      "Epoch 160/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 172.9875 - mean_squared_error: 162.0142\n",
      "Epoch 00160: val_loss did not improve from 177.49780\n",
      "526/526 [==============================] - 0s 542us/step - loss: 172.5499 - mean_squared_error: 161.5768 - val_loss: 185.1930 - val_mean_squared_error: 174.2247\n",
      "Epoch 161/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 177.0002 - mean_squared_error: 166.0362\n",
      "Epoch 00161: val_loss did not improve from 177.49780\n",
      "526/526 [==============================] - 0s 540us/step - loss: 177.3168 - mean_squared_error: 166.3527 - val_loss: 184.6776 - val_mean_squared_error: 173.7100\n",
      "Epoch 162/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 175.3722 - mean_squared_error: 164.3966\n",
      "Epoch 00162: val_loss did not improve from 177.49780\n",
      "526/526 [==============================] - 0s 542us/step - loss: 175.3437 - mean_squared_error: 164.3680 - val_loss: 184.3795 - val_mean_squared_error: 173.4027\n",
      "Epoch 163/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 174.6438 - mean_squared_error: 163.6651\n",
      "Epoch 00163: val_loss did not improve from 177.49780\n",
      "526/526 [==============================] - 0s 539us/step - loss: 174.7234 - mean_squared_error: 163.7447 - val_loss: 195.1854 - val_mean_squared_error: 184.2097\n",
      "Epoch 164/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 173.5612 - mean_squared_error: 162.5941\n",
      "Epoch 00164: val_loss did not improve from 177.49780\n",
      "526/526 [==============================] - 0s 542us/step - loss: 173.7530 - mean_squared_error: 162.7859 - val_loss: 181.4037 - val_mean_squared_error: 170.4359\n",
      "Epoch 165/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 173.5101 - mean_squared_error: 162.5347\n",
      "Epoch 00165: val_loss improved from 177.49780 to 171.87849, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 782us/step - loss: 173.5219 - mean_squared_error: 162.5466 - val_loss: 171.8785 - val_mean_squared_error: 160.9078\n",
      "Epoch 166/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 174.4875 - mean_squared_error: 163.5222\n",
      "Epoch 00166: val_loss did not improve from 171.87849\n",
      "526/526 [==============================] - 0s 539us/step - loss: 174.7532 - mean_squared_error: 163.7880 - val_loss: 185.6492 - val_mean_squared_error: 174.6865\n",
      "Epoch 167/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 173.7448 - mean_squared_error: 162.7780\n",
      "Epoch 00167: val_loss did not improve from 171.87849\n",
      "526/526 [==============================] - 0s 542us/step - loss: 174.2749 - mean_squared_error: 163.3083 - val_loss: 216.1194 - val_mean_squared_error: 205.1580\n",
      "Epoch 168/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 170.3782 - mean_squared_error: 159.4234\n",
      "Epoch 00168: val_loss did not improve from 171.87849\n",
      "526/526 [==============================] - 0s 539us/step - loss: 170.7857 - mean_squared_error: 159.8312 - val_loss: 171.8960 - val_mean_squared_error: 160.9508\n",
      "Epoch 169/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 173.9601 - mean_squared_error: 163.0057\n",
      "Epoch 00169: val_loss did not improve from 171.87849\n",
      "526/526 [==============================] - 0s 542us/step - loss: 174.7866 - mean_squared_error: 163.8320 - val_loss: 186.4856 - val_mean_squared_error: 175.5242\n",
      "Epoch 170/500\n",
      "502/526 [===========================>..] - ETA: 0s - loss: 172.2910 - mean_squared_error: 161.3314\n",
      "Epoch 00170: val_loss did not improve from 171.87849\n",
      "526/526 [==============================] - 0s 548us/step - loss: 171.9230 - mean_squared_error: 160.9637 - val_loss: 182.0135 - val_mean_squared_error: 171.0606\n",
      "Epoch 171/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 170.7648 - mean_squared_error: 159.8103\n",
      "Epoch 00171: val_loss did not improve from 171.87849\n",
      "526/526 [==============================] - 0s 540us/step - loss: 170.6370 - mean_squared_error: 159.6822 - val_loss: 176.1081 - val_mean_squared_error: 165.1390\n",
      "Epoch 172/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 170.7040 - mean_squared_error: 159.7266\n",
      "Epoch 00172: val_loss did not improve from 171.87849\n",
      "526/526 [==============================] - 0s 542us/step - loss: 170.9705 - mean_squared_error: 159.9926 - val_loss: 183.9345 - val_mean_squared_error: 172.9414\n",
      "Epoch 173/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 170.8985 - mean_squared_error: 159.9203\n",
      "Epoch 00173: val_loss did not improve from 171.87849\n",
      "526/526 [==============================] - 0s 539us/step - loss: 171.0455 - mean_squared_error: 160.0676 - val_loss: 194.3668 - val_mean_squared_error: 183.3975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 170.6876 - mean_squared_error: 159.7276\n",
      "Epoch 00174: val_loss did not improve from 171.87849\n",
      "526/526 [==============================] - 0s 540us/step - loss: 171.2244 - mean_squared_error: 160.2644 - val_loss: 182.3625 - val_mean_squared_error: 171.4021\n",
      "Epoch 175/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 169.2031 - mean_squared_error: 158.2522\n",
      "Epoch 00175: val_loss did not improve from 171.87849\n",
      "526/526 [==============================] - 0s 544us/step - loss: 169.2980 - mean_squared_error: 158.3473 - val_loss: 181.9830 - val_mean_squared_error: 171.0366\n",
      "Epoch 176/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 173.2060 - mean_squared_error: 162.2529\n",
      "Epoch 00176: val_loss did not improve from 171.87849\n",
      "526/526 [==============================] - 0s 539us/step - loss: 173.0081 - mean_squared_error: 162.0548 - val_loss: 177.8187 - val_mean_squared_error: 166.8597\n",
      "Epoch 177/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 167.7230 - mean_squared_error: 156.7640\n",
      "Epoch 00177: val_loss did not improve from 171.87849\n",
      "526/526 [==============================] - 0s 539us/step - loss: 167.6123 - mean_squared_error: 156.6533 - val_loss: 185.0710 - val_mean_squared_error: 174.1097\n",
      "Epoch 178/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 169.9007 - mean_squared_error: 158.9385\n",
      "Epoch 00178: val_loss did not improve from 171.87849\n",
      "526/526 [==============================] - 0s 540us/step - loss: 169.4985 - mean_squared_error: 158.5360 - val_loss: 193.2352 - val_mean_squared_error: 182.2634\n",
      "Epoch 179/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 166.4964 - mean_squared_error: 155.5269\n",
      "Epoch 00179: val_loss did not improve from 171.87849\n",
      "526/526 [==============================] - 0s 539us/step - loss: 167.3715 - mean_squared_error: 156.4020 - val_loss: 181.5894 - val_mean_squared_error: 170.6206\n",
      "Epoch 180/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 167.7963 - mean_squared_error: 156.8258\n",
      "Epoch 00180: val_loss did not improve from 171.87849\n",
      "526/526 [==============================] - 0s 539us/step - loss: 167.7123 - mean_squared_error: 156.7418 - val_loss: 184.0449 - val_mean_squared_error: 173.0761\n",
      "Epoch 181/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 169.3754 - mean_squared_error: 158.3910\n",
      "Epoch 00181: val_loss did not improve from 171.87849\n",
      "526/526 [==============================] - 0s 544us/step - loss: 169.0143 - mean_squared_error: 158.0296 - val_loss: 172.3194 - val_mean_squared_error: 161.3279\n",
      "Epoch 182/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 171.4186 - mean_squared_error: 160.4261\n",
      "Epoch 00182: val_loss improved from 171.87849 to 168.13640, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 780us/step - loss: 170.0515 - mean_squared_error: 159.0589 - val_loss: 168.1364 - val_mean_squared_error: 157.1397\n",
      "Epoch 183/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 168.1020 - mean_squared_error: 157.1087\n",
      "Epoch 00183: val_loss did not improve from 168.13640\n",
      "526/526 [==============================] - 0s 537us/step - loss: 168.6086 - mean_squared_error: 157.6151 - val_loss: 180.6714 - val_mean_squared_error: 169.6711\n",
      "Epoch 184/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 165.2701 - mean_squared_error: 154.2709\n",
      "Epoch 00184: val_loss did not improve from 168.13640\n",
      "526/526 [==============================] - 0s 544us/step - loss: 166.9999 - mean_squared_error: 156.0006 - val_loss: 205.2741 - val_mean_squared_error: 194.2682\n",
      "Epoch 185/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 167.0347 - mean_squared_error: 156.0368\n",
      "Epoch 00185: val_loss did not improve from 168.13640\n",
      "526/526 [==============================] - 0s 540us/step - loss: 166.2084 - mean_squared_error: 155.2107 - val_loss: 179.8848 - val_mean_squared_error: 168.8955\n",
      "Epoch 186/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 164.4963 - mean_squared_error: 153.5092\n",
      "Epoch 00186: val_loss did not improve from 168.13640\n",
      "526/526 [==============================] - 0s 544us/step - loss: 163.9753 - mean_squared_error: 152.9883 - val_loss: 197.1647 - val_mean_squared_error: 186.1818\n",
      "Epoch 187/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 164.4396 - mean_squared_error: 153.4565\n",
      "Epoch 00187: val_loss did not improve from 168.13640\n",
      "526/526 [==============================] - 0s 539us/step - loss: 164.8248 - mean_squared_error: 153.8418 - val_loss: 177.0154 - val_mean_squared_error: 166.0421\n",
      "Epoch 188/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 165.6358 - mean_squared_error: 154.6600\n",
      "Epoch 00188: val_loss did not improve from 168.13640\n",
      "526/526 [==============================] - 0s 542us/step - loss: 165.1016 - mean_squared_error: 154.1256 - val_loss: 169.2502 - val_mean_squared_error: 158.2693\n",
      "Epoch 189/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 162.4416 - mean_squared_error: 151.4610\n",
      "Epoch 00189: val_loss did not improve from 168.13640\n",
      "526/526 [==============================] - 0s 537us/step - loss: 162.1896 - mean_squared_error: 151.2090 - val_loss: 193.2642 - val_mean_squared_error: 182.2822\n",
      "Epoch 190/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 163.9611 - mean_squared_error: 152.9767\n",
      "Epoch 00190: val_loss improved from 168.13640 to 167.95247, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 782us/step - loss: 163.9549 - mean_squared_error: 152.9705 - val_loss: 167.9525 - val_mean_squared_error: 156.9700\n",
      "Epoch 191/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 165.0197 - mean_squared_error: 154.0409\n",
      "Epoch 00191: val_loss did not improve from 167.95247\n",
      "526/526 [==============================] - 0s 542us/step - loss: 165.4960 - mean_squared_error: 154.5172 - val_loss: 183.4115 - val_mean_squared_error: 172.4321\n",
      "Epoch 192/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 161.3959 - mean_squared_error: 150.4186\n",
      "Epoch 00192: val_loss improved from 167.95247 to 167.33366, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 773us/step - loss: 161.9345 - mean_squared_error: 150.9574 - val_loss: 167.3337 - val_mean_squared_error: 156.3601\n",
      "Epoch 193/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 162.0631 - mean_squared_error: 151.0772\n",
      "Epoch 00193: val_loss did not improve from 167.33366\n",
      "526/526 [==============================] - 0s 539us/step - loss: 162.0913 - mean_squared_error: 151.1052 - val_loss: 189.2860 - val_mean_squared_error: 178.2943\n",
      "Epoch 194/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 160.9990 - mean_squared_error: 150.0103\n",
      "Epoch 00194: val_loss did not improve from 167.33366\n",
      "526/526 [==============================] - 0s 544us/step - loss: 160.8434 - mean_squared_error: 149.8547 - val_loss: 172.3820 - val_mean_squared_error: 161.3927\n",
      "Epoch 195/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 158.7852 - mean_squared_error: 147.8041\n",
      "Epoch 00195: val_loss did not improve from 167.33366\n",
      "526/526 [==============================] - 0s 539us/step - loss: 158.7763 - mean_squared_error: 147.7953 - val_loss: 192.1017 - val_mean_squared_error: 181.1244\n",
      "Epoch 196/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 164.7701 - mean_squared_error: 153.7927\n",
      "Epoch 00196: val_loss did not improve from 167.33366\n",
      "526/526 [==============================] - 0s 544us/step - loss: 164.6068 - mean_squared_error: 153.6294 - val_loss: 239.7179 - val_mean_squared_error: 228.7380\n",
      "Epoch 197/500\n",
      "504/526 [===========================>..] - ETA: 0s - loss: 162.0014 - mean_squared_error: 151.0096\n",
      "Epoch 00197: val_loss did not improve from 167.33366\n",
      "526/526 [==============================] - 0s 546us/step - loss: 161.5098 - mean_squared_error: 150.5178 - val_loss: 173.9096 - val_mean_squared_error: 162.9147\n",
      "Epoch 198/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 161.6484 - mean_squared_error: 150.6548\n",
      "Epoch 00198: val_loss did not improve from 167.33366\n",
      "526/526 [==============================] - 0s 544us/step - loss: 161.5435 - mean_squared_error: 150.5498 - val_loss: 192.0775 - val_mean_squared_error: 181.0841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 161.9049 - mean_squared_error: 150.9191\n",
      "Epoch 00199: val_loss did not improve from 167.33366\n",
      "526/526 [==============================] - 0s 542us/step - loss: 161.6677 - mean_squared_error: 150.6819 - val_loss: 169.7927 - val_mean_squared_error: 158.8039\n",
      "Epoch 200/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 157.1494 - mean_squared_error: 146.1455\n",
      "Epoch 00200: val_loss did not improve from 167.33366\n",
      "526/526 [==============================] - 0s 537us/step - loss: 156.8730 - mean_squared_error: 145.8690 - val_loss: 182.2111 - val_mean_squared_error: 171.1987\n",
      "Epoch 201/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 158.0499 - mean_squared_error: 147.0450\n",
      "Epoch 00201: val_loss did not improve from 167.33366\n",
      "526/526 [==============================] - 0s 542us/step - loss: 157.8020 - mean_squared_error: 146.7973 - val_loss: 178.5563 - val_mean_squared_error: 167.5565\n",
      "Epoch 202/500\n",
      "504/526 [===========================>..] - ETA: 0s - loss: 160.8141 - mean_squared_error: 149.8182\n",
      "Epoch 00202: val_loss did not improve from 167.33366\n",
      "526/526 [==============================] - 0s 548us/step - loss: 161.3042 - mean_squared_error: 150.3087 - val_loss: 174.1751 - val_mean_squared_error: 163.1864\n",
      "Epoch 203/500\n",
      "504/526 [===========================>..] - ETA: 0s - loss: 156.1844 - mean_squared_error: 145.2005\n",
      "Epoch 00203: val_loss did not improve from 167.33366\n",
      "526/526 [==============================] - 0s 549us/step - loss: 156.6650 - mean_squared_error: 145.6813 - val_loss: 173.2988 - val_mean_squared_error: 162.3168\n",
      "Epoch 204/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 158.7275 - mean_squared_error: 147.7475\n",
      "Epoch 00204: val_loss did not improve from 167.33366\n",
      "526/526 [==============================] - 0s 539us/step - loss: 159.7630 - mean_squared_error: 148.7829 - val_loss: 170.2065 - val_mean_squared_error: 159.2260\n",
      "Epoch 205/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 157.6102 - mean_squared_error: 146.6328\n",
      "Epoch 00205: val_loss did not improve from 167.33366\n",
      "526/526 [==============================] - 0s 540us/step - loss: 157.5812 - mean_squared_error: 146.6039 - val_loss: 210.0424 - val_mean_squared_error: 199.0680\n",
      "Epoch 206/500\n",
      "493/526 [===========================>..] - ETA: 0s - loss: 158.2086 - mean_squared_error: 147.2209\n",
      "Epoch 00206: val_loss did not improve from 167.33366\n",
      "526/526 [==============================] - 0s 558us/step - loss: 159.0173 - mean_squared_error: 148.0289 - val_loss: 190.6326 - val_mean_squared_error: 179.6348\n",
      "Epoch 207/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 155.7372 - mean_squared_error: 144.7398\n",
      "Epoch 00207: val_loss did not improve from 167.33366\n",
      "526/526 [==============================] - 0s 542us/step - loss: 156.5288 - mean_squared_error: 145.5314 - val_loss: 189.3926 - val_mean_squared_error: 178.3980\n",
      "Epoch 208/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 157.0311 - mean_squared_error: 146.0403\n",
      "Epoch 00208: val_loss improved from 167.33366 to 163.03912, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 715us/step - loss: 156.6002 - mean_squared_error: 145.6098 - val_loss: 163.0391 - val_mean_squared_error: 152.0567\n",
      "Epoch 209/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 157.3703 - mean_squared_error: 146.3688\n",
      "Epoch 00209: val_loss did not improve from 163.03912\n",
      "526/526 [==============================] - 0s 546us/step - loss: 157.2193 - mean_squared_error: 146.2175 - val_loss: 186.1692 - val_mean_squared_error: 175.1577\n",
      "Epoch 210/500\n",
      "505/526 [===========================>..] - ETA: 0s - loss: 156.3780 - mean_squared_error: 145.3656\n",
      "Epoch 00210: val_loss did not improve from 163.03912\n",
      "526/526 [==============================] - 0s 544us/step - loss: 157.3037 - mean_squared_error: 146.2913 - val_loss: 170.8230 - val_mean_squared_error: 159.8108\n",
      "Epoch 211/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 156.5087 - mean_squared_error: 145.4951\n",
      "Epoch 00211: val_loss did not improve from 163.03912\n",
      "526/526 [==============================] - 0s 544us/step - loss: 156.1266 - mean_squared_error: 145.1132 - val_loss: 167.3795 - val_mean_squared_error: 156.3731\n",
      "Epoch 212/500\n",
      "504/526 [===========================>..] - ETA: 0s - loss: 158.6863 - mean_squared_error: 147.6774\n",
      "Epoch 00212: val_loss improved from 163.03912 to 160.06313, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 769us/step - loss: 158.8849 - mean_squared_error: 147.8761 - val_loss: 160.0631 - val_mean_squared_error: 149.0600\n",
      "Epoch 213/500\n",
      "506/526 [===========================>..] - ETA: 0s - loss: 155.1934 - mean_squared_error: 144.1862\n",
      "Epoch 00213: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 546us/step - loss: 156.4326 - mean_squared_error: 145.4253 - val_loss: 177.9626 - val_mean_squared_error: 166.9523\n",
      "Epoch 214/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 156.4254 - mean_squared_error: 145.4185\n",
      "Epoch 00214: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 542us/step - loss: 156.7160 - mean_squared_error: 145.7092 - val_loss: 169.3521 - val_mean_squared_error: 158.3496\n",
      "Epoch 215/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 156.9520 - mean_squared_error: 145.9534\n",
      "Epoch 00215: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 544us/step - loss: 155.9729 - mean_squared_error: 144.9742 - val_loss: 167.9412 - val_mean_squared_error: 156.9402\n",
      "Epoch 216/500\n",
      "506/526 [===========================>..] - ETA: 0s - loss: 155.8344 - mean_squared_error: 144.8309\n",
      "Epoch 00216: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 544us/step - loss: 154.9060 - mean_squared_error: 143.9022 - val_loss: 177.3026 - val_mean_squared_error: 166.2892\n",
      "Epoch 217/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 154.9133 - mean_squared_error: 143.9068\n",
      "Epoch 00217: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 542us/step - loss: 155.3488 - mean_squared_error: 144.3424 - val_loss: 171.8589 - val_mean_squared_error: 160.8542\n",
      "Epoch 218/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 156.7928 - mean_squared_error: 145.7862\n",
      "Epoch 00218: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 540us/step - loss: 156.8305 - mean_squared_error: 145.8241 - val_loss: 165.0756 - val_mean_squared_error: 154.0759\n",
      "Epoch 219/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 151.9321 - mean_squared_error: 140.9297\n",
      "Epoch 00219: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 542us/step - loss: 152.4452 - mean_squared_error: 141.4430 - val_loss: 184.3432 - val_mean_squared_error: 173.3494\n",
      "Epoch 220/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 152.1668 - mean_squared_error: 141.1672\n",
      "Epoch 00220: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 540us/step - loss: 152.3046 - mean_squared_error: 141.3045 - val_loss: 198.7105 - val_mean_squared_error: 187.6915\n",
      "Epoch 221/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 154.5969 - mean_squared_error: 143.5778\n",
      "Epoch 00221: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 539us/step - loss: 154.8147 - mean_squared_error: 143.7957 - val_loss: 163.2547 - val_mean_squared_error: 152.2428\n",
      "Epoch 222/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 153.3482 - mean_squared_error: 142.3286\n",
      "Epoch 00222: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 540us/step - loss: 153.5784 - mean_squared_error: 142.5585 - val_loss: 169.1813 - val_mean_squared_error: 158.1481\n",
      "Epoch 223/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 153.4142 - mean_squared_error: 142.3818\n",
      "Epoch 00223: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 540us/step - loss: 153.1263 - mean_squared_error: 142.0940 - val_loss: 181.0361 - val_mean_squared_error: 170.0093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 152.5800 - mean_squared_error: 141.5592\n",
      "Epoch 00224: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 539us/step - loss: 152.7357 - mean_squared_error: 141.7150 - val_loss: 175.1669 - val_mean_squared_error: 164.1493\n",
      "Epoch 225/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 151.2070 - mean_squared_error: 140.1967\n",
      "Epoch 00225: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 537us/step - loss: 151.3092 - mean_squared_error: 140.2989 - val_loss: 170.8473 - val_mean_squared_error: 159.8384\n",
      "Epoch 226/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 153.9728 - mean_squared_error: 142.9568\n",
      "Epoch 00226: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 540us/step - loss: 154.1824 - mean_squared_error: 143.1665 - val_loss: 168.5829 - val_mean_squared_error: 157.5719\n",
      "Epoch 227/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 150.6399 - mean_squared_error: 139.6264\n",
      "Epoch 00227: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 537us/step - loss: 150.9032 - mean_squared_error: 139.8897 - val_loss: 163.3726 - val_mean_squared_error: 152.3609\n",
      "Epoch 228/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 149.2115 - mean_squared_error: 138.2010\n",
      "Epoch 00228: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 537us/step - loss: 149.6563 - mean_squared_error: 138.6460 - val_loss: 164.1068 - val_mean_squared_error: 153.1006\n",
      "Epoch 229/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 150.2352 - mean_squared_error: 139.2303\n",
      "Epoch 00229: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 535us/step - loss: 151.2113 - mean_squared_error: 140.2062 - val_loss: 164.9530 - val_mean_squared_error: 153.9415\n",
      "Epoch 230/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 155.2561 - mean_squared_error: 144.2407\n",
      "Epoch 00230: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 539us/step - loss: 154.4815 - mean_squared_error: 143.4659 - val_loss: 165.9265 - val_mean_squared_error: 154.9033\n",
      "Epoch 231/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 146.9901 - mean_squared_error: 135.9662\n",
      "Epoch 00231: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 537us/step - loss: 147.3268 - mean_squared_error: 136.3029 - val_loss: 160.7585 - val_mean_squared_error: 149.7373\n",
      "Epoch 232/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 150.2010 - mean_squared_error: 139.1807\n",
      "Epoch 00232: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 539us/step - loss: 149.7156 - mean_squared_error: 138.6954 - val_loss: 169.1067 - val_mean_squared_error: 158.0857\n",
      "Epoch 233/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 151.4290 - mean_squared_error: 140.4068\n",
      "Epoch 00233: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 542us/step - loss: 151.1294 - mean_squared_error: 140.1075 - val_loss: 164.1212 - val_mean_squared_error: 153.1095\n",
      "Epoch 234/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 150.3879 - mean_squared_error: 139.3737\n",
      "Epoch 00234: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 540us/step - loss: 150.6894 - mean_squared_error: 139.6753 - val_loss: 164.1953 - val_mean_squared_error: 153.1830\n",
      "Epoch 235/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 149.3372 - mean_squared_error: 138.3184\n",
      "Epoch 00235: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 539us/step - loss: 149.2225 - mean_squared_error: 138.2039 - val_loss: 178.2502 - val_mean_squared_error: 167.2394\n",
      "Epoch 236/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 150.9768 - mean_squared_error: 139.9614\n",
      "Epoch 00236: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 540us/step - loss: 150.7515 - mean_squared_error: 139.7361 - val_loss: 199.8964 - val_mean_squared_error: 188.8782\n",
      "Epoch 237/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 149.4836 - mean_squared_error: 138.4674\n",
      "Epoch 00237: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 542us/step - loss: 149.0392 - mean_squared_error: 138.0231 - val_loss: 163.3330 - val_mean_squared_error: 152.3211\n",
      "Epoch 238/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 146.3573 - mean_squared_error: 135.3494\n",
      "Epoch 00238: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 540us/step - loss: 146.0813 - mean_squared_error: 135.0732 - val_loss: 171.1581 - val_mean_squared_error: 160.1418\n",
      "Epoch 239/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 147.3387 - mean_squared_error: 136.3208\n",
      "Epoch 00239: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 542us/step - loss: 147.2711 - mean_squared_error: 136.2532 - val_loss: 172.3713 - val_mean_squared_error: 161.3515\n",
      "Epoch 240/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 149.3696 - mean_squared_error: 138.3492\n",
      "Epoch 00240: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 540us/step - loss: 150.3295 - mean_squared_error: 139.3092 - val_loss: 182.5806 - val_mean_squared_error: 171.5593\n",
      "Epoch 241/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 145.1061 - mean_squared_error: 134.0875\n",
      "Epoch 00241: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 542us/step - loss: 145.5760 - mean_squared_error: 134.5575 - val_loss: 161.9696 - val_mean_squared_error: 150.9555\n",
      "Epoch 242/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 148.0152 - mean_squared_error: 137.0031\n",
      "Epoch 00242: val_loss did not improve from 160.06313\n",
      "526/526 [==============================] - 0s 542us/step - loss: 147.7353 - mean_squared_error: 136.7231 - val_loss: 162.6145 - val_mean_squared_error: 151.6030\n",
      "Epoch 243/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 148.6321 - mean_squared_error: 137.6201\n",
      "Epoch 00243: val_loss improved from 160.06313 to 159.42885, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 573us/step - loss: 148.0429 - mean_squared_error: 137.0307 - val_loss: 159.4288 - val_mean_squared_error: 148.4127\n",
      "Epoch 244/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 146.9713 - mean_squared_error: 135.9513\n",
      "Epoch 00244: val_loss did not improve from 159.42885\n",
      "526/526 [==============================] - 0s 544us/step - loss: 146.8694 - mean_squared_error: 135.8493 - val_loss: 159.6978 - val_mean_squared_error: 148.6756\n",
      "Epoch 245/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 146.7209 - mean_squared_error: 135.7073\n",
      "Epoch 00245: val_loss improved from 159.42885 to 158.25737, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 653us/step - loss: 146.5717 - mean_squared_error: 135.5581 - val_loss: 158.2574 - val_mean_squared_error: 147.2452\n",
      "Epoch 246/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 145.5384 - mean_squared_error: 134.5277\n",
      "Epoch 00246: val_loss did not improve from 158.25737\n",
      "526/526 [==============================] - 0s 542us/step - loss: 145.6403 - mean_squared_error: 134.6294 - val_loss: 167.4956 - val_mean_squared_error: 156.4763\n",
      "Epoch 247/500\n",
      "506/526 [===========================>..] - ETA: 0s - loss: 142.7660 - mean_squared_error: 131.7550\n",
      "Epoch 00247: val_loss did not improve from 158.25737\n",
      "526/526 [==============================] - 0s 546us/step - loss: 142.1506 - mean_squared_error: 131.1397 - val_loss: 169.6474 - val_mean_squared_error: 158.6408\n",
      "Epoch 248/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 144.3405 - mean_squared_error: 133.3201\n",
      "Epoch 00248: val_loss did not improve from 158.25737\n",
      "526/526 [==============================] - 0s 542us/step - loss: 144.2440 - mean_squared_error: 133.2236 - val_loss: 163.8814 - val_mean_squared_error: 152.8589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 146.4118 - mean_squared_error: 135.3799\n",
      "Epoch 00249: val_loss did not improve from 158.25737\n",
      "526/526 [==============================] - 0s 542us/step - loss: 146.5340 - mean_squared_error: 135.5023 - val_loss: 163.7013 - val_mean_squared_error: 152.6722\n",
      "Epoch 250/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 144.6315 - mean_squared_error: 133.6050\n",
      "Epoch 00250: val_loss improved from 158.25737 to 157.62959, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 803us/step - loss: 144.7868 - mean_squared_error: 133.7598 - val_loss: 157.6296 - val_mean_squared_error: 146.5881\n",
      "Epoch 251/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 147.4070 - mean_squared_error: 136.3718\n",
      "Epoch 00251: val_loss improved from 157.62959 to 151.82602, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 739us/step - loss: 147.3038 - mean_squared_error: 136.2688 - val_loss: 151.8260 - val_mean_squared_error: 140.7942\n",
      "Epoch 252/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 142.7433 - mean_squared_error: 131.7113\n",
      "Epoch 00252: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 540us/step - loss: 142.6087 - mean_squared_error: 131.5767 - val_loss: 173.8950 - val_mean_squared_error: 162.8632\n",
      "Epoch 253/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 142.1554 - mean_squared_error: 131.1267\n",
      "Epoch 00253: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 544us/step - loss: 143.6839 - mean_squared_error: 132.6553 - val_loss: 189.5141 - val_mean_squared_error: 178.4916\n",
      "Epoch 254/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 144.9966 - mean_squared_error: 133.9776\n",
      "Epoch 00254: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 542us/step - loss: 145.0350 - mean_squared_error: 134.0159 - val_loss: 155.4673 - val_mean_squared_error: 144.4451\n",
      "Epoch 255/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 142.8538 - mean_squared_error: 131.8223\n",
      "Epoch 00255: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 537us/step - loss: 143.1162 - mean_squared_error: 132.0848 - val_loss: 161.0080 - val_mean_squared_error: 149.9802\n",
      "Epoch 256/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 144.5123 - mean_squared_error: 133.4794\n",
      "Epoch 00256: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 540us/step - loss: 144.5256 - mean_squared_error: 133.4927 - val_loss: 159.8840 - val_mean_squared_error: 148.8549\n",
      "Epoch 257/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 143.5374 - mean_squared_error: 132.5104\n",
      "Epoch 00257: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 539us/step - loss: 143.0935 - mean_squared_error: 132.0666 - val_loss: 165.6077 - val_mean_squared_error: 154.5821\n",
      "Epoch 258/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 146.5767 - mean_squared_error: 135.5513\n",
      "Epoch 00258: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 544us/step - loss: 145.7965 - mean_squared_error: 134.7708 - val_loss: 165.1851 - val_mean_squared_error: 154.1552\n",
      "Epoch 259/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 143.9049 - mean_squared_error: 132.8757\n",
      "Epoch 00259: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 544us/step - loss: 142.9879 - mean_squared_error: 131.9587 - val_loss: 165.1969 - val_mean_squared_error: 154.1655\n",
      "Epoch 260/500\n",
      "506/526 [===========================>..] - ETA: 0s - loss: 145.1013 - mean_squared_error: 134.0629\n",
      "Epoch 00260: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 548us/step - loss: 144.5775 - mean_squared_error: 133.5390 - val_loss: 157.2870 - val_mean_squared_error: 146.2441\n",
      "Epoch 261/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 142.2557 - mean_squared_error: 131.2127\n",
      "Epoch 00261: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 540us/step - loss: 142.5336 - mean_squared_error: 131.4904 - val_loss: 163.3835 - val_mean_squared_error: 152.3326\n",
      "Epoch 262/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 141.2085 - mean_squared_error: 130.1626\n",
      "Epoch 00262: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 544us/step - loss: 141.6065 - mean_squared_error: 130.5609 - val_loss: 161.6725 - val_mean_squared_error: 150.6339\n",
      "Epoch 263/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 140.6086 - mean_squared_error: 129.5726\n",
      "Epoch 00263: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 542us/step - loss: 140.5798 - mean_squared_error: 129.5436 - val_loss: 158.6352 - val_mean_squared_error: 147.5931\n",
      "Epoch 264/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 141.4663 - mean_squared_error: 130.4167\n",
      "Epoch 00264: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 542us/step - loss: 142.0095 - mean_squared_error: 130.9597 - val_loss: 162.9651 - val_mean_squared_error: 151.9061\n",
      "Epoch 265/500\n",
      "506/526 [===========================>..] - ETA: 0s - loss: 143.3724 - mean_squared_error: 132.3083\n",
      "Epoch 00265: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 544us/step - loss: 142.6050 - mean_squared_error: 131.5409 - val_loss: 158.2342 - val_mean_squared_error: 147.1666\n",
      "Epoch 266/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 144.5566 - mean_squared_error: 133.4958\n",
      "Epoch 00266: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 544us/step - loss: 144.4203 - mean_squared_error: 133.3595 - val_loss: 169.7268 - val_mean_squared_error: 158.6655\n",
      "Epoch 267/500\n",
      "503/526 [===========================>..] - ETA: 0s - loss: 137.6369 - mean_squared_error: 126.5717\n",
      "Epoch 00267: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 546us/step - loss: 138.1946 - mean_squared_error: 127.1296 - val_loss: 158.5949 - val_mean_squared_error: 147.5346\n",
      "Epoch 268/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 139.9077 - mean_squared_error: 128.8444\n",
      "Epoch 00268: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 542us/step - loss: 139.8172 - mean_squared_error: 128.7536 - val_loss: 158.9765 - val_mean_squared_error: 147.9034\n",
      "Epoch 269/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 140.7755 - mean_squared_error: 129.7070\n",
      "Epoch 00269: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 544us/step - loss: 140.3753 - mean_squared_error: 129.3071 - val_loss: 152.3342 - val_mean_squared_error: 141.2731\n",
      "Epoch 270/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 140.6897 - mean_squared_error: 129.6345\n",
      "Epoch 00270: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 540us/step - loss: 139.9586 - mean_squared_error: 128.9032 - val_loss: 158.3078 - val_mean_squared_error: 147.2450\n",
      "Epoch 271/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 139.9732 - mean_squared_error: 128.9144\n",
      "Epoch 00271: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 539us/step - loss: 139.9694 - mean_squared_error: 128.9108 - val_loss: 164.5835 - val_mean_squared_error: 153.5349\n",
      "Epoch 272/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 138.5562 - mean_squared_error: 127.5019\n",
      "Epoch 00272: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 542us/step - loss: 139.4991 - mean_squared_error: 128.4448 - val_loss: 163.0668 - val_mean_squared_error: 152.0108\n",
      "Epoch 273/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 143.8585 - mean_squared_error: 132.7946\n",
      "Epoch 00273: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 535us/step - loss: 143.9948 - mean_squared_error: 132.9309 - val_loss: 170.7330 - val_mean_squared_error: 159.6685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 141.0564 - mean_squared_error: 130.0007\n",
      "Epoch 00274: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 535us/step - loss: 140.6719 - mean_squared_error: 129.6164 - val_loss: 161.0666 - val_mean_squared_error: 150.0149\n",
      "Epoch 275/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 141.1059 - mean_squared_error: 130.0439\n",
      "Epoch 00275: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 531us/step - loss: 141.2489 - mean_squared_error: 130.1868 - val_loss: 171.9786 - val_mean_squared_error: 160.8978\n",
      "Epoch 276/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 138.2790 - mean_squared_error: 127.1974\n",
      "Epoch 00276: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 539us/step - loss: 138.5800 - mean_squared_error: 127.4981 - val_loss: 161.5634 - val_mean_squared_error: 150.4669\n",
      "Epoch 277/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 136.1142 - mean_squared_error: 125.0243\n",
      "Epoch 00277: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 540us/step - loss: 135.9542 - mean_squared_error: 124.8643 - val_loss: 176.2897 - val_mean_squared_error: 165.2028\n",
      "Epoch 278/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 138.1455 - mean_squared_error: 127.0533\n",
      "Epoch 00278: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 537us/step - loss: 138.2076 - mean_squared_error: 127.1154 - val_loss: 156.1790 - val_mean_squared_error: 145.0867\n",
      "Epoch 279/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 138.2996 - mean_squared_error: 127.2057\n",
      "Epoch 00279: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 540us/step - loss: 138.2239 - mean_squared_error: 127.1298 - val_loss: 152.3917 - val_mean_squared_error: 141.2895\n",
      "Epoch 280/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 138.5972 - mean_squared_error: 127.5018\n",
      "Epoch 00280: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 537us/step - loss: 138.5215 - mean_squared_error: 127.4262 - val_loss: 165.1079 - val_mean_squared_error: 154.0162\n",
      "Epoch 281/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 137.3515 - mean_squared_error: 126.2600\n",
      "Epoch 00281: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 535us/step - loss: 137.0726 - mean_squared_error: 125.9811 - val_loss: 159.9621 - val_mean_squared_error: 148.8754\n",
      "Epoch 282/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 138.4718 - mean_squared_error: 127.3932\n",
      "Epoch 00282: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 537us/step - loss: 138.0626 - mean_squared_error: 126.9841 - val_loss: 154.0526 - val_mean_squared_error: 142.9754\n",
      "Epoch 283/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 137.1746 - mean_squared_error: 126.1011\n",
      "Epoch 00283: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 542us/step - loss: 137.2573 - mean_squared_error: 126.1840 - val_loss: 155.7963 - val_mean_squared_error: 144.7306\n",
      "Epoch 284/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 136.2269 - mean_squared_error: 125.1566\n",
      "Epoch 00284: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 537us/step - loss: 136.1160 - mean_squared_error: 125.0457 - val_loss: 174.7093 - val_mean_squared_error: 163.6398\n",
      "Epoch 285/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 137.6598 - mean_squared_error: 126.5851\n",
      "Epoch 00285: val_loss did not improve from 151.82602\n",
      "526/526 [==============================] - 0s 535us/step - loss: 137.1708 - mean_squared_error: 126.0961 - val_loss: 153.0246 - val_mean_squared_error: 141.9482\n",
      "Epoch 286/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 136.0947 - mean_squared_error: 125.0128\n",
      "Epoch 00286: val_loss improved from 151.82602 to 150.66075, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 685us/step - loss: 135.4867 - mean_squared_error: 124.4050 - val_loss: 150.6608 - val_mean_squared_error: 139.5851\n",
      "Epoch 287/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 137.4582 - mean_squared_error: 126.3809\n",
      "Epoch 00287: val_loss did not improve from 150.66075\n",
      "526/526 [==============================] - 0s 539us/step - loss: 138.2916 - mean_squared_error: 127.2143 - val_loss: 166.7682 - val_mean_squared_error: 155.6932\n",
      "Epoch 288/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 135.9171 - mean_squared_error: 124.8290\n",
      "Epoch 00288: val_loss did not improve from 150.66075\n",
      "526/526 [==============================] - 0s 539us/step - loss: 136.6853 - mean_squared_error: 125.5970 - val_loss: 159.6217 - val_mean_squared_error: 148.5258\n",
      "Epoch 289/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 135.2440 - mean_squared_error: 124.1476\n",
      "Epoch 00289: val_loss improved from 150.66075 to 147.80101, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 638us/step - loss: 135.4611 - mean_squared_error: 124.3647 - val_loss: 147.8010 - val_mean_squared_error: 136.7064\n",
      "Epoch 290/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 135.7601 - mean_squared_error: 124.6615\n",
      "Epoch 00290: val_loss did not improve from 147.80101\n",
      "526/526 [==============================] - 0s 540us/step - loss: 136.2070 - mean_squared_error: 125.1084 - val_loss: 149.3634 - val_mean_squared_error: 138.2660\n",
      "Epoch 291/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 135.5303 - mean_squared_error: 124.4339\n",
      "Epoch 00291: val_loss did not improve from 147.80101\n",
      "526/526 [==============================] - 0s 537us/step - loss: 135.4378 - mean_squared_error: 124.3413 - val_loss: 165.5975 - val_mean_squared_error: 154.4951\n",
      "Epoch 292/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 138.1690 - mean_squared_error: 127.0646\n",
      "Epoch 00292: val_loss did not improve from 147.80101\n",
      "526/526 [==============================] - 0s 535us/step - loss: 138.0197 - mean_squared_error: 126.9152 - val_loss: 180.7959 - val_mean_squared_error: 169.6860\n",
      "Epoch 293/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 135.1119 - mean_squared_error: 124.0023\n",
      "Epoch 00293: val_loss did not improve from 147.80101\n",
      "526/526 [==============================] - 0s 537us/step - loss: 135.1111 - mean_squared_error: 124.0015 - val_loss: 152.9059 - val_mean_squared_error: 141.7960\n",
      "Epoch 294/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 138.9055 - mean_squared_error: 127.7910\n",
      "Epoch 00294: val_loss improved from 147.80101 to 145.27972, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 712us/step - loss: 138.2857 - mean_squared_error: 127.1713 - val_loss: 145.2797 - val_mean_squared_error: 134.1687\n",
      "Epoch 295/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 134.3644 - mean_squared_error: 123.2580\n",
      "Epoch 00295: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 537us/step - loss: 134.2083 - mean_squared_error: 123.1021 - val_loss: 157.1835 - val_mean_squared_error: 146.0813\n",
      "Epoch 296/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 134.9550 - mean_squared_error: 123.8467\n",
      "Epoch 00296: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 539us/step - loss: 135.1336 - mean_squared_error: 124.0251 - val_loss: 155.1204 - val_mean_squared_error: 144.0039\n",
      "Epoch 297/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 135.4787 - mean_squared_error: 124.3557\n",
      "Epoch 00297: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 544us/step - loss: 135.6191 - mean_squared_error: 124.4961 - val_loss: 152.0966 - val_mean_squared_error: 140.9759\n",
      "Epoch 298/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 134.1356 - mean_squared_error: 123.0180\n",
      "Epoch 00298: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 542us/step - loss: 133.9886 - mean_squared_error: 122.8708 - val_loss: 153.7648 - val_mean_squared_error: 142.6419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 132.1582 - mean_squared_error: 121.0356\n",
      "Epoch 00299: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 537us/step - loss: 134.2780 - mean_squared_error: 123.1554 - val_loss: 197.2864 - val_mean_squared_error: 186.1645\n",
      "Epoch 300/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 135.8870 - mean_squared_error: 124.7709\n",
      "Epoch 00300: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 540us/step - loss: 135.5628 - mean_squared_error: 124.4468 - val_loss: 160.3080 - val_mean_squared_error: 149.1947\n",
      "Epoch 301/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 134.1615 - mean_squared_error: 123.0398\n",
      "Epoch 00301: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 542us/step - loss: 133.9324 - mean_squared_error: 122.8108 - val_loss: 149.7952 - val_mean_squared_error: 138.6770\n",
      "Epoch 302/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 134.7472 - mean_squared_error: 123.6205\n",
      "Epoch 00302: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 537us/step - loss: 134.5917 - mean_squared_error: 123.4651 - val_loss: 164.2202 - val_mean_squared_error: 153.0980\n",
      "Epoch 303/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 131.4670 - mean_squared_error: 120.3389\n",
      "Epoch 00303: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 537us/step - loss: 132.0096 - mean_squared_error: 120.8811 - val_loss: 163.0539 - val_mean_squared_error: 151.9157\n",
      "Epoch 304/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 132.6976 - mean_squared_error: 121.5629\n",
      "Epoch 00304: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 542us/step - loss: 132.2373 - mean_squared_error: 121.1027 - val_loss: 159.3347 - val_mean_squared_error: 148.2056\n",
      "Epoch 305/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 134.0359 - mean_squared_error: 122.9159\n",
      "Epoch 00305: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 537us/step - loss: 133.6147 - mean_squared_error: 122.4949 - val_loss: 155.7751 - val_mean_squared_error: 144.6621\n",
      "Epoch 306/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 135.1059 - mean_squared_error: 123.9759\n",
      "Epoch 00306: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 537us/step - loss: 134.8340 - mean_squared_error: 123.7038 - val_loss: 160.4458 - val_mean_squared_error: 149.3094\n",
      "Epoch 307/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 132.6619 - mean_squared_error: 121.5238\n",
      "Epoch 00307: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 535us/step - loss: 133.0316 - mean_squared_error: 121.8932 - val_loss: 164.5934 - val_mean_squared_error: 153.4418\n",
      "Epoch 308/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 132.1811 - mean_squared_error: 121.0386\n",
      "Epoch 00308: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 540us/step - loss: 132.4279 - mean_squared_error: 121.2857 - val_loss: 151.1074 - val_mean_squared_error: 139.9704\n",
      "Epoch 309/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 137.7770 - mean_squared_error: 126.6298\n",
      "Epoch 00309: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 537us/step - loss: 137.2915 - mean_squared_error: 126.1443 - val_loss: 159.7767 - val_mean_squared_error: 148.6268\n",
      "Epoch 310/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 135.2478 - mean_squared_error: 124.1003\n",
      "Epoch 00310: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 537us/step - loss: 135.1713 - mean_squared_error: 124.0239 - val_loss: 149.9059 - val_mean_squared_error: 138.7665\n",
      "Epoch 311/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 133.9247 - mean_squared_error: 122.7760\n",
      "Epoch 00311: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 540us/step - loss: 134.5543 - mean_squared_error: 123.4052 - val_loss: 170.9199 - val_mean_squared_error: 159.7540\n",
      "Epoch 312/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 135.4992 - mean_squared_error: 124.3384\n",
      "Epoch 00312: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 540us/step - loss: 134.5973 - mean_squared_error: 123.4364 - val_loss: 167.3750 - val_mean_squared_error: 156.2132\n",
      "Epoch 313/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 135.3536 - mean_squared_error: 124.2011\n",
      "Epoch 00313: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 540us/step - loss: 135.0347 - mean_squared_error: 123.8824 - val_loss: 150.8171 - val_mean_squared_error: 139.6728\n",
      "Epoch 314/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 130.6817 - mean_squared_error: 119.5425\n",
      "Epoch 00314: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 537us/step - loss: 130.9390 - mean_squared_error: 119.7999 - val_loss: 154.7369 - val_mean_squared_error: 143.5990\n",
      "Epoch 315/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 132.4349 - mean_squared_error: 121.2838\n",
      "Epoch 00315: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 539us/step - loss: 131.7544 - mean_squared_error: 120.6032 - val_loss: 156.3893 - val_mean_squared_error: 145.2363\n",
      "Epoch 316/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 130.3030 - mean_squared_error: 119.1536\n",
      "Epoch 00316: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 537us/step - loss: 130.3798 - mean_squared_error: 119.2306 - val_loss: 152.7084 - val_mean_squared_error: 141.5676\n",
      "Epoch 317/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 136.9153 - mean_squared_error: 125.7667\n",
      "Epoch 00317: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 539us/step - loss: 137.1484 - mean_squared_error: 125.9996 - val_loss: 154.9202 - val_mean_squared_error: 143.7603\n",
      "Epoch 318/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 132.7721 - mean_squared_error: 121.6146\n",
      "Epoch 00318: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 540us/step - loss: 133.2452 - mean_squared_error: 122.0879 - val_loss: 170.1121 - val_mean_squared_error: 158.9617\n",
      "Epoch 319/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 131.5874 - mean_squared_error: 120.4419\n",
      "Epoch 00319: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 539us/step - loss: 132.0075 - mean_squared_error: 120.8621 - val_loss: 172.5073 - val_mean_squared_error: 161.3666\n",
      "Epoch 320/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 130.1842 - mean_squared_error: 119.0424\n",
      "Epoch 00320: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 535us/step - loss: 130.2654 - mean_squared_error: 119.1237 - val_loss: 155.6126 - val_mean_squared_error: 144.4713\n",
      "Epoch 321/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 136.0877 - mean_squared_error: 124.9365\n",
      "Epoch 00321: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 539us/step - loss: 135.5101 - mean_squared_error: 124.3588 - val_loss: 155.9208 - val_mean_squared_error: 144.7659\n",
      "Epoch 322/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 132.1522 - mean_squared_error: 120.9948\n",
      "Epoch 00322: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 540us/step - loss: 131.7867 - mean_squared_error: 120.6295 - val_loss: 153.7206 - val_mean_squared_error: 142.5714\n",
      "Epoch 323/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 132.7713 - mean_squared_error: 121.6150\n",
      "Epoch 00323: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 539us/step - loss: 132.2362 - mean_squared_error: 121.0798 - val_loss: 158.8600 - val_mean_squared_error: 147.6980\n",
      "Epoch 324/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 131.8949 - mean_squared_error: 120.7294\n",
      "Epoch 00324: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 537us/step - loss: 132.2615 - mean_squared_error: 121.0960 - val_loss: 150.7566 - val_mean_squared_error: 139.5921\n",
      "Epoch 325/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 128.9825 - mean_squared_error: 117.8222\n",
      "Epoch 00325: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 535us/step - loss: 128.3390 - mean_squared_error: 117.1787 - val_loss: 150.9534 - val_mean_squared_error: 139.7979\n",
      "Epoch 326/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 127.4135 - mean_squared_error: 116.2597\n",
      "Epoch 00326: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 540us/step - loss: 128.3043 - mean_squared_error: 117.1504 - val_loss: 158.6960 - val_mean_squared_error: 147.5382\n",
      "Epoch 327/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 126.7003 - mean_squared_error: 115.5278\n",
      "Epoch 00327: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 537us/step - loss: 126.0810 - mean_squared_error: 114.9084 - val_loss: 152.0763 - val_mean_squared_error: 140.9062\n",
      "Epoch 328/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 131.4478 - mean_squared_error: 120.2786\n",
      "Epoch 00328: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 539us/step - loss: 131.7684 - mean_squared_error: 120.5993 - val_loss: 153.3964 - val_mean_squared_error: 142.2314\n",
      "Epoch 329/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 131.8911 - mean_squared_error: 120.7294\n",
      "Epoch 00329: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 537us/step - loss: 131.7882 - mean_squared_error: 120.6264 - val_loss: 147.2694 - val_mean_squared_error: 136.1031\n",
      "Epoch 330/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 128.5622 - mean_squared_error: 117.3899\n",
      "Epoch 00330: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 540us/step - loss: 128.7808 - mean_squared_error: 117.6086 - val_loss: 158.5061 - val_mean_squared_error: 147.3354\n",
      "Epoch 331/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 127.4534 - mean_squared_error: 116.2875\n",
      "Epoch 00331: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 535us/step - loss: 128.1485 - mean_squared_error: 116.9826 - val_loss: 163.6156 - val_mean_squared_error: 152.4460\n",
      "Epoch 332/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 131.0898 - mean_squared_error: 119.9105\n",
      "Epoch 00332: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 535us/step - loss: 130.8569 - mean_squared_error: 119.6775 - val_loss: 150.6224 - val_mean_squared_error: 139.4348\n",
      "Epoch 333/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 129.3770 - mean_squared_error: 118.1881\n",
      "Epoch 00333: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 542us/step - loss: 129.2701 - mean_squared_error: 118.0812 - val_loss: 167.5811 - val_mean_squared_error: 156.3890\n",
      "Epoch 334/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 131.3889 - mean_squared_error: 120.1942\n",
      "Epoch 00334: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 537us/step - loss: 131.3498 - mean_squared_error: 120.1550 - val_loss: 185.7950 - val_mean_squared_error: 174.5950\n",
      "Epoch 335/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 128.4740 - mean_squared_error: 117.2682\n",
      "Epoch 00335: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 540us/step - loss: 128.9361 - mean_squared_error: 117.7303 - val_loss: 158.1075 - val_mean_squared_error: 146.9034\n",
      "Epoch 336/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 130.5032 - mean_squared_error: 119.2990\n",
      "Epoch 00336: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 539us/step - loss: 129.4541 - mean_squared_error: 118.2500 - val_loss: 158.7222 - val_mean_squared_error: 147.5234\n",
      "Epoch 337/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 130.4496 - mean_squared_error: 119.2531\n",
      "Epoch 00337: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 539us/step - loss: 130.0685 - mean_squared_error: 118.8719 - val_loss: 146.1484 - val_mean_squared_error: 134.9515\n",
      "Epoch 338/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 127.9851 - mean_squared_error: 116.7909\n",
      "Epoch 00338: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 535us/step - loss: 128.3005 - mean_squared_error: 117.1063 - val_loss: 156.6827 - val_mean_squared_error: 145.4886\n",
      "Epoch 339/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 127.6933 - mean_squared_error: 116.4965\n",
      "Epoch 00339: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 531us/step - loss: 127.4280 - mean_squared_error: 116.2312 - val_loss: 148.4342 - val_mean_squared_error: 137.2383\n",
      "Epoch 340/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 128.7446 - mean_squared_error: 117.5492\n",
      "Epoch 00340: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 539us/step - loss: 128.4267 - mean_squared_error: 117.2314 - val_loss: 146.1595 - val_mean_squared_error: 134.9648\n",
      "Epoch 341/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 125.0527 - mean_squared_error: 113.8613\n",
      "Epoch 00341: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 535us/step - loss: 124.7879 - mean_squared_error: 113.5964 - val_loss: 175.2467 - val_mean_squared_error: 164.0515\n",
      "Epoch 342/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 128.7071 - mean_squared_error: 117.5054\n",
      "Epoch 00342: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 535us/step - loss: 129.4604 - mean_squared_error: 118.2587 - val_loss: 174.0336 - val_mean_squared_error: 162.8309\n",
      "Epoch 343/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 127.9074 - mean_squared_error: 116.7128\n",
      "Epoch 00343: val_loss did not improve from 145.27972\n",
      "526/526 [==============================] - 0s 535us/step - loss: 127.9244 - mean_squared_error: 116.7299 - val_loss: 167.3535 - val_mean_squared_error: 156.1631\n",
      "Epoch 344/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 129.1943 - mean_squared_error: 118.0030\n",
      "Epoch 00344: val_loss improved from 145.27972 to 142.20178, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 788us/step - loss: 129.5514 - mean_squared_error: 118.3599 - val_loss: 142.2018 - val_mean_squared_error: 131.0014\n",
      "Epoch 345/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 125.8640 - mean_squared_error: 114.6582\n",
      "Epoch 00345: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 535us/step - loss: 126.3740 - mean_squared_error: 115.1683 - val_loss: 157.1890 - val_mean_squared_error: 145.9800\n",
      "Epoch 346/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 128.3218 - mean_squared_error: 117.1226\n",
      "Epoch 00346: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 539us/step - loss: 128.5558 - mean_squared_error: 117.3568 - val_loss: 156.5770 - val_mean_squared_error: 145.3841\n",
      "Epoch 347/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 124.4291 - mean_squared_error: 113.2411\n",
      "Epoch 00347: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 542us/step - loss: 124.9846 - mean_squared_error: 113.7969 - val_loss: 151.1155 - val_mean_squared_error: 139.9360\n",
      "Epoch 348/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 126.2609 - mean_squared_error: 115.0748\n",
      "Epoch 00348: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 544us/step - loss: 126.1381 - mean_squared_error: 114.9517 - val_loss: 155.9737 - val_mean_squared_error: 144.7795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 126.6578 - mean_squared_error: 115.4618\n",
      "Epoch 00349: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 537us/step - loss: 126.6681 - mean_squared_error: 115.4722 - val_loss: 147.6761 - val_mean_squared_error: 136.4845\n",
      "Epoch 350/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 126.1967 - mean_squared_error: 114.9964\n",
      "Epoch 00350: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 537us/step - loss: 126.7366 - mean_squared_error: 115.5363 - val_loss: 148.3482 - val_mean_squared_error: 137.1470\n",
      "Epoch 351/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 124.7750 - mean_squared_error: 113.5648\n",
      "Epoch 00351: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 540us/step - loss: 124.6851 - mean_squared_error: 113.4744 - val_loss: 166.1295 - val_mean_squared_error: 154.9074\n",
      "Epoch 352/500\n",
      "506/526 [===========================>..] - ETA: 0s - loss: 123.8235 - mean_squared_error: 112.6048\n",
      "Epoch 00352: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 544us/step - loss: 124.3812 - mean_squared_error: 113.1628 - val_loss: 203.6038 - val_mean_squared_error: 192.3926\n",
      "Epoch 353/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 125.6545 - mean_squared_error: 114.4401\n",
      "Epoch 00353: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 539us/step - loss: 126.1233 - mean_squared_error: 114.9088 - val_loss: 143.8007 - val_mean_squared_error: 132.5824\n",
      "Epoch 354/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 126.9886 - mean_squared_error: 115.7670\n",
      "Epoch 00354: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 542us/step - loss: 126.9523 - mean_squared_error: 115.7307 - val_loss: 150.8895 - val_mean_squared_error: 139.6666\n",
      "Epoch 355/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 125.7817 - mean_squared_error: 114.5581\n",
      "Epoch 00355: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 544us/step - loss: 126.5605 - mean_squared_error: 115.3369 - val_loss: 158.7380 - val_mean_squared_error: 147.5136\n",
      "Epoch 356/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 128.1591 - mean_squared_error: 116.9372\n",
      "Epoch 00356: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 540us/step - loss: 128.8796 - mean_squared_error: 117.6575 - val_loss: 163.8944 - val_mean_squared_error: 152.6616\n",
      "Epoch 357/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 127.0647 - mean_squared_error: 115.8260\n",
      "Epoch 00357: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 542us/step - loss: 127.3757 - mean_squared_error: 116.1367 - val_loss: 150.6033 - val_mean_squared_error: 139.3546\n",
      "Epoch 358/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 125.1596 - mean_squared_error: 113.9117\n",
      "Epoch 00358: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 544us/step - loss: 125.0579 - mean_squared_error: 113.8103 - val_loss: 161.9099 - val_mean_squared_error: 150.6690\n",
      "Epoch 359/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 125.3636 - mean_squared_error: 114.1287\n",
      "Epoch 00359: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 542us/step - loss: 125.4132 - mean_squared_error: 114.1785 - val_loss: 158.5184 - val_mean_squared_error: 147.2897\n",
      "Epoch 360/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 124.7712 - mean_squared_error: 113.5444\n",
      "Epoch 00360: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 542us/step - loss: 124.6228 - mean_squared_error: 113.3957 - val_loss: 143.3187 - val_mean_squared_error: 132.0819\n",
      "Epoch 361/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 123.7960 - mean_squared_error: 112.5659\n",
      "Epoch 00361: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 540us/step - loss: 124.2599 - mean_squared_error: 113.0300 - val_loss: 152.6800 - val_mean_squared_error: 141.4579\n",
      "Epoch 362/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 131.1132 - mean_squared_error: 119.8898\n",
      "Epoch 00362: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 542us/step - loss: 130.7505 - mean_squared_error: 119.5270 - val_loss: 156.8914 - val_mean_squared_error: 145.6639\n",
      "Epoch 363/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 125.5566 - mean_squared_error: 114.3267\n",
      "Epoch 00363: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 539us/step - loss: 125.5690 - mean_squared_error: 114.3392 - val_loss: 155.8622 - val_mean_squared_error: 144.6352\n",
      "Epoch 364/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 124.8707 - mean_squared_error: 113.6442\n",
      "Epoch 00364: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 544us/step - loss: 124.4013 - mean_squared_error: 113.1749 - val_loss: 145.6443 - val_mean_squared_error: 134.4197\n",
      "Epoch 365/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 123.0414 - mean_squared_error: 111.8108\n",
      "Epoch 00365: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 539us/step - loss: 123.2067 - mean_squared_error: 111.9761 - val_loss: 182.1199 - val_mean_squared_error: 170.8888\n",
      "Epoch 366/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 125.4533 - mean_squared_error: 114.2260\n",
      "Epoch 00366: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 542us/step - loss: 125.0272 - mean_squared_error: 113.8001 - val_loss: 151.1319 - val_mean_squared_error: 139.9113\n",
      "Epoch 367/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 122.8283 - mean_squared_error: 111.6000\n",
      "Epoch 00367: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 540us/step - loss: 122.1008 - mean_squared_error: 110.8725 - val_loss: 146.4145 - val_mean_squared_error: 135.1816\n",
      "Epoch 368/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 124.6866 - mean_squared_error: 113.4477\n",
      "Epoch 00368: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 542us/step - loss: 124.6123 - mean_squared_error: 113.3736 - val_loss: 149.5589 - val_mean_squared_error: 138.3229\n",
      "Epoch 369/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 125.0595 - mean_squared_error: 113.8166\n",
      "Epoch 00369: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 544us/step - loss: 124.6042 - mean_squared_error: 113.3613 - val_loss: 161.1972 - val_mean_squared_error: 149.9570\n",
      "Epoch 370/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 122.8034 - mean_squared_error: 111.5663\n",
      "Epoch 00370: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 539us/step - loss: 122.8710 - mean_squared_error: 111.6337 - val_loss: 145.8087 - val_mean_squared_error: 134.5663\n",
      "Epoch 371/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 123.1759 - mean_squared_error: 111.9325\n",
      "Epoch 00371: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 542us/step - loss: 123.1299 - mean_squared_error: 111.8866 - val_loss: 152.7775 - val_mean_squared_error: 141.5391\n",
      "Epoch 372/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 122.4939 - mean_squared_error: 111.2509\n",
      "Epoch 00372: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 542us/step - loss: 122.5019 - mean_squared_error: 111.2584 - val_loss: 146.8544 - val_mean_squared_error: 135.5995\n",
      "Epoch 373/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 123.8327 - mean_squared_error: 112.5894\n",
      "Epoch 00373: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 542us/step - loss: 123.5487 - mean_squared_error: 112.3056 - val_loss: 149.4289 - val_mean_squared_error: 138.1920\n",
      "Epoch 374/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 124.4451 - mean_squared_error: 113.2104\n",
      "Epoch 00374: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 540us/step - loss: 124.9577 - mean_squared_error: 113.7229 - val_loss: 149.1612 - val_mean_squared_error: 137.9206\n",
      "Epoch 375/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 124.1390 - mean_squared_error: 112.9081\n",
      "Epoch 00375: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 544us/step - loss: 123.6001 - mean_squared_error: 112.3691 - val_loss: 142.6932 - val_mean_squared_error: 131.4595\n",
      "Epoch 376/500\n",
      "498/526 [===========================>..] - ETA: 0s - loss: 126.3048 - mean_squared_error: 115.0666\n",
      "Epoch 00376: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 558us/step - loss: 126.1653 - mean_squared_error: 114.9270 - val_loss: 161.1531 - val_mean_squared_error: 149.9167\n",
      "Epoch 377/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 124.3334 - mean_squared_error: 113.0996\n",
      "Epoch 00377: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 539us/step - loss: 124.1838 - mean_squared_error: 112.9500 - val_loss: 157.8686 - val_mean_squared_error: 146.6348\n",
      "Epoch 378/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 123.8623 - mean_squared_error: 112.6257\n",
      "Epoch 00378: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 539us/step - loss: 123.6378 - mean_squared_error: 112.4013 - val_loss: 144.8636 - val_mean_squared_error: 133.6330\n",
      "Epoch 379/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 121.5048 - mean_squared_error: 110.2641\n",
      "Epoch 00379: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 537us/step - loss: 122.0782 - mean_squared_error: 110.8375 - val_loss: 146.4568 - val_mean_squared_error: 135.2168\n",
      "Epoch 380/500\n",
      "503/526 [===========================>..] - ETA: 0s - loss: 123.8850 - mean_squared_error: 112.6423\n",
      "Epoch 00380: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 550us/step - loss: 124.1809 - mean_squared_error: 112.9375 - val_loss: 146.1043 - val_mean_squared_error: 134.8457\n",
      "Epoch 381/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 123.3399 - mean_squared_error: 112.0865\n",
      "Epoch 00381: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 544us/step - loss: 124.5717 - mean_squared_error: 113.3183 - val_loss: 155.4776 - val_mean_squared_error: 144.2232\n",
      "Epoch 382/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 121.1663 - mean_squared_error: 109.9121\n",
      "Epoch 00382: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 540us/step - loss: 120.6359 - mean_squared_error: 109.3815 - val_loss: 147.6349 - val_mean_squared_error: 136.3759\n",
      "Epoch 383/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 120.0394 - mean_squared_error: 108.7871\n",
      "Epoch 00383: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 535us/step - loss: 120.4661 - mean_squared_error: 109.2137 - val_loss: 161.2419 - val_mean_squared_error: 149.9863\n",
      "Epoch 384/500\n",
      "496/526 [===========================>..] - ETA: 0s - loss: 124.0310 - mean_squared_error: 112.7769\n",
      "Epoch 00384: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 556us/step - loss: 124.0939 - mean_squared_error: 112.8394 - val_loss: 150.6897 - val_mean_squared_error: 139.4283\n",
      "Epoch 385/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 125.4792 - mean_squared_error: 114.2247\n",
      "Epoch 00385: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 565us/step - loss: 123.8788 - mean_squared_error: 112.6239 - val_loss: 147.8631 - val_mean_squared_error: 136.6063\n",
      "Epoch 386/500\n",
      "492/526 [===========================>..] - ETA: 0s - loss: 119.7044 - mean_squared_error: 108.4539\n",
      "Epoch 00386: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 559us/step - loss: 119.5519 - mean_squared_error: 108.3016 - val_loss: 166.2182 - val_mean_squared_error: 154.9711\n",
      "Epoch 387/500\n",
      "491/526 [===========================>..] - ETA: 0s - loss: 121.4902 - mean_squared_error: 110.2365\n",
      "Epoch 00387: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 561us/step - loss: 122.3209 - mean_squared_error: 111.0666 - val_loss: 147.0229 - val_mean_squared_error: 135.7594\n",
      "Epoch 388/500\n",
      "492/526 [===========================>..] - ETA: 0s - loss: 120.9757 - mean_squared_error: 109.7164\n",
      "Epoch 00388: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 563us/step - loss: 120.9618 - mean_squared_error: 109.7018 - val_loss: 147.7781 - val_mean_squared_error: 136.5098\n",
      "Epoch 389/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 121.5443 - mean_squared_error: 110.2802\n",
      "Epoch 00389: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 563us/step - loss: 122.1652 - mean_squared_error: 110.9016 - val_loss: 163.9873 - val_mean_squared_error: 152.7311\n",
      "Epoch 390/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 120.2704 - mean_squared_error: 109.0206\n",
      "Epoch 00390: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 563us/step - loss: 119.8272 - mean_squared_error: 108.5776 - val_loss: 157.4927 - val_mean_squared_error: 146.2451\n",
      "Epoch 391/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 121.6712 - mean_squared_error: 110.4203\n",
      "Epoch 00391: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 565us/step - loss: 122.2263 - mean_squared_error: 110.9748 - val_loss: 152.5566 - val_mean_squared_error: 141.2970\n",
      "Epoch 392/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 119.5200 - mean_squared_error: 108.2614\n",
      "Epoch 00392: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 565us/step - loss: 119.9110 - mean_squared_error: 108.6523 - val_loss: 142.9949 - val_mean_squared_error: 131.7361\n",
      "Epoch 393/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 118.2952 - mean_squared_error: 107.0417\n",
      "Epoch 00393: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 565us/step - loss: 119.8859 - mean_squared_error: 108.6324 - val_loss: 155.8993 - val_mean_squared_error: 144.6454\n",
      "Epoch 394/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 120.7660 - mean_squared_error: 109.5108\n",
      "Epoch 00394: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 565us/step - loss: 121.1774 - mean_squared_error: 109.9218 - val_loss: 145.8131 - val_mean_squared_error: 134.5538\n",
      "Epoch 395/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 121.4808 - mean_squared_error: 110.2215\n",
      "Epoch 00395: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 563us/step - loss: 121.5834 - mean_squared_error: 110.3232 - val_loss: 166.4111 - val_mean_squared_error: 155.1383\n",
      "Epoch 396/500\n",
      "491/526 [===========================>..] - ETA: 0s - loss: 119.7288 - mean_squared_error: 108.4613\n",
      "Epoch 00396: val_loss did not improve from 142.20178\n",
      "526/526 [==============================] - 0s 561us/step - loss: 120.1372 - mean_squared_error: 108.8701 - val_loss: 157.4031 - val_mean_squared_error: 146.1409\n",
      "Epoch 397/500\n",
      "492/526 [===========================>..] - ETA: 0s - loss: 123.0730 - mean_squared_error: 111.8066\n",
      "Epoch 00397: val_loss improved from 142.20178 to 139.80577, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 750us/step - loss: 122.4588 - mean_squared_error: 111.1925 - val_loss: 139.8058 - val_mean_squared_error: 128.5400\n",
      "Epoch 398/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 119.4099 - mean_squared_error: 108.1321\n",
      "Epoch 00398: val_loss did not improve from 139.80577\n",
      "526/526 [==============================] - 0s 567us/step - loss: 119.3794 - mean_squared_error: 108.1020 - val_loss: 150.7166 - val_mean_squared_error: 139.4455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/500\n",
      "491/526 [===========================>..] - ETA: 0s - loss: 121.0026 - mean_squared_error: 109.7336\n",
      "Epoch 00399: val_loss did not improve from 139.80577\n",
      "526/526 [==============================] - 0s 561us/step - loss: 121.0794 - mean_squared_error: 109.8111 - val_loss: 145.6537 - val_mean_squared_error: 134.3951\n",
      "Epoch 400/500\n",
      "493/526 [===========================>..] - ETA: 0s - loss: 121.1186 - mean_squared_error: 109.8559\n",
      "Epoch 00400: val_loss did not improve from 139.80577\n",
      "526/526 [==============================] - 0s 558us/step - loss: 121.0302 - mean_squared_error: 109.7676 - val_loss: 142.2043 - val_mean_squared_error: 130.9422\n",
      "Epoch 401/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 122.2083 - mean_squared_error: 110.9471\n",
      "Epoch 00401: val_loss did not improve from 139.80577\n",
      "526/526 [==============================] - 0s 565us/step - loss: 121.7360 - mean_squared_error: 110.4745 - val_loss: 153.5177 - val_mean_squared_error: 142.2535\n",
      "Epoch 402/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 117.8832 - mean_squared_error: 106.6222\n",
      "Epoch 00402: val_loss did not improve from 139.80577\n",
      "526/526 [==============================] - 0s 563us/step - loss: 118.9749 - mean_squared_error: 107.7142 - val_loss: 148.6013 - val_mean_squared_error: 137.3471\n",
      "Epoch 403/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 117.4568 - mean_squared_error: 106.1976\n",
      "Epoch 00403: val_loss did not improve from 139.80577\n",
      "526/526 [==============================] - 0s 561us/step - loss: 118.5644 - mean_squared_error: 107.3045 - val_loss: 149.8518 - val_mean_squared_error: 138.5834\n",
      "Epoch 404/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 119.6013 - mean_squared_error: 108.3360\n",
      "Epoch 00404: val_loss did not improve from 139.80577\n",
      "526/526 [==============================] - 0s 563us/step - loss: 118.9694 - mean_squared_error: 107.7036 - val_loss: 154.1945 - val_mean_squared_error: 142.9176\n",
      "Epoch 405/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 117.5791 - mean_squared_error: 106.3015\n",
      "Epoch 00405: val_loss did not improve from 139.80577\n",
      "526/526 [==============================] - 0s 565us/step - loss: 119.1928 - mean_squared_error: 107.9155 - val_loss: 151.3761 - val_mean_squared_error: 140.1027\n",
      "Epoch 406/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 120.4768 - mean_squared_error: 109.1933\n",
      "Epoch 00406: val_loss did not improve from 139.80577\n",
      "526/526 [==============================] - 0s 565us/step - loss: 119.8821 - mean_squared_error: 108.5979 - val_loss: 145.4811 - val_mean_squared_error: 134.1893\n",
      "Epoch 407/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 120.7941 - mean_squared_error: 109.5069\n",
      "Epoch 00407: val_loss did not improve from 139.80577\n",
      "526/526 [==============================] - 0s 565us/step - loss: 119.7777 - mean_squared_error: 108.4899 - val_loss: 145.2692 - val_mean_squared_error: 133.9771\n",
      "Epoch 408/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 119.6626 - mean_squared_error: 108.3805\n",
      "Epoch 00408: val_loss did not improve from 139.80577\n",
      "526/526 [==============================] - 0s 567us/step - loss: 119.4476 - mean_squared_error: 108.1657 - val_loss: 147.3061 - val_mean_squared_error: 136.0267\n",
      "Epoch 409/500\n",
      "491/526 [===========================>..] - ETA: 0s - loss: 117.3304 - mean_squared_error: 106.0592\n",
      "Epoch 00409: val_loss did not improve from 139.80577\n",
      "526/526 [==============================] - 0s 563us/step - loss: 116.9752 - mean_squared_error: 105.7043 - val_loss: 153.0690 - val_mean_squared_error: 141.8024\n",
      "Epoch 410/500\n",
      "492/526 [===========================>..] - ETA: 0s - loss: 117.6236 - mean_squared_error: 106.3574\n",
      "Epoch 00410: val_loss did not improve from 139.80577\n",
      "526/526 [==============================] - 0s 559us/step - loss: 117.3989 - mean_squared_error: 106.1321 - val_loss: 151.3673 - val_mean_squared_error: 140.0915\n",
      "Epoch 411/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 124.1275 - mean_squared_error: 112.8491\n",
      "Epoch 00411: val_loss did not improve from 139.80577\n",
      "526/526 [==============================] - 0s 565us/step - loss: 123.1915 - mean_squared_error: 111.9129 - val_loss: 143.9434 - val_mean_squared_error: 132.6625\n",
      "Epoch 412/500\n",
      "492/526 [===========================>..] - ETA: 0s - loss: 121.1846 - mean_squared_error: 109.9078\n",
      "Epoch 00412: val_loss did not improve from 139.80577\n",
      "526/526 [==============================] - 0s 561us/step - loss: 120.2157 - mean_squared_error: 108.9392 - val_loss: 143.3992 - val_mean_squared_error: 132.1273\n",
      "Epoch 413/500\n",
      "492/526 [===========================>..] - ETA: 0s - loss: 118.7010 - mean_squared_error: 107.4264\n",
      "Epoch 00413: val_loss did not improve from 139.80577\n",
      "526/526 [==============================] - 0s 563us/step - loss: 118.9753 - mean_squared_error: 107.7005 - val_loss: 152.3790 - val_mean_squared_error: 141.1034\n",
      "Epoch 414/500\n",
      "492/526 [===========================>..] - ETA: 0s - loss: 118.9797 - mean_squared_error: 107.7050\n",
      "Epoch 00414: val_loss did not improve from 139.80577\n",
      "526/526 [==============================] - 0s 563us/step - loss: 117.7248 - mean_squared_error: 106.4504 - val_loss: 145.7547 - val_mean_squared_error: 134.4874\n",
      "Epoch 415/500\n",
      "480/526 [==========================>...] - ETA: 0s - loss: 118.2172 - mean_squared_error: 106.9454\n",
      "Epoch 00415: val_loss did not improve from 139.80577\n",
      "526/526 [==============================] - 0s 573us/step - loss: 119.4526 - mean_squared_error: 108.1806 - val_loss: 158.9192 - val_mean_squared_error: 147.6451\n",
      "Epoch 416/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 117.5060 - mean_squared_error: 106.2282\n",
      "Epoch 00416: val_loss did not improve from 139.80577\n",
      "526/526 [==============================] - 0s 563us/step - loss: 117.3289 - mean_squared_error: 106.0513 - val_loss: 156.8289 - val_mean_squared_error: 145.5546\n",
      "Epoch 417/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 118.2067 - mean_squared_error: 106.9280\n",
      "Epoch 00417: val_loss did not improve from 139.80577\n",
      "526/526 [==============================] - 0s 563us/step - loss: 118.1325 - mean_squared_error: 106.8533 - val_loss: 155.2301 - val_mean_squared_error: 143.9438\n",
      "Epoch 418/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 120.4122 - mean_squared_error: 109.1131\n",
      "Epoch 00418: val_loss improved from 139.80577 to 138.38559, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 742us/step - loss: 120.6007 - mean_squared_error: 109.3013 - val_loss: 138.3856 - val_mean_squared_error: 127.0835\n",
      "Epoch 419/500\n",
      "493/526 [===========================>..] - ETA: 0s - loss: 117.2367 - mean_squared_error: 105.9420\n",
      "Epoch 00419: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 559us/step - loss: 118.4524 - mean_squared_error: 107.1578 - val_loss: 142.2699 - val_mean_squared_error: 130.9770\n",
      "Epoch 420/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 119.1360 - mean_squared_error: 107.8472\n",
      "Epoch 00420: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 561us/step - loss: 118.7906 - mean_squared_error: 107.5016 - val_loss: 160.7360 - val_mean_squared_error: 149.4453\n",
      "Epoch 421/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 120.2510 - mean_squared_error: 108.9602\n",
      "Epoch 00421: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 567us/step - loss: 119.7562 - mean_squared_error: 108.4655 - val_loss: 140.7875 - val_mean_squared_error: 129.4987\n",
      "Epoch 422/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 117.5033 - mean_squared_error: 106.2163\n",
      "Epoch 00422: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 563us/step - loss: 117.2188 - mean_squared_error: 105.9322 - val_loss: 151.8061 - val_mean_squared_error: 140.5240\n",
      "Epoch 423/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 119.7488 - mean_squared_error: 108.4685\n",
      "Epoch 00423: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 563us/step - loss: 119.2268 - mean_squared_error: 107.9456 - val_loss: 146.8541 - val_mean_squared_error: 135.5625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 424/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 118.7323 - mean_squared_error: 107.4430\n",
      "Epoch 00424: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 565us/step - loss: 118.7502 - mean_squared_error: 107.4609 - val_loss: 158.6399 - val_mean_squared_error: 147.3482\n",
      "Epoch 425/500\n",
      "486/526 [==========================>...] - ETA: 0s - loss: 121.5162 - mean_squared_error: 110.2142\n",
      "Epoch 00425: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 567us/step - loss: 120.9847 - mean_squared_error: 109.6831 - val_loss: 145.9702 - val_mean_squared_error: 134.6748\n",
      "Epoch 426/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 119.1537 - mean_squared_error: 107.8457\n",
      "Epoch 00426: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 565us/step - loss: 118.3127 - mean_squared_error: 107.0047 - val_loss: 141.7712 - val_mean_squared_error: 130.4615\n",
      "Epoch 427/500\n",
      "492/526 [===========================>..] - ETA: 0s - loss: 117.3172 - mean_squared_error: 106.0133\n",
      "Epoch 00427: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 559us/step - loss: 116.6363 - mean_squared_error: 105.3330 - val_loss: 147.7941 - val_mean_squared_error: 136.4992\n",
      "Epoch 428/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 119.9726 - mean_squared_error: 108.6777\n",
      "Epoch 00428: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 567us/step - loss: 120.4283 - mean_squared_error: 109.1335 - val_loss: 150.2236 - val_mean_squared_error: 138.9325\n",
      "Epoch 429/500\n",
      "491/526 [===========================>..] - ETA: 0s - loss: 118.4111 - mean_squared_error: 107.1267\n",
      "Epoch 00429: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 561us/step - loss: 119.0020 - mean_squared_error: 107.7181 - val_loss: 141.6478 - val_mean_squared_error: 130.3718\n",
      "Epoch 430/500\n",
      "489/526 [==========================>...] - ETA: 0s - loss: 117.0430 - mean_squared_error: 105.7700\n",
      "Epoch 00430: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 563us/step - loss: 117.2808 - mean_squared_error: 106.0077 - val_loss: 159.0657 - val_mean_squared_error: 147.7886\n",
      "Epoch 431/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 116.8806 - mean_squared_error: 105.6048\n",
      "Epoch 00431: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 561us/step - loss: 117.1094 - mean_squared_error: 105.8336 - val_loss: 149.2658 - val_mean_squared_error: 137.9908\n",
      "Epoch 432/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 115.0265 - mean_squared_error: 103.7458\n",
      "Epoch 00432: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 565us/step - loss: 116.2180 - mean_squared_error: 104.9368 - val_loss: 150.5260 - val_mean_squared_error: 139.2380\n",
      "Epoch 433/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 118.3731 - mean_squared_error: 107.0855\n",
      "Epoch 00433: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 561us/step - loss: 120.9191 - mean_squared_error: 109.6313 - val_loss: 142.9390 - val_mean_squared_error: 131.6501\n",
      "Epoch 434/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 116.9687 - mean_squared_error: 105.6809\n",
      "Epoch 00434: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 567us/step - loss: 116.7604 - mean_squared_error: 105.4713 - val_loss: 146.5203 - val_mean_squared_error: 135.2137\n",
      "Epoch 435/500\n",
      "487/526 [==========================>...] - ETA: 0s - loss: 115.6561 - mean_squared_error: 104.3516\n",
      "Epoch 00435: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 569us/step - loss: 114.8525 - mean_squared_error: 103.5486 - val_loss: 144.6689 - val_mean_squared_error: 133.3733\n",
      "Epoch 436/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 119.4012 - mean_squared_error: 108.0828\n",
      "Epoch 00436: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 544us/step - loss: 119.2135 - mean_squared_error: 107.8951 - val_loss: 152.1275 - val_mean_squared_error: 140.8074\n",
      "Epoch 437/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 116.9495 - mean_squared_error: 105.6369\n",
      "Epoch 00437: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 540us/step - loss: 117.6616 - mean_squared_error: 106.3493 - val_loss: 145.7435 - val_mean_squared_error: 134.4386\n",
      "Epoch 438/500\n",
      "490/526 [==========================>...] - ETA: 0s - loss: 119.4152 - mean_squared_error: 108.1112\n",
      "Epoch 00438: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 563us/step - loss: 118.4763 - mean_squared_error: 107.1722 - val_loss: 146.2844 - val_mean_squared_error: 134.9796\n",
      "Epoch 439/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 115.2061 - mean_squared_error: 103.9014\n",
      "Epoch 00439: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 563us/step - loss: 115.1787 - mean_squared_error: 103.8739 - val_loss: 147.2225 - val_mean_squared_error: 135.9178\n",
      "Epoch 440/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 117.9603 - mean_squared_error: 106.6531\n",
      "Epoch 00440: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 565us/step - loss: 117.3599 - mean_squared_error: 106.0529 - val_loss: 144.0920 - val_mean_squared_error: 132.7884\n",
      "Epoch 441/500\n",
      "492/526 [===========================>..] - ETA: 0s - loss: 112.9613 - mean_squared_error: 101.6654\n",
      "Epoch 00441: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 559us/step - loss: 113.1145 - mean_squared_error: 101.8190 - val_loss: 147.4595 - val_mean_squared_error: 136.1717\n",
      "Epoch 442/500\n",
      "495/526 [===========================>..] - ETA: 0s - loss: 117.3329 - mean_squared_error: 106.0487\n",
      "Epoch 00442: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 561us/step - loss: 117.7815 - mean_squared_error: 106.4974 - val_loss: 141.1409 - val_mean_squared_error: 129.8547\n",
      "Epoch 443/500\n",
      "503/526 [===========================>..] - ETA: 0s - loss: 115.3904 - mean_squared_error: 104.0940\n",
      "Epoch 00443: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 548us/step - loss: 115.4190 - mean_squared_error: 104.1224 - val_loss: 139.0159 - val_mean_squared_error: 127.7153\n",
      "Epoch 444/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 114.7465 - mean_squared_error: 103.4502\n",
      "Epoch 00444: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 537us/step - loss: 114.8852 - mean_squared_error: 103.5890 - val_loss: 164.6893 - val_mean_squared_error: 153.3992\n",
      "Epoch 445/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 118.1955 - mean_squared_error: 106.9049\n",
      "Epoch 00445: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 544us/step - loss: 118.3122 - mean_squared_error: 107.0219 - val_loss: 167.7951 - val_mean_squared_error: 156.5115\n",
      "Epoch 446/500\n",
      "506/526 [===========================>..] - ETA: 0s - loss: 117.1740 - mean_squared_error: 105.8823\n",
      "Epoch 00446: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 544us/step - loss: 116.0261 - mean_squared_error: 104.7344 - val_loss: 146.5823 - val_mean_squared_error: 135.2882\n",
      "Epoch 447/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 115.5146 - mean_squared_error: 104.2240\n",
      "Epoch 00447: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 544us/step - loss: 115.8665 - mean_squared_error: 104.5760 - val_loss: 139.0707 - val_mean_squared_error: 127.7796\n",
      "Epoch 448/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 113.2596 - mean_squared_error: 101.9649\n",
      "Epoch 00448: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 544us/step - loss: 113.8174 - mean_squared_error: 102.5224 - val_loss: 149.2399 - val_mean_squared_error: 137.9341\n",
      "Epoch 449/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 114.0636 - mean_squared_error: 102.7558\n",
      "Epoch 00449: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 537us/step - loss: 114.3515 - mean_squared_error: 103.0437 - val_loss: 148.0590 - val_mean_squared_error: 136.7502\n",
      "Epoch 450/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 117.2961 - mean_squared_error: 105.9849\n",
      "Epoch 00450: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 539us/step - loss: 117.9397 - mean_squared_error: 106.6285 - val_loss: 148.8726 - val_mean_squared_error: 137.5591\n",
      "Epoch 451/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 113.5691 - mean_squared_error: 102.2578\n",
      "Epoch 00451: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 537us/step - loss: 113.7976 - mean_squared_error: 102.4862 - val_loss: 141.1339 - val_mean_squared_error: 129.8194\n",
      "Epoch 452/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 115.4257 - mean_squared_error: 104.1077\n",
      "Epoch 00452: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 535us/step - loss: 115.6008 - mean_squared_error: 104.2826 - val_loss: 149.4546 - val_mean_squared_error: 138.1277\n",
      "Epoch 453/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 116.8576 - mean_squared_error: 105.5386\n",
      "Epoch 00453: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 539us/step - loss: 116.8160 - mean_squared_error: 105.4970 - val_loss: 141.0059 - val_mean_squared_error: 129.6901\n",
      "Epoch 454/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 113.2542 - mean_squared_error: 101.9375\n",
      "Epoch 00454: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 542us/step - loss: 113.0679 - mean_squared_error: 101.7513 - val_loss: 140.5722 - val_mean_squared_error: 129.2580\n",
      "Epoch 455/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 115.6224 - mean_squared_error: 104.3128\n",
      "Epoch 00455: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 539us/step - loss: 115.2975 - mean_squared_error: 103.9880 - val_loss: 146.2889 - val_mean_squared_error: 134.9821\n",
      "Epoch 456/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 115.3571 - mean_squared_error: 104.0506\n",
      "Epoch 00456: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 539us/step - loss: 116.2966 - mean_squared_error: 104.9898 - val_loss: 185.3972 - val_mean_squared_error: 174.0808\n",
      "Epoch 457/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 116.2539 - mean_squared_error: 104.9445\n",
      "Epoch 00457: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 542us/step - loss: 115.8991 - mean_squared_error: 104.5898 - val_loss: 139.2834 - val_mean_squared_error: 127.9740\n",
      "Epoch 458/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 114.5018 - mean_squared_error: 103.1929\n",
      "Epoch 00458: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 537us/step - loss: 114.7218 - mean_squared_error: 103.4127 - val_loss: 148.7736 - val_mean_squared_error: 137.4535\n",
      "Epoch 459/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 114.7419 - mean_squared_error: 103.4168\n",
      "Epoch 00459: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 539us/step - loss: 114.5240 - mean_squared_error: 103.1988 - val_loss: 152.6401 - val_mean_squared_error: 141.3137\n",
      "Epoch 460/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 114.2354 - mean_squared_error: 102.9071\n",
      "Epoch 00460: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 537us/step - loss: 114.8101 - mean_squared_error: 103.4819 - val_loss: 144.2011 - val_mean_squared_error: 132.8755\n",
      "Epoch 461/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 112.2838 - mean_squared_error: 100.9694\n",
      "Epoch 00461: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 540us/step - loss: 113.2038 - mean_squared_error: 101.8895 - val_loss: 154.4497 - val_mean_squared_error: 143.1375\n",
      "Epoch 462/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 114.1915 - mean_squared_error: 102.8760\n",
      "Epoch 00462: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 537us/step - loss: 114.3213 - mean_squared_error: 103.0059 - val_loss: 142.6192 - val_mean_squared_error: 131.3067\n",
      "Epoch 463/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 112.9378 - mean_squared_error: 101.6212\n",
      "Epoch 00463: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 537us/step - loss: 113.3971 - mean_squared_error: 102.0804 - val_loss: 153.1066 - val_mean_squared_error: 141.7898\n",
      "Epoch 464/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 116.4847 - mean_squared_error: 105.1616\n",
      "Epoch 00464: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 542us/step - loss: 116.3846 - mean_squared_error: 105.0612 - val_loss: 146.7747 - val_mean_squared_error: 135.4430\n",
      "Epoch 465/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 114.9503 - mean_squared_error: 103.6146\n",
      "Epoch 00465: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 539us/step - loss: 114.9514 - mean_squared_error: 103.6157 - val_loss: 141.5311 - val_mean_squared_error: 130.1983\n",
      "Epoch 466/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 114.3154 - mean_squared_error: 102.9725\n",
      "Epoch 00466: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 539us/step - loss: 114.3519 - mean_squared_error: 103.0090 - val_loss: 141.6968 - val_mean_squared_error: 130.3579\n",
      "Epoch 467/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 112.9393 - mean_squared_error: 101.6029\n",
      "Epoch 00467: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 537us/step - loss: 113.6545 - mean_squared_error: 102.3181 - val_loss: 145.9171 - val_mean_squared_error: 134.5795\n",
      "Epoch 468/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 115.3246 - mean_squared_error: 103.9909\n",
      "Epoch 00468: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 540us/step - loss: 114.9867 - mean_squared_error: 103.6530 - val_loss: 147.8234 - val_mean_squared_error: 136.4881\n",
      "Epoch 469/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 115.3550 - mean_squared_error: 104.0164\n",
      "Epoch 00469: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 540us/step - loss: 115.0364 - mean_squared_error: 103.6979 - val_loss: 143.6016 - val_mean_squared_error: 132.2642\n",
      "Epoch 470/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 112.4963 - mean_squared_error: 101.1520\n",
      "Epoch 00470: val_loss did not improve from 138.38559\n",
      "526/526 [==============================] - 0s 539us/step - loss: 112.4133 - mean_squared_error: 101.0689 - val_loss: 148.2981 - val_mean_squared_error: 136.9482\n",
      "Epoch 471/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 112.2017 - mean_squared_error: 100.8600\n",
      "Epoch 00471: val_loss improved from 138.38559 to 137.46976, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 653us/step - loss: 111.9256 - mean_squared_error: 100.5842 - val_loss: 137.4698 - val_mean_squared_error: 126.1379\n",
      "Epoch 472/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 113.2228 - mean_squared_error: 101.8947\n",
      "Epoch 00472: val_loss did not improve from 137.46976\n",
      "526/526 [==============================] - 0s 537us/step - loss: 112.6480 - mean_squared_error: 101.3199 - val_loss: 145.3573 - val_mean_squared_error: 134.0283\n",
      "Epoch 473/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 112.3228 - mean_squared_error: 100.9999\n",
      "Epoch 00473: val_loss did not improve from 137.46976\n",
      "526/526 [==============================] - 0s 546us/step - loss: 112.9980 - mean_squared_error: 101.6753 - val_loss: 139.8942 - val_mean_squared_error: 128.5766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 113.6771 - mean_squared_error: 102.3534\n",
      "Epoch 00474: val_loss did not improve from 137.46976\n",
      "526/526 [==============================] - 0s 537us/step - loss: 113.3907 - mean_squared_error: 102.0672 - val_loss: 144.1906 - val_mean_squared_error: 132.8740\n",
      "Epoch 475/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 118.6763 - mean_squared_error: 107.3501\n",
      "Epoch 00475: val_loss did not improve from 137.46976\n",
      "526/526 [==============================] - 0s 542us/step - loss: 118.1508 - mean_squared_error: 106.8243 - val_loss: 149.3781 - val_mean_squared_error: 138.0420\n",
      "Epoch 476/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 112.9122 - mean_squared_error: 101.5746\n",
      "Epoch 00476: val_loss did not improve from 137.46976\n",
      "526/526 [==============================] - 0s 539us/step - loss: 113.2532 - mean_squared_error: 101.9155 - val_loss: 139.7113 - val_mean_squared_error: 128.3677\n",
      "Epoch 477/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 112.2060 - mean_squared_error: 100.8623\n",
      "Epoch 00477: val_loss did not improve from 137.46976\n",
      "526/526 [==============================] - 0s 540us/step - loss: 111.4985 - mean_squared_error: 100.1548 - val_loss: 145.3285 - val_mean_squared_error: 133.9850\n",
      "Epoch 478/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 114.7654 - mean_squared_error: 103.4164\n",
      "Epoch 00478: val_loss did not improve from 137.46976\n",
      "526/526 [==============================] - 0s 539us/step - loss: 114.5238 - mean_squared_error: 103.1749 - val_loss: 140.7589 - val_mean_squared_error: 129.4157\n",
      "Epoch 479/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 113.4473 - mean_squared_error: 102.1031\n",
      "Epoch 00479: val_loss did not improve from 137.46976\n",
      "526/526 [==============================] - 0s 542us/step - loss: 113.3622 - mean_squared_error: 102.0179 - val_loss: 154.1357 - val_mean_squared_error: 142.7888\n",
      "Epoch 480/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 112.2643 - mean_squared_error: 100.9250\n",
      "Epoch 00480: val_loss did not improve from 137.46976\n",
      "526/526 [==============================] - 0s 540us/step - loss: 112.3442 - mean_squared_error: 101.0048 - val_loss: 143.5683 - val_mean_squared_error: 132.2287\n",
      "Epoch 481/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 111.8804 - mean_squared_error: 100.5445\n",
      "Epoch 00481: val_loss did not improve from 137.46976\n",
      "526/526 [==============================] - 0s 540us/step - loss: 111.9701 - mean_squared_error: 100.6343 - val_loss: 150.2780 - val_mean_squared_error: 138.9415\n",
      "Epoch 482/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 111.3959 - mean_squared_error: 100.0621\n",
      "Epoch 00482: val_loss did not improve from 137.46976\n",
      "526/526 [==============================] - 0s 542us/step - loss: 112.1227 - mean_squared_error: 100.7891 - val_loss: 151.8802 - val_mean_squared_error: 140.5527\n",
      "Epoch 483/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 115.4426 - mean_squared_error: 104.1162\n",
      "Epoch 00483: val_loss did not improve from 137.46976\n",
      "526/526 [==============================] - 0s 540us/step - loss: 115.1508 - mean_squared_error: 103.8245 - val_loss: 145.0637 - val_mean_squared_error: 133.7373\n",
      "Epoch 484/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 114.0566 - mean_squared_error: 102.7167\n",
      "Epoch 00484: val_loss did not improve from 137.46976\n",
      "526/526 [==============================] - 0s 540us/step - loss: 114.4346 - mean_squared_error: 103.0945 - val_loss: 162.9289 - val_mean_squared_error: 151.5818\n",
      "Epoch 485/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 113.0869 - mean_squared_error: 101.7403\n",
      "Epoch 00485: val_loss did not improve from 137.46976\n",
      "526/526 [==============================] - 0s 539us/step - loss: 113.5142 - mean_squared_error: 102.1677 - val_loss: 147.6462 - val_mean_squared_error: 136.3022\n",
      "Epoch 486/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 113.1475 - mean_squared_error: 101.8049\n",
      "Epoch 00486: val_loss improved from 137.46976 to 135.59554, saving model to model5.hdf5\n",
      "526/526 [==============================] - 0s 695us/step - loss: 112.2510 - mean_squared_error: 100.9084 - val_loss: 135.5955 - val_mean_squared_error: 124.2569\n",
      "Epoch 487/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 109.8224 - mean_squared_error: 98.4834\n",
      "Epoch 00487: val_loss did not improve from 135.59554\n",
      "526/526 [==============================] - 0s 535us/step - loss: 110.0388 - mean_squared_error: 98.6999 - val_loss: 142.6895 - val_mean_squared_error: 131.3535\n",
      "Epoch 488/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 113.4387 - mean_squared_error: 102.0902\n",
      "Epoch 00488: val_loss did not improve from 135.59554\n",
      "526/526 [==============================] - 0s 537us/step - loss: 113.6043 - mean_squared_error: 102.2556 - val_loss: 144.8646 - val_mean_squared_error: 133.5085\n",
      "Epoch 489/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 112.4816 - mean_squared_error: 101.1263\n",
      "Epoch 00489: val_loss did not improve from 135.59554\n",
      "526/526 [==============================] - 0s 540us/step - loss: 112.4770 - mean_squared_error: 101.1217 - val_loss: 170.1623 - val_mean_squared_error: 158.8040\n",
      "Epoch 490/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 112.1140 - mean_squared_error: 100.7557\n",
      "Epoch 00490: val_loss did not improve from 135.59554\n",
      "526/526 [==============================] - 0s 537us/step - loss: 111.8568 - mean_squared_error: 100.4985 - val_loss: 144.3174 - val_mean_squared_error: 132.9583\n",
      "Epoch 491/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 114.1912 - mean_squared_error: 102.8403\n",
      "Epoch 00491: val_loss did not improve from 135.59554\n",
      "526/526 [==============================] - 0s 537us/step - loss: 113.6457 - mean_squared_error: 102.2948 - val_loss: 136.4223 - val_mean_squared_error: 125.0792\n",
      "Epoch 492/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 111.6807 - mean_squared_error: 100.3382\n",
      "Epoch 00492: val_loss did not improve from 135.59554\n",
      "526/526 [==============================] - 0s 539us/step - loss: 111.5909 - mean_squared_error: 100.2482 - val_loss: 155.9845 - val_mean_squared_error: 144.6291\n",
      "Epoch 493/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 112.5025 - mean_squared_error: 101.1540\n",
      "Epoch 00493: val_loss did not improve from 135.59554\n",
      "526/526 [==============================] - 0s 539us/step - loss: 112.3427 - mean_squared_error: 100.9944 - val_loss: 143.0272 - val_mean_squared_error: 131.6896\n",
      "Epoch 494/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 110.7970 - mean_squared_error: 99.4588\n",
      "Epoch 00494: val_loss did not improve from 135.59554\n",
      "526/526 [==============================] - 0s 537us/step - loss: 110.0779 - mean_squared_error: 98.7396 - val_loss: 142.8035 - val_mean_squared_error: 131.4643\n",
      "Epoch 495/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 112.1577 - mean_squared_error: 100.8135\n",
      "Epoch 00495: val_loss did not improve from 135.59554\n",
      "526/526 [==============================] - 0s 540us/step - loss: 112.0351 - mean_squared_error: 100.6910 - val_loss: 145.8794 - val_mean_squared_error: 134.5356\n",
      "Epoch 496/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 114.8735 - mean_squared_error: 103.5292\n",
      "Epoch 00496: val_loss did not improve from 135.59554\n",
      "526/526 [==============================] - 0s 537us/step - loss: 114.2752 - mean_squared_error: 102.9309 - val_loss: 144.1037 - val_mean_squared_error: 132.7638\n",
      "Epoch 497/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 110.4523 - mean_squared_error: 99.1080 \n",
      "Epoch 00497: val_loss did not improve from 135.59554\n",
      "526/526 [==============================] - 0s 537us/step - loss: 110.2583 - mean_squared_error: 98.9138 - val_loss: 141.6476 - val_mean_squared_error: 130.2952\n",
      "Epoch 498/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 112.5833 - mean_squared_error: 101.2279\n",
      "Epoch 00498: val_loss did not improve from 135.59554\n",
      "526/526 [==============================] - 0s 539us/step - loss: 113.1434 - mean_squared_error: 101.7877 - val_loss: 161.9858 - val_mean_squared_error: 150.6177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 111.1964 - mean_squared_error: 99.8385\n",
      "Epoch 00499: val_loss did not improve from 135.59554\n",
      "526/526 [==============================] - 0s 537us/step - loss: 110.7738 - mean_squared_error: 99.4161 - val_loss: 149.1766 - val_mean_squared_error: 137.8263\n",
      "Epoch 500/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 111.1161 - mean_squared_error: 99.7630 \n",
      "Epoch 00500: val_loss did not improve from 135.59554\n",
      "526/526 [==============================] - 0s 542us/step - loss: 111.3567 - mean_squared_error: 100.0035 - val_loss: 140.1854 - val_mean_squared_error: 128.8290\n"
     ]
    }
   ],
   "source": [
    "model5 = models.Sequential()\n",
    "model5.add(layers.Dense(256,activation=\"relu\",kernel_regularizer=regularizers.l1(0.005),input_dim=81))\n",
    "model5.add(layers.Dense(128,activation=\"relu\",kernel_regularizer=regularizers.l1(0.005)))\n",
    "model5.add(layers.Dense(128,activation=\"relu\",kernel_regularizer=regularizers.l1(0.005)))\n",
    "model5.add(layers.Dense(1))\n",
    "model5.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    loss = losses.mean_squared_error,\n",
    "    metrics = ['mean_squared_error']\n",
    ")\n",
    "file_path = \"model5.hdf5\"\n",
    "checkpoint = ModelCheckpoint(file_path,monitor='val_loss', verbose=1,\n",
    "                             save_best_only=True,period=1)\n",
    "train_history5 = model5.fit(x_train,y_train,epochs=500,batch_size = 32,\n",
    "                            validation_data = (x_val,y_val),callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21a80418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/500\n",
      "473/526 [=========================>....] - ETA: 0s - loss: 144613.0781 - mean_squared_error: 144613.0781\n",
      "Epoch 00001: val_loss improved from inf to 2953.68652, saving model to model6.hdf5\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 133634.4844 - mean_squared_error: 133634.4844 - val_loss: 2953.6865 - val_mean_squared_error: 2953.6865\n",
      "Epoch 2/500\n",
      "471/526 [=========================>....] - ETA: 0s - loss: 22760.4805 - mean_squared_error: 22760.4805\n",
      "Epoch 00002: val_loss did not improve from 2953.68652\n",
      "526/526 [==============================] - 0s 792us/step - loss: 22159.4180 - mean_squared_error: 22159.4180 - val_loss: 3501.6038 - val_mean_squared_error: 3501.6038\n",
      "Epoch 3/500\n",
      "476/526 [==========================>...] - ETA: 0s - loss: 11480.0039 - mean_squared_error: 11480.0039\n",
      "Epoch 00003: val_loss did not improve from 2953.68652\n",
      "526/526 [==============================] - 0s 784us/step - loss: 11300.2314 - mean_squared_error: 11300.2314 - val_loss: 3175.9705 - val_mean_squared_error: 3175.9705\n",
      "Epoch 4/500\n",
      "472/526 [=========================>....] - ETA: 0s - loss: 6895.3579 - mean_squared_error: 6895.3579\n",
      "Epoch 00004: val_loss improved from 2953.68652 to 2863.79980, saving model to model6.hdf5\n",
      "526/526 [==============================] - 1s 982us/step - loss: 6830.5859 - mean_squared_error: 6830.5859 - val_loss: 2863.7998 - val_mean_squared_error: 2863.7998\n",
      "Epoch 5/500\n",
      "472/526 [=========================>....] - ETA: 0s - loss: 4851.9976 - mean_squared_error: 4851.9976\n",
      "Epoch 00005: val_loss improved from 2863.79980 to 1729.00793, saving model to model6.hdf5\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 4756.8354 - mean_squared_error: 4756.8354 - val_loss: 1729.0079 - val_mean_squared_error: 1729.0079\n",
      "Epoch 6/500\n",
      "475/526 [==========================>...] - ETA: 0s - loss: 3360.1980 - mean_squared_error: 3360.1980\n",
      "Epoch 00006: val_loss improved from 1729.00793 to 1519.61377, saving model to model6.hdf5\n",
      "526/526 [==============================] - 0s 948us/step - loss: 3321.4148 - mean_squared_error: 3321.4148 - val_loss: 1519.6138 - val_mean_squared_error: 1519.6138\n",
      "Epoch 7/500\n",
      "475/526 [==========================>...] - ETA: 0s - loss: 2671.5715 - mean_squared_error: 2671.5715\n",
      "Epoch 00007: val_loss improved from 1519.61377 to 1402.71545, saving model to model6.hdf5\n",
      "526/526 [==============================] - 1s 979us/step - loss: 2645.5498 - mean_squared_error: 2645.5498 - val_loss: 1402.7155 - val_mean_squared_error: 1402.7155\n",
      "Epoch 8/500\n",
      "475/526 [==========================>...] - ETA: 0s - loss: 2083.3093 - mean_squared_error: 2083.3093\n",
      "Epoch 00008: val_loss improved from 1402.71545 to 1258.26831, saving model to model6.hdf5\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 2073.5952 - mean_squared_error: 2073.5952 - val_loss: 1258.2683 - val_mean_squared_error: 1258.2683\n",
      "Epoch 9/500\n",
      "476/526 [==========================>...] - ETA: 0s - loss: 1833.5410 - mean_squared_error: 1833.5410\n",
      "Epoch 00009: val_loss improved from 1258.26831 to 1077.29260, saving model to model6.hdf5\n",
      "526/526 [==============================] - 0s 942us/step - loss: 1818.5706 - mean_squared_error: 1818.5706 - val_loss: 1077.2926 - val_mean_squared_error: 1077.2926\n",
      "Epoch 10/500\n",
      "476/526 [==========================>...] - ETA: 0s - loss: 1516.1334 - mean_squared_error: 1516.1334\n",
      "Epoch 00010: val_loss improved from 1077.29260 to 969.57910, saving model to model6.hdf5\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 1508.2764 - mean_squared_error: 1508.2764 - val_loss: 969.5791 - val_mean_squared_error: 969.5791\n",
      "Epoch 11/500\n",
      "476/526 [==========================>...] - ETA: 0s - loss: 1317.0863 - mean_squared_error: 1317.0863\n",
      "Epoch 00011: val_loss did not improve from 969.57910\n",
      "526/526 [==============================] - 0s 784us/step - loss: 1313.2655 - mean_squared_error: 1313.2655 - val_loss: 1082.6527 - val_mean_squared_error: 1082.6527\n",
      "Epoch 12/500\n",
      "473/526 [=========================>....] - ETA: 0s - loss: 1200.8888 - mean_squared_error: 1200.8888\n",
      "Epoch 00012: val_loss improved from 969.57910 to 895.09637, saving model to model6.hdf5\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 1186.7212 - mean_squared_error: 1186.7212 - val_loss: 895.0964 - val_mean_squared_error: 895.0964\n",
      "Epoch 13/500\n",
      "473/526 [=========================>....] - ETA: 0s - loss: 1050.2816 - mean_squared_error: 1050.2816\n",
      "Epoch 00013: val_loss did not improve from 895.09637\n",
      "526/526 [==============================] - 0s 788us/step - loss: 1044.8811 - mean_squared_error: 1044.8811 - val_loss: 928.4590 - val_mean_squared_error: 928.4590\n",
      "Epoch 14/500\n",
      "473/526 [=========================>....] - ETA: 0s - loss: 957.7379 - mean_squared_error: 957.7379\n",
      "Epoch 00014: val_loss did not improve from 895.09637\n",
      "526/526 [==============================] - 0s 788us/step - loss: 958.9294 - mean_squared_error: 958.9294 - val_loss: 934.6411 - val_mean_squared_error: 934.6411\n",
      "Epoch 15/500\n",
      "476/526 [==========================>...] - ETA: 0s - loss: 896.1288 - mean_squared_error: 896.1288\n",
      "Epoch 00015: val_loss did not improve from 895.09637\n",
      "526/526 [==============================] - 0s 790us/step - loss: 888.4906 - mean_squared_error: 888.4906 - val_loss: 1003.4396 - val_mean_squared_error: 1003.4396\n",
      "Epoch 16/500\n",
      "476/526 [==========================>...] - ETA: 0s - loss: 832.6387 - mean_squared_error: 832.6387\n",
      "Epoch 00016: val_loss did not improve from 895.09637\n",
      "526/526 [==============================] - 0s 784us/step - loss: 829.4835 - mean_squared_error: 829.4835 - val_loss: 918.3320 - val_mean_squared_error: 918.3320\n",
      "Epoch 17/500\n",
      "475/526 [==========================>...] - ETA: 0s - loss: 801.4059 - mean_squared_error: 801.4059\n",
      "Epoch 00017: val_loss improved from 895.09637 to 860.89105, saving model to model6.hdf5\n",
      "526/526 [==============================] - 1s 964us/step - loss: 802.4567 - mean_squared_error: 802.4567 - val_loss: 860.8911 - val_mean_squared_error: 860.8911\n",
      "Epoch 18/500\n",
      "474/526 [==========================>...] - ETA: 0s - loss: 758.4562 - mean_squared_error: 758.4562\n",
      "Epoch 00018: val_loss did not improve from 860.89105\n",
      "526/526 [==============================] - 0s 788us/step - loss: 753.3123 - mean_squared_error: 753.3123 - val_loss: 875.7723 - val_mean_squared_error: 875.7723\n",
      "Epoch 19/500\n",
      "474/526 [==========================>...] - ETA: 0s - loss: 700.2236 - mean_squared_error: 700.2236\n",
      "Epoch 00019: val_loss improved from 860.89105 to 721.21497, saving model to model6.hdf5\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 698.2559 - mean_squared_error: 698.2559 - val_loss: 721.2150 - val_mean_squared_error: 721.2150\n",
      "Epoch 20/500\n",
      "472/526 [=========================>....] - ETA: 0s - loss: 678.5944 - mean_squared_error: 678.5944\n",
      "Epoch 00020: val_loss did not improve from 721.21497\n",
      "526/526 [==============================] - 0s 790us/step - loss: 677.0980 - mean_squared_error: 677.0980 - val_loss: 812.2310 - val_mean_squared_error: 812.2310\n",
      "Epoch 21/500\n",
      "473/526 [=========================>....] - ETA: 0s - loss: 635.2501 - mean_squared_error: 635.2501\n",
      "Epoch 00021: val_loss improved from 721.21497 to 621.16046, saving model to model6.hdf5\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 632.3013 - mean_squared_error: 632.3013 - val_loss: 621.1605 - val_mean_squared_error: 621.1605\n",
      "Epoch 22/500\n",
      "474/526 [==========================>...] - ETA: 0s - loss: 599.3380 - mean_squared_error: 599.3380\n",
      "Epoch 00022: val_loss did not improve from 621.16046\n",
      "526/526 [==============================] - 0s 788us/step - loss: 594.6796 - mean_squared_error: 594.6796 - val_loss: 656.1926 - val_mean_squared_error: 656.1926\n",
      "Epoch 23/500\n",
      "475/526 [==========================>...] - ETA: 0s - loss: 560.7750 - mean_squared_error: 560.7750\n",
      "Epoch 00023: val_loss improved from 621.16046 to 594.58136, saving model to model6.hdf5\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 560.4006 - mean_squared_error: 560.4006 - val_loss: 594.5814 - val_mean_squared_error: 594.5814\n",
      "Epoch 24/500\n",
      "477/526 [==========================>...] - ETA: 0s - loss: 525.3633 - mean_squared_error: 525.3633\n",
      "Epoch 00024: val_loss did not improve from 594.58136\n",
      "526/526 [==============================] - 0s 784us/step - loss: 521.1804 - mean_squared_error: 521.1804 - val_loss: 627.0744 - val_mean_squared_error: 627.0744\n",
      "Epoch 25/500\n",
      "475/526 [==========================>...] - ETA: 0s - loss: 503.0332 - mean_squared_error: 503.0332\n",
      "Epoch 00025: val_loss improved from 594.58136 to 575.68414, saving model to model6.hdf5\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 502.3951 - mean_squared_error: 502.3951 - val_loss: 575.6841 - val_mean_squared_error: 575.6841\n",
      "Epoch 26/500\n",
      "474/526 [==========================>...] - ETA: 0s - loss: 483.1619 - mean_squared_error: 483.1619\n",
      "Epoch 00026: val_loss improved from 575.68414 to 573.35565, saving model to model6.hdf5\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 481.8224 - mean_squared_error: 481.8224 - val_loss: 573.3557 - val_mean_squared_error: 573.3557\n",
      "Epoch 27/500\n",
      "473/526 [=========================>....] - ETA: 0s - loss: 468.9687 - mean_squared_error: 468.9687\n",
      "Epoch 00027: val_loss improved from 573.35565 to 515.05530, saving model to model6.hdf5\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 466.5305 - mean_squared_error: 466.5305 - val_loss: 515.0553 - val_mean_squared_error: 515.0553\n",
      "Epoch 28/500\n",
      "478/526 [==========================>...] - ETA: 0s - loss: 439.9594 - mean_squared_error: 439.9594\n",
      "Epoch 00028: val_loss did not improve from 515.05530\n",
      "526/526 [==============================] - 0s 782us/step - loss: 442.1665 - mean_squared_error: 442.1665 - val_loss: 558.3645 - val_mean_squared_error: 558.3645\n",
      "Epoch 29/500\n",
      "475/526 [==========================>...] - ETA: 0s - loss: 430.7744 - mean_squared_error: 430.7744\n",
      "Epoch 00029: val_loss improved from 515.05530 to 503.99539, saving model to model6.hdf5\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 430.5987 - mean_squared_error: 430.5987 - val_loss: 503.9954 - val_mean_squared_error: 503.9954\n",
      "Epoch 30/500\n",
      "488/526 [==========================>...] - ETA: 0s - loss: 415.8412 - mean_squared_error: 415.8412\n",
      "Epoch 00030: val_loss did not improve from 503.99539\n",
      "526/526 [==============================] - 0s 879us/step - loss: 417.0461 - mean_squared_error: 417.0461 - val_loss: 518.2449 - val_mean_squared_error: 518.2449\n",
      "Epoch 31/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 405.5536 - mean_squared_error: 405.5536\n",
      "Epoch 00031: val_loss did not improve from 503.99539\n",
      "526/526 [==============================] - 0s 820us/step - loss: 405.8493 - mean_squared_error: 405.8493 - val_loss: 505.7498 - val_mean_squared_error: 505.7498\n",
      "Epoch 32/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 396.1589 - mean_squared_error: 396.1589\n",
      "Epoch 00032: val_loss did not improve from 503.99539\n",
      "526/526 [==============================] - 0s 813us/step - loss: 396.1589 - mean_squared_error: 396.1589 - val_loss: 605.4847 - val_mean_squared_error: 605.4847\n",
      "Epoch 33/500\n",
      "474/526 [==========================>...] - ETA: 0s - loss: 377.9687 - mean_squared_error: 377.9687\n",
      "Epoch 00033: val_loss did not improve from 503.99539\n",
      "526/526 [==============================] - 0s 786us/step - loss: 380.0324 - mean_squared_error: 380.0324 - val_loss: 573.4007 - val_mean_squared_error: 573.4007\n",
      "Epoch 34/500\n",
      "477/526 [==========================>...] - ETA: 0s - loss: 374.3111 - mean_squared_error: 374.3111\n",
      "Epoch 00034: val_loss improved from 503.99539 to 501.43665, saving model to model6.hdf5\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 373.4846 - mean_squared_error: 373.4846 - val_loss: 501.4366 - val_mean_squared_error: 501.4366\n",
      "Epoch 35/500\n",
      "479/526 [==========================>...] - ETA: 0s - loss: 366.7889 - mean_squared_error: 366.7889\n",
      "Epoch 00035: val_loss did not improve from 501.43665\n",
      "526/526 [==============================] - 0s 780us/step - loss: 366.7043 - mean_squared_error: 366.7043 - val_loss: 554.5536 - val_mean_squared_error: 554.5536\n",
      "Epoch 36/500\n",
      "473/526 [=========================>....] - ETA: 0s - loss: 350.9608 - mean_squared_error: 350.9608\n",
      "Epoch 00036: val_loss improved from 501.43665 to 484.31641, saving model to model6.hdf5\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 354.7690 - mean_squared_error: 354.7690 - val_loss: 484.3164 - val_mean_squared_error: 484.3164\n",
      "Epoch 37/500\n",
      "478/526 [==========================>...] - ETA: 0s - loss: 354.9657 - mean_squared_error: 354.9657\n",
      "Epoch 00037: val_loss did not improve from 484.31641\n",
      "526/526 [==============================] - 0s 780us/step - loss: 356.4321 - mean_squared_error: 356.4321 - val_loss: 571.9918 - val_mean_squared_error: 571.9918\n",
      "Epoch 38/500\n",
      "476/526 [==========================>...] - ETA: 0s - loss: 346.4919 - mean_squared_error: 346.4919\n",
      "Epoch 00038: val_loss did not improve from 484.31641\n",
      "526/526 [==============================] - 0s 784us/step - loss: 345.4645 - mean_squared_error: 345.4645 - val_loss: 508.7389 - val_mean_squared_error: 508.7389\n",
      "Epoch 39/500\n",
      "473/526 [=========================>....] - ETA: 0s - loss: 338.6949 - mean_squared_error: 338.6949\n",
      "Epoch 00039: val_loss did not improve from 484.31641\n",
      "526/526 [==============================] - 0s 788us/step - loss: 337.1994 - mean_squared_error: 337.1994 - val_loss: 541.8623 - val_mean_squared_error: 541.8623\n",
      "Epoch 40/500\n",
      "475/526 [==========================>...] - ETA: 0s - loss: 339.4036 - mean_squared_error: 339.4036\n",
      "Epoch 00040: val_loss did not improve from 484.31641\n",
      "526/526 [==============================] - 0s 786us/step - loss: 338.1054 - mean_squared_error: 338.1054 - val_loss: 562.8253 - val_mean_squared_error: 562.8253\n",
      "Epoch 41/500\n",
      "472/526 [=========================>....] - ETA: 0s - loss: 322.9260 - mean_squared_error: 322.9260\n",
      "Epoch 00041: val_loss improved from 484.31641 to 439.92395, saving model to model6.hdf5\n",
      "526/526 [==============================] - 1s 974us/step - loss: 324.4310 - mean_squared_error: 324.4310 - val_loss: 439.9240 - val_mean_squared_error: 439.9240\n",
      "Epoch 42/500\n",
      "472/526 [=========================>....] - ETA: 0s - loss: 327.1648 - mean_squared_error: 327.1648\n",
      "Epoch 00042: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 792us/step - loss: 327.7479 - mean_squared_error: 327.7479 - val_loss: 618.0168 - val_mean_squared_error: 618.0168\n",
      "Epoch 43/500\n",
      "474/526 [==========================>...] - ETA: 0s - loss: 324.2417 - mean_squared_error: 324.2417\n",
      "Epoch 00043: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 788us/step - loss: 323.4261 - mean_squared_error: 323.4261 - val_loss: 530.6367 - val_mean_squared_error: 530.6367\n",
      "Epoch 44/500\n",
      "468/526 [=========================>....] - ETA: 0s - loss: 316.5408 - mean_squared_error: 316.5408\n",
      "Epoch 00044: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 797us/step - loss: 314.3298 - mean_squared_error: 314.3298 - val_loss: 553.2992 - val_mean_squared_error: 553.2992\n",
      "Epoch 45/500\n",
      "468/526 [=========================>....] - ETA: 0s - loss: 311.6993 - mean_squared_error: 311.6993\n",
      "Epoch 00045: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 797us/step - loss: 312.4747 - mean_squared_error: 312.4747 - val_loss: 643.5067 - val_mean_squared_error: 643.5067\n",
      "Epoch 46/500\n",
      "472/526 [=========================>....] - ETA: 0s - loss: 307.6860 - mean_squared_error: 307.6860\n",
      "Epoch 00046: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 790us/step - loss: 306.4228 - mean_squared_error: 306.4228 - val_loss: 533.0652 - val_mean_squared_error: 533.0652\n",
      "Epoch 47/500\n",
      "473/526 [=========================>....] - ETA: 0s - loss: 309.0709 - mean_squared_error: 309.0709\n",
      "Epoch 00047: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 790us/step - loss: 311.3412 - mean_squared_error: 311.3412 - val_loss: 583.5413 - val_mean_squared_error: 583.5413\n",
      "Epoch 48/500\n",
      "472/526 [=========================>....] - ETA: 0s - loss: 308.4261 - mean_squared_error: 308.4261\n",
      "Epoch 00048: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 792us/step - loss: 308.5764 - mean_squared_error: 308.5764 - val_loss: 524.0887 - val_mean_squared_error: 524.0887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/500\n",
      "474/526 [==========================>...] - ETA: 0s - loss: 303.7328 - mean_squared_error: 303.7328\n",
      "Epoch 00049: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 788us/step - loss: 305.0126 - mean_squared_error: 305.0126 - val_loss: 630.1425 - val_mean_squared_error: 630.1425\n",
      "Epoch 50/500\n",
      "472/526 [=========================>....] - ETA: 0s - loss: 303.2968 - mean_squared_error: 303.2968\n",
      "Epoch 00050: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 790us/step - loss: 304.9359 - mean_squared_error: 304.9359 - val_loss: 677.1832 - val_mean_squared_error: 677.1832\n",
      "Epoch 51/500\n",
      "469/526 [=========================>....] - ETA: 0s - loss: 302.3285 - mean_squared_error: 302.3285\n",
      "Epoch 00051: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 793us/step - loss: 299.0535 - mean_squared_error: 299.0535 - val_loss: 527.0965 - val_mean_squared_error: 527.0965\n",
      "Epoch 52/500\n",
      "477/526 [==========================>...] - ETA: 0s - loss: 298.8367 - mean_squared_error: 298.8367\n",
      "Epoch 00052: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 782us/step - loss: 301.1038 - mean_squared_error: 301.1038 - val_loss: 667.6987 - val_mean_squared_error: 667.6987\n",
      "Epoch 53/500\n",
      "474/526 [==========================>...] - ETA: 0s - loss: 295.3893 - mean_squared_error: 295.3893\n",
      "Epoch 00053: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 790us/step - loss: 295.4566 - mean_squared_error: 295.4566 - val_loss: 574.9533 - val_mean_squared_error: 574.9533\n",
      "Epoch 54/500\n",
      "471/526 [=========================>....] - ETA: 0s - loss: 302.7073 - mean_squared_error: 302.7073\n",
      "Epoch 00054: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 790us/step - loss: 299.2282 - mean_squared_error: 299.2282 - val_loss: 578.8170 - val_mean_squared_error: 578.8170\n",
      "Epoch 55/500\n",
      "472/526 [=========================>....] - ETA: 0s - loss: 295.8481 - mean_squared_error: 295.8481\n",
      "Epoch 00055: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 792us/step - loss: 295.2534 - mean_squared_error: 295.2534 - val_loss: 493.0992 - val_mean_squared_error: 493.0992\n",
      "Epoch 56/500\n",
      "471/526 [=========================>....] - ETA: 0s - loss: 291.4539 - mean_squared_error: 291.4539\n",
      "Epoch 00056: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 793us/step - loss: 293.8197 - mean_squared_error: 293.8197 - val_loss: 557.8974 - val_mean_squared_error: 557.8974\n",
      "Epoch 57/500\n",
      "472/526 [=========================>....] - ETA: 0s - loss: 292.2415 - mean_squared_error: 292.2415\n",
      "Epoch 00057: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 790us/step - loss: 291.2821 - mean_squared_error: 291.2821 - val_loss: 535.9037 - val_mean_squared_error: 535.9037\n",
      "Epoch 58/500\n",
      "470/526 [=========================>....] - ETA: 0s - loss: 286.8466 - mean_squared_error: 286.8466\n",
      "Epoch 00058: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 793us/step - loss: 287.4668 - mean_squared_error: 287.4668 - val_loss: 471.7636 - val_mean_squared_error: 471.7636\n",
      "Epoch 59/500\n",
      "469/526 [=========================>....] - ETA: 0s - loss: 293.3789 - mean_squared_error: 293.3789\n",
      "Epoch 00059: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 795us/step - loss: 290.2482 - mean_squared_error: 290.2482 - val_loss: 573.8064 - val_mean_squared_error: 573.8064\n",
      "Epoch 60/500\n",
      "470/526 [=========================>....] - ETA: 0s - loss: 288.0342 - mean_squared_error: 288.0342\n",
      "Epoch 00060: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 792us/step - loss: 288.0117 - mean_squared_error: 288.0117 - val_loss: 520.7374 - val_mean_squared_error: 520.7374\n",
      "Epoch 61/500\n",
      "471/526 [=========================>....] - ETA: 0s - loss: 286.0797 - mean_squared_error: 286.0797\n",
      "Epoch 00061: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 793us/step - loss: 285.6726 - mean_squared_error: 285.6726 - val_loss: 569.2437 - val_mean_squared_error: 569.2437\n",
      "Epoch 62/500\n",
      "469/526 [=========================>....] - ETA: 0s - loss: 280.8087 - mean_squared_error: 280.8087\n",
      "Epoch 00062: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 793us/step - loss: 282.7250 - mean_squared_error: 282.7250 - val_loss: 556.9996 - val_mean_squared_error: 556.9996\n",
      "Epoch 63/500\n",
      "470/526 [=========================>....] - ETA: 0s - loss: 284.1714 - mean_squared_error: 284.1714\n",
      "Epoch 00063: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 793us/step - loss: 285.0272 - mean_squared_error: 285.0272 - val_loss: 570.0619 - val_mean_squared_error: 570.0619\n",
      "Epoch 64/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 279.9448 - mean_squared_error: 279.9448\n",
      "Epoch 00064: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 818us/step - loss: 280.2156 - mean_squared_error: 280.2156 - val_loss: 584.6746 - val_mean_squared_error: 584.6746\n",
      "Epoch 65/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 281.4826 - mean_squared_error: 281.4826\n",
      "Epoch 00065: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 814us/step - loss: 281.9203 - mean_squared_error: 281.9203 - val_loss: 538.6375 - val_mean_squared_error: 538.6375\n",
      "Epoch 66/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 280.8054 - mean_squared_error: 280.8054\n",
      "Epoch 00066: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 816us/step - loss: 280.9659 - mean_squared_error: 280.9659 - val_loss: 501.4866 - val_mean_squared_error: 501.4866\n",
      "Epoch 67/500\n",
      "468/526 [=========================>....] - ETA: 0s - loss: 282.8384 - mean_squared_error: 282.8384\n",
      "Epoch 00067: val_loss did not improve from 439.92395\n",
      "526/526 [==============================] - 0s 797us/step - loss: 282.6176 - mean_squared_error: 282.6176 - val_loss: 502.5889 - val_mean_squared_error: 502.5889\n",
      "Epoch 68/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 279.8817 - mean_squared_error: 279.8817\n",
      "Epoch 00068: val_loss improved from 439.92395 to 413.63632, saving model to model6.hdf5\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 280.0069 - mean_squared_error: 280.0069 - val_loss: 413.6363 - val_mean_squared_error: 413.6363\n",
      "Epoch 69/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 277.9158 - mean_squared_error: 277.9158\n",
      "Epoch 00069: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 837us/step - loss: 277.0515 - mean_squared_error: 277.0515 - val_loss: 548.4575 - val_mean_squared_error: 548.4575\n",
      "Epoch 70/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 277.9064 - mean_squared_error: 277.9064\n",
      "Epoch 00070: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 278.1240 - mean_squared_error: 278.1240 - val_loss: 595.9836 - val_mean_squared_error: 595.9836\n",
      "Epoch 71/500\n",
      "461/526 [=========================>....] - ETA: 0s - loss: 278.3879 - mean_squared_error: 278.3879\n",
      "Epoch 00071: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 809us/step - loss: 279.2278 - mean_squared_error: 279.2278 - val_loss: 506.4446 - val_mean_squared_error: 506.4446\n",
      "Epoch 72/500\n",
      "469/526 [=========================>....] - ETA: 0s - loss: 280.9659 - mean_squared_error: 280.9659\n",
      "Epoch 00072: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 801us/step - loss: 279.1653 - mean_squared_error: 279.1653 - val_loss: 511.3075 - val_mean_squared_error: 511.3075\n",
      "Epoch 73/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 271.6844 - mean_squared_error: 271.6844\n",
      "Epoch 00073: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 824us/step - loss: 271.8957 - mean_squared_error: 271.8957 - val_loss: 524.3259 - val_mean_squared_error: 524.3259\n",
      "Epoch 74/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462/526 [=========================>....] - ETA: 0s - loss: 274.7199 - mean_squared_error: 274.7199\n",
      "Epoch 00074: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 811us/step - loss: 273.2762 - mean_squared_error: 273.2762 - val_loss: 591.6721 - val_mean_squared_error: 591.6721\n",
      "Epoch 75/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 274.0916 - mean_squared_error: 274.0916\n",
      "Epoch 00075: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 274.6663 - mean_squared_error: 274.6663 - val_loss: 598.4849 - val_mean_squared_error: 598.4849\n",
      "Epoch 76/500\n",
      "471/526 [=========================>....] - ETA: 0s - loss: 271.1904 - mean_squared_error: 271.1904\n",
      "Epoch 00076: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 793us/step - loss: 270.9664 - mean_squared_error: 270.9664 - val_loss: 584.6513 - val_mean_squared_error: 584.6513\n",
      "Epoch 77/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 274.4312 - mean_squared_error: 274.4312\n",
      "Epoch 00077: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 820us/step - loss: 274.1893 - mean_squared_error: 274.1893 - val_loss: 515.3056 - val_mean_squared_error: 515.3056\n",
      "Epoch 78/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 271.0807 - mean_squared_error: 271.0807\n",
      "Epoch 00078: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 271.1727 - mean_squared_error: 271.1727 - val_loss: 541.5015 - val_mean_squared_error: 541.5015\n",
      "Epoch 79/500\n",
      "464/526 [=========================>....] - ETA: 0s - loss: 268.6172 - mean_squared_error: 268.6172\n",
      "Epoch 00079: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 807us/step - loss: 269.6398 - mean_squared_error: 269.6398 - val_loss: 519.3739 - val_mean_squared_error: 519.3739\n",
      "Epoch 80/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 270.6530 - mean_squared_error: 270.6530\n",
      "Epoch 00080: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 270.8575 - mean_squared_error: 270.8575 - val_loss: 570.7036 - val_mean_squared_error: 570.7036\n",
      "Epoch 81/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 268.8037 - mean_squared_error: 268.8037\n",
      "Epoch 00081: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 268.4101 - mean_squared_error: 268.4101 - val_loss: 559.2816 - val_mean_squared_error: 559.2816\n",
      "Epoch 82/500\n",
      "462/526 [=========================>....] - ETA: 0s - loss: 271.2285 - mean_squared_error: 271.2285\n",
      "Epoch 00082: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 807us/step - loss: 270.8940 - mean_squared_error: 270.8940 - val_loss: 606.5914 - val_mean_squared_error: 606.5914\n",
      "Epoch 83/500\n",
      "469/526 [=========================>....] - ETA: 0s - loss: 269.0325 - mean_squared_error: 269.0325\n",
      "Epoch 00083: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 797us/step - loss: 268.9856 - mean_squared_error: 268.9856 - val_loss: 586.8680 - val_mean_squared_error: 586.8680\n",
      "Epoch 84/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 265.8362 - mean_squared_error: 265.8362\n",
      "Epoch 00084: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 265.8362 - mean_squared_error: 265.8362 - val_loss: 477.2343 - val_mean_squared_error: 477.2343\n",
      "Epoch 85/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 267.3097 - mean_squared_error: 267.3097\n",
      "Epoch 00085: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 266.6907 - mean_squared_error: 266.6907 - val_loss: 559.4282 - val_mean_squared_error: 559.4282\n",
      "Epoch 86/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 267.5144 - mean_squared_error: 267.5144\n",
      "Epoch 00086: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 820us/step - loss: 267.3426 - mean_squared_error: 267.3426 - val_loss: 596.9127 - val_mean_squared_error: 596.9127\n",
      "Epoch 87/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 265.1953 - mean_squared_error: 265.1953\n",
      "Epoch 00087: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 833us/step - loss: 264.8345 - mean_squared_error: 264.8345 - val_loss: 527.1648 - val_mean_squared_error: 527.1648\n",
      "Epoch 88/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 262.4338 - mean_squared_error: 262.4338\n",
      "Epoch 00088: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 826us/step - loss: 261.8909 - mean_squared_error: 261.8909 - val_loss: 547.0753 - val_mean_squared_error: 547.0753\n",
      "Epoch 89/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 263.5082 - mean_squared_error: 263.5082\n",
      "Epoch 00089: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 263.5626 - mean_squared_error: 263.5626 - val_loss: 548.1303 - val_mean_squared_error: 548.1303\n",
      "Epoch 90/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 264.6969 - mean_squared_error: 264.6969\n",
      "Epoch 00090: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 264.6697 - mean_squared_error: 264.6697 - val_loss: 569.2247 - val_mean_squared_error: 569.2247\n",
      "Epoch 91/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 261.1476 - mean_squared_error: 261.1476\n",
      "Epoch 00091: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 826us/step - loss: 260.9633 - mean_squared_error: 260.9633 - val_loss: 586.2598 - val_mean_squared_error: 586.2598\n",
      "Epoch 92/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 258.8975 - mean_squared_error: 258.8975\n",
      "Epoch 00092: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 826us/step - loss: 259.2186 - mean_squared_error: 259.2186 - val_loss: 480.2203 - val_mean_squared_error: 480.2203\n",
      "Epoch 93/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 262.6890 - mean_squared_error: 262.6890\n",
      "Epoch 00093: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 822us/step - loss: 262.5567 - mean_squared_error: 262.5567 - val_loss: 583.5125 - val_mean_squared_error: 583.5125\n",
      "Epoch 94/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 261.0519 - mean_squared_error: 261.0519\n",
      "Epoch 00094: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 833us/step - loss: 261.4448 - mean_squared_error: 261.4448 - val_loss: 631.9006 - val_mean_squared_error: 631.9006\n",
      "Epoch 95/500\n",
      "467/526 [=========================>....] - ETA: 0s - loss: 257.3864 - mean_squared_error: 257.3864\n",
      "Epoch 00095: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 797us/step - loss: 258.2655 - mean_squared_error: 258.2655 - val_loss: 524.9302 - val_mean_squared_error: 524.9302\n",
      "Epoch 96/500\n",
      "471/526 [=========================>....] - ETA: 0s - loss: 258.3063 - mean_squared_error: 258.3063\n",
      "Epoch 00096: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 793us/step - loss: 258.6028 - mean_squared_error: 258.6028 - val_loss: 590.1620 - val_mean_squared_error: 590.1620\n",
      "Epoch 97/500\n",
      "466/526 [=========================>....] - ETA: 0s - loss: 257.9676 - mean_squared_error: 257.9676\n",
      "Epoch 00097: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 799us/step - loss: 259.5589 - mean_squared_error: 259.5589 - val_loss: 590.1658 - val_mean_squared_error: 590.1658\n",
      "Epoch 98/500\n",
      "463/526 [=========================>....] - ETA: 0s - loss: 258.0057 - mean_squared_error: 258.0057\n",
      "Epoch 00098: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 807us/step - loss: 256.8020 - mean_squared_error: 256.8020 - val_loss: 657.4194 - val_mean_squared_error: 657.4194\n",
      "Epoch 99/500\n",
      "461/526 [=========================>....] - ETA: 0s - loss: 250.2909 - mean_squared_error: 250.2909\n",
      "Epoch 00099: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 809us/step - loss: 252.0369 - mean_squared_error: 252.0369 - val_loss: 664.8979 - val_mean_squared_error: 664.8979\n",
      "Epoch 100/500\n",
      "466/526 [=========================>....] - ETA: 0s - loss: 254.2202 - mean_squared_error: 254.2202\n",
      "Epoch 00100: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 799us/step - loss: 254.4671 - mean_squared_error: 254.4671 - val_loss: 558.6929 - val_mean_squared_error: 558.6929\n",
      "Epoch 101/500\n",
      "466/526 [=========================>....] - ETA: 0s - loss: 255.9320 - mean_squared_error: 255.9320\n",
      "Epoch 00101: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 797us/step - loss: 257.7005 - mean_squared_error: 257.7005 - val_loss: 678.0823 - val_mean_squared_error: 678.0823\n",
      "Epoch 102/500\n",
      "464/526 [=========================>....] - ETA: 0s - loss: 253.8135 - mean_squared_error: 253.8135\n",
      "Epoch 00102: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 809us/step - loss: 253.1454 - mean_squared_error: 253.1454 - val_loss: 488.6987 - val_mean_squared_error: 488.6987\n",
      "Epoch 103/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 251.6453 - mean_squared_error: 251.6453\n",
      "Epoch 00103: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 820us/step - loss: 252.0869 - mean_squared_error: 252.0869 - val_loss: 566.6627 - val_mean_squared_error: 566.6627\n",
      "Epoch 104/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 256.8324 - mean_squared_error: 256.8324\n",
      "Epoch 00104: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 820us/step - loss: 256.6740 - mean_squared_error: 256.6740 - val_loss: 607.7897 - val_mean_squared_error: 607.7897\n",
      "Epoch 105/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 260.4813 - mean_squared_error: 260.4813\n",
      "Epoch 00105: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 826us/step - loss: 259.8801 - mean_squared_error: 259.8801 - val_loss: 497.4407 - val_mean_squared_error: 497.4407\n",
      "Epoch 106/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 253.5064 - mean_squared_error: 253.5064\n",
      "Epoch 00106: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 906us/step - loss: 253.0863 - mean_squared_error: 253.0863 - val_loss: 555.9885 - val_mean_squared_error: 555.9885\n",
      "Epoch 107/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 255.9253 - mean_squared_error: 255.9253\n",
      "Epoch 00107: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 845us/step - loss: 255.6104 - mean_squared_error: 255.6104 - val_loss: 590.0558 - val_mean_squared_error: 590.0558\n",
      "Epoch 108/500\n",
      "498/526 [===========================>..] - ETA: 0s - loss: 251.4268 - mean_squared_error: 251.4268\n",
      "Epoch 00108: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 858us/step - loss: 252.5260 - mean_squared_error: 252.5260 - val_loss: 604.1758 - val_mean_squared_error: 604.1758\n",
      "Epoch 109/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 254.3867 - mean_squared_error: 254.3867\n",
      "Epoch 00109: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 841us/step - loss: 254.4515 - mean_squared_error: 254.4515 - val_loss: 478.4096 - val_mean_squared_error: 478.4096\n",
      "Epoch 110/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 252.8058 - mean_squared_error: 252.8058\n",
      "Epoch 00110: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 829us/step - loss: 251.4715 - mean_squared_error: 251.4715 - val_loss: 585.2909 - val_mean_squared_error: 585.2909\n",
      "Epoch 111/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 248.8748 - mean_squared_error: 248.8748\n",
      "Epoch 00111: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 822us/step - loss: 249.6406 - mean_squared_error: 249.6406 - val_loss: 584.6011 - val_mean_squared_error: 584.6011\n",
      "Epoch 112/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 249.4644 - mean_squared_error: 249.4644\n",
      "Epoch 00112: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 826us/step - loss: 249.5371 - mean_squared_error: 249.5371 - val_loss: 686.7714 - val_mean_squared_error: 686.7714\n",
      "Epoch 113/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 252.1453 - mean_squared_error: 252.1453\n",
      "Epoch 00113: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 832us/step - loss: 252.4279 - mean_squared_error: 252.4279 - val_loss: 610.4834 - val_mean_squared_error: 610.4834\n",
      "Epoch 114/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 250.0343 - mean_squared_error: 250.0343\n",
      "Epoch 00114: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 830us/step - loss: 250.0836 - mean_squared_error: 250.0836 - val_loss: 571.8727 - val_mean_squared_error: 571.8727\n",
      "Epoch 115/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 254.0332 - mean_squared_error: 254.0332\n",
      "Epoch 00115: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 828us/step - loss: 254.1929 - mean_squared_error: 254.1929 - val_loss: 603.9265 - val_mean_squared_error: 603.9265\n",
      "Epoch 116/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 247.2665 - mean_squared_error: 247.2665\n",
      "Epoch 00116: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 829us/step - loss: 247.1280 - mean_squared_error: 247.1280 - val_loss: 559.7624 - val_mean_squared_error: 559.7624\n",
      "Epoch 117/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 251.7738 - mean_squared_error: 251.7738\n",
      "Epoch 00117: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 820us/step - loss: 252.1098 - mean_squared_error: 252.1098 - val_loss: 508.5396 - val_mean_squared_error: 508.5396\n",
      "Epoch 118/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 252.9623 - mean_squared_error: 252.9623\n",
      "Epoch 00118: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 822us/step - loss: 252.4354 - mean_squared_error: 252.4354 - val_loss: 634.8478 - val_mean_squared_error: 634.8478\n",
      "Epoch 119/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 244.4379 - mean_squared_error: 244.4379\n",
      "Epoch 00119: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 826us/step - loss: 244.7426 - mean_squared_error: 244.7426 - val_loss: 483.1691 - val_mean_squared_error: 483.1691\n",
      "Epoch 120/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 248.5140 - mean_squared_error: 248.5140 ETA: 0s - loss: 241.4312 - mean_squared_error\n",
      "Epoch 00120: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 828us/step - loss: 248.0803 - mean_squared_error: 248.0803 - val_loss: 541.3195 - val_mean_squared_error: 541.3195\n",
      "Epoch 121/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 248.6294 - mean_squared_error: 248.6294\n",
      "Epoch 00121: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 826us/step - loss: 248.4801 - mean_squared_error: 248.4801 - val_loss: 541.0683 - val_mean_squared_error: 541.0683\n",
      "Epoch 122/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 246.5682 - mean_squared_error: 246.5682\n",
      "Epoch 00122: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 824us/step - loss: 246.8282 - mean_squared_error: 246.8282 - val_loss: 553.8690 - val_mean_squared_error: 553.8690\n",
      "Epoch 123/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 250.0782 - mean_squared_error: 250.0782\n",
      "Epoch 00123: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 826us/step - loss: 249.2113 - mean_squared_error: 249.2113 - val_loss: 513.0443 - val_mean_squared_error: 513.0443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 246.8214 - mean_squared_error: 246.8214\n",
      "Epoch 00124: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 841us/step - loss: 246.9738 - mean_squared_error: 246.9738 - val_loss: 554.6473 - val_mean_squared_error: 554.6473\n",
      "Epoch 125/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 245.0353 - mean_squared_error: 245.0353\n",
      "Epoch 00125: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 843us/step - loss: 245.3835 - mean_squared_error: 245.3835 - val_loss: 645.2305 - val_mean_squared_error: 645.2305\n",
      "Epoch 126/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 244.4647 - mean_squared_error: 244.4647\n",
      "Epoch 00126: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 843us/step - loss: 245.2151 - mean_squared_error: 245.2151 - val_loss: 561.0667 - val_mean_squared_error: 561.0667\n",
      "Epoch 127/500\n",
      "505/526 [===========================>..] - ETA: 0s - loss: 245.5132 - mean_squared_error: 245.5132\n",
      "Epoch 00127: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 847us/step - loss: 246.6460 - mean_squared_error: 246.6460 - val_loss: 532.6471 - val_mean_squared_error: 532.6471\n",
      "Epoch 128/500\n",
      "496/526 [===========================>..] - ETA: 0s - loss: 247.8262 - mean_squared_error: 247.8262\n",
      "Epoch 00128: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 858us/step - loss: 247.9242 - mean_squared_error: 247.9242 - val_loss: 570.6975 - val_mean_squared_error: 570.6975\n",
      "Epoch 129/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 248.7508 - mean_squared_error: 248.7508\n",
      "Epoch 00129: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 248.3666 - mean_squared_error: 248.3666 - val_loss: 579.1281 - val_mean_squared_error: 579.1281\n",
      "Epoch 130/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 247.3055 - mean_squared_error: 247.3055\n",
      "Epoch 00130: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 247.0693 - mean_squared_error: 247.0693 - val_loss: 589.3989 - val_mean_squared_error: 589.3989\n",
      "Epoch 131/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 246.1842 - mean_squared_error: 246.1842\n",
      "Epoch 00131: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 820us/step - loss: 245.7015 - mean_squared_error: 245.7015 - val_loss: 605.4210 - val_mean_squared_error: 605.4210\n",
      "Epoch 132/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 246.3648 - mean_squared_error: 246.3648\n",
      "Epoch 00132: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 830us/step - loss: 245.4597 - mean_squared_error: 245.4597 - val_loss: 540.3116 - val_mean_squared_error: 540.3116\n",
      "Epoch 133/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 245.8678 - mean_squared_error: 245.8678\n",
      "Epoch 00133: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 833us/step - loss: 245.7075 - mean_squared_error: 245.7075 - val_loss: 608.2381 - val_mean_squared_error: 608.2381\n",
      "Epoch 134/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 244.6883 - mean_squared_error: 244.6883\n",
      "Epoch 00134: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 833us/step - loss: 244.7332 - mean_squared_error: 244.7332 - val_loss: 499.8003 - val_mean_squared_error: 499.8003\n",
      "Epoch 135/500\n",
      "505/526 [===========================>..] - ETA: 0s - loss: 244.6602 - mean_squared_error: 244.6602\n",
      "Epoch 00135: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 843us/step - loss: 245.9939 - mean_squared_error: 245.9939 - val_loss: 700.4531 - val_mean_squared_error: 700.4531\n",
      "Epoch 136/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 243.9313 - mean_squared_error: 243.9313\n",
      "Epoch 00136: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 243.9744 - mean_squared_error: 243.9744 - val_loss: 528.0980 - val_mean_squared_error: 528.0980\n",
      "Epoch 137/500\n",
      "462/526 [=========================>....] - ETA: 0s - loss: 243.9410 - mean_squared_error: 243.9410\n",
      "Epoch 00137: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 809us/step - loss: 245.1843 - mean_squared_error: 245.1843 - val_loss: 504.8061 - val_mean_squared_error: 504.8061\n",
      "Epoch 138/500\n",
      "465/526 [=========================>....] - ETA: 0s - loss: 244.8915 - mean_squared_error: 244.8915\n",
      "Epoch 00138: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 799us/step - loss: 244.5582 - mean_squared_error: 244.5582 - val_loss: 484.0565 - val_mean_squared_error: 484.0565\n",
      "Epoch 139/500\n",
      "477/526 [==========================>...] - ETA: 0s - loss: 240.3613 - mean_squared_error: 240.3613\n",
      "Epoch 00139: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 787us/step - loss: 244.1941 - mean_squared_error: 244.1941 - val_loss: 549.6331 - val_mean_squared_error: 549.6331\n",
      "Epoch 140/500\n",
      "469/526 [=========================>....] - ETA: 0s - loss: 241.4710 - mean_squared_error: 241.4710\n",
      "Epoch 00140: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 801us/step - loss: 242.5409 - mean_squared_error: 242.5409 - val_loss: 525.7876 - val_mean_squared_error: 525.7876\n",
      "Epoch 141/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 244.8610 - mean_squared_error: 244.8610\n",
      "Epoch 00141: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 837us/step - loss: 243.9128 - mean_squared_error: 243.9128 - val_loss: 572.5229 - val_mean_squared_error: 572.5229\n",
      "Epoch 142/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 241.4273 - mean_squared_error: 241.4273\n",
      "Epoch 00142: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 820us/step - loss: 241.4098 - mean_squared_error: 241.4098 - val_loss: 596.6453 - val_mean_squared_error: 596.6453\n",
      "Epoch 143/500\n",
      "468/526 [=========================>....] - ETA: 0s - loss: 239.7853 - mean_squared_error: 239.7853\n",
      "Epoch 00143: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 797us/step - loss: 241.6772 - mean_squared_error: 241.6772 - val_loss: 549.4460 - val_mean_squared_error: 549.4460\n",
      "Epoch 144/500\n",
      "470/526 [=========================>....] - ETA: 0s - loss: 245.3810 - mean_squared_error: 245.3810\n",
      "Epoch 00144: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 793us/step - loss: 242.8940 - mean_squared_error: 242.8940 - val_loss: 549.4495 - val_mean_squared_error: 549.4495\n",
      "Epoch 145/500\n",
      "468/526 [=========================>....] - ETA: 0s - loss: 240.8659 - mean_squared_error: 240.8659\n",
      "Epoch 00145: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 797us/step - loss: 241.5724 - mean_squared_error: 241.5724 - val_loss: 600.5499 - val_mean_squared_error: 600.5499\n",
      "Epoch 146/500\n",
      "471/526 [=========================>....] - ETA: 0s - loss: 240.2022 - mean_squared_error: 240.2022\n",
      "Epoch 00146: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 795us/step - loss: 238.5039 - mean_squared_error: 238.5039 - val_loss: 505.7713 - val_mean_squared_error: 505.7713\n",
      "Epoch 147/500\n",
      "468/526 [=========================>....] - ETA: 0s - loss: 241.5653 - mean_squared_error: 241.5653\n",
      "Epoch 00147: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 803us/step - loss: 241.0442 - mean_squared_error: 241.0442 - val_loss: 483.9091 - val_mean_squared_error: 483.9091\n",
      "Epoch 148/500\n",
      "465/526 [=========================>....] - ETA: 0s - loss: 244.8026 - mean_squared_error: 244.8026\n",
      "Epoch 00148: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 801us/step - loss: 244.5642 - mean_squared_error: 244.5642 - val_loss: 565.9427 - val_mean_squared_error: 565.9427\n",
      "Epoch 149/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 238.2993 - mean_squared_error: 238.2993\n",
      "Epoch 00149: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 822us/step - loss: 238.5211 - mean_squared_error: 238.5211 - val_loss: 646.0994 - val_mean_squared_error: 646.0994\n",
      "Epoch 150/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 241.3979 - mean_squared_error: 241.3979\n",
      "Epoch 00150: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 241.0549 - mean_squared_error: 241.0549 - val_loss: 599.1753 - val_mean_squared_error: 599.1753\n",
      "Epoch 151/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 237.0023 - mean_squared_error: 237.0023\n",
      "Epoch 00151: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 828us/step - loss: 238.3463 - mean_squared_error: 238.3463 - val_loss: 640.1863 - val_mean_squared_error: 640.1863\n",
      "Epoch 152/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 238.4719 - mean_squared_error: 238.4719\n",
      "Epoch 00152: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 820us/step - loss: 238.6995 - mean_squared_error: 238.6995 - val_loss: 555.0811 - val_mean_squared_error: 555.0811\n",
      "Epoch 153/500\n",
      "474/526 [==========================>...] - ETA: 0s - loss: 239.0390 - mean_squared_error: 239.0390\n",
      "Epoch 00153: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 786us/step - loss: 237.6804 - mean_squared_error: 237.6804 - val_loss: 590.3383 - val_mean_squared_error: 590.3383\n",
      "Epoch 154/500\n",
      "471/526 [=========================>....] - ETA: 0s - loss: 238.5343 - mean_squared_error: 238.5343\n",
      "Epoch 00154: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 790us/step - loss: 236.8171 - mean_squared_error: 236.8171 - val_loss: 552.5472 - val_mean_squared_error: 552.5472\n",
      "Epoch 155/500\n",
      "473/526 [=========================>....] - ETA: 0s - loss: 240.1921 - mean_squared_error: 240.1921\n",
      "Epoch 00155: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 788us/step - loss: 239.6148 - mean_squared_error: 239.6148 - val_loss: 498.8282 - val_mean_squared_error: 498.8282\n",
      "Epoch 156/500\n",
      "472/526 [=========================>....] - ETA: 0s - loss: 234.7694 - mean_squared_error: 234.7694\n",
      "Epoch 00156: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 792us/step - loss: 237.4731 - mean_squared_error: 237.4731 - val_loss: 552.8954 - val_mean_squared_error: 552.8954\n",
      "Epoch 157/500\n",
      "470/526 [=========================>....] - ETA: 0s - loss: 231.9261 - mean_squared_error: 231.9261\n",
      "Epoch 00157: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 792us/step - loss: 236.4454 - mean_squared_error: 236.4454 - val_loss: 579.3157 - val_mean_squared_error: 579.3157\n",
      "Epoch 158/500\n",
      "474/526 [==========================>...] - ETA: 0s - loss: 238.4091 - mean_squared_error: 238.4091\n",
      "Epoch 00158: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 786us/step - loss: 238.3747 - mean_squared_error: 238.3747 - val_loss: 527.6809 - val_mean_squared_error: 527.6809\n",
      "Epoch 159/500\n",
      "471/526 [=========================>....] - ETA: 0s - loss: 234.7547 - mean_squared_error: 234.7547\n",
      "Epoch 00159: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 793us/step - loss: 234.9786 - mean_squared_error: 234.9786 - val_loss: 565.7083 - val_mean_squared_error: 565.7083\n",
      "Epoch 160/500\n",
      "475/526 [==========================>...] - ETA: 0s - loss: 237.6425 - mean_squared_error: 237.6425\n",
      "Epoch 00160: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 786us/step - loss: 236.3542 - mean_squared_error: 236.3542 - val_loss: 477.3133 - val_mean_squared_error: 477.3133\n",
      "Epoch 161/500\n",
      "461/526 [=========================>....] - ETA: 0s - loss: 240.1102 - mean_squared_error: 240.1102\n",
      "Epoch 00161: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 810us/step - loss: 235.3326 - mean_squared_error: 235.3326 - val_loss: 606.9666 - val_mean_squared_error: 606.9666\n",
      "Epoch 162/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 234.9729 - mean_squared_error: 234.9729\n",
      "Epoch 00162: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 234.9729 - mean_squared_error: 234.9729 - val_loss: 700.8003 - val_mean_squared_error: 700.8003\n",
      "Epoch 163/500\n",
      "474/526 [==========================>...] - ETA: 0s - loss: 235.9224 - mean_squared_error: 235.9224\n",
      "Epoch 00163: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 788us/step - loss: 235.7066 - mean_squared_error: 235.7066 - val_loss: 526.8918 - val_mean_squared_error: 526.8918\n",
      "Epoch 164/500\n",
      "472/526 [=========================>....] - ETA: 0s - loss: 241.1463 - mean_squared_error: 241.1463\n",
      "Epoch 00164: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 790us/step - loss: 240.6674 - mean_squared_error: 240.6674 - val_loss: 547.6690 - val_mean_squared_error: 547.6690\n",
      "Epoch 165/500\n",
      "469/526 [=========================>....] - ETA: 0s - loss: 233.9647 - mean_squared_error: 233.9647\n",
      "Epoch 00165: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 795us/step - loss: 234.4810 - mean_squared_error: 234.4810 - val_loss: 600.9750 - val_mean_squared_error: 600.9750\n",
      "Epoch 166/500\n",
      "475/526 [==========================>...] - ETA: 0s - loss: 235.5637 - mean_squared_error: 235.5637\n",
      "Epoch 00166: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 789us/step - loss: 233.4219 - mean_squared_error: 233.4219 - val_loss: 463.6267 - val_mean_squared_error: 463.6267\n",
      "Epoch 167/500\n",
      "468/526 [=========================>....] - ETA: 0s - loss: 234.5320 - mean_squared_error: 234.5320\n",
      "Epoch 00167: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 805us/step - loss: 232.3435 - mean_squared_error: 232.3435 - val_loss: 536.1599 - val_mean_squared_error: 536.1599\n",
      "Epoch 168/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 234.7538 - mean_squared_error: 234.7538\n",
      "Epoch 00168: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 234.7538 - mean_squared_error: 234.7538 - val_loss: 534.8709 - val_mean_squared_error: 534.8709\n",
      "Epoch 169/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 236.5808 - mean_squared_error: 236.5808\n",
      "Epoch 00169: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 824us/step - loss: 236.2765 - mean_squared_error: 236.2765 - val_loss: 550.0330 - val_mean_squared_error: 550.0330\n",
      "Epoch 170/500\n",
      "501/526 [===========================>..] - ETA: 0s - loss: 237.7850 - mean_squared_error: 237.7850\n",
      "Epoch 00170: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 1s 986us/step - loss: 239.8680 - mean_squared_error: 239.8680 - val_loss: 678.1859 - val_mean_squared_error: 678.1859\n",
      "Epoch 171/500\n",
      "475/526 [==========================>...] - ETA: 0s - loss: 237.6305 - mean_squared_error: 237.6305\n",
      "Epoch 00171: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 898us/step - loss: 237.5645 - mean_squared_error: 237.5645 - val_loss: 521.9722 - val_mean_squared_error: 521.9722\n",
      "Epoch 172/500\n",
      "482/526 [==========================>...] - ETA: 0s - loss: 235.4654 - mean_squared_error: 235.4654\n",
      "Epoch 00172: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 885us/step - loss: 235.6996 - mean_squared_error: 235.6996 - val_loss: 635.1027 - val_mean_squared_error: 635.1027\n",
      "Epoch 173/500\n",
      "479/526 [==========================>...] - ETA: 0s - loss: 235.2268 - mean_squared_error: 235.2268\n",
      "Epoch 00173: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 1s 986us/step - loss: 236.2582 - mean_squared_error: 236.2582 - val_loss: 584.1643 - val_mean_squared_error: 584.1643\n",
      "Epoch 174/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461/526 [=========================>....] - ETA: 0s - loss: 234.5370 - mean_squared_error: 234.5370\n",
      "Epoch 00174: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 908us/step - loss: 231.9785 - mean_squared_error: 231.9785 - val_loss: 585.1898 - val_mean_squared_error: 585.1898\n",
      "Epoch 175/500\n",
      "461/526 [=========================>....] - ETA: 0s - loss: 233.7340 - mean_squared_error: 233.7340\n",
      "Epoch 00175: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 811us/step - loss: 234.7274 - mean_squared_error: 234.7274 - val_loss: 617.1290 - val_mean_squared_error: 617.1290\n",
      "Epoch 176/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 232.3424 - mean_squared_error: 232.3424\n",
      "Epoch 00176: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 820us/step - loss: 232.1721 - mean_squared_error: 232.1721 - val_loss: 606.2203 - val_mean_squared_error: 606.2203\n",
      "Epoch 177/500\n",
      "463/526 [=========================>....] - ETA: 0s - loss: 238.4714 - mean_squared_error: 238.4714\n",
      "Epoch 00177: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 805us/step - loss: 240.4947 - mean_squared_error: 240.4947 - val_loss: 605.4160 - val_mean_squared_error: 605.4160\n",
      "Epoch 178/500\n",
      "468/526 [=========================>....] - ETA: 0s - loss: 236.6432 - mean_squared_error: 236.6432\n",
      "Epoch 00178: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 826us/step - loss: 235.4213 - mean_squared_error: 235.4213 - val_loss: 609.8549 - val_mean_squared_error: 609.8549\n",
      "Epoch 179/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 235.1555 - mean_squared_error: 235.1555\n",
      "Epoch 00179: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 813us/step - loss: 235.1555 - mean_squared_error: 235.1555 - val_loss: 618.0052 - val_mean_squared_error: 618.0052\n",
      "Epoch 180/500\n",
      "463/526 [=========================>....] - ETA: 0s - loss: 231.5235 - mean_squared_error: 231.5235\n",
      "Epoch 00180: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 803us/step - loss: 229.5462 - mean_squared_error: 229.5462 - val_loss: 626.3207 - val_mean_squared_error: 626.3207\n",
      "Epoch 181/500\n",
      "471/526 [=========================>....] - ETA: 0s - loss: 233.0398 - mean_squared_error: 233.0398\n",
      "Epoch 00181: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 792us/step - loss: 234.5881 - mean_squared_error: 234.5881 - val_loss: 685.7242 - val_mean_squared_error: 685.7242\n",
      "Epoch 182/500\n",
      "467/526 [=========================>....] - ETA: 0s - loss: 231.6654 - mean_squared_error: 231.6654\n",
      "Epoch 00182: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 799us/step - loss: 231.0414 - mean_squared_error: 231.0414 - val_loss: 534.1762 - val_mean_squared_error: 534.1762\n",
      "Epoch 183/500\n",
      "470/526 [=========================>....] - ETA: 0s - loss: 229.6078 - mean_squared_error: 229.6078\n",
      "Epoch 00183: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 793us/step - loss: 231.4512 - mean_squared_error: 231.4512 - val_loss: 551.4485 - val_mean_squared_error: 551.4485\n",
      "Epoch 184/500\n",
      "464/526 [=========================>....] - ETA: 0s - loss: 231.9107 - mean_squared_error: 231.9107\n",
      "Epoch 00184: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 803us/step - loss: 231.1782 - mean_squared_error: 231.1782 - val_loss: 477.4881 - val_mean_squared_error: 477.4881\n",
      "Epoch 185/500\n",
      "467/526 [=========================>....] - ETA: 0s - loss: 233.1255 - mean_squared_error: 233.1255\n",
      "Epoch 00185: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 799us/step - loss: 233.8318 - mean_squared_error: 233.8318 - val_loss: 579.6464 - val_mean_squared_error: 579.6464\n",
      "Epoch 186/500\n",
      "465/526 [=========================>....] - ETA: 0s - loss: 233.4421 - mean_squared_error: 233.4421\n",
      "Epoch 00186: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 806us/step - loss: 232.3903 - mean_squared_error: 232.3903 - val_loss: 624.7864 - val_mean_squared_error: 624.7864\n",
      "Epoch 187/500\n",
      "464/526 [=========================>....] - ETA: 0s - loss: 227.0450 - mean_squared_error: 227.0450\n",
      "Epoch 00187: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 808us/step - loss: 228.6099 - mean_squared_error: 228.6099 - val_loss: 580.6047 - val_mean_squared_error: 580.6047\n",
      "Epoch 188/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 231.5041 - mean_squared_error: 231.5041\n",
      "Epoch 00188: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 826us/step - loss: 231.4334 - mean_squared_error: 231.4334 - val_loss: 580.7068 - val_mean_squared_error: 580.7068\n",
      "Epoch 189/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 235.0333 - mean_squared_error: 235.0333\n",
      "Epoch 00189: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 826us/step - loss: 235.2337 - mean_squared_error: 235.2337 - val_loss: 569.0399 - val_mean_squared_error: 569.0399\n",
      "Epoch 190/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 231.4285 - mean_squared_error: 231.4285\n",
      "Epoch 00190: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 828us/step - loss: 231.5291 - mean_squared_error: 231.5291 - val_loss: 599.6447 - val_mean_squared_error: 599.6447\n",
      "Epoch 191/500\n",
      "501/526 [===========================>..] - ETA: 0s - loss: 233.6085 - mean_squared_error: 233.6085\n",
      "Epoch 00191: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 1s 953us/step - loss: 231.9748 - mean_squared_error: 231.9748 - val_loss: 627.9440 - val_mean_squared_error: 627.9440\n",
      "Epoch 192/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 230.1740 - mean_squared_error: 230.1740\n",
      "Epoch 00192: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 843us/step - loss: 230.4452 - mean_squared_error: 230.4452 - val_loss: 573.8921 - val_mean_squared_error: 573.8921\n",
      "Epoch 193/500\n",
      "462/526 [=========================>....] - ETA: 0s - loss: 225.1379 - mean_squared_error: 225.1379\n",
      "Epoch 00193: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 809us/step - loss: 227.9802 - mean_squared_error: 227.9802 - val_loss: 639.7800 - val_mean_squared_error: 639.7800\n",
      "Epoch 194/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 228.0999 - mean_squared_error: 228.0999\n",
      "Epoch 00194: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 824us/step - loss: 227.7970 - mean_squared_error: 227.7970 - val_loss: 568.3644 - val_mean_squared_error: 568.3644\n",
      "Epoch 195/500\n",
      "462/526 [=========================>....] - ETA: 0s - loss: 226.8085 - mean_squared_error: 226.8085\n",
      "Epoch 00195: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 807us/step - loss: 228.8377 - mean_squared_error: 228.8377 - val_loss: 585.9242 - val_mean_squared_error: 585.9242\n",
      "Epoch 196/500\n",
      "461/526 [=========================>....] - ETA: 0s - loss: 224.5831 - mean_squared_error: 224.5831\n",
      "Epoch 00196: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 811us/step - loss: 228.0993 - mean_squared_error: 228.0993 - val_loss: 510.2570 - val_mean_squared_error: 510.2570\n",
      "Epoch 197/500\n",
      "491/526 [===========================>..] - ETA: 0s - loss: 229.3843 - mean_squared_error: 229.3843\n",
      "Epoch 00197: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 862us/step - loss: 227.7831 - mean_squared_error: 227.7831 - val_loss: 568.9661 - val_mean_squared_error: 568.9661\n",
      "Epoch 198/500\n",
      "463/526 [=========================>....] - ETA: 0s - loss: 227.3420 - mean_squared_error: 227.3420\n",
      "Epoch 00198: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 805us/step - loss: 226.7839 - mean_squared_error: 226.7839 - val_loss: 577.5148 - val_mean_squared_error: 577.5148\n",
      "Epoch 199/500\n",
      "467/526 [=========================>....] - ETA: 0s - loss: 225.8881 - mean_squared_error: 225.8881\n",
      "Epoch 00199: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 799us/step - loss: 226.9194 - mean_squared_error: 226.9194 - val_loss: 616.8959 - val_mean_squared_error: 616.8959\n",
      "Epoch 200/500\n",
      "470/526 [=========================>....] - ETA: 0s - loss: 227.2010 - mean_squared_error: 227.2010\n",
      "Epoch 00200: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 793us/step - loss: 228.0614 - mean_squared_error: 228.0614 - val_loss: 579.6544 - val_mean_squared_error: 579.6544\n",
      "Epoch 201/500\n",
      "472/526 [=========================>....] - ETA: 0s - loss: 227.8199 - mean_squared_error: 227.8199\n",
      "Epoch 00201: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 792us/step - loss: 228.3259 - mean_squared_error: 228.3259 - val_loss: 553.6194 - val_mean_squared_error: 553.6194\n",
      "Epoch 202/500\n",
      "473/526 [=========================>....] - ETA: 0s - loss: 229.2706 - mean_squared_error: 229.2706\n",
      "Epoch 00202: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 790us/step - loss: 228.1769 - mean_squared_error: 228.1769 - val_loss: 591.3317 - val_mean_squared_error: 591.3317\n",
      "Epoch 203/500\n",
      "470/526 [=========================>....] - ETA: 0s - loss: 228.0525 - mean_squared_error: 228.0525\n",
      "Epoch 00203: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 793us/step - loss: 228.1319 - mean_squared_error: 228.1319 - val_loss: 596.1725 - val_mean_squared_error: 596.1725\n",
      "Epoch 204/500\n",
      "471/526 [=========================>....] - ETA: 0s - loss: 228.5642 - mean_squared_error: 228.5642\n",
      "Epoch 00204: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 792us/step - loss: 228.6830 - mean_squared_error: 228.6830 - val_loss: 562.2084 - val_mean_squared_error: 562.2084\n",
      "Epoch 205/500\n",
      "470/526 [=========================>....] - ETA: 0s - loss: 227.2502 - mean_squared_error: 227.2502\n",
      "Epoch 00205: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 795us/step - loss: 225.9648 - mean_squared_error: 225.9648 - val_loss: 580.7167 - val_mean_squared_error: 580.7167\n",
      "Epoch 206/500\n",
      "472/526 [=========================>....] - ETA: 0s - loss: 224.0336 - mean_squared_error: 224.0336\n",
      "Epoch 00206: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 790us/step - loss: 224.1258 - mean_squared_error: 224.1258 - val_loss: 543.0945 - val_mean_squared_error: 543.0945\n",
      "Epoch 207/500\n",
      "472/526 [=========================>....] - ETA: 0s - loss: 223.5106 - mean_squared_error: 223.5106\n",
      "Epoch 00207: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 792us/step - loss: 227.3886 - mean_squared_error: 227.3886 - val_loss: 484.2343 - val_mean_squared_error: 484.2343\n",
      "Epoch 208/500\n",
      "473/526 [=========================>....] - ETA: 0s - loss: 227.9382 - mean_squared_error: 227.9382\n",
      "Epoch 00208: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 790us/step - loss: 229.1261 - mean_squared_error: 229.1261 - val_loss: 566.1626 - val_mean_squared_error: 566.1626\n",
      "Epoch 209/500\n",
      "467/526 [=========================>....] - ETA: 0s - loss: 231.0472 - mean_squared_error: 231.0472\n",
      "Epoch 00209: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 803us/step - loss: 230.2079 - mean_squared_error: 230.2079 - val_loss: 518.3708 - val_mean_squared_error: 518.3708\n",
      "Epoch 210/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 224.9647 - mean_squared_error: 224.9647\n",
      "Epoch 00210: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 225.3231 - mean_squared_error: 225.3231 - val_loss: 504.9171 - val_mean_squared_error: 504.9171\n",
      "Epoch 211/500\n",
      "501/526 [===========================>..] - ETA: 0s - loss: 225.2458 - mean_squared_error: 225.2458\n",
      "Epoch 00211: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 853us/step - loss: 224.4673 - mean_squared_error: 224.4673 - val_loss: 559.8578 - val_mean_squared_error: 559.8578\n",
      "Epoch 212/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 226.6740 - mean_squared_error: 226.6740\n",
      "Epoch 00212: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 835us/step - loss: 227.2203 - mean_squared_error: 227.2203 - val_loss: 493.4348 - val_mean_squared_error: 493.4348\n",
      "Epoch 213/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 226.1416 - mean_squared_error: 226.1416\n",
      "Epoch 00213: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 832us/step - loss: 226.2029 - mean_squared_error: 226.2029 - val_loss: 685.1909 - val_mean_squared_error: 685.1909\n",
      "Epoch 214/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 223.5440 - mean_squared_error: 223.5440\n",
      "Epoch 00214: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 826us/step - loss: 223.4879 - mean_squared_error: 223.4879 - val_loss: 503.1152 - val_mean_squared_error: 503.1152\n",
      "Epoch 215/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 225.0451 - mean_squared_error: 225.0451\n",
      "Epoch 00215: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 833us/step - loss: 225.6139 - mean_squared_error: 225.6139 - val_loss: 563.1115 - val_mean_squared_error: 563.1115\n",
      "Epoch 216/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 220.6059 - mean_squared_error: 220.6059\n",
      "Epoch 00216: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 830us/step - loss: 220.7567 - mean_squared_error: 220.7567 - val_loss: 543.3507 - val_mean_squared_error: 543.3507\n",
      "Epoch 217/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 224.5808 - mean_squared_error: 224.5808\n",
      "Epoch 00217: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 832us/step - loss: 224.2578 - mean_squared_error: 224.2578 - val_loss: 474.8339 - val_mean_squared_error: 474.8339\n",
      "Epoch 218/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 223.3195 - mean_squared_error: 223.3195\n",
      "Epoch 00218: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 826us/step - loss: 222.8735 - mean_squared_error: 222.8735 - val_loss: 556.2639 - val_mean_squared_error: 556.2639\n",
      "Epoch 219/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 225.6916 - mean_squared_error: 225.6916\n",
      "Epoch 00219: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 824us/step - loss: 226.2447 - mean_squared_error: 226.2447 - val_loss: 543.8713 - val_mean_squared_error: 543.8713\n",
      "Epoch 220/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 226.8107 - mean_squared_error: 226.8107\n",
      "Epoch 00220: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 226.9729 - mean_squared_error: 226.9729 - val_loss: 536.6568 - val_mean_squared_error: 536.6568\n",
      "Epoch 221/500\n",
      "472/526 [=========================>....] - ETA: 0s - loss: 224.1439 - mean_squared_error: 224.1439\n",
      "Epoch 00221: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 792us/step - loss: 223.2856 - mean_squared_error: 223.2856 - val_loss: 585.0986 - val_mean_squared_error: 585.0986\n",
      "Epoch 222/500\n",
      "463/526 [=========================>....] - ETA: 0s - loss: 221.6404 - mean_squared_error: 221.6404\n",
      "Epoch 00222: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 811us/step - loss: 222.1574 - mean_squared_error: 222.1574 - val_loss: 570.2460 - val_mean_squared_error: 570.2460\n",
      "Epoch 223/500\n",
      "467/526 [=========================>....] - ETA: 0s - loss: 223.2845 - mean_squared_error: 223.2845\n",
      "Epoch 00223: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 797us/step - loss: 223.1130 - mean_squared_error: 223.1130 - val_loss: 535.9260 - val_mean_squared_error: 535.9260\n",
      "Epoch 224/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465/526 [=========================>....] - ETA: 0s - loss: 223.4335 - mean_squared_error: 223.4335\n",
      "Epoch 00224: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 801us/step - loss: 222.7586 - mean_squared_error: 222.7586 - val_loss: 521.3043 - val_mean_squared_error: 521.3043\n",
      "Epoch 225/500\n",
      "474/526 [==========================>...] - ETA: 0s - loss: 220.5449 - mean_squared_error: 220.5449\n",
      "Epoch 00225: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 788us/step - loss: 220.3360 - mean_squared_error: 220.3360 - val_loss: 587.4347 - val_mean_squared_error: 587.4347\n",
      "Epoch 226/500\n",
      "476/526 [==========================>...] - ETA: 0s - loss: 223.6325 - mean_squared_error: 223.6325\n",
      "Epoch 00226: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 784us/step - loss: 224.6517 - mean_squared_error: 224.6517 - val_loss: 542.0260 - val_mean_squared_error: 542.0260\n",
      "Epoch 227/500\n",
      "465/526 [=========================>....] - ETA: 0s - loss: 227.2247 - mean_squared_error: 227.2247\n",
      "Epoch 00227: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 805us/step - loss: 225.5893 - mean_squared_error: 225.5893 - val_loss: 567.1206 - val_mean_squared_error: 567.1206\n",
      "Epoch 228/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 223.4527 - mean_squared_error: 223.4527\n",
      "Epoch 00228: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 843us/step - loss: 222.8887 - mean_squared_error: 222.8887 - val_loss: 572.5304 - val_mean_squared_error: 572.5304\n",
      "Epoch 229/500\n",
      "475/526 [==========================>...] - ETA: 0s - loss: 225.7422 - mean_squared_error: 225.7422\n",
      "Epoch 00229: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 891us/step - loss: 223.4508 - mean_squared_error: 223.4508 - val_loss: 619.2089 - val_mean_squared_error: 619.2089\n",
      "Epoch 230/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 227.5023 - mean_squared_error: 227.5023\n",
      "Epoch 00230: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 836us/step - loss: 226.3086 - mean_squared_error: 226.3086 - val_loss: 549.7690 - val_mean_squared_error: 549.7690\n",
      "Epoch 231/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 219.5012 - mean_squared_error: 219.5012\n",
      "Epoch 00231: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 833us/step - loss: 219.2132 - mean_squared_error: 219.2132 - val_loss: 560.4266 - val_mean_squared_error: 560.4266\n",
      "Epoch 232/500\n",
      "464/526 [=========================>....] - ETA: 0s - loss: 223.1067 - mean_squared_error: 223.1067\n",
      "Epoch 00232: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 807us/step - loss: 221.6819 - mean_squared_error: 221.6819 - val_loss: 586.0551 - val_mean_squared_error: 586.0551\n",
      "Epoch 233/500\n",
      "464/526 [=========================>....] - ETA: 0s - loss: 222.1980 - mean_squared_error: 222.1980\n",
      "Epoch 00233: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 807us/step - loss: 220.2598 - mean_squared_error: 220.2598 - val_loss: 570.4552 - val_mean_squared_error: 570.4552\n",
      "Epoch 234/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 221.5726 - mean_squared_error: 221.5726\n",
      "Epoch 00234: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 826us/step - loss: 220.7821 - mean_squared_error: 220.7821 - val_loss: 531.7921 - val_mean_squared_error: 531.7921\n",
      "Epoch 235/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 221.9158 - mean_squared_error: 221.9158\n",
      "Epoch 00235: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 815us/step - loss: 221.8861 - mean_squared_error: 221.8861 - val_loss: 623.8781 - val_mean_squared_error: 623.8781\n",
      "Epoch 236/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 221.6629 - mean_squared_error: 221.6629\n",
      "Epoch 00236: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 825us/step - loss: 221.6865 - mean_squared_error: 221.6865 - val_loss: 620.5577 - val_mean_squared_error: 620.5577\n",
      "Epoch 237/500\n",
      "465/526 [=========================>....] - ETA: 0s - loss: 219.8882 - mean_squared_error: 219.8882\n",
      "Epoch 00237: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 803us/step - loss: 223.4319 - mean_squared_error: 223.4319 - val_loss: 584.2326 - val_mean_squared_error: 584.2326\n",
      "Epoch 238/500\n",
      "463/526 [=========================>....] - ETA: 0s - loss: 224.1434 - mean_squared_error: 224.1434\n",
      "Epoch 00238: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 807us/step - loss: 224.5953 - mean_squared_error: 224.5953 - val_loss: 605.2667 - val_mean_squared_error: 605.2667\n",
      "Epoch 239/500\n",
      "468/526 [=========================>....] - ETA: 0s - loss: 218.6461 - mean_squared_error: 218.6461\n",
      "Epoch 00239: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 797us/step - loss: 220.4939 - mean_squared_error: 220.4939 - val_loss: 521.2357 - val_mean_squared_error: 521.2357\n",
      "Epoch 240/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 218.0310 - mean_squared_error: 218.0310\n",
      "Epoch 00240: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 822us/step - loss: 218.0245 - mean_squared_error: 218.0245 - val_loss: 541.6851 - val_mean_squared_error: 541.6851\n",
      "Epoch 241/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 222.4409 - mean_squared_error: 222.4409\n",
      "Epoch 00241: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 222.2686 - mean_squared_error: 222.2686 - val_loss: 608.6131 - val_mean_squared_error: 608.6131\n",
      "Epoch 242/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 221.3831 - mean_squared_error: 221.3831\n",
      "Epoch 00242: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 222.0938 - mean_squared_error: 222.0938 - val_loss: 509.1415 - val_mean_squared_error: 509.1415\n",
      "Epoch 243/500\n",
      "464/526 [=========================>....] - ETA: 0s - loss: 221.1551 - mean_squared_error: 221.1551\n",
      "Epoch 00243: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 805us/step - loss: 220.6882 - mean_squared_error: 220.6882 - val_loss: 553.2367 - val_mean_squared_error: 553.2367\n",
      "Epoch 244/500\n",
      "466/526 [=========================>....] - ETA: 0s - loss: 221.9931 - mean_squared_error: 221.9931\n",
      "Epoch 00244: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 799us/step - loss: 221.0293 - mean_squared_error: 221.0293 - val_loss: 576.3997 - val_mean_squared_error: 576.3997\n",
      "Epoch 245/500\n",
      "470/526 [=========================>....] - ETA: 0s - loss: 212.9589 - mean_squared_error: 212.9589\n",
      "Epoch 00245: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 793us/step - loss: 217.6145 - mean_squared_error: 217.6145 - val_loss: 587.2684 - val_mean_squared_error: 587.2684\n",
      "Epoch 246/500\n",
      "468/526 [=========================>....] - ETA: 0s - loss: 218.1566 - mean_squared_error: 218.1566\n",
      "Epoch 00246: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 797us/step - loss: 218.6666 - mean_squared_error: 218.6666 - val_loss: 499.1342 - val_mean_squared_error: 499.1342\n",
      "Epoch 247/500\n",
      "467/526 [=========================>....] - ETA: 0s - loss: 216.2778 - mean_squared_error: 216.2778\n",
      "Epoch 00247: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 797us/step - loss: 217.0822 - mean_squared_error: 217.0822 - val_loss: 553.0869 - val_mean_squared_error: 553.0869\n",
      "Epoch 248/500\n",
      "471/526 [=========================>....] - ETA: 0s - loss: 221.6198 - mean_squared_error: 221.6198\n",
      "Epoch 00248: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 793us/step - loss: 220.8907 - mean_squared_error: 220.8907 - val_loss: 502.9420 - val_mean_squared_error: 502.9420\n",
      "Epoch 249/500\n",
      "466/526 [=========================>....] - ETA: 0s - loss: 218.2269 - mean_squared_error: 218.2269\n",
      "Epoch 00249: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 803us/step - loss: 220.2867 - mean_squared_error: 220.2867 - val_loss: 651.0505 - val_mean_squared_error: 651.0505\n",
      "Epoch 250/500\n",
      "466/526 [=========================>....] - ETA: 0s - loss: 220.0497 - mean_squared_error: 220.0497\n",
      "Epoch 00250: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 803us/step - loss: 218.6918 - mean_squared_error: 218.6918 - val_loss: 500.9653 - val_mean_squared_error: 500.9653\n",
      "Epoch 251/500\n",
      "469/526 [=========================>....] - ETA: 0s - loss: 215.5901 - mean_squared_error: 215.5901\n",
      "Epoch 00251: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 797us/step - loss: 214.9597 - mean_squared_error: 214.9597 - val_loss: 522.7847 - val_mean_squared_error: 522.7847\n",
      "Epoch 252/500\n",
      "465/526 [=========================>....] - ETA: 0s - loss: 222.1102 - mean_squared_error: 222.1102\n",
      "Epoch 00252: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 807us/step - loss: 220.1784 - mean_squared_error: 220.1784 - val_loss: 508.8565 - val_mean_squared_error: 508.8565\n",
      "Epoch 253/500\n",
      "466/526 [=========================>....] - ETA: 0s - loss: 215.2785 - mean_squared_error: 215.2785\n",
      "Epoch 00253: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 799us/step - loss: 214.6842 - mean_squared_error: 214.6842 - val_loss: 531.0255 - val_mean_squared_error: 531.0255\n",
      "Epoch 254/500\n",
      "468/526 [=========================>....] - ETA: 0s - loss: 216.2762 - mean_squared_error: 216.2762\n",
      "Epoch 00254: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 797us/step - loss: 217.1209 - mean_squared_error: 217.1209 - val_loss: 662.7723 - val_mean_squared_error: 662.7723\n",
      "Epoch 255/500\n",
      "471/526 [=========================>....] - ETA: 0s - loss: 220.2492 - mean_squared_error: 220.2492\n",
      "Epoch 00255: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 792us/step - loss: 219.2966 - mean_squared_error: 219.2966 - val_loss: 492.5087 - val_mean_squared_error: 492.5087\n",
      "Epoch 256/500\n",
      "471/526 [=========================>....] - ETA: 0s - loss: 218.2219 - mean_squared_error: 218.2219\n",
      "Epoch 00256: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 791us/step - loss: 216.7637 - mean_squared_error: 216.7637 - val_loss: 554.3000 - val_mean_squared_error: 554.3000\n",
      "Epoch 257/500\n",
      "471/526 [=========================>....] - ETA: 0s - loss: 220.6195 - mean_squared_error: 220.6195\n",
      "Epoch 00257: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 793us/step - loss: 220.1477 - mean_squared_error: 220.1477 - val_loss: 619.7550 - val_mean_squared_error: 619.7550\n",
      "Epoch 258/500\n",
      "467/526 [=========================>....] - ETA: 0s - loss: 218.3717 - mean_squared_error: 218.3717\n",
      "Epoch 00258: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 805us/step - loss: 217.2779 - mean_squared_error: 217.2779 - val_loss: 642.4040 - val_mean_squared_error: 642.4040\n",
      "Epoch 259/500\n",
      "462/526 [=========================>....] - ETA: 0s - loss: 221.5765 - mean_squared_error: 221.5765\n",
      "Epoch 00259: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 809us/step - loss: 217.1247 - mean_squared_error: 217.1247 - val_loss: 577.9716 - val_mean_squared_error: 577.9716\n",
      "Epoch 260/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 217.3647 - mean_squared_error: 217.3647\n",
      "Epoch 00260: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 815us/step - loss: 217.3647 - mean_squared_error: 217.3647 - val_loss: 560.3327 - val_mean_squared_error: 560.3327\n",
      "Epoch 261/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 217.7949 - mean_squared_error: 217.7949\n",
      "Epoch 00261: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 824us/step - loss: 218.3088 - mean_squared_error: 218.3088 - val_loss: 605.9306 - val_mean_squared_error: 605.9306\n",
      "Epoch 262/500\n",
      "479/526 [==========================>...] - ETA: 0s - loss: 214.3579 - mean_squared_error: 214.3579\n",
      "Epoch 00262: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 887us/step - loss: 213.8574 - mean_squared_error: 213.8574 - val_loss: 573.9612 - val_mean_squared_error: 573.9612\n",
      "Epoch 263/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 220.9704 - mean_squared_error: 220.9704\n",
      "Epoch 00263: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 822us/step - loss: 220.7480 - mean_squared_error: 220.7480 - val_loss: 543.1668 - val_mean_squared_error: 543.1668\n",
      "Epoch 264/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 213.8722 - mean_squared_error: 213.8722\n",
      "Epoch 00264: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 824us/step - loss: 214.2435 - mean_squared_error: 214.2435 - val_loss: 573.0510 - val_mean_squared_error: 573.0510\n",
      "Epoch 265/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 217.6174 - mean_squared_error: 217.6174\n",
      "Epoch 00265: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 824us/step - loss: 218.1559 - mean_squared_error: 218.1559 - val_loss: 640.6692 - val_mean_squared_error: 640.6692\n",
      "Epoch 266/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 216.0124 - mean_squared_error: 216.0124\n",
      "Epoch 00266: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 824us/step - loss: 216.0637 - mean_squared_error: 216.0637 - val_loss: 568.6564 - val_mean_squared_error: 568.6564\n",
      "Epoch 267/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 212.9209 - mean_squared_error: 212.9209\n",
      "Epoch 00267: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 830us/step - loss: 213.1188 - mean_squared_error: 213.1188 - val_loss: 592.9941 - val_mean_squared_error: 592.9941\n",
      "Epoch 268/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 215.6959 - mean_squared_error: 215.6959\n",
      "Epoch 00268: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 833us/step - loss: 215.5062 - mean_squared_error: 215.5062 - val_loss: 523.1331 - val_mean_squared_error: 523.1331\n",
      "Epoch 269/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 213.0066 - mean_squared_error: 213.0066\n",
      "Epoch 00269: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 824us/step - loss: 213.0976 - mean_squared_error: 213.0976 - val_loss: 527.5260 - val_mean_squared_error: 527.5260\n",
      "Epoch 270/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 217.4624 - mean_squared_error: 217.4624\n",
      "Epoch 00270: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 833us/step - loss: 217.3467 - mean_squared_error: 217.3467 - val_loss: 591.6644 - val_mean_squared_error: 591.6644\n",
      "Epoch 271/500\n",
      "462/526 [=========================>....] - ETA: 0s - loss: 211.3004 - mean_squared_error: 211.3004\n",
      "Epoch 00271: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 813us/step - loss: 212.5852 - mean_squared_error: 212.5852 - val_loss: 544.2921 - val_mean_squared_error: 544.2921\n",
      "Epoch 272/500\n",
      "498/526 [===========================>..] - ETA: 0s - loss: 216.3974 - mean_squared_error: 216.3974\n",
      "Epoch 00272: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 862us/step - loss: 215.6648 - mean_squared_error: 215.6648 - val_loss: 529.1370 - val_mean_squared_error: 529.1370\n",
      "Epoch 273/500\n",
      "506/526 [===========================>..] - ETA: 0s - loss: 213.2853 - mean_squared_error: 213.2853\n",
      "Epoch 00273: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 845us/step - loss: 214.0646 - mean_squared_error: 214.0646 - val_loss: 609.0402 - val_mean_squared_error: 609.0402\n",
      "Epoch 274/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503/526 [===========================>..] - ETA: 0s - loss: 212.7429 - mean_squared_error: 212.7429\n",
      "Epoch 00274: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 851us/step - loss: 213.0311 - mean_squared_error: 213.0311 - val_loss: 517.7936 - val_mean_squared_error: 517.7936\n",
      "Epoch 275/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 217.7325 - mean_squared_error: 217.7325\n",
      "Epoch 00275: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 826us/step - loss: 217.8975 - mean_squared_error: 217.8975 - val_loss: 580.8749 - val_mean_squared_error: 580.8749\n",
      "Epoch 276/500\n",
      "497/526 [===========================>..] - ETA: 0s - loss: 215.5882 - mean_squared_error: 215.5882\n",
      "Epoch 00276: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 858us/step - loss: 215.4728 - mean_squared_error: 215.4728 - val_loss: 486.8235 - val_mean_squared_error: 486.8235\n",
      "Epoch 277/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 212.0132 - mean_squared_error: 212.0132\n",
      "Epoch 00277: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 826us/step - loss: 212.2644 - mean_squared_error: 212.2644 - val_loss: 575.6525 - val_mean_squared_error: 575.6525\n",
      "Epoch 278/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 214.9182 - mean_squared_error: 214.9182\n",
      "Epoch 00278: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 824us/step - loss: 215.0665 - mean_squared_error: 215.0665 - val_loss: 522.2848 - val_mean_squared_error: 522.2848\n",
      "Epoch 279/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 214.2877 - mean_squared_error: 214.2877\n",
      "Epoch 00279: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 828us/step - loss: 213.6128 - mean_squared_error: 213.6128 - val_loss: 542.5833 - val_mean_squared_error: 542.5833\n",
      "Epoch 280/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 211.5236 - mean_squared_error: 211.5236 ETA: 0s - loss: 218.2515 - mean_squared_error\n",
      "Epoch 00280: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 211.1311 - mean_squared_error: 211.1311 - val_loss: 538.0749 - val_mean_squared_error: 538.0749\n",
      "Epoch 281/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 214.4958 - mean_squared_error: 214.4958\n",
      "Epoch 00281: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 837us/step - loss: 214.2730 - mean_squared_error: 214.2730 - val_loss: 626.7014 - val_mean_squared_error: 626.7014\n",
      "Epoch 282/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 215.8664 - mean_squared_error: 215.8664\n",
      "Epoch 00282: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 820us/step - loss: 215.7159 - mean_squared_error: 215.7159 - val_loss: 573.7545 - val_mean_squared_error: 573.7545\n",
      "Epoch 283/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 214.8890 - mean_squared_error: 214.8890\n",
      "Epoch 00283: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 830us/step - loss: 214.7117 - mean_squared_error: 214.7117 - val_loss: 515.2330 - val_mean_squared_error: 515.2330\n",
      "Epoch 284/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 209.0591 - mean_squared_error: 209.0591\n",
      "Epoch 00284: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 822us/step - loss: 209.4410 - mean_squared_error: 209.4410 - val_loss: 592.0167 - val_mean_squared_error: 592.0167\n",
      "Epoch 285/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 214.4027 - mean_squared_error: 214.4027\n",
      "Epoch 00285: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 820us/step - loss: 214.4647 - mean_squared_error: 214.4647 - val_loss: 524.7927 - val_mean_squared_error: 524.7927\n",
      "Epoch 286/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 212.7083 - mean_squared_error: 212.7083\n",
      "Epoch 00286: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 837us/step - loss: 213.2576 - mean_squared_error: 213.2576 - val_loss: 614.2369 - val_mean_squared_error: 614.2369\n",
      "Epoch 287/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 215.6609 - mean_squared_error: 215.6609\n",
      "Epoch 00287: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 833us/step - loss: 216.0533 - mean_squared_error: 216.0533 - val_loss: 558.6559 - val_mean_squared_error: 558.6559\n",
      "Epoch 288/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 213.7972 - mean_squared_error: 213.7972\n",
      "Epoch 00288: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 833us/step - loss: 213.7770 - mean_squared_error: 213.7770 - val_loss: 486.4716 - val_mean_squared_error: 486.4716\n",
      "Epoch 289/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 210.2888 - mean_squared_error: 210.2888\n",
      "Epoch 00289: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 210.1568 - mean_squared_error: 210.1568 - val_loss: 497.0288 - val_mean_squared_error: 497.0288\n",
      "Epoch 290/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 212.7232 - mean_squared_error: 212.7232\n",
      "Epoch 00290: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 824us/step - loss: 212.9372 - mean_squared_error: 212.9372 - val_loss: 588.7339 - val_mean_squared_error: 588.7339\n",
      "Epoch 291/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 213.0415 - mean_squared_error: 213.0415\n",
      "Epoch 00291: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 213.1210 - mean_squared_error: 213.1210 - val_loss: 610.6794 - val_mean_squared_error: 610.6794\n",
      "Epoch 292/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 212.0886 - mean_squared_error: 212.0886\n",
      "Epoch 00292: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 820us/step - loss: 211.7942 - mean_squared_error: 211.7942 - val_loss: 541.5843 - val_mean_squared_error: 541.5843\n",
      "Epoch 293/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 210.3749 - mean_squared_error: 210.3749\n",
      "Epoch 00293: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 210.2250 - mean_squared_error: 210.2250 - val_loss: 515.6352 - val_mean_squared_error: 515.6352\n",
      "Epoch 294/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 211.6760 - mean_squared_error: 211.6760\n",
      "Epoch 00294: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 211.5562 - mean_squared_error: 211.5562 - val_loss: 611.7303 - val_mean_squared_error: 611.7303\n",
      "Epoch 295/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 212.3570 - mean_squared_error: 212.3570\n",
      "Epoch 00295: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 825us/step - loss: 212.3555 - mean_squared_error: 212.3555 - val_loss: 549.6351 - val_mean_squared_error: 549.6351\n",
      "Epoch 296/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 210.6743 - mean_squared_error: 210.6743\n",
      "Epoch 00296: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 824us/step - loss: 211.1185 - mean_squared_error: 211.1185 - val_loss: 520.5994 - val_mean_squared_error: 520.5994\n",
      "Epoch 297/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 212.2412 - mean_squared_error: 212.2412\n",
      "Epoch 00297: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 212.4766 - mean_squared_error: 212.4766 - val_loss: 559.4514 - val_mean_squared_error: 559.4514\n",
      "Epoch 298/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 209.0964 - mean_squared_error: 209.0964\n",
      "Epoch 00298: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 817us/step - loss: 208.8301 - mean_squared_error: 208.8301 - val_loss: 543.6561 - val_mean_squared_error: 543.6561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 211.6997 - mean_squared_error: 211.6997\n",
      "Epoch 00299: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 211.6997 - mean_squared_error: 211.6997 - val_loss: 551.4250 - val_mean_squared_error: 551.4250\n",
      "Epoch 300/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 210.5408 - mean_squared_error: 210.5408\n",
      "Epoch 00300: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 819us/step - loss: 210.5092 - mean_squared_error: 210.5092 - val_loss: 554.2047 - val_mean_squared_error: 554.2047\n",
      "Epoch 301/500\n",
      "461/526 [=========================>....] - ETA: 0s - loss: 214.0078 - mean_squared_error: 214.0078\n",
      "Epoch 00301: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 213.0963 - mean_squared_error: 213.0963 - val_loss: 536.0894 - val_mean_squared_error: 536.0894\n",
      "Epoch 302/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 211.2452 - mean_squared_error: 211.2452\n",
      "Epoch 00302: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 211.9426 - mean_squared_error: 211.9426 - val_loss: 579.3584 - val_mean_squared_error: 579.3584\n",
      "Epoch 303/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 210.6140 - mean_squared_error: 210.6140\n",
      "Epoch 00303: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 210.5919 - mean_squared_error: 210.5919 - val_loss: 544.3832 - val_mean_squared_error: 544.3832\n",
      "Epoch 304/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 211.5537 - mean_squared_error: 211.5537\n",
      "Epoch 00304: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 211.2577 - mean_squared_error: 211.2577 - val_loss: 550.9778 - val_mean_squared_error: 550.9778\n",
      "Epoch 305/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 210.2472 - mean_squared_error: 210.2472\n",
      "Epoch 00305: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 813us/step - loss: 210.2472 - mean_squared_error: 210.2472 - val_loss: 605.9728 - val_mean_squared_error: 605.9728\n",
      "Epoch 306/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 208.3661 - mean_squared_error: 208.3661\n",
      "Epoch 00306: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 824us/step - loss: 208.3727 - mean_squared_error: 208.3727 - val_loss: 504.0329 - val_mean_squared_error: 504.0329\n",
      "Epoch 307/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 211.6360 - mean_squared_error: 211.6360\n",
      "Epoch 00307: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 211.5477 - mean_squared_error: 211.5477 - val_loss: 517.7338 - val_mean_squared_error: 517.7338\n",
      "Epoch 308/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 210.4154 - mean_squared_error: 210.4154\n",
      "Epoch 00308: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 210.5624 - mean_squared_error: 210.5624 - val_loss: 669.7961 - val_mean_squared_error: 669.7961\n",
      "Epoch 309/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 208.6950 - mean_squared_error: 208.6950\n",
      "Epoch 00309: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 824us/step - loss: 209.2881 - mean_squared_error: 209.2881 - val_loss: 649.6017 - val_mean_squared_error: 649.6017\n",
      "Epoch 310/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 211.7001 - mean_squared_error: 211.7001\n",
      "Epoch 00310: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 211.4419 - mean_squared_error: 211.4419 - val_loss: 636.3452 - val_mean_squared_error: 636.3452\n",
      "Epoch 311/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 211.4405 - mean_squared_error: 211.4405\n",
      "Epoch 00311: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 211.3002 - mean_squared_error: 211.3002 - val_loss: 561.2788 - val_mean_squared_error: 561.2788\n",
      "Epoch 312/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 207.0250 - mean_squared_error: 207.0250\n",
      "Epoch 00312: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 207.1966 - mean_squared_error: 207.1966 - val_loss: 635.3030 - val_mean_squared_error: 635.3030\n",
      "Epoch 313/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 210.5537 - mean_squared_error: 210.5537\n",
      "Epoch 00313: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 824us/step - loss: 210.1134 - mean_squared_error: 210.1134 - val_loss: 598.2859 - val_mean_squared_error: 598.2859\n",
      "Epoch 314/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 209.0458 - mean_squared_error: 209.0458\n",
      "Epoch 00314: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 824us/step - loss: 209.4807 - mean_squared_error: 209.4807 - val_loss: 582.4224 - val_mean_squared_error: 582.4224\n",
      "Epoch 315/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 209.5300 - mean_squared_error: 209.5300\n",
      "Epoch 00315: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 209.5954 - mean_squared_error: 209.5954 - val_loss: 489.7292 - val_mean_squared_error: 489.7292\n",
      "Epoch 316/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 208.5815 - mean_squared_error: 208.5815\n",
      "Epoch 00316: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 824us/step - loss: 208.6924 - mean_squared_error: 208.6924 - val_loss: 650.5750 - val_mean_squared_error: 650.5750\n",
      "Epoch 317/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 209.8131 - mean_squared_error: 209.8131\n",
      "Epoch 00317: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 826us/step - loss: 210.4166 - mean_squared_error: 210.4166 - val_loss: 588.9911 - val_mean_squared_error: 588.9911\n",
      "Epoch 318/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 207.7487 - mean_squared_error: 207.7487\n",
      "Epoch 00318: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 207.6329 - mean_squared_error: 207.6329 - val_loss: 526.0623 - val_mean_squared_error: 526.0623\n",
      "Epoch 319/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 208.5364 - mean_squared_error: 208.5364\n",
      "Epoch 00319: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 208.6860 - mean_squared_error: 208.6860 - val_loss: 558.2070 - val_mean_squared_error: 558.2070\n",
      "Epoch 320/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 208.1844 - mean_squared_error: 208.1844\n",
      "Epoch 00320: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 820us/step - loss: 208.3220 - mean_squared_error: 208.3220 - val_loss: 545.6455 - val_mean_squared_error: 545.6455\n",
      "Epoch 321/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 208.2113 - mean_squared_error: 208.2113\n",
      "Epoch 00321: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 208.0211 - mean_squared_error: 208.0211 - val_loss: 597.8381 - val_mean_squared_error: 597.8381\n",
      "Epoch 322/500\n",
      "462/526 [=========================>....] - ETA: 0s - loss: 206.5140 - mean_squared_error: 206.5140\n",
      "Epoch 00322: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 812us/step - loss: 207.0520 - mean_squared_error: 207.0520 - val_loss: 551.9431 - val_mean_squared_error: 551.9431\n",
      "Epoch 323/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 210.1589 - mean_squared_error: 210.1589\n",
      "Epoch 00323: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 832us/step - loss: 209.9407 - mean_squared_error: 209.9407 - val_loss: 612.0110 - val_mean_squared_error: 612.0110\n",
      "Epoch 324/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 209.0755 - mean_squared_error: 209.0755\n",
      "Epoch 00324: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 828us/step - loss: 208.1179 - mean_squared_error: 208.1179 - val_loss: 528.6410 - val_mean_squared_error: 528.6410\n",
      "Epoch 325/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 206.8739 - mean_squared_error: 206.8739\n",
      "Epoch 00325: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 830us/step - loss: 206.9170 - mean_squared_error: 206.9170 - val_loss: 514.9592 - val_mean_squared_error: 514.9592\n",
      "Epoch 326/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 207.5361 - mean_squared_error: 207.5361\n",
      "Epoch 00326: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 849us/step - loss: 207.4307 - mean_squared_error: 207.4307 - val_loss: 558.2424 - val_mean_squared_error: 558.2424\n",
      "Epoch 327/500\n",
      "473/526 [=========================>....] - ETA: 0s - loss: 209.2636 - mean_squared_error: 209.2636\n",
      "Epoch 00327: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 209.0133 - mean_squared_error: 209.0133 - val_loss: 584.5383 - val_mean_squared_error: 584.5383\n",
      "Epoch 328/500\n",
      "497/526 [===========================>..] - ETA: 0s - loss: 206.8491 - mean_squared_error: 206.8491\n",
      "Epoch 00328: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 1s 970us/step - loss: 206.1887 - mean_squared_error: 206.1887 - val_loss: 617.4386 - val_mean_squared_error: 617.4386\n",
      "Epoch 329/500\n",
      "509/526 [============================>.] - ETA: 0s - loss: 206.9703 - mean_squared_error: 206.9703\n",
      "Epoch 00329: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 1s 951us/step - loss: 207.7475 - mean_squared_error: 207.7475 - val_loss: 599.3917 - val_mean_squared_error: 599.3917\n",
      "Epoch 330/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 206.0894 - mean_squared_error: 206.0894\n",
      "Epoch 00330: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 919us/step - loss: 206.0535 - mean_squared_error: 206.0535 - val_loss: 501.8810 - val_mean_squared_error: 501.8810\n",
      "Epoch 331/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 203.8732 - mean_squared_error: 203.8732\n",
      "Epoch 00331: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 925us/step - loss: 204.1745 - mean_squared_error: 204.1745 - val_loss: 624.0416 - val_mean_squared_error: 624.0416\n",
      "Epoch 332/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 205.0592 - mean_squared_error: 205.0592\n",
      "Epoch 00332: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 927us/step - loss: 204.4916 - mean_squared_error: 204.4916 - val_loss: 584.8681 - val_mean_squared_error: 584.8681\n",
      "Epoch 333/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 206.6185 - mean_squared_error: 206.6185\n",
      "Epoch 00333: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 931us/step - loss: 206.2328 - mean_squared_error: 206.2328 - val_loss: 605.8032 - val_mean_squared_error: 605.8032\n",
      "Epoch 334/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 205.7350 - mean_squared_error: 205.7350\n",
      "Epoch 00334: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 921us/step - loss: 206.2861 - mean_squared_error: 206.2861 - val_loss: 567.8412 - val_mean_squared_error: 567.8412\n",
      "Epoch 335/500\n",
      "469/526 [=========================>....] - ETA: 0s - loss: 206.1389 - mean_squared_error: 206.1389\n",
      "Epoch 00335: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 915us/step - loss: 203.7783 - mean_squared_error: 203.7783 - val_loss: 537.5833 - val_mean_squared_error: 537.5833\n",
      "Epoch 336/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 204.4978 - mean_squared_error: 204.4978\n",
      "Epoch 00336: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 921us/step - loss: 204.3289 - mean_squared_error: 204.3289 - val_loss: 500.0971 - val_mean_squared_error: 500.0971\n",
      "Epoch 337/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 204.8412 - mean_squared_error: 204.8412\n",
      "Epoch 00337: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 938us/step - loss: 205.2675 - mean_squared_error: 205.2675 - val_loss: 575.6779 - val_mean_squared_error: 575.6779\n",
      "Epoch 338/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 205.9062 - mean_squared_error: 205.9062\n",
      "Epoch 00338: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 921us/step - loss: 205.9451 - mean_squared_error: 205.9451 - val_loss: 593.0322 - val_mean_squared_error: 593.0322\n",
      "Epoch 339/500\n",
      "481/526 [==========================>...] - ETA: 0s - loss: 206.0505 - mean_squared_error: 206.0505\n",
      "Epoch 00339: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 885us/step - loss: 205.7671 - mean_squared_error: 205.7671 - val_loss: 625.7504 - val_mean_squared_error: 625.7504\n",
      "Epoch 340/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 203.6049 - mean_squared_error: 203.6049\n",
      "Epoch 00340: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 824us/step - loss: 203.2032 - mean_squared_error: 203.2032 - val_loss: 487.9386 - val_mean_squared_error: 487.9386\n",
      "Epoch 341/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 208.8721 - mean_squared_error: 208.8721\n",
      "Epoch 00341: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 837us/step - loss: 209.0691 - mean_squared_error: 209.0691 - val_loss: 576.7018 - val_mean_squared_error: 576.7018\n",
      "Epoch 342/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 205.3106 - mean_squared_error: 205.3106\n",
      "Epoch 00342: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 833us/step - loss: 205.4633 - mean_squared_error: 205.4633 - val_loss: 575.5867 - val_mean_squared_error: 575.5867\n",
      "Epoch 343/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 209.0211 - mean_squared_error: 209.0211\n",
      "Epoch 00343: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 826us/step - loss: 208.6075 - mean_squared_error: 208.6075 - val_loss: 502.3228 - val_mean_squared_error: 502.3228\n",
      "Epoch 344/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 202.9818 - mean_squared_error: 202.9818\n",
      "Epoch 00344: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 825us/step - loss: 203.1687 - mean_squared_error: 203.1687 - val_loss: 565.9271 - val_mean_squared_error: 565.9271\n",
      "Epoch 345/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 208.2667 - mean_squared_error: 208.2667\n",
      "Epoch 00345: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 826us/step - loss: 208.7554 - mean_squared_error: 208.7554 - val_loss: 458.3324 - val_mean_squared_error: 458.3324\n",
      "Epoch 346/500\n",
      "508/526 [===========================>..] - ETA: 0s - loss: 204.9317 - mean_squared_error: 204.9317\n",
      "Epoch 00346: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 841us/step - loss: 204.7447 - mean_squared_error: 204.7447 - val_loss: 571.4735 - val_mean_squared_error: 571.4735\n",
      "Epoch 347/500\n",
      "515/526 [============================>.] - ETA: 0s - loss: 203.0570 - mean_squared_error: 203.0570\n",
      "Epoch 00347: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 840us/step - loss: 202.8625 - mean_squared_error: 202.8625 - val_loss: 529.6686 - val_mean_squared_error: 529.6686\n",
      "Epoch 348/500\n",
      "503/526 [===========================>..] - ETA: 0s - loss: 205.4133 - mean_squared_error: 205.4133\n",
      "Epoch 00348: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 852us/step - loss: 205.5228 - mean_squared_error: 205.5228 - val_loss: 605.4926 - val_mean_squared_error: 605.4926\n",
      "Epoch 349/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/526 [============================>.] - ETA: 0s - loss: 205.5930 - mean_squared_error: 205.5930\n",
      "Epoch 00349: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 838us/step - loss: 205.7522 - mean_squared_error: 205.7522 - val_loss: 524.7547 - val_mean_squared_error: 524.7547\n",
      "Epoch 350/500\n",
      "498/526 [===========================>..] - ETA: 0s - loss: 201.4241 - mean_squared_error: 201.4241\n",
      "Epoch 00350: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 854us/step - loss: 202.0102 - mean_squared_error: 202.0102 - val_loss: 524.9559 - val_mean_squared_error: 524.9559\n",
      "Epoch 351/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 206.5679 - mean_squared_error: 206.5679\n",
      "Epoch 00351: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 837us/step - loss: 206.5264 - mean_squared_error: 206.5264 - val_loss: 524.6537 - val_mean_squared_error: 524.6537\n",
      "Epoch 352/500\n",
      "513/526 [============================>.] - ETA: 0s - loss: 206.1173 - mean_squared_error: 206.1173\n",
      "Epoch 00352: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 833us/step - loss: 205.3488 - mean_squared_error: 205.3488 - val_loss: 552.4590 - val_mean_squared_error: 552.4590\n",
      "Epoch 353/500\n",
      "510/526 [============================>.] - ETA: 0s - loss: 202.8542 - mean_squared_error: 202.8542\n",
      "Epoch 00353: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 839us/step - loss: 203.1739 - mean_squared_error: 203.1739 - val_loss: 572.0123 - val_mean_squared_error: 572.0123\n",
      "Epoch 354/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 202.4856 - mean_squared_error: 202.4856\n",
      "Epoch 00354: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 841us/step - loss: 202.0206 - mean_squared_error: 202.0206 - val_loss: 521.8156 - val_mean_squared_error: 521.8156\n",
      "Epoch 355/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 202.5427 - mean_squared_error: 202.5427\n",
      "Epoch 00355: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 843us/step - loss: 202.5325 - mean_squared_error: 202.5325 - val_loss: 572.9088 - val_mean_squared_error: 572.9088\n",
      "Epoch 356/500\n",
      "512/526 [============================>.] - ETA: 0s - loss: 203.9770 - mean_squared_error: 203.9770\n",
      "Epoch 00356: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 835us/step - loss: 203.5232 - mean_squared_error: 203.5232 - val_loss: 533.0521 - val_mean_squared_error: 533.0521\n",
      "Epoch 357/500\n",
      "505/526 [===========================>..] - ETA: 0s - loss: 201.2108 - mean_squared_error: 201.2108\n",
      "Epoch 00357: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 847us/step - loss: 200.8615 - mean_squared_error: 200.8615 - val_loss: 587.7412 - val_mean_squared_error: 587.7412\n",
      "Epoch 358/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 203.0730 - mean_squared_error: 203.0730\n",
      "Epoch 00358: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 843us/step - loss: 203.1228 - mean_squared_error: 203.1228 - val_loss: 493.9076 - val_mean_squared_error: 493.9076\n",
      "Epoch 359/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 201.4845 - mean_squared_error: 201.4845\n",
      "Epoch 00359: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 851us/step - loss: 202.7775 - mean_squared_error: 202.7775 - val_loss: 553.2287 - val_mean_squared_error: 553.2287\n",
      "Epoch 360/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 202.0397 - mean_squared_error: 202.0397\n",
      "Epoch 00360: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 843us/step - loss: 202.4355 - mean_squared_error: 202.4355 - val_loss: 574.7024 - val_mean_squared_error: 574.7024\n",
      "Epoch 361/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 202.3991 - mean_squared_error: 202.3991\n",
      "Epoch 00361: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 839us/step - loss: 203.2904 - mean_squared_error: 203.2904 - val_loss: 570.1882 - val_mean_squared_error: 570.1882\n",
      "Epoch 362/500\n",
      "507/526 [===========================>..] - ETA: 0s - loss: 203.6982 - mean_squared_error: 203.6982\n",
      "Epoch 00362: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 843us/step - loss: 204.1268 - mean_squared_error: 204.1268 - val_loss: 552.1942 - val_mean_squared_error: 552.1942\n",
      "Epoch 363/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 204.9823 - mean_squared_error: 204.9823\n",
      "Epoch 00363: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 832us/step - loss: 203.6339 - mean_squared_error: 203.6339 - val_loss: 477.8932 - val_mean_squared_error: 477.8932\n",
      "Epoch 364/500\n",
      "514/526 [============================>.] - ETA: 0s - loss: 201.8978 - mean_squared_error: 201.8978\n",
      "Epoch 00364: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 830us/step - loss: 201.9909 - mean_squared_error: 201.9909 - val_loss: 568.6838 - val_mean_squared_error: 568.6838\n",
      "Epoch 365/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 199.6812 - mean_squared_error: 199.6812\n",
      "Epoch 00365: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 199.3829 - mean_squared_error: 199.3829 - val_loss: 520.2492 - val_mean_squared_error: 520.2492\n",
      "Epoch 366/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 203.5135 - mean_squared_error: 203.5135\n",
      "Epoch 00366: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 820us/step - loss: 203.3267 - mean_squared_error: 203.3267 - val_loss: 543.8950 - val_mean_squared_error: 543.8950\n",
      "Epoch 367/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 204.0252 - mean_squared_error: 204.0252\n",
      "Epoch 00367: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 820us/step - loss: 204.0017 - mean_squared_error: 204.0017 - val_loss: 559.7708 - val_mean_squared_error: 559.7708\n",
      "Epoch 368/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 202.6657 - mean_squared_error: 202.6657\n",
      "Epoch 00368: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 820us/step - loss: 203.9056 - mean_squared_error: 203.9056 - val_loss: 498.7273 - val_mean_squared_error: 498.7273\n",
      "Epoch 369/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 202.1516 - mean_squared_error: 202.1516\n",
      "Epoch 00369: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 830us/step - loss: 202.1044 - mean_squared_error: 202.1044 - val_loss: 514.8892 - val_mean_squared_error: 514.8892\n",
      "Epoch 370/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 201.1667 - mean_squared_error: 201.1667\n",
      "Epoch 00370: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 825us/step - loss: 201.1041 - mean_squared_error: 201.1041 - val_loss: 600.4380 - val_mean_squared_error: 600.4380\n",
      "Epoch 371/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 196.6652 - mean_squared_error: 196.6652\n",
      "Epoch 00371: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 822us/step - loss: 196.8753 - mean_squared_error: 196.8753 - val_loss: 572.8864 - val_mean_squared_error: 572.8864\n",
      "Epoch 372/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 201.1060 - mean_squared_error: 201.1060\n",
      "Epoch 00372: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 827us/step - loss: 201.3056 - mean_squared_error: 201.3056 - val_loss: 567.6492 - val_mean_squared_error: 567.6492\n",
      "Epoch 373/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 199.5573 - mean_squared_error: 199.5573\n",
      "Epoch 00373: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 822us/step - loss: 199.7738 - mean_squared_error: 199.7738 - val_loss: 533.2455 - val_mean_squared_error: 533.2455\n",
      "Epoch 374/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 201.3477 - mean_squared_error: 201.3477\n",
      "Epoch 00374: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 817us/step - loss: 201.5915 - mean_squared_error: 201.5915 - val_loss: 603.0303 - val_mean_squared_error: 603.0303\n",
      "Epoch 375/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 201.1203 - mean_squared_error: 201.1203\n",
      "Epoch 00375: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 201.3659 - mean_squared_error: 201.3659 - val_loss: 567.6462 - val_mean_squared_error: 567.6462\n",
      "Epoch 376/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 201.9449 - mean_squared_error: 201.9449\n",
      "Epoch 00376: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 826us/step - loss: 201.8944 - mean_squared_error: 201.8944 - val_loss: 606.1379 - val_mean_squared_error: 606.1379\n",
      "Epoch 377/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 200.1202 - mean_squared_error: 200.1202\n",
      "Epoch 00377: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 199.9760 - mean_squared_error: 199.9760 - val_loss: 618.0118 - val_mean_squared_error: 618.0118\n",
      "Epoch 378/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 199.8882 - mean_squared_error: 199.8882\n",
      "Epoch 00378: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 199.8106 - mean_squared_error: 199.8106 - val_loss: 553.0493 - val_mean_squared_error: 553.0493\n",
      "Epoch 379/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 199.9658 - mean_squared_error: 199.9658\n",
      "Epoch 00379: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 199.7570 - mean_squared_error: 199.7570 - val_loss: 529.1699 - val_mean_squared_error: 529.1699\n",
      "Epoch 380/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 198.3643 - mean_squared_error: 198.3643\n",
      "Epoch 00380: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 198.5943 - mean_squared_error: 198.5943 - val_loss: 631.7681 - val_mean_squared_error: 631.7681\n",
      "Epoch 381/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 200.5425 - mean_squared_error: 200.5425\n",
      "Epoch 00381: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 200.6591 - mean_squared_error: 200.6591 - val_loss: 485.2294 - val_mean_squared_error: 485.2294\n",
      "Epoch 382/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 201.4630 - mean_squared_error: 201.4630\n",
      "Epoch 00382: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 201.9575 - mean_squared_error: 201.9575 - val_loss: 483.7042 - val_mean_squared_error: 483.7042\n",
      "Epoch 383/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 201.3711 - mean_squared_error: 201.3711\n",
      "Epoch 00383: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 201.2659 - mean_squared_error: 201.2659 - val_loss: 530.7365 - val_mean_squared_error: 530.7365\n",
      "Epoch 384/500\n",
      "461/526 [=========================>....] - ETA: 0s - loss: 197.9218 - mean_squared_error: 197.9218\n",
      "Epoch 00384: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 811us/step - loss: 196.4564 - mean_squared_error: 196.4564 - val_loss: 460.8767 - val_mean_squared_error: 460.8767\n",
      "Epoch 385/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 201.1519 - mean_squared_error: 201.1519\n",
      "Epoch 00385: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 201.1026 - mean_squared_error: 201.1026 - val_loss: 556.9268 - val_mean_squared_error: 556.9268\n",
      "Epoch 386/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 200.4107 - mean_squared_error: 200.4107\n",
      "Epoch 00386: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 200.5704 - mean_squared_error: 200.5704 - val_loss: 595.0285 - val_mean_squared_error: 595.0285\n",
      "Epoch 387/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 197.9245 - mean_squared_error: 197.9245\n",
      "Epoch 00387: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 197.9066 - mean_squared_error: 197.9066 - val_loss: 561.7744 - val_mean_squared_error: 561.7744\n",
      "Epoch 388/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 195.7687 - mean_squared_error: 195.7687\n",
      "Epoch 00388: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 195.8844 - mean_squared_error: 195.8844 - val_loss: 519.6157 - val_mean_squared_error: 519.6157\n",
      "Epoch 389/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 202.7262 - mean_squared_error: 202.7262\n",
      "Epoch 00389: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 202.7262 - mean_squared_error: 202.7262 - val_loss: 516.4302 - val_mean_squared_error: 516.4302\n",
      "Epoch 390/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 199.4715 - mean_squared_error: 199.4715\n",
      "Epoch 00390: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 822us/step - loss: 199.7438 - mean_squared_error: 199.7438 - val_loss: 542.8839 - val_mean_squared_error: 542.8839\n",
      "Epoch 391/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 197.0527 - mean_squared_error: 197.0527\n",
      "Epoch 00391: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 822us/step - loss: 196.9900 - mean_squared_error: 196.9900 - val_loss: 548.4490 - val_mean_squared_error: 548.4490\n",
      "Epoch 392/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 198.9261 - mean_squared_error: 198.9261\n",
      "Epoch 00392: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 198.8130 - mean_squared_error: 198.8130 - val_loss: 589.6339 - val_mean_squared_error: 589.6339\n",
      "Epoch 393/500\n",
      "517/526 [============================>.] - ETA: 0s - loss: 195.5500 - mean_squared_error: 195.5500\n",
      "Epoch 00393: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 829us/step - loss: 195.9324 - mean_squared_error: 195.9324 - val_loss: 572.2989 - val_mean_squared_error: 572.2989\n",
      "Epoch 394/500\n",
      "463/526 [=========================>....] - ETA: 0s - loss: 200.3879 - mean_squared_error: 200.3879\n",
      "Epoch 00394: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 809us/step - loss: 201.5577 - mean_squared_error: 201.5577 - val_loss: 500.4561 - val_mean_squared_error: 500.4561\n",
      "Epoch 395/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 194.8290 - mean_squared_error: 194.8290\n",
      "Epoch 00395: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 826us/step - loss: 195.0583 - mean_squared_error: 195.0583 - val_loss: 517.0602 - val_mean_squared_error: 517.0602\n",
      "Epoch 396/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 197.4405 - mean_squared_error: 197.4405\n",
      "Epoch 00396: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 815us/step - loss: 197.4405 - mean_squared_error: 197.4405 - val_loss: 483.8188 - val_mean_squared_error: 483.8188\n",
      "Epoch 397/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 199.4188 - mean_squared_error: 199.4188\n",
      "Epoch 00397: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 199.2729 - mean_squared_error: 199.2729 - val_loss: 461.8703 - val_mean_squared_error: 461.8703\n",
      "Epoch 398/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 196.1512 - mean_squared_error: 196.1512\n",
      "Epoch 00398: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 195.6334 - mean_squared_error: 195.6334 - val_loss: 599.3567 - val_mean_squared_error: 599.3567\n",
      "Epoch 399/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522/526 [============================>.] - ETA: 0s - loss: 198.7142 - mean_squared_error: 198.7142\n",
      "Epoch 00399: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 198.2398 - mean_squared_error: 198.2398 - val_loss: 506.6788 - val_mean_squared_error: 506.6788\n",
      "Epoch 400/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 199.0380 - mean_squared_error: 199.0380\n",
      "Epoch 00400: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 830us/step - loss: 199.0395 - mean_squared_error: 199.0395 - val_loss: 492.1376 - val_mean_squared_error: 492.1376\n",
      "Epoch 401/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 199.2658 - mean_squared_error: 199.2658\n",
      "Epoch 00401: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 199.1342 - mean_squared_error: 199.1342 - val_loss: 530.0208 - val_mean_squared_error: 530.0208\n",
      "Epoch 402/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 197.5058 - mean_squared_error: 197.5058\n",
      "Epoch 00402: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 824us/step - loss: 197.2196 - mean_squared_error: 197.2196 - val_loss: 505.1317 - val_mean_squared_error: 505.1317\n",
      "Epoch 403/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 196.1054 - mean_squared_error: 196.1054\n",
      "Epoch 00403: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 196.2280 - mean_squared_error: 196.2280 - val_loss: 429.1871 - val_mean_squared_error: 429.1871\n",
      "Epoch 404/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 198.2955 - mean_squared_error: 198.2955\n",
      "Epoch 00404: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 198.2412 - mean_squared_error: 198.2412 - val_loss: 580.6282 - val_mean_squared_error: 580.6282\n",
      "Epoch 405/500\n",
      "462/526 [=========================>....] - ETA: 0s - loss: 199.2901 - mean_squared_error: 199.2901\n",
      "Epoch 00405: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 811us/step - loss: 199.3187 - mean_squared_error: 199.3187 - val_loss: 566.4431 - val_mean_squared_error: 566.4431\n",
      "Epoch 406/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 200.5129 - mean_squared_error: 200.5129\n",
      "Epoch 00406: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 200.4341 - mean_squared_error: 200.4341 - val_loss: 529.5148 - val_mean_squared_error: 529.5148\n",
      "Epoch 407/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 195.8143 - mean_squared_error: 195.8143\n",
      "Epoch 00407: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 195.4590 - mean_squared_error: 195.4590 - val_loss: 590.6984 - val_mean_squared_error: 590.6984\n",
      "Epoch 408/500\n",
      "460/526 [=========================>....] - ETA: 0s - loss: 196.5416 - mean_squared_error: 196.5416\n",
      "Epoch 00408: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 811us/step - loss: 195.1526 - mean_squared_error: 195.1526 - val_loss: 494.3667 - val_mean_squared_error: 494.3667\n",
      "Epoch 409/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 198.1344 - mean_squared_error: 198.1344\n",
      "Epoch 00409: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 198.1344 - mean_squared_error: 198.1344 - val_loss: 511.6758 - val_mean_squared_error: 511.6758\n",
      "Epoch 410/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 193.9021 - mean_squared_error: 193.9021\n",
      "Epoch 00410: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 193.8850 - mean_squared_error: 193.8850 - val_loss: 559.0799 - val_mean_squared_error: 559.0799\n",
      "Epoch 411/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 197.0903 - mean_squared_error: 197.0903\n",
      "Epoch 00411: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 196.9452 - mean_squared_error: 196.9452 - val_loss: 492.6251 - val_mean_squared_error: 492.6251\n",
      "Epoch 412/500\n",
      "461/526 [=========================>....] - ETA: 0s - loss: 196.6967 - mean_squared_error: 196.6967\n",
      "Epoch 00412: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 811us/step - loss: 195.0096 - mean_squared_error: 195.0096 - val_loss: 481.3396 - val_mean_squared_error: 481.3396\n",
      "Epoch 413/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 194.3647 - mean_squared_error: 194.3647\n",
      "Epoch 00413: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 194.3984 - mean_squared_error: 194.3984 - val_loss: 534.9838 - val_mean_squared_error: 534.9838\n",
      "Epoch 414/500\n",
      "462/526 [=========================>....] - ETA: 0s - loss: 199.0208 - mean_squared_error: 199.0208\n",
      "Epoch 00414: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 811us/step - loss: 199.1775 - mean_squared_error: 199.1775 - val_loss: 539.5952 - val_mean_squared_error: 539.5952\n",
      "Epoch 415/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 196.3417 - mean_squared_error: 196.3417\n",
      "Epoch 00415: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 196.2467 - mean_squared_error: 196.2467 - val_loss: 514.9858 - val_mean_squared_error: 514.9858\n",
      "Epoch 416/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 194.3867 - mean_squared_error: 194.3867\n",
      "Epoch 00416: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 194.5114 - mean_squared_error: 194.5114 - val_loss: 551.7647 - val_mean_squared_error: 551.7647\n",
      "Epoch 417/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 198.4827 - mean_squared_error: 198.4827\n",
      "Epoch 00417: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 198.4827 - mean_squared_error: 198.4827 - val_loss: 549.4017 - val_mean_squared_error: 549.4017\n",
      "Epoch 418/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 197.1012 - mean_squared_error: 197.1012\n",
      "Epoch 00418: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 196.9975 - mean_squared_error: 196.9975 - val_loss: 596.1301 - val_mean_squared_error: 596.1301\n",
      "Epoch 419/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 192.9808 - mean_squared_error: 192.9808\n",
      "Epoch 00419: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 192.9264 - mean_squared_error: 192.9264 - val_loss: 516.5560 - val_mean_squared_error: 516.5560\n",
      "Epoch 420/500\n",
      "464/526 [=========================>....] - ETA: 0s - loss: 196.4153 - mean_squared_error: 196.4153\n",
      "Epoch 00420: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 806us/step - loss: 196.0524 - mean_squared_error: 196.0524 - val_loss: 544.9420 - val_mean_squared_error: 544.9420\n",
      "Epoch 421/500\n",
      "462/526 [=========================>....] - ETA: 0s - loss: 194.7517 - mean_squared_error: 194.7517\n",
      "Epoch 00421: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 811us/step - loss: 194.8274 - mean_squared_error: 194.8274 - val_loss: 516.7823 - val_mean_squared_error: 516.7823\n",
      "Epoch 422/500\n",
      "461/526 [=========================>....] - ETA: 0s - loss: 194.3462 - mean_squared_error: 194.3462\n",
      "Epoch 00422: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 815us/step - loss: 193.6612 - mean_squared_error: 193.6612 - val_loss: 527.6851 - val_mean_squared_error: 527.6851\n",
      "Epoch 423/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 194.9144 - mean_squared_error: 194.9144\n",
      "Epoch 00423: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 820us/step - loss: 194.9002 - mean_squared_error: 194.9002 - val_loss: 572.9979 - val_mean_squared_error: 572.9979\n",
      "Epoch 424/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 195.4606 - mean_squared_error: 195.4606\n",
      "Epoch 00424: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 820us/step - loss: 195.4313 - mean_squared_error: 195.4313 - val_loss: 480.2343 - val_mean_squared_error: 480.2343\n",
      "Epoch 425/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 195.4975 - mean_squared_error: 195.4975\n",
      "Epoch 00425: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 195.4972 - mean_squared_error: 195.4972 - val_loss: 620.3364 - val_mean_squared_error: 620.3364\n",
      "Epoch 426/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 195.8214 - mean_squared_error: 195.8214\n",
      "Epoch 00426: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 195.7025 - mean_squared_error: 195.7025 - val_loss: 555.4844 - val_mean_squared_error: 555.4844\n",
      "Epoch 427/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 193.2696 - mean_squared_error: 193.2696\n",
      "Epoch 00427: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 193.5758 - mean_squared_error: 193.5758 - val_loss: 536.8642 - val_mean_squared_error: 536.8642\n",
      "Epoch 428/500\n",
      "461/526 [=========================>....] - ETA: 0s - loss: 200.2497 - mean_squared_error: 200.2497\n",
      "Epoch 00428: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 813us/step - loss: 201.1160 - mean_squared_error: 201.1160 - val_loss: 541.9570 - val_mean_squared_error: 541.9570\n",
      "Epoch 429/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 193.6933 - mean_squared_error: 193.6933\n",
      "Epoch 00429: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 193.9186 - mean_squared_error: 193.9186 - val_loss: 530.0557 - val_mean_squared_error: 530.0557\n",
      "Epoch 430/500\n",
      "464/526 [=========================>....] - ETA: 0s - loss: 198.4765 - mean_squared_error: 198.4765\n",
      "Epoch 00430: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 807us/step - loss: 197.5480 - mean_squared_error: 197.5480 - val_loss: 550.5842 - val_mean_squared_error: 550.5842\n",
      "Epoch 431/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 194.9576 - mean_squared_error: 194.9576\n",
      "Epoch 00431: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 194.8705 - mean_squared_error: 194.8705 - val_loss: 522.2800 - val_mean_squared_error: 522.2800\n",
      "Epoch 432/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 194.9186 - mean_squared_error: 194.9186\n",
      "Epoch 00432: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 194.9658 - mean_squared_error: 194.9658 - val_loss: 560.2951 - val_mean_squared_error: 560.2951\n",
      "Epoch 433/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 196.2478 - mean_squared_error: 196.2478\n",
      "Epoch 00433: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 196.4585 - mean_squared_error: 196.4585 - val_loss: 552.9376 - val_mean_squared_error: 552.9376\n",
      "Epoch 434/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 194.8646 - mean_squared_error: 194.8646\n",
      "Epoch 00434: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 194.5827 - mean_squared_error: 194.5827 - val_loss: 553.3244 - val_mean_squared_error: 553.3244\n",
      "Epoch 435/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 196.7497 - mean_squared_error: 196.7497\n",
      "Epoch 00435: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 813us/step - loss: 196.7497 - mean_squared_error: 196.7497 - val_loss: 594.9063 - val_mean_squared_error: 594.9063\n",
      "Epoch 436/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 189.6825 - mean_squared_error: 189.6825\n",
      "Epoch 00436: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 813us/step - loss: 189.6825 - mean_squared_error: 189.6825 - val_loss: 542.3521 - val_mean_squared_error: 542.3521\n",
      "Epoch 437/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 198.1570 - mean_squared_error: 198.1570\n",
      "Epoch 00437: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 198.1570 - mean_squared_error: 198.1570 - val_loss: 530.4186 - val_mean_squared_error: 530.4186\n",
      "Epoch 438/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 194.9923 - mean_squared_error: 194.9923\n",
      "Epoch 00438: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 195.0872 - mean_squared_error: 195.0872 - val_loss: 528.0795 - val_mean_squared_error: 528.0795\n",
      "Epoch 439/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 199.0553 - mean_squared_error: 199.0553\n",
      "Epoch 00439: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 813us/step - loss: 199.0553 - mean_squared_error: 199.0553 - val_loss: 532.0027 - val_mean_squared_error: 532.0027\n",
      "Epoch 440/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 195.0014 - mean_squared_error: 195.0014\n",
      "Epoch 00440: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 194.9409 - mean_squared_error: 194.9409 - val_loss: 632.8867 - val_mean_squared_error: 632.8867\n",
      "Epoch 441/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 194.6808 - mean_squared_error: 194.6808\n",
      "Epoch 00441: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 194.8186 - mean_squared_error: 194.8186 - val_loss: 618.8638 - val_mean_squared_error: 618.8638\n",
      "Epoch 442/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 195.8887 - mean_squared_error: 195.8887\n",
      "Epoch 00442: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 826us/step - loss: 195.6755 - mean_squared_error: 195.6755 - val_loss: 600.8849 - val_mean_squared_error: 600.8849\n",
      "Epoch 443/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 191.8331 - mean_squared_error: 191.8331\n",
      "Epoch 00443: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 831us/step - loss: 191.6492 - mean_squared_error: 191.6492 - val_loss: 518.0110 - val_mean_squared_error: 518.0110\n",
      "Epoch 444/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 194.5552 - mean_squared_error: 194.5552\n",
      "Epoch 00444: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 817us/step - loss: 194.5552 - mean_squared_error: 194.5552 - val_loss: 529.2877 - val_mean_squared_error: 529.2877\n",
      "Epoch 445/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 193.5092 - mean_squared_error: 193.5092\n",
      "Epoch 00445: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 820us/step - loss: 193.7481 - mean_squared_error: 193.7481 - val_loss: 538.0863 - val_mean_squared_error: 538.0863\n",
      "Epoch 446/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 191.9336 - mean_squared_error: 191.9336\n",
      "Epoch 00446: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 191.8338 - mean_squared_error: 191.8338 - val_loss: 563.3328 - val_mean_squared_error: 563.3328\n",
      "Epoch 447/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 194.4613 - mean_squared_error: 194.4613\n",
      "Epoch 00447: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 813us/step - loss: 194.4613 - mean_squared_error: 194.4613 - val_loss: 658.4857 - val_mean_squared_error: 658.4857\n",
      "Epoch 448/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 190.2980 - mean_squared_error: 190.2980\n",
      "Epoch 00448: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 820us/step - loss: 190.1718 - mean_squared_error: 190.1718 - val_loss: 512.6528 - val_mean_squared_error: 512.6528\n",
      "Epoch 449/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521/526 [============================>.] - ETA: 0s - loss: 192.5316 - mean_squared_error: 192.5316\n",
      "Epoch 00449: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 822us/step - loss: 192.5150 - mean_squared_error: 192.5150 - val_loss: 551.8720 - val_mean_squared_error: 551.8720\n",
      "Epoch 450/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 193.3547 - mean_squared_error: 193.3547\n",
      "Epoch 00450: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 193.4746 - mean_squared_error: 193.4746 - val_loss: 522.2521 - val_mean_squared_error: 522.2521\n",
      "Epoch 451/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 194.4821 - mean_squared_error: 194.4821\n",
      "Epoch 00451: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 813us/step - loss: 194.4127 - mean_squared_error: 194.4127 - val_loss: 602.7739 - val_mean_squared_error: 602.7739\n",
      "Epoch 452/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 194.4408 - mean_squared_error: 194.4408\n",
      "Epoch 00452: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 194.3748 - mean_squared_error: 194.3748 - val_loss: 606.0999 - val_mean_squared_error: 606.0999\n",
      "Epoch 453/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 191.8271 - mean_squared_error: 191.8271\n",
      "Epoch 00453: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 191.8280 - mean_squared_error: 191.8280 - val_loss: 559.5060 - val_mean_squared_error: 559.5060\n",
      "Epoch 454/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 192.0852 - mean_squared_error: 192.0852\n",
      "Epoch 00454: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 192.0676 - mean_squared_error: 192.0676 - val_loss: 550.9932 - val_mean_squared_error: 550.9932\n",
      "Epoch 455/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 192.6985 - mean_squared_error: 192.6985\n",
      "Epoch 00455: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 192.7068 - mean_squared_error: 192.7068 - val_loss: 558.8833 - val_mean_squared_error: 558.8833\n",
      "Epoch 456/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 192.3257 - mean_squared_error: 192.3257\n",
      "Epoch 00456: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 192.3257 - mean_squared_error: 192.3257 - val_loss: 510.9608 - val_mean_squared_error: 510.9608\n",
      "Epoch 457/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 192.3110 - mean_squared_error: 192.3110\n",
      "Epoch 00457: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 820us/step - loss: 192.4742 - mean_squared_error: 192.4742 - val_loss: 568.7522 - val_mean_squared_error: 568.7522\n",
      "Epoch 458/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 194.9317 - mean_squared_error: 194.9317\n",
      "Epoch 00458: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 194.7026 - mean_squared_error: 194.7026 - val_loss: 546.2320 - val_mean_squared_error: 546.2320\n",
      "Epoch 459/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 192.7930 - mean_squared_error: 192.7930\n",
      "Epoch 00459: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 192.6718 - mean_squared_error: 192.6718 - val_loss: 572.5112 - val_mean_squared_error: 572.5112\n",
      "Epoch 460/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 189.9181 - mean_squared_error: 189.9181\n",
      "Epoch 00460: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 822us/step - loss: 190.0777 - mean_squared_error: 190.0777 - val_loss: 521.4386 - val_mean_squared_error: 521.4386\n",
      "Epoch 461/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 194.5316 - mean_squared_error: 194.5316\n",
      "Epoch 00461: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 194.5164 - mean_squared_error: 194.5164 - val_loss: 586.1956 - val_mean_squared_error: 586.1956\n",
      "Epoch 462/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 190.8384 - mean_squared_error: 190.8384\n",
      "Epoch 00462: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 190.8065 - mean_squared_error: 190.8065 - val_loss: 500.2417 - val_mean_squared_error: 500.2417\n",
      "Epoch 463/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 190.5625 - mean_squared_error: 190.5625\n",
      "Epoch 00463: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 819us/step - loss: 190.6426 - mean_squared_error: 190.6426 - val_loss: 553.5690 - val_mean_squared_error: 553.5690\n",
      "Epoch 464/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 191.9832 - mean_squared_error: 191.9832\n",
      "Epoch 00464: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 837us/step - loss: 191.3587 - mean_squared_error: 191.3587 - val_loss: 605.0454 - val_mean_squared_error: 605.0454\n",
      "Epoch 465/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 192.5982 - mean_squared_error: 192.5982\n",
      "Epoch 00465: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 192.6057 - mean_squared_error: 192.6057 - val_loss: 615.2206 - val_mean_squared_error: 615.2206\n",
      "Epoch 466/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 193.1467 - mean_squared_error: 193.1467\n",
      "Epoch 00466: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 823us/step - loss: 193.8311 - mean_squared_error: 193.8311 - val_loss: 521.1356 - val_mean_squared_error: 521.1356\n",
      "Epoch 467/500\n",
      "511/526 [============================>.] - ETA: 0s - loss: 193.2845 - mean_squared_error: 193.2845\n",
      "Epoch 00467: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 836us/step - loss: 193.0177 - mean_squared_error: 193.0177 - val_loss: 525.2612 - val_mean_squared_error: 525.2612\n",
      "Epoch 468/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 191.2105 - mean_squared_error: 191.2105\n",
      "Epoch 00468: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 813us/step - loss: 191.2105 - mean_squared_error: 191.2105 - val_loss: 559.8447 - val_mean_squared_error: 559.8447\n",
      "Epoch 469/500\n",
      "516/526 [============================>.] - ETA: 0s - loss: 191.5690 - mean_squared_error: 191.5690\n",
      "Epoch 00469: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 828us/step - loss: 191.6613 - mean_squared_error: 191.6613 - val_loss: 544.5790 - val_mean_squared_error: 544.5790\n",
      "Epoch 470/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 191.1879 - mean_squared_error: 191.1879\n",
      "Epoch 00470: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 191.3566 - mean_squared_error: 191.3566 - val_loss: 493.0254 - val_mean_squared_error: 493.0254\n",
      "Epoch 471/500\n",
      "519/526 [============================>.] - ETA: 0s - loss: 189.7040 - mean_squared_error: 189.7040\n",
      "Epoch 00471: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 824us/step - loss: 189.9824 - mean_squared_error: 189.9824 - val_loss: 516.7378 - val_mean_squared_error: 516.7378\n",
      "Epoch 472/500\n",
      "521/526 [============================>.] - ETA: 0s - loss: 188.6305 - mean_squared_error: 188.6305\n",
      "Epoch 00472: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 820us/step - loss: 188.6471 - mean_squared_error: 188.6471 - val_loss: 513.6763 - val_mean_squared_error: 513.6763\n",
      "Epoch 473/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 193.2874 - mean_squared_error: 193.2874\n",
      "Epoch 00473: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 193.4183 - mean_squared_error: 193.4183 - val_loss: 560.2789 - val_mean_squared_error: 560.2789\n",
      "Epoch 474/500\n",
      "461/526 [=========================>....] - ETA: 0s - loss: 194.9441 - mean_squared_error: 194.9441\n",
      "Epoch 00474: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 811us/step - loss: 193.6309 - mean_squared_error: 193.6309 - val_loss: 486.6064 - val_mean_squared_error: 486.6064\n",
      "Epoch 475/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 190.8094 - mean_squared_error: 190.8094\n",
      "Epoch 00475: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 190.7190 - mean_squared_error: 190.7190 - val_loss: 530.0439 - val_mean_squared_error: 530.0439\n",
      "Epoch 476/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 188.1742 - mean_squared_error: 188.1742\n",
      "Epoch 00476: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 188.1680 - mean_squared_error: 188.1680 - val_loss: 560.2156 - val_mean_squared_error: 560.2156\n",
      "Epoch 477/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 189.8145 - mean_squared_error: 189.8145\n",
      "Epoch 00477: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 189.7153 - mean_squared_error: 189.7153 - val_loss: 560.8412 - val_mean_squared_error: 560.8412\n",
      "Epoch 478/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 188.5974 - mean_squared_error: 188.5974\n",
      "Epoch 00478: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 188.3148 - mean_squared_error: 188.3148 - val_loss: 533.6336 - val_mean_squared_error: 533.6336\n",
      "Epoch 479/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 193.4255 - mean_squared_error: 193.4255\n",
      "Epoch 00479: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 193.4255 - mean_squared_error: 193.4255 - val_loss: 601.7601 - val_mean_squared_error: 601.7601\n",
      "Epoch 480/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 190.0305 - mean_squared_error: 190.0305\n",
      "Epoch 00480: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 189.9890 - mean_squared_error: 189.9890 - val_loss: 538.7778 - val_mean_squared_error: 538.7778\n",
      "Epoch 481/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 190.3354 - mean_squared_error: 190.3354\n",
      "Epoch 00481: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 190.6075 - mean_squared_error: 190.6075 - val_loss: 530.2809 - val_mean_squared_error: 530.2809\n",
      "Epoch 482/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 190.2718 - mean_squared_error: 190.2718\n",
      "Epoch 00482: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 822us/step - loss: 190.1341 - mean_squared_error: 190.1341 - val_loss: 536.4228 - val_mean_squared_error: 536.4228\n",
      "Epoch 483/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 191.8329 - mean_squared_error: 191.8329\n",
      "Epoch 00483: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 191.7439 - mean_squared_error: 191.7439 - val_loss: 582.7020 - val_mean_squared_error: 582.7020\n",
      "Epoch 484/500\n",
      "520/526 [============================>.] - ETA: 0s - loss: 194.0682 - mean_squared_error: 194.0682\n",
      "Epoch 00484: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 822us/step - loss: 193.8736 - mean_squared_error: 193.8736 - val_loss: 509.9404 - val_mean_squared_error: 509.9404\n",
      "Epoch 485/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 190.0152 - mean_squared_error: 190.0152\n",
      "Epoch 00485: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 819us/step - loss: 189.7189 - mean_squared_error: 189.7189 - val_loss: 510.4584 - val_mean_squared_error: 510.4584\n",
      "Epoch 486/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 190.1509 - mean_squared_error: 190.1509\n",
      "Epoch 00486: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 190.1444 - mean_squared_error: 190.1444 - val_loss: 582.3296 - val_mean_squared_error: 582.3296\n",
      "Epoch 487/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 191.3598 - mean_squared_error: 191.3598\n",
      "Epoch 00487: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 821us/step - loss: 191.2596 - mean_squared_error: 191.2596 - val_loss: 578.4282 - val_mean_squared_error: 578.4282\n",
      "Epoch 488/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 190.4587 - mean_squared_error: 190.4587\n",
      "Epoch 00488: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 820us/step - loss: 190.5122 - mean_squared_error: 190.5122 - val_loss: 532.7339 - val_mean_squared_error: 532.7339\n",
      "Epoch 489/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 191.2511 - mean_squared_error: 191.2511\n",
      "Epoch 00489: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 821us/step - loss: 191.2627 - mean_squared_error: 191.2627 - val_loss: 555.2434 - val_mean_squared_error: 555.2434\n",
      "Epoch 490/500\n",
      "461/526 [=========================>....] - ETA: 0s - loss: 189.9145 - mean_squared_error: 189.9145\n",
      "Epoch 00490: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 190.2094 - mean_squared_error: 190.2094 - val_loss: 597.2947 - val_mean_squared_error: 597.2947\n",
      "Epoch 491/500\n",
      "524/526 [============================>.] - ETA: 0s - loss: 187.9304 - mean_squared_error: 187.9304\n",
      "Epoch 00491: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 821us/step - loss: 187.8396 - mean_squared_error: 187.8396 - val_loss: 589.7425 - val_mean_squared_error: 589.7425\n",
      "Epoch 492/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 191.1813 - mean_squared_error: 191.1813\n",
      "Epoch 00492: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 823us/step - loss: 190.8214 - mean_squared_error: 190.8214 - val_loss: 575.3119 - val_mean_squared_error: 575.3119\n",
      "Epoch 493/500\n",
      "522/526 [============================>.] - ETA: 0s - loss: 190.2099 - mean_squared_error: 190.2099\n",
      "Epoch 00493: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 189.9449 - mean_squared_error: 189.9449 - val_loss: 469.3249 - val_mean_squared_error: 469.3249\n",
      "Epoch 494/500\n",
      "518/526 [============================>.] - ETA: 0s - loss: 187.3939 - mean_squared_error: 187.3939\n",
      "Epoch 00494: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 826us/step - loss: 187.3203 - mean_squared_error: 187.3203 - val_loss: 566.0394 - val_mean_squared_error: 566.0394\n",
      "Epoch 495/500\n",
      "462/526 [=========================>....] - ETA: 0s - loss: 189.3043 - mean_squared_error: 189.3043\n",
      "Epoch 00495: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 811us/step - loss: 191.2822 - mean_squared_error: 191.2822 - val_loss: 622.1431 - val_mean_squared_error: 622.1431\n",
      "Epoch 496/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 190.2146 - mean_squared_error: 190.2146\n",
      "Epoch 00496: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 816us/step - loss: 190.2146 - mean_squared_error: 190.2146 - val_loss: 524.3727 - val_mean_squared_error: 524.3727\n",
      "Epoch 497/500\n",
      "525/526 [============================>.] - ETA: 0s - loss: 189.3712 - mean_squared_error: 189.3712\n",
      "Epoch 00497: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 189.2133 - mean_squared_error: 189.2133 - val_loss: 528.1201 - val_mean_squared_error: 528.1201\n",
      "Epoch 498/500\n",
      "523/526 [============================>.] - ETA: 0s - loss: 186.8610 - mean_squared_error: 186.8610\n",
      "Epoch 00498: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 818us/step - loss: 186.9971 - mean_squared_error: 186.9971 - val_loss: 570.0316 - val_mean_squared_error: 570.0316\n",
      "Epoch 499/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525/526 [============================>.] - ETA: 0s - loss: 190.4272 - mean_squared_error: 190.4272\n",
      "Epoch 00499: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 814us/step - loss: 190.4469 - mean_squared_error: 190.4469 - val_loss: 511.3651 - val_mean_squared_error: 511.3651\n",
      "Epoch 500/500\n",
      "526/526 [==============================] - ETA: 0s - loss: 190.9642 - mean_squared_error: 190.9642\n",
      "Epoch 00500: val_loss did not improve from 413.63632\n",
      "526/526 [==============================] - 0s 813us/step - loss: 190.9642 - mean_squared_error: 190.9642 - val_loss: 510.3230 - val_mean_squared_error: 510.3230\n"
     ]
    }
   ],
   "source": [
    "model6 = models.Sequential()\n",
    "model6.add(layers.Dense(256,activation=\"relu\",input_dim=81))\n",
    "model6.add(layers.Dropout(0.3))\n",
    "model6.add(layers.Dense(128,activation=\"relu\"))\n",
    "model6.add(layers.Dropout(0.3))\n",
    "model6.add(layers.Dense(128,activation=\"relu\"))\n",
    "model6.add(layers.Dense(1))\n",
    "model6.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    loss = losses.mean_squared_error,\n",
    "    metrics = ['mean_squared_error']\n",
    ")\n",
    "file_path = \"model6.hdf5\"\n",
    "checkpoint = ModelCheckpoint(file_path,monitor='val_loss', verbose=1,\n",
    "                             save_best_only=True,period=1)\n",
    "train_history6 = model6.fit(x_train,y_train,epochs=500,batch_size = 32,\n",
    "                            validation_data = (x_val,y_val),callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5410d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1 best val mse:123.40611267089844\n",
      "model2 best val mse:211.79542541503906\n",
      "model3 best val mse:153.5111846923828\n",
      "model4 best val mse:118.9293441772461\n",
      "model5 best val mse:135.5955352783203\n",
      "model6 best val mse:413.6363220214844\n"
     ]
    }
   ],
   "source": [
    "print(\"model1 best val mse:{}\".format(min(train_history1.history['val_loss'])))\n",
    "print(\"model2 best val mse:{}\".format(min(train_history2.history['val_loss'])))\n",
    "print(\"model3 best val mse:{}\".format(min(train_history3.history['val_loss'])))\n",
    "print(\"model4 best val mse:{}\".format(min(train_history4.history['val_loss'])))\n",
    "print(\"model5 best val mse:{}\".format(min(train_history5.history['val_loss'])))\n",
    "print(\"model6 best val mse:{}\".format(min(train_history6.history['val_loss'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8fc574",
   "metadata": {},
   "source": [
    "#### Part b\n",
    "As we can see, the best model here is model4 which is 3 hidden layers with l2 norm.\n",
    "We load the best model, predict for test set and get the test mse is \n",
    "136.88799634697085."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10ab91ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136.88799634697085\n"
     ]
    }
   ],
   "source": [
    "best_model = models.load_model(\"model4.hdf5\")\n",
    "y_hat_test = best_model.predict(x_test)\n",
    "print(mean_squared_error(y_hat_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a47f01c",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "We will upload the script we run in cluster,\n",
    "we will also run that code here with local pyspark\n",
    "(but no hadoop, and a little bit change in the code) here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26140696",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_home = \"F:\\spark-3.1.2-bin-hadoop3.2\"\n",
    "python_path = \"E:\\python\\python.exe\"\n",
    "findspark.init(spark_home,python_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb25aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_key = pd.read_csv(\"stats507/user_key.csv\")\n",
    "tran = pd.read_csv(\"stats507/triangles.csv\")\n",
    "rect = pd.read_csv(\"stats507/rectangles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "998bf18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('ps8_qs2') \\\n",
    "    .getOrCreate()\n",
    "tran_res = {}\n",
    "rect_res = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5254bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_key = spark.createDataFrame(user_key)\n",
    "user_key = user_key.filter(user_key.user == \"tiejin\")\n",
    "tran = spark.createDataFrame(tran)\n",
    "rect = spark.createDataFrame(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c2a2d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tran = user_key.join(tran,user_key.key==tran.key,'left')\n",
    "my_rect = user_key.join(rect,user_key.key==rect.key,'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3e07fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tran_area =my_tran.withColumn(\"area\",my_tran['base']*my_tran['height']*0.5)\n",
    "my_rect_area =my_rect.withColumn(\"area\",my_rect['width']*my_rect['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac64d6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tran = my_tran_area.select(mean('area')).first()[0]\n",
    "mean_rect = my_rect_area.select(mean('area')).first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab454aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tran = my_tran_area.select('area').rdd.map(lambda x:x[0]).reduce(lambda x,y:x+y)\n",
    "total_rect = my_rect_area.select('area').rdd.map(lambda x:x[0]).reduce(lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2d1b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_res['number'] = my_tran_area.select('area').rdd.count()\n",
    "tran_res['total areas'] = total_tran\n",
    "tran_res['mean areas'] = mean_tran\n",
    "rect_res['number'] = my_rect_area.select('area').rdd.count()\n",
    "rect_res['total areas'] = total_rect\n",
    "rect_res['mean areas'] = mean_rect\n",
    "\n",
    "final_dict = {\"triangles\":tran_res,\n",
    "              \"rectangles\":rect_res}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "311363b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(final_dict)\n",
    "final_df.to_csv(\"ps8_q2_tiejin_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c493f25c",
   "metadata": {},
   "source": [
    "After all the code finish, we can get the csv file, and we read it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6251c70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ps8_q2_tiejin_results.csv\",index_col=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de2245dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['number'] = df['number'].astype(\"int\")\n",
    "df['total areas'] = df['total areas'].apply(lambda x:round(x,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "512422c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>total areas</th>\n",
       "      <th>mean areas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>triangles</th>\n",
       "      <td>5937</td>\n",
       "      <td>23707233.14</td>\n",
       "      <td>3993.133424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rectangles</th>\n",
       "      <td>6087</td>\n",
       "      <td>12590875.40</td>\n",
       "      <td>2068.486183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            number  total areas   mean areas\n",
       "triangles     5937  23707233.14  3993.133424\n",
       "rectangles    6087  12590875.40  2068.486183"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22e220a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea1062b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,auto:light",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
